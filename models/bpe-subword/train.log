2024-05-28 12:37:21,671 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2024-05-28 12:37:21,671 - INFO - joeynmt.helpers -                           cfg.name : transformer_bpe-subword_config
2024-05-28 12:37:21,671 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2024-05-28 12:37:21,671 - INFO - joeynmt.helpers -                     cfg.data.train : data/sub_train.ro-en
2024-05-28 12:37:21,672 - INFO - joeynmt.helpers -                       cfg.data.dev : data/dev.ro-en
2024-05-28 12:37:21,672 - INFO - joeynmt.helpers -                      cfg.data.test : data/test.ro-en
2024-05-28 12:37:21,672 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2024-05-28 12:37:21,672 - INFO - joeynmt.helpers -                  cfg.data.src.lang : ro
2024-05-28 12:37:21,672 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2024-05-28 12:37:21,672 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2024-05-28 12:37:21,672 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2024-05-28 12:37:21,672 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : data/vocab_clean.bpe
2024-05-28 12:37:21,672 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt
2024-05-28 12:37:21,672 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : data/bpe.codes
2024-05-28 12:37:21,672 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : en
2024-05-28 12:37:21,672 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2024-05-28 12:37:21,672 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2024-05-28 12:37:21,672 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2024-05-28 12:37:21,672 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : data/vocab_clean.bpe
2024-05-28 12:37:21,672 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt
2024-05-28 12:37:21,672 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : data/bpe.codes
2024-05-28 12:37:21,672 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2024-05-28 12:37:21,672 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2024-05-28 12:37:21,672 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2024-05-28 12:37:21,673 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2024-05-28 12:37:21,673 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2024-05-28 12:37:21,673 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2024-05-28 12:37:21,673 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2024-05-28 12:37:21,673 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2024-05-28 12:37:21,673 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2024-05-28 12:37:21,673 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2024-05-28 12:37:21,673 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2024-05-28 12:37:21,673 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2024-05-28 12:37:21,673 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2024-05-28 12:37:21,673 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2024-05-28 12:37:21,673 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2024-05-28 12:37:21,673 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2024-05-28 12:37:21,673 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2024-05-28 12:37:21,673 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2024-05-28 12:37:21,673 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2024-05-28 12:37:21,673 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/bpe-subword
2024-05-28 12:37:21,673 - INFO - joeynmt.helpers -             cfg.training.overwrite : False
2024-05-28 12:37:21,673 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2024-05-28 12:37:21,673 - INFO - joeynmt.helpers -              cfg.training.use_cuda : True
2024-05-28 12:37:21,673 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2024-05-28 12:37:21,674 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2024-05-28 12:37:21,674 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2024-05-28 12:37:21,674 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2024-05-28 12:37:21,674 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2024-05-28 12:37:21,674 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2024-05-28 12:37:21,674 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2024-05-28 12:37:21,674 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2024-05-28 12:37:21,674 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : True
2024-05-28 12:37:21,674 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2024-05-28 12:37:21,674 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2024-05-28 12:37:21,674 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2024-05-28 12:37:21,674 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2024-05-28 12:37:21,674 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2024-05-28 12:37:21,674 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2024-05-28 12:37:21,674 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2024-05-28 12:37:21,674 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2024-05-28 12:37:21,674 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2024-05-28 12:37:21,674 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2024-05-28 12:37:21,674 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2024-05-28 12:37:21,674 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2024-05-28 12:37:21,675 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2024-05-28 12:37:21,675 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2024-05-28 12:37:21,675 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2024-05-28 12:37:21,675 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2024-05-28 12:37:21,675 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2024-05-28 12:37:21,675 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2024-05-28 12:37:21,675 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2024-05-28 12:37:21,965 - INFO - joeynmt.data - Building tokenizer...
2024-05-28 12:37:21,973 - INFO - joeynmt.tokenizers - ro tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2024-05-28 12:37:21,973 - INFO - joeynmt.tokenizers - en tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2024-05-28 12:37:21,973 - INFO - joeynmt.data - Loading train set...
2024-05-28 12:37:22,313 - INFO - joeynmt.data - Building vocabulary...
2024-05-28 12:37:22,473 - INFO - joeynmt.data - Loading dev set...
2024-05-28 12:37:22,560 - INFO - joeynmt.data - Loading test set...
2024-05-28 12:37:22,613 - INFO - joeynmt.data - Data loaded.
2024-05-28 12:37:22,613 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=100000, src_lang=ro, trg_lang=en, has_trg=True, random_subset=-1)
2024-05-28 12:37:22,613 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=914, src_lang=ro, trg_lang=en, has_trg=True, random_subset=-1)
2024-05-28 12:37:22,613 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1678, src_lang=ro, trg_lang=en, has_trg=True, random_subset=-1)
2024-05-28 12:37:22,613 - INFO - joeynmt.data - First training example:
	[SRC] A@@ t@@ unc@@ i, pentru voi vis@@ ul e@@ ...
	[TRG] F@@ or you@@ , the dre@@ am here then is that --
2024-05-28 12:37:22,613 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) a (5) the (6) de (7) to (8) and (9) of
2024-05-28 12:37:22,614 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) a (5) the (6) de (7) to (8) and (9) of
2024-05-28 12:37:22,614 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 2002
2024-05-28 12:37:22,614 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 2002
2024-05-28 12:37:22,615 - INFO - joeynmt.model - Building an encoder-decoder model...
2024-05-28 12:37:22,849 - INFO - joeynmt.model - Enc-dec model built.
2024-05-28 12:37:22,853 - INFO - joeynmt.model - Total params: 3411712
2024-05-28 12:37:22,854 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight']
2024-05-28 12:37:22,854 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2002),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2002),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2024-05-28 12:37:23,643 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2024-05-28 12:37:23,643 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, verbose=False, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2024-05-28 12:37:23,644 - INFO - joeynmt.training - Train stats:
	device: cuda
	n_gpu: 1
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2024-05-28 12:37:23,644 - INFO - joeynmt.training - EPOCH 1
2024-05-28 12:37:28,029 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     3.978675, Batch Acc: 0.038938, Tokens per Sec:    16303, Lr: 0.000300
2024-05-28 12:37:31,426 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     3.902120, Batch Acc: 0.062786, Tokens per Sec:    21061, Lr: 0.000300
2024-05-28 12:37:34,777 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     3.532811, Batch Acc: 0.083141, Tokens per Sec:    20578, Lr: 0.000300
2024-05-28 12:37:38,156 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     3.487997, Batch Acc: 0.104365, Tokens per Sec:    21178, Lr: 0.000300
2024-05-28 12:37:41,747 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     3.277332, Batch Acc: 0.127359, Tokens per Sec:    19409, Lr: 0.000300
2024-05-28 12:37:41,748 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:37:41,748 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:37:53,903 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.31, ppl:  27.26, acc:   0.13, generation: 12.1140[sec], evaluation: 0.0000[sec]
2024-05-28 12:37:53,903 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:37:53,993 - INFO - joeynmt.training - Example #0
2024-05-28 12:37:53,993 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:37:53,993 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:37:53,993 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'think', 'of', 'the', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'and', 'the', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@']
2024-05-28 12:37:53,994 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:37:53,994 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:37:53,994 - INFO - joeynmt.training - 	Hypothesis: And I think of the same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same and the fffffffffffffffffffffffffffffffff
2024-05-28 12:37:53,994 - INFO - joeynmt.training - Example #1
2024-05-28 12:37:53,994 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:37:53,994 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:37:53,994 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'think', 'of', 'the', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 's@@', 's@@', 's@@', 's@@', 's@@', 's@@', 's@@', 's@@', 's@@', 's@@', '?', '</s>']
2024-05-28 12:37:53,995 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:37:53,995 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:37:53,995 - INFO - joeynmt.training - 	Hypothesis: And I think of the same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same ssssssssss?
2024-05-28 12:37:53,995 - INFO - joeynmt.training - Example #2
2024-05-28 12:37:53,995 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:37:53,995 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:37:53,995 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'think', 'of', 'the', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 's@@', 's@@', 's@@', 's@@', 's@@', 's@@', 's@@', 's@@', 's@@', 's@@', '?', '</s>']
2024-05-28 12:37:53,995 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:37:53,995 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:37:53,995 - INFO - joeynmt.training - 	Hypothesis: And I think of the same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same ssssssssss?
2024-05-28 12:37:53,995 - INFO - joeynmt.training - Example #3
2024-05-28 12:37:53,996 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:37:53,996 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:37:53,996 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'think', 'of', 'the', 'f@@', 'f@@', 'f@@', 'is@@', 'is@@', 'is@@', 'is@@', 'is@@', 'is@@', 'is@@', 'is@@', 'is@@', 'is@@', 'is@@', 'is@@', 'is@@', 'is@@', 'is@@', 'is@@', 'is@@', 'is@@', 'is@@', 'is@@', 'is@@', 'is@@', '.', '</s>']
2024-05-28 12:37:53,996 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:37:53,996 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:37:53,996 - INFO - joeynmt.training - 	Hypothesis: And I think of the fffisisisisisisisisisisisisisisisisisisisisisis.
2024-05-28 12:37:53,996 - INFO - joeynmt.training - Example #4
2024-05-28 12:37:53,996 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:37:53,996 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:37:53,996 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'think', 'of', 'the', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'of', 'the', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@']
2024-05-28 12:37:53,997 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:37:53,997 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:37:53,997 - INFO - joeynmt.training - 	Hypothesis: And I think of the same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same same of the bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb
2024-05-28 12:37:57,531 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     3.165094, Batch Acc: 0.144162, Tokens per Sec:    19616, Lr: 0.000300
2024-05-28 12:38:01,283 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     3.179616, Batch Acc: 0.156028, Tokens per Sec:    18838, Lr: 0.000300
2024-05-28 12:38:05,290 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     3.178479, Batch Acc: 0.165668, Tokens per Sec:    17831, Lr: 0.000300
2024-05-28 12:38:09,525 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     3.085860, Batch Acc: 0.171595, Tokens per Sec:    16533, Lr: 0.000300
2024-05-28 12:38:13,651 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     2.957979, Batch Acc: 0.171766, Tokens per Sec:    17223, Lr: 0.000300
2024-05-28 12:38:13,651 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:38:13,651 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:38:51,173 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.01, ppl:  20.27, acc:   0.18, generation: 37.5021[sec], evaluation: 0.0000[sec]
2024-05-28 12:38:51,174 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:38:51,245 - INFO - joeynmt.training - Example #0
2024-05-28 12:38:51,246 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:38:51,246 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:38:51,246 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'a', 'lot', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'same', 'of', 'the', 'first', 'of', 'the', 'st@@', 'or@@', 'or@@', 't@@', 't@@', 't@@', 't@@', 's,', 'and', 'the', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 's', 'of', 'the', 'first', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'st@@', 'or@@', 't@@', 't@@', 't@@', 't@@', 't@@', 't@@', 't@@', 't@@', 't@@', 't@@', 't@@', 't@@', 't@@', 't@@', 's.', '</s>']
2024-05-28 12:38:51,246 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:38:51,246 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:38:51,246 - INFO - joeynmt.training - 	Hypothesis: And I was a lot of the first of the first of the first of the first of the first of the first of the first of the first of the first of the same of the first of the storortttts, and the ppppppppppppppppppps of the first first of the first of the first of the first of the stortttttttttttttts.
2024-05-28 12:38:51,246 - INFO - joeynmt.training - Example #1
2024-05-28 12:38:51,247 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:38:51,247 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:38:51,247 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'think', 'that', 'we', 'can', 'see', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'st@@', 'or@@', 'y.', '</s>']
2024-05-28 12:38:51,247 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:38:51,247 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:38:51,247 - INFO - joeynmt.training - 	Hypothesis: And I think that we can see the first of the first of the first of the first of the first of the first of the first of the first of the first of the story.
2024-05-28 12:38:51,247 - INFO - joeynmt.training - Example #2
2024-05-28 12:38:51,247 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:38:51,247 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:38:51,247 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'same', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'worl@@', 'd.', '</s>']
2024-05-28 12:38:51,248 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:38:51,248 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:38:51,248 - INFO - joeynmt.training - 	Hypothesis: And the first of the first of the first of the same of the first of the first of the first of the world.
2024-05-28 12:38:51,248 - INFO - joeynmt.training - Example #3
2024-05-28 12:38:51,248 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:38:51,248 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:38:51,248 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'a', 'lot', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'worl@@', 'd.', '</s>']
2024-05-28 12:38:51,249 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:38:51,249 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:38:51,249 - INFO - joeynmt.training - 	Hypothesis: And I was a lot of the first of the first of the world.
2024-05-28 12:38:51,249 - INFO - joeynmt.training - Example #4
2024-05-28 12:38:51,249 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:38:51,249 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:38:51,249 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'a', 'lot', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'st@@', 're@@', 're@@', 're@@', 're@@', 're@@', 're@@', 're@@', 're@@', 'd.', '</s>']
2024-05-28 12:38:51,249 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:38:51,249 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:38:51,249 - INFO - joeynmt.training - 	Hypothesis: And I was a lot of the first of the first of the first of the first of the first of the first of the first of the first of the first of the strererererererered.
2024-05-28 12:38:55,398 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     3.017182, Batch Acc: 0.176532, Tokens per Sec:    16910, Lr: 0.000300
2024-05-28 12:38:58,999 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     2.860297, Batch Acc: 0.183237, Tokens per Sec:    19528, Lr: 0.000300
2024-05-28 12:39:02,512 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     2.778704, Batch Acc: 0.186408, Tokens per Sec:    19533, Lr: 0.000300
2024-05-28 12:39:06,128 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     2.863560, Batch Acc: 0.186218, Tokens per Sec:    19586, Lr: 0.000300
2024-05-28 12:39:09,687 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     2.863643, Batch Acc: 0.189756, Tokens per Sec:    20036, Lr: 0.000300
2024-05-28 12:39:09,687 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:39:09,687 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:39:15,070 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.89, ppl:  17.96, acc:   0.19, generation: 5.3701[sec], evaluation: 0.0000[sec]
2024-05-28 12:39:15,071 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:39:15,140 - INFO - joeynmt.training - Example #0
2024-05-28 12:39:15,140 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:39:15,140 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:39:15,140 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'of', 'the', 'p@@', 'ast', 'of', 'the', 'p@@', 'ast', 'of', 'the', 'p@@', 'ast', 'of', 'the', 'p@@', 'ho@@', 'to@@', 'p', 'of', 'the', 'p@@', 'ho@@', 'to@@', 'p', 'of', 'the', 'p@@', 'ho@@', 'to@@', 'p', 'of', 'the', 'p@@', 'ho@@', 'to@@', 'p', 'of', 'the', 'p@@', 'ho@@', 'to@@', 'p', 'of', 'the', 'p@@', 'ho@@', 'to@@', 'grap@@', 'h@@', '.', '</s>']
2024-05-28 12:39:15,141 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:39:15,141 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:39:15,141 - INFO - joeynmt.training - 	Hypothesis: And the first of the past of the past of the past of the photop of the photop of the photop of the photop of the photop of the photograph.
2024-05-28 12:39:15,141 - INFO - joeynmt.training - Example #1
2024-05-28 12:39:15,141 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:39:15,141 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:39:15,141 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'of', 'the', 'same', 'thing', 'is', 'that', 'we', 'have', 'a', 'lot', 'of', 'the', 'p@@', 'ho@@', 'to@@', 'grap@@', 'h@@', '.', '</s>']
2024-05-28 12:39:15,141 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:39:15,141 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:39:15,141 - INFO - joeynmt.training - 	Hypothesis: And the first of the same thing is that we have a lot of the photograph.
2024-05-28 12:39:15,141 - INFO - joeynmt.training - Example #2
2024-05-28 12:39:15,142 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:39:15,142 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:39:15,142 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'of', 'the', 'p@@', 'ast', 'of', 'the', 'p@@', 'ho@@', 'to@@', 'p', 'of', 'the', 'p@@', 'ho@@', 'to@@', 'to@@', '.', '</s>']
2024-05-28 12:39:15,142 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:39:15,142 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:39:15,142 - INFO - joeynmt.training - 	Hypothesis: And the first of the past of the photop of the phototo.
2024-05-28 12:39:15,142 - INFO - joeynmt.training - Example #3
2024-05-28 12:39:15,142 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:39:15,142 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:39:15,142 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'same', 'thing', 'is', 'the', 'same', 'thing', 'is', 'the', 'p@@', 'ho@@', 'to@@', '.', '</s>']
2024-05-28 12:39:15,143 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:39:15,143 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:39:15,143 - INFO - joeynmt.training - 	Hypothesis: And the same thing is the same thing is the photo.
2024-05-28 12:39:15,143 - INFO - joeynmt.training - Example #4
2024-05-28 12:39:15,143 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:39:15,143 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:39:15,143 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'think', 'of', 'the', 'same', 'thing', 'is', 'that', 'we', 'have', 'a', 'lot', 'of', 'the', 'p@@', 'ho@@', 'to@@', 'p', 'of', 'the', 'worl@@', 'd.', '</s>']
2024-05-28 12:39:15,144 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:39:15,144 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:39:15,144 - INFO - joeynmt.training - 	Hypothesis: And I think of the same thing is that we have a lot of the photop of the world.
2024-05-28 12:39:18,623 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     2.754782, Batch Acc: 0.194092, Tokens per Sec:    20412, Lr: 0.000300
2024-05-28 12:39:22,169 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     2.751160, Batch Acc: 0.197662, Tokens per Sec:    20219, Lr: 0.000300
2024-05-28 12:39:26,015 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     2.991822, Batch Acc: 0.202168, Tokens per Sec:    18928, Lr: 0.000300
2024-05-28 12:39:29,278 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     2.797442, Batch Acc: 0.204597, Tokens per Sec:    21922, Lr: 0.000300
2024-05-28 12:39:32,986 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     2.809522, Batch Acc: 0.207349, Tokens per Sec:    19343, Lr: 0.000300
2024-05-28 12:39:32,986 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:39:32,986 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:39:43,034 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.80, ppl:  16.44, acc:   0.21, generation: 10.0334[sec], evaluation: 0.0000[sec]
2024-05-28 12:39:43,035 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:39:43,104 - INFO - joeynmt.training - Example #0
2024-05-28 12:39:43,104 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:39:43,104 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:39:43,105 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'thing', 'that', 'we', 'are', 'a', 'b@@', 'ea@@', 'u@@', 'ti@@', 'ful', 'and', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'ar@@', 'ri@@', 'st@@', 's', 'and', 'the', 'b@@', 'ut@@', 'ure', 'of', 'the', 'b@@', 'ro@@', 'om', 'and', 'the', 'st@@', 'o@@', 'ver@@', '.', '</s>']
2024-05-28 12:39:43,105 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:39:43,105 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:39:43,105 - INFO - joeynmt.training - 	Hypothesis: And the first thing that we are a beautiful and the best of the best of the best of the best of the best of the best of the best of the best of the barrists and the buture of the broom and the stover.
2024-05-28 12:39:43,105 - INFO - joeynmt.training - Example #1
2024-05-28 12:39:43,105 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:39:43,105 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:39:43,105 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'same', 'thing', 'that', 'we', 'are', 'a', 'lot', 'of', 'the', 'b@@', 'est', 'of', 'the', 'worl@@', 'd,', 'and', 'we', 'can', 'do', 'it', 'to', 'the', 'worl@@', 'd.', '</s>']
2024-05-28 12:39:43,106 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:39:43,106 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:39:43,106 - INFO - joeynmt.training - 	Hypothesis: And the same thing that we are a lot of the best of the world, and we can do it to the world.
2024-05-28 12:39:43,106 - INFO - joeynmt.training - Example #2
2024-05-28 12:39:43,106 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:39:43,106 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:39:43,106 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'thing', 'is', 'a', 'lot', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'worl@@', 'd.', '</s>']
2024-05-28 12:39:43,107 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:39:43,107 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:39:43,107 - INFO - joeynmt.training - 	Hypothesis: And the first thing is a lot of the best of the best of the world.
2024-05-28 12:39:43,107 - INFO - joeynmt.training - Example #3
2024-05-28 12:39:43,107 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:39:43,107 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:39:43,107 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'same', 'thing', 'that', 'we', 'are', 'a', 'lot', 'of', 'the', 'worl@@', 'd.', '</s>']
2024-05-28 12:39:43,107 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:39:43,107 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:39:43,108 - INFO - joeynmt.training - 	Hypothesis: And the same thing that we are a lot of the world.
2024-05-28 12:39:43,108 - INFO - joeynmt.training - Example #4
2024-05-28 12:39:43,108 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:39:43,108 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:39:43,108 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'a', 'lot', 'of', 'the', 'same', 'thing', 'to', 'the', 'worl@@', 'd,', 'and', 'I', 'was', 'a', 'lot', 'of', 'the', 'worl@@', 'd,', 'and', 'I', 'was', 'a', 'lot', 'of', 'the', 'worl@@', 'd.', '</s>']
2024-05-28 12:39:43,108 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:39:43,108 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:39:43,108 - INFO - joeynmt.training - 	Hypothesis: And I was a lot of the same thing to the world, and I was a lot of the world, and I was a lot of the world.
2024-05-28 12:39:46,592 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     2.792928, Batch Acc: 0.210943, Tokens per Sec:    19734, Lr: 0.000300
2024-05-28 12:39:50,197 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     2.684247, Batch Acc: 0.215163, Tokens per Sec:    19310, Lr: 0.000300
2024-05-28 12:39:54,060 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     2.718225, Batch Acc: 0.214086, Tokens per Sec:    18355, Lr: 0.000300
2024-05-28 12:39:57,524 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     2.687896, Batch Acc: 0.221508, Tokens per Sec:    20582, Lr: 0.000300
2024-05-28 12:40:01,436 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     2.719373, Batch Acc: 0.221520, Tokens per Sec:    18150, Lr: 0.000300
2024-05-28 12:40:01,437 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:40:01,437 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:40:25,447 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.74, ppl:  15.42, acc:   0.22, generation: 23.9878[sec], evaluation: 0.0000[sec]
2024-05-28 12:40:25,447 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:40:25,525 - INFO - joeynmt.training - Example #0
2024-05-28 12:40:25,525 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:40:25,525 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:40:25,525 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'time', 'I', 'was', 'a', 'b@@', 'ea@@', 'u@@', 'ti@@', 'ful', 'and', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'en@@', 'ef@@', 'ul', 'in', 'the', 'b@@', 'en@@', 'ef@@', 'ul', 'in', 'the', 'b@@', 'en@@', 'ef@@', 'ul', 'in', 'the', 'b@@', 'ea@@', 'u@@', 'ti@@', 'ful', 'of', 'the', 'b@@', 'en@@', 'ef@@', 'ul', 'of', 'the', 'b@@', 'en@@', 'ef@@', 'ul', 'in', 'the', 'b@@', 'en@@', 'ef@@', 'ul', 'in', 'the', 'b@@', 'en@@', 'ef@@', 'ul', 'of', 'the', 'b@@', 'en@@', 'ef@@', 'ul', 'in', 'the', 'b@@', 'en@@', 'ef@@', 'ul', 'of', 'the', 'b@@', 'en@@', 'ef@@', 'ul', 'and', 'the', 'b@@', 'ro@@', 'w@@', 'ing', 'of', 'the', 'b@@', 'en@@', 'ef@@', 'ul', 'of', 'the', 'b@@']
2024-05-28 12:40:25,526 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:40:25,526 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:40:25,526 - INFO - joeynmt.training - 	Hypothesis: And the first time I was a beautiful and the best of the best of the best of the best of the best of the beneful in the beneful in the beneful in the beautiful of the beneful of the beneful in the beneful in the beneful of the beneful in the beneful of the beneful and the browing of the beneful of the b
2024-05-28 12:40:25,526 - INFO - joeynmt.training - Example #1
2024-05-28 12:40:25,526 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:40:25,526 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:40:25,526 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'en@@', 'ef@@', 'ul', 'of', 'the', 'b@@', 'en@@', 'ef@@', 'ul', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'en@@', 'ef@@', 'ul', 'of', 'the', 'b@@', 'en@@', 'ef@@', 'ul', 'of', 'the', 'b@@', 'en@@', 'ef@@', '.', '</s>']
2024-05-28 12:40:25,527 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:40:25,527 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:40:25,527 - INFO - joeynmt.training - 	Hypothesis: And the best of the best of the beneful of the beneful of the best of the beneful of the beneful of the benef.
2024-05-28 12:40:25,527 - INFO - joeynmt.training - Example #2
2024-05-28 12:40:25,527 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:40:25,527 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:40:25,527 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'en@@', 'ef@@', 'ul', 'of', 'the', 'b@@', 'en@@', 'ef@@', 'ul', 'of', 'the', 'b@@', 'en@@', 'ef@@', 'ul', 'of', 'the', 'b@@', 'en@@', 'ef@@', 'ul', 'of', 'the', 'b@@', 'en@@', '.', '</s>']
2024-05-28 12:40:25,527 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:40:25,528 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:40:25,528 - INFO - joeynmt.training - 	Hypothesis: And the best of the best of the beneful of the beneful of the beneful of the beneful of the ben.
2024-05-28 12:40:25,528 - INFO - joeynmt.training - Example #3
2024-05-28 12:40:25,528 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:40:25,528 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:40:25,528 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'en@@', 'ef@@', 'ul', 'of', 'the', 'b@@', 'en@@', '.', '</s>']
2024-05-28 12:40:25,528 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:40:25,528 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:40:25,528 - INFO - joeynmt.training - 	Hypothesis: And the best of the best of the beneful of the ben.
2024-05-28 12:40:25,528 - INFO - joeynmt.training - Example #4
2024-05-28 12:40:25,529 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:40:25,529 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:40:25,529 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'a', 'b@@', 'ea@@', 'u@@', 'ti@@', 'ful', 'and', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'en@@', 'ef@@', 'ul', 'and', 'the', 'b@@', 'en@@', 'ef@@', 'ul', 'of', 'the', 'b@@', 'en@@', '.', '</s>']
2024-05-28 12:40:25,529 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:40:25,529 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:40:25,529 - INFO - joeynmt.training - 	Hypothesis: And I was a beautiful and the best of the best of the best of the best of the best of the beneful and the beneful of the ben.
2024-05-28 12:40:29,032 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     2.659635, Batch Acc: 0.225875, Tokens per Sec:    20188, Lr: 0.000300
2024-05-28 12:40:32,882 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     2.711731, Batch Acc: 0.226573, Tokens per Sec:    18568, Lr: 0.000300
2024-05-28 12:40:36,853 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     2.646954, Batch Acc: 0.225567, Tokens per Sec:    17870, Lr: 0.000300
2024-05-28 12:40:40,729 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     2.586114, Batch Acc: 0.231435, Tokens per Sec:    18118, Lr: 0.000300
2024-05-28 12:40:44,350 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     2.637079, Batch Acc: 0.231464, Tokens per Sec:    19731, Lr: 0.000300
2024-05-28 12:40:44,350 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:40:44,351 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:41:10,011 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.69, ppl:  14.78, acc:   0.23, generation: 25.6404[sec], evaluation: 0.0000[sec]
2024-05-28 12:41:10,062 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:41:10,143 - INFO - joeynmt.helpers - delete models/bpe-subword/500.ckpt
2024-05-28 12:41:10,144 - INFO - joeynmt.training - Example #0
2024-05-28 12:41:10,144 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:41:10,145 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:41:10,145 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'time', 'I', 'was', 'a', 'little', 'bit', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'world', 'and', 'the', 'world', 'in', 'the', 'world', 'and', 'the', 'world', 'of', 'the', 'world', 'and', 'the', 'world', 'in', 'the', 'world', 'and', 'the', 'world', 'of', 'the', 'world', 'and', 'the', 'world', 'and', 'the', 'world', 'and', 'the', 'world', 'and', 'the', 'world', 'is', 'that', 'the', 'world', 'and', 'the', 'world', 'and', 'the', 'world', 'and', 'the', 'world', 'and', 'the', 'world', 'and', 'the', 'world', 'and', 'the', 'world', 'and', 'the', 'world', 'in', 'the', 'p@@', 'ap@@', 'p@@', 'er', 'and', 'the', 'world', 'that', 'was', 'a', 'very', 'very', 'very', 'very', 'ex@@', 'p@@', 'ec@@', 't.', '</s>']
2024-05-28 12:41:10,145 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:41:10,145 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:41:10,145 - INFO - joeynmt.training - 	Hypothesis: And the first time I was a little bit of the future of the future of the future of the world and the world in the world and the world of the world and the world in the world and the world of the world and the world and the world and the world and the world is that the world and the world and the world and the world and the world and the world and the world and the world in the papper and the world that was a very very very very expect.
2024-05-28 12:41:10,145 - INFO - joeynmt.training - Example #1
2024-05-28 12:41:10,145 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:41:10,145 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:41:10,145 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'way', 'we', 'have', 'a', 'lot', 'of', 'the', 'world', 'is', 'that', 'we', 'have', 'a', 'lot', 'of', 'the', 'world', 'is', 'that', 'the', 'world', 'is', 'that', 'the', 'world', 'is', 'that', 'the', 'world', 'are', 'not', 'going', 'to', 'be', 'a', 'lot', 'of', 'the', 's@@', 'our@@', 'ce.', '</s>']
2024-05-28 12:41:10,146 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:41:10,146 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:41:10,146 - INFO - joeynmt.training - 	Hypothesis: And the way we have a lot of the world is that we have a lot of the world is that the world is that the world is that the world are not going to be a lot of the source.
2024-05-28 12:41:10,146 - INFO - joeynmt.training - Example #2
2024-05-28 12:41:10,146 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:41:10,146 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:41:10,146 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 's@@', 'our@@', 'ce', 'of', 'the', 's@@', 'ha@@', 'ir@@', 's', 'of', 'the', 's@@', 'ha@@', 'ir@@', '.', '</s>']
2024-05-28 12:41:10,147 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:41:10,147 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:41:10,147 - INFO - joeynmt.training - 	Hypothesis: And the first of the future of the future of the source of the shairs of the shair.
2024-05-28 12:41:10,147 - INFO - joeynmt.training - Example #3
2024-05-28 12:41:10,147 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:41:10,147 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:41:10,147 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'thing', 'is', 'that', 'the', 'world', 'is', 'that', 'the', 's@@', 'our@@', 'ce', 'of', 'the', 's@@', 'our@@', 'ce', 'of', 'the', 'worl@@', 'd.', '</s>']
2024-05-28 12:41:10,147 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:41:10,147 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:41:10,147 - INFO - joeynmt.training - 	Hypothesis: And the first thing is that the world is that the source of the source of the world.
2024-05-28 12:41:10,147 - INFO - joeynmt.training - Example #4
2024-05-28 12:41:10,148 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:41:10,148 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:41:10,148 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'time', 'I', 'was', 'a', 'lot', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'world', 'is', 'that', 'the', 'world', 'is', 'that', 'the', 'world', 'is', 'that', 'the', 'world', 'is', 'that', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'world', 'of', 'the', 'world', 'and', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'worl@@', 'd.', '</s>']
2024-05-28 12:41:10,148 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:41:10,148 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:41:10,148 - INFO - joeynmt.training - 	Hypothesis: And the first time I was a lot of the future of the future of the future of the world is that the world is that the world is that the world is that the future of the world of the world and the future of the world.
2024-05-28 12:41:14,016 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     2.734067, Batch Acc: 0.230059, Tokens per Sec:    17403, Lr: 0.000300
2024-05-28 12:41:18,137 - INFO - joeynmt.training - Epoch   1, Step:     3200, Batch Loss:     2.760845, Batch Acc: 0.235216, Tokens per Sec:    16914, Lr: 0.000300
2024-05-28 12:41:21,811 - INFO - joeynmt.training - Epoch   1, Step:     3300, Batch Loss:     2.594508, Batch Acc: 0.237712, Tokens per Sec:    19108, Lr: 0.000300
2024-05-28 12:41:25,721 - INFO - joeynmt.training - Epoch   1, Step:     3400, Batch Loss:     2.757511, Batch Acc: 0.239768, Tokens per Sec:    18199, Lr: 0.000300
2024-05-28 12:41:29,724 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:     2.595789, Batch Acc: 0.240490, Tokens per Sec:    18181, Lr: 0.000300
2024-05-28 12:41:29,724 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:41:29,724 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:41:40,410 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.65, ppl:  14.21, acc:   0.24, generation: 10.6711[sec], evaluation: 0.0000[sec]
2024-05-28 12:41:40,411 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:41:40,929 - INFO - joeynmt.helpers - delete models/bpe-subword/1000.ckpt
2024-05-28 12:41:40,930 - INFO - joeynmt.training - Example #0
2024-05-28 12:41:40,930 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:41:40,930 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:41:40,930 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'time', 'of', 'the', 'first', 'of', 'the', 'f@@', 'ut@@', 'u@@', 're,', 'and', 'the', 'f@@', 'ut@@', 'u@@', 're,', 'and', 'the', 'f@@', 'ut@@', 'u@@', 're,', 'and', 'the', 'f@@', 'ut@@', 'u@@', 're,', 'and', 'the', 'f@@', 'ut@@', 'ure', 'out', 'of', 'the', 'f@@', 'ut@@', 'ure', 'out', 'of', 'the', 'f@@', 'ut@@', 'ure', 'out', 'of', 'the', 's@@', 'ha@@', 'pe', 'of', 'the', 'worl@@', 'd.', '</s>']
2024-05-28 12:41:40,931 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:41:40,931 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:41:40,931 - INFO - joeynmt.training - 	Hypothesis: And the first time of the first of the future, and the future, and the future, and the future, and the future out of the future out of the future out of the shape of the world.
2024-05-28 12:41:40,931 - INFO - joeynmt.training - Example #1
2024-05-28 12:41:40,931 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:41:40,931 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:41:40,931 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'same', 'tim@@', 'e,', 'you', 'can', 'see', 'the', 'same', 'tim@@', 'e,', 'and', 'the', 'same', 'tim@@', 'e,', 'and', 'the', 'same', 'tim@@', 'e.', '</s>']
2024-05-28 12:41:40,932 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:41:40,932 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:41:40,932 - INFO - joeynmt.training - 	Hypothesis: And the same time, you can see the same time, and the same time, and the same time.
2024-05-28 12:41:40,932 - INFO - joeynmt.training - Example #2
2024-05-28 12:41:40,932 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:41:40,932 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:41:40,932 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'of', 'the', 'f@@', 'ut@@', 'u@@', 're,', 'the', 'f@@', 'ut@@', 'u@@', 're.', '</s>']
2024-05-28 12:41:40,932 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:41:40,933 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:41:40,933 - INFO - joeynmt.training - 	Hypothesis: And the first of the future, the future.
2024-05-28 12:41:40,933 - INFO - joeynmt.training - Example #3
2024-05-28 12:41:40,933 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:41:40,933 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:41:40,933 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'time', 'of', 'the', 'same', 'tim@@', 'e.', '</s>']
2024-05-28 12:41:40,933 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:41:40,933 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:41:40,933 - INFO - joeynmt.training - 	Hypothesis: And the first time of the same time.
2024-05-28 12:41:40,933 - INFO - joeynmt.training - Example #4
2024-05-28 12:41:40,933 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:41:40,934 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:41:40,934 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'a', 'lot', 'of', 'of', 'the', 'f@@', 'ut@@', 'u@@', 're,', 'and', 'the', 'f@@', 'ut@@', 'u@@', 're,', 'and', 'the', 'f@@', 'ut@@', 'ure', 'out', 'of', 'the', 'f@@', 'ut@@', 'u@@', 're.', '</s>']
2024-05-28 12:41:40,934 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:41:40,934 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:41:40,934 - INFO - joeynmt.training - 	Hypothesis: And I was a lot of of the future, and the future, and the future out of the future.
2024-05-28 12:41:44,976 - INFO - joeynmt.training - Epoch   1, Step:     3600, Batch Loss:     2.532937, Batch Acc: 0.244234, Tokens per Sec:    15822, Lr: 0.000300
2024-05-28 12:41:48,965 - INFO - joeynmt.training - Epoch   1, Step:     3700, Batch Loss:     2.517263, Batch Acc: 0.242426, Tokens per Sec:    17462, Lr: 0.000300
2024-05-28 12:41:52,987 - INFO - joeynmt.training - Epoch   1, Step:     3800, Batch Loss:     2.467965, Batch Acc: 0.245951, Tokens per Sec:    17595, Lr: 0.000300
2024-05-28 12:41:57,135 - INFO - joeynmt.training - Epoch   1, Step:     3900, Batch Loss:     2.580922, Batch Acc: 0.248654, Tokens per Sec:    17327, Lr: 0.000300
2024-05-28 12:42:00,759 - INFO - joeynmt.training - Epoch   1, Step:     4000, Batch Loss:     2.501244, Batch Acc: 0.245086, Tokens per Sec:    19730, Lr: 0.000300
2024-05-28 12:42:00,759 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:42:00,759 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:42:21,657 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.62, ppl:  13.80, acc:   0.25, generation: 20.8798[sec], evaluation: 0.0000[sec]
2024-05-28 12:42:21,657 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:42:22,524 - INFO - joeynmt.helpers - delete models/bpe-subword/1500.ckpt
2024-05-28 12:42:22,525 - INFO - joeynmt.training - Example #0
2024-05-28 12:42:22,525 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:42:22,525 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:42:22,525 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'time', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 's@@', 'our@@', 'ce', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 's@@', 'our@@', 'ce', 'of', 'the', 's@@', 'our@@', 'ce', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'st@@', 'ate', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 's@@', 'our@@', 'ce', 'of', 'the', 'st@@', 'ate', 'of', 'the', 'f@@', 'ut@@', 'u@@', 're.', '</s>']
2024-05-28 12:42:22,526 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:42:22,526 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:42:22,526 - INFO - joeynmt.training - 	Hypothesis: And the first time of the future of the future of the source of the future of the future of the future of the source of the source of the future of the future of the future of the future of the state of the future of the future of the source of the state of the future.
2024-05-28 12:42:22,526 - INFO - joeynmt.training - Example #1
2024-05-28 12:42:22,526 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:42:22,526 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:42:22,526 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'st@@', 'ory', 'of', 'the', 'st@@', 'ory', 'of', 'the', 'st@@', 'ory', 'of', 'the', 'st@@', 'or@@', 'y.', '</s>']
2024-05-28 12:42:22,527 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:42:22,527 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:42:22,527 - INFO - joeynmt.training - 	Hypothesis: And the future of the story of the story of the story of the story.
2024-05-28 12:42:22,527 - INFO - joeynmt.training - Example #2
2024-05-28 12:42:22,527 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:42:22,527 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:42:22,527 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 's@@', 'our@@', 'ce', 'of', 'the', 's@@', 'ha@@', 'pe', 'of', 'the', 'f@@', 'ut@@', 'u@@', 're.', '</s>']
2024-05-28 12:42:22,527 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:42:22,527 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:42:22,528 - INFO - joeynmt.training - 	Hypothesis: And the future of the future of the source of the shape of the future.
2024-05-28 12:42:22,528 - INFO - joeynmt.training - Example #3
2024-05-28 12:42:22,528 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:42:22,528 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:42:22,528 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'st@@', 'at@@', 'es', 'of', 'the', 'st@@', 'at@@', 'es.', '</s>']
2024-05-28 12:42:22,528 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:42:22,528 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:42:22,528 - INFO - joeynmt.training - 	Hypothesis: And the future of the states of the states.
2024-05-28 12:42:22,528 - INFO - joeynmt.training - Example #4
2024-05-28 12:42:22,528 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:42:22,529 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:42:22,529 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'time', 'to', 'the', 'st@@', 'o@@', 'p', 'of', 'the', 's@@', 'our@@', 'ce', 'of', 'the', 's@@', 'ha@@', 'pe', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 's@@', 'our@@', 'ce', 'of', 'the', 's@@', 'our@@', 'ce', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 's@@', 'our@@', 'ce', 'of', 'the', 'f@@', 'ut@@', 'u@@', 're.', '</s>']
2024-05-28 12:42:22,529 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:42:22,529 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:42:22,529 - INFO - joeynmt.training - 	Hypothesis: And the first time to the stop of the source of the shape of the future of the future of the future of the source of the source of the future of the future of the source of the future.
2024-05-28 12:42:25,934 - INFO - joeynmt.training - Epoch   1, Step:     4100, Batch Loss:     2.534442, Batch Acc: 0.253603, Tokens per Sec:    16838, Lr: 0.000300
2024-05-28 12:42:29,630 - INFO - joeynmt.training - Epoch   1, Step:     4200, Batch Loss:     2.623068, Batch Acc: 0.254494, Tokens per Sec:    18938, Lr: 0.000300
2024-05-28 12:42:32,996 - INFO - joeynmt.training - Epoch   1, Step:     4300, Batch Loss:     2.592072, Batch Acc: 0.253358, Tokens per Sec:    20727, Lr: 0.000300
2024-05-28 12:42:36,643 - INFO - joeynmt.training - Epoch   1, Step:     4400, Batch Loss:     2.671679, Batch Acc: 0.248841, Tokens per Sec:    19105, Lr: 0.000300
2024-05-28 12:42:40,176 - INFO - joeynmt.training - Epoch   1, Step:     4500, Batch Loss:     2.532306, Batch Acc: 0.253263, Tokens per Sec:    20040, Lr: 0.000300
2024-05-28 12:42:40,176 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:42:40,176 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:42:50,691 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.60, ppl:  13.46, acc:   0.25, generation: 10.4971[sec], evaluation: 0.0000[sec]
2024-05-28 12:42:50,692 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:42:50,771 - INFO - joeynmt.helpers - delete models/bpe-subword/2000.ckpt
2024-05-28 12:42:50,771 - INFO - joeynmt.training - Example #0
2024-05-28 12:42:50,771 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:42:50,772 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:42:50,772 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'time', 'of', 'the', 'first', 'of', 'the', 'f@@', 'ut@@', 'u@@', 're,', 'and', 'the', 'most', 'of', 'the', 'f@@', 'ut@@', 'u@@', 're,', 'and', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'f@@', 'ut@@', 'u@@', 're,', 'and', 'the', 'c@@', 'ity', 'of', 'the', 're@@', 'sear@@', 'ch', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'f@@', 'ut@@', 'u@@', 're.', '</s>']
2024-05-28 12:42:50,772 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:42:50,772 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:42:50,772 - INFO - joeynmt.training - 	Hypothesis: And the first time of the first of the future, and the most of the future, and the best of the best of the future, and the city of the research of the best of the best of the future.
2024-05-28 12:42:50,772 - INFO - joeynmt.training - Example #1
2024-05-28 12:42:50,772 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:42:50,772 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:42:50,772 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', "it's", 'not', 'not', 'only', 'a', 'lot', 'of', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'c@@', 'ell@@', 's.', '</s>']
2024-05-28 12:42:50,773 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:42:50,773 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:42:50,773 - INFO - joeynmt.training - 	Hypothesis: And it's not not only a lot of of the best of the best of the best of the best of the best of the best of the best of the cells.
2024-05-28 12:42:50,773 - INFO - joeynmt.training - Example #2
2024-05-28 12:42:50,773 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:42:50,773 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:42:50,773 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'a', 'very', 'very', 'ex@@', 'cit@@', 'ed', 'in', 'the', 'f@@', 'ut@@', 'u@@', 're,', 'and', 'the', 'b@@', 'est', 'of', 'the', 'c@@', 'ity', 'of', 'the', 'c@@', 'ity', 'of', 'the', 'c@@', 'ell@@', '.', '</s>']
2024-05-28 12:42:50,774 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:42:50,774 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:42:50,774 - INFO - joeynmt.training - 	Hypothesis: It's a very very excited in the future, and the best of the city of the city of the cell.
2024-05-28 12:42:50,774 - INFO - joeynmt.training - Example #3
2024-05-28 12:42:50,774 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:42:50,774 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:42:50,774 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'b@@', 'est', 'of', 'the', 'c@@', 'ity', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'c@@', 'ell@@', 's.', '</s>']
2024-05-28 12:42:50,774 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:42:50,774 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:42:50,774 - INFO - joeynmt.training - 	Hypothesis: And the best of the city of the best of the best of the cells.
2024-05-28 12:42:50,774 - INFO - joeynmt.training - Example #4
2024-05-28 12:42:50,775 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:42:50,775 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:42:50,775 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'time', 'I', 'was', 'a', 'lot', 'of', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:42:50,775 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:42:50,775 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:42:50,775 - INFO - joeynmt.training - 	Hypothesis: And the first time I was a lot of of the best of the best of the best of the best of the best of the best of the same.
2024-05-28 12:42:52,587 - INFO - joeynmt.training - Epoch   1: total training loss 13038.18
2024-05-28 12:42:52,587 - INFO - joeynmt.training - EPOCH 2
2024-05-28 12:42:54,002 - INFO - joeynmt.training - Epoch   2, Step:     4600, Batch Loss:     2.605381, Batch Acc: 0.257011, Tokens per Sec:    23522, Lr: 0.000300
2024-05-28 12:42:57,221 - INFO - joeynmt.training - Epoch   2, Step:     4700, Batch Loss:     2.512083, Batch Acc: 0.261396, Tokens per Sec:    21849, Lr: 0.000300
2024-05-28 12:43:00,434 - INFO - joeynmt.training - Epoch   2, Step:     4800, Batch Loss:     2.521405, Batch Acc: 0.265430, Tokens per Sec:    22225, Lr: 0.000300
2024-05-28 12:43:03,643 - INFO - joeynmt.training - Epoch   2, Step:     4900, Batch Loss:     2.476142, Batch Acc: 0.263823, Tokens per Sec:    21419, Lr: 0.000300
2024-05-28 12:43:06,906 - INFO - joeynmt.training - Epoch   2, Step:     5000, Batch Loss:     2.450325, Batch Acc: 0.265292, Tokens per Sec:    21885, Lr: 0.000300
2024-05-28 12:43:06,907 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:43:06,907 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:43:17,821 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.58, ppl:  13.18, acc:   0.26, generation: 10.8943[sec], evaluation: 0.0000[sec]
2024-05-28 12:43:17,821 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:43:17,899 - INFO - joeynmt.helpers - delete models/bpe-subword/2500.ckpt
2024-05-28 12:43:17,900 - INFO - joeynmt.training - Example #0
2024-05-28 12:43:17,900 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:43:17,900 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:43:17,900 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'time', 'I', 'was', 'a', 'lot', 'of', 'the', 'first', 'time', 'of', 'the', 'world', 'was', 'a', 'lot', 'of', 'the', 'world', 'in', 'the', 'world', 'of', 'the', 'world', 'in', 'the', 'worl@@', 'd,', 'and', 'the', 'first', 'time', 'of', 'the', 'world', 'in', 'the', 'worl@@', 'd,', 'and', 'the', 'world', 'in', 'the', 'worl@@', 'd@@', "'s", 're@@', 'li@@', 'gi@@', 'on', 'the', 'worl@@', 'd@@', "'s", 'st@@', 'and@@', 'ing', 'of', 'the', 'world', 'and', 'the', 'st@@', 'ate', 'of', 'the', 'world', 'and', 'the', 'world', 'in', 'the', 'world', 'and', 'the', 'world', 'in', 'the', 'worl@@', 'd.', '</s>']
2024-05-28 12:43:17,901 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:43:17,901 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:43:17,901 - INFO - joeynmt.training - 	Hypothesis: And the first time I was a lot of the first time of the world was a lot of the world in the world of the world in the world, and the first time of the world in the world, and the world in the world's religion the world's standing of the world and the state of the world and the world in the world and the world in the world.
2024-05-28 12:43:17,901 - INFO - joeynmt.training - Example #1
2024-05-28 12:43:17,901 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:43:17,901 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:43:17,901 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'the', 'other', 'thing', 'that', 'we', 'can', 'see', 'the', 'same', 'thing@@', ',', 'and', 'we', 'can', 'see', 'the', 'same', 'thing@@', '.', '</s>']
2024-05-28 12:43:17,902 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:43:17,902 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:43:17,902 - INFO - joeynmt.training - 	Hypothesis: But the other thing that we can see the same thing, and we can see the same thing.
2024-05-28 12:43:17,902 - INFO - joeynmt.training - Example #2
2024-05-28 12:43:17,902 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:43:17,902 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:43:17,902 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'other', 'other', 'wor@@', 'ds,', 'the', 'st@@', 'ory', 'of', 'the', 'st@@', 'ory', 'of', 'the', 's@@', 'itu@@', 'ation', 'of', 'the', 's@@', 'ha@@', 'res', 'of', 'the', 's@@', 'ha@@', 'res', 'of', 'the', 's@@', 'itu@@', 'ation.', '</s>']
2024-05-28 12:43:17,902 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:43:17,902 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:43:17,902 - INFO - joeynmt.training - 	Hypothesis: The other other words, the story of the story of the situation of the shares of the shares of the situation.
2024-05-28 12:43:17,902 - INFO - joeynmt.training - Example #3
2024-05-28 12:43:17,903 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:43:17,903 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:43:17,903 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'st@@', 'ory', 'of', 'the', 'st@@', 'ate', 'of', 'the', 'st@@', 'ate', 'of', 'the', 'st@@', 'and@@', 'ar@@', 'd', 'of', 'the', 'st@@', 'or@@', 'y.', '</s>']
2024-05-28 12:43:17,903 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:43:17,903 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:43:17,903 - INFO - joeynmt.training - 	Hypothesis: And the story of the state of the state of the standard of the story.
2024-05-28 12:43:17,903 - INFO - joeynmt.training - Example #4
2024-05-28 12:43:17,903 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:43:17,903 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:43:17,904 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'a', 'lot', 'of', 'the', 'first', 'time', 'I', 'was', 'a', 'b@@', 'ea@@', 'u@@', 'ti@@', 'ful', 'st@@', 'or@@', 'y,', 'and', 'I', 'was', 'a', 'lot', 'of', 'the', 'st@@', 'ory', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'world', 'in', 'the', 'worl@@', 'd.', '</s>']
2024-05-28 12:43:17,904 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:43:17,904 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:43:17,904 - INFO - joeynmt.training - 	Hypothesis: And I was a lot of the first time I was a beautiful story, and I was a lot of the story of the first time of the first time of the world in the world.
2024-05-28 12:43:21,062 - INFO - joeynmt.training - Epoch   2, Step:     5100, Batch Loss:     2.611235, Batch Acc: 0.265970, Tokens per Sec:    21452, Lr: 0.000300
2024-05-28 12:43:24,177 - INFO - joeynmt.training - Epoch   2, Step:     5200, Batch Loss:     2.495761, Batch Acc: 0.260507, Tokens per Sec:    22695, Lr: 0.000300
2024-05-28 12:43:27,447 - INFO - joeynmt.training - Epoch   2, Step:     5300, Batch Loss:     2.580113, Batch Acc: 0.268500, Tokens per Sec:    22021, Lr: 0.000300
2024-05-28 12:43:30,456 - INFO - joeynmt.training - Epoch   2, Step:     5400, Batch Loss:     2.431985, Batch Acc: 0.267663, Tokens per Sec:    23017, Lr: 0.000300
2024-05-28 12:43:33,435 - INFO - joeynmt.training - Epoch   2, Step:     5500, Batch Loss:     2.506948, Batch Acc: 0.269055, Tokens per Sec:    24017, Lr: 0.000300
2024-05-28 12:43:33,435 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:43:33,435 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:43:41,287 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.55, ppl:  12.82, acc:   0.26, generation: 7.8364[sec], evaluation: 0.0000[sec]
2024-05-28 12:43:41,287 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:43:41,356 - INFO - joeynmt.helpers - delete models/bpe-subword/3000.ckpt
2024-05-28 12:43:41,357 - INFO - joeynmt.training - Example #0
2024-05-28 12:43:41,357 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:43:41,357 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:43:41,357 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'time', 'I', 'was', 'a', 'very', 'f@@', 'ar', 'and', 'the', 'first', 'time', 'in', 'the', 'last', 'few', 'years', 'ag@@', 'o,', 'and', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'in', 'the', 'worl@@', 'd,', 'and', 'the', 'most', 'of', 'the', 'first', 'time', 'in', 'the', 'last', '1@@', '0@@', ',', 'and', 'the', 'first', 'of', 'the', 'f@@', 'our', 'our', 'h@@', 'ist@@', 'ory', 'of', 'the', 'first', 'time', 'in', 'the', 'worl@@', 'd.', '</s>']
2024-05-28 12:43:41,358 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:43:41,358 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:43:41,358 - INFO - joeynmt.training - 	Hypothesis: And the first time I was a very far and the first time in the last few years ago, and the first time of the first time of the first time of the first time of the first time in the world, and the most of the first time in the last 10, and the first of the four our history of the first time in the world.
2024-05-28 12:43:41,358 - INFO - joeynmt.training - Example #1
2024-05-28 12:43:41,358 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:43:41,358 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:43:41,358 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'a', 'very', 'important', 'thing', 'that', 'we', 'have', 'a', 'lot', 'of', 'the', 'same', 'thing@@', ',', 'but', 'the', 'way', 'that', 'we', 'have', 'a', 'lot', 'of', 'the', 'same', 'thing@@', '.', '</s>']
2024-05-28 12:43:41,358 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:43:41,358 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:43:41,359 - INFO - joeynmt.training - 	Hypothesis: But this is a very important thing that we have a lot of the same thing, but the way that we have a lot of the same thing.
2024-05-28 12:43:41,359 - INFO - joeynmt.training - Example #2
2024-05-28 12:43:41,359 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:43:41,359 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:43:41,359 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'thing', 'is', 'that', 'the', 's@@', 'am@@', 'pl@@', 'es', 'of', 'the', 's@@', 'am@@', 'pl@@', 'es', 'of', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:43:41,359 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:43:41,359 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:43:41,359 - INFO - joeynmt.training - 	Hypothesis: The first thing is that the samples of the samples of the same.
2024-05-28 12:43:41,359 - INFO - joeynmt.training - Example #3
2024-05-28 12:43:41,359 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:43:41,359 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:43:41,360 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'thing', 'that', 'we', 'have', 'to', 'do', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:43:41,360 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:43:41,360 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:43:41,360 - INFO - joeynmt.training - 	Hypothesis: And the first thing that we have to do the same.
2024-05-28 12:43:41,360 - INFO - joeynmt.training - Example #4
2024-05-28 12:43:41,360 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:43:41,360 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:43:41,360 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'this', 'is', 'a', 'few', 'years', 'ag@@', 'o,', 'I', 'was', 'a', 'very', 's@@', 'ha@@', 'pe', 'of', 'the', 'first', 'time', 'to', 'be', 'a', 'few', 'years', 'ag@@', 'o,', 'and', 'the', 'first', 'time', 'to', 'be', 'a', 'little', 'bit', 'of', 'the', 'first', 'time', 'to', 'be', 'a', 'very', 'l@@', 'ong', 'tim@@', 'e.', '</s>']
2024-05-28 12:43:41,361 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:43:41,361 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:43:41,361 - INFO - joeynmt.training - 	Hypothesis: And this is a few years ago, I was a very shape of the first time to be a few years ago, and the first time to be a little bit of the first time to be a very long time.
2024-05-28 12:43:44,653 - INFO - joeynmt.training - Epoch   2, Step:     5600, Batch Loss:     2.511454, Batch Acc: 0.268695, Tokens per Sec:    21360, Lr: 0.000300
2024-05-28 12:43:47,882 - INFO - joeynmt.training - Epoch   2, Step:     5700, Batch Loss:     2.512216, Batch Acc: 0.265092, Tokens per Sec:    21905, Lr: 0.000300
2024-05-28 12:43:50,951 - INFO - joeynmt.training - Epoch   2, Step:     5800, Batch Loss:     2.556282, Batch Acc: 0.270380, Tokens per Sec:    23147, Lr: 0.000300
2024-05-28 12:43:54,075 - INFO - joeynmt.training - Epoch   2, Step:     5900, Batch Loss:     2.491107, Batch Acc: 0.270596, Tokens per Sec:    22762, Lr: 0.000300
2024-05-28 12:43:57,459 - INFO - joeynmt.training - Epoch   2, Step:     6000, Batch Loss:     2.697967, Batch Acc: 0.271144, Tokens per Sec:    20863, Lr: 0.000300
2024-05-28 12:43:57,459 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:43:57,460 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:44:07,275 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.53, ppl:  12.54, acc:   0.27, generation: 9.7980[sec], evaluation: 0.0000[sec]
2024-05-28 12:44:07,276 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:44:07,348 - INFO - joeynmt.helpers - delete models/bpe-subword/3500.ckpt
2024-05-28 12:44:07,349 - INFO - joeynmt.training - Example #0
2024-05-28 12:44:07,349 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:44:07,349 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:44:07,349 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'most', 'important', 'in', 'the', 'worl@@', 'd,', 'in', '19@@', '8@@', '0@@', ',', 'and', 'the', 'most', 'important', 'of', 'the', 'worl@@', 'd,', 'and', 'the', 'most', 'important', 'of', 'the', 'worl@@', 'd,', 'and', 'the', 'most', 'important', 'thing', 'in', 'the', 'worl@@', 'd,', 'and', 'the', 'most', 'important', 'of', 'the', 'worl@@', 'd,', 'and', 'the', 'most', 'important', 'of', 'cour@@', 'se,', 'and', 'the', 'first', 'of', 'the', 'worl@@', 'd@@', "'s", '1@@', '0@@', ',000', 'years', 'ag@@', 'o,', 'and', 'the', 'most', 'of', 'the', 'worl@@', 'd.', '</s>']
2024-05-28 12:44:07,350 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:44:07,350 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:44:07,350 - INFO - joeynmt.training - 	Hypothesis: And the first time of the first time of the most important in the world, in 1980, and the most important of the world, and the most important of the world, and the most important thing in the world, and the most important of the world, and the most important of course, and the first of the world's 10,000 years ago, and the most of the world.
2024-05-28 12:44:07,350 - INFO - joeynmt.training - Example #1
2024-05-28 12:44:07,350 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:44:07,350 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:44:07,350 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'a', 'lot', 'of', 'the', 'world', 'is', 'that', 'the', 'most', 'important', 'is', 'that', 'we', 'have', 'a', 'lot', 'of', 'the', 'worl@@', 'd.', '</s>']
2024-05-28 12:44:07,351 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:44:07,351 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:44:07,351 - INFO - joeynmt.training - 	Hypothesis: But this is a lot of the world is that the most important is that we have a lot of the world.
2024-05-28 12:44:07,351 - INFO - joeynmt.training - Example #2
2024-05-28 12:44:07,351 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:44:07,351 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:44:07,351 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['This', 'is', 'a', 'very', 'w@@', 'ell@@', '-@@', 'old', 'b@@', 'ut@@', 'ter@@', ',', 'and', 'the', 'most', 'important', 'is', 'that', 'the', 'most', 'important', 'thing', 'is', 'a', 'very', 'w@@', 'ell@@', '.', '</s>']
2024-05-28 12:44:07,351 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:44:07,351 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:44:07,351 - INFO - joeynmt.training - 	Hypothesis: This is a very well-old butter, and the most important is that the most important thing is a very well.
2024-05-28 12:44:07,352 - INFO - joeynmt.training - Example #3
2024-05-28 12:44:07,352 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:44:07,352 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:44:07,352 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'thing', 'we', 'can', 'see', 'the', 'worl@@', 'd@@', "'s", 're@@', 'li@@', 'gi@@', 'on', 'the', 'l@@', 'l@@', 'ang@@', 'u@@', 'ag@@', 'e.', '</s>']
2024-05-28 12:44:07,352 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:44:07,352 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:44:07,352 - INFO - joeynmt.training - 	Hypothesis: The first thing we can see the world's religion the llanguage.
2024-05-28 12:44:07,352 - INFO - joeynmt.training - Example #4
2024-05-28 12:44:07,352 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:44:07,352 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:44:07,353 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'time', 'I', 'was', 'a', 'lot', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'l@@', 'ang@@', 'u@@', 'ag@@', 'e.', '</s>']
2024-05-28 12:44:07,353 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:44:07,353 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:44:07,353 - INFO - joeynmt.training - 	Hypothesis: And the first time I was a lot of the first time of the first time of the first time of the first time of the first time of the language.
2024-05-28 12:44:10,511 - INFO - joeynmt.training - Epoch   2, Step:     6100, Batch Loss:     2.369658, Batch Acc: 0.278058, Tokens per Sec:    22833, Lr: 0.000300
2024-05-28 12:44:14,325 - INFO - joeynmt.training - Epoch   2, Step:     6200, Batch Loss:     2.514859, Batch Acc: 0.279311, Tokens per Sec:    18703, Lr: 0.000300
2024-05-28 12:44:17,726 - INFO - joeynmt.training - Epoch   2, Step:     6300, Batch Loss:     2.468382, Batch Acc: 0.281478, Tokens per Sec:    20976, Lr: 0.000300
2024-05-28 12:44:21,005 - INFO - joeynmt.training - Epoch   2, Step:     6400, Batch Loss:     2.469150, Batch Acc: 0.286911, Tokens per Sec:    22096, Lr: 0.000300
2024-05-28 12:44:24,869 - INFO - joeynmt.training - Epoch   2, Step:     6500, Batch Loss:     2.396081, Batch Acc: 0.287176, Tokens per Sec:    18996, Lr: 0.000300
2024-05-28 12:44:24,870 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:44:24,870 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:44:41,247 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.48, ppl:  11.98, acc:   0.28, generation: 16.3590[sec], evaluation: 0.0000[sec]
2024-05-28 12:44:41,247 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:44:41,340 - INFO - joeynmt.helpers - delete models/bpe-subword/4000.ckpt
2024-05-28 12:44:41,341 - INFO - joeynmt.training - Example #0
2024-05-28 12:44:41,341 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:44:41,341 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:44:41,342 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'was', 'the', 'first', 'time', 'in', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'that', 'we', 'have', 'a', 'lot', 'of', 'the', 'worl@@', 'd,', 'and', 'the', 'first', 'time', 'in', 'the', 'worl@@', 'd,', 'and', 'the', 'first', 'time', 'in', 'the', 'worl@@', 'd,', 'and', 'the', 'world', 'in', 'the', 'worl@@', 'd.', '</s>']
2024-05-28 12:44:41,342 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:44:41,342 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:44:41,342 - INFO - joeynmt.training - 	Hypothesis: The first was the first time in the world of the world of the world that we have a lot of the world, and the first time in the world, and the first time in the world, and the world in the world.
2024-05-28 12:44:41,342 - INFO - joeynmt.training - Example #1
2024-05-28 12:44:41,342 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:44:41,342 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:44:41,342 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'that', 'this', 'is', 'that', 'the', 'way', 'that', 'is', 'that', 'the', 'way', 'that', 'is', 'that', 'the', 's@@', 'ha@@', 'pe', 'of', 'the', 'worl@@', 'd.', '</s>']
2024-05-28 12:44:41,343 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:44:41,343 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:44:41,343 - INFO - joeynmt.training - 	Hypothesis: But this is that this is that the way that is that the way that is that the shape of the world.
2024-05-28 12:44:41,343 - INFO - joeynmt.training - Example #2
2024-05-28 12:44:41,343 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:44:41,343 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:44:41,343 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'thing', 'is', 'a', 'very', 's@@', 'ha@@', 'red', 'in', 'the', 'worl@@', 'd,', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:44:41,344 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:44:41,344 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:44:41,344 - INFO - joeynmt.training - 	Hypothesis: The first thing is a very shared in the world, the future of the same.
2024-05-28 12:44:41,344 - INFO - joeynmt.training - Example #3
2024-05-28 12:44:41,344 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:44:41,344 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:44:41,344 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'thing', 'that', 'is', 'that', 'the', 'st@@', 're@@', 'et', 'of', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:44:41,344 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:44:41,344 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:44:41,344 - INFO - joeynmt.training - 	Hypothesis: The first thing that is that the street of the same.
2024-05-28 12:44:41,345 - INFO - joeynmt.training - Example #4
2024-05-28 12:44:41,345 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:44:41,345 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:44:41,345 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'thing', 'that', 'I', 'want', 'to', 'be', 'a', 'lot', 'of', 'that', 'I', 'want', 'to', 'be', 'a', 'lot', 'of', 'time', 'to', 'be', 'a', 'lot', 'of', 'that', 'I', 'was', 'a', 'lot', 'of', 'that', 'I', 'was', 'a', 'lot', 'of', 'that', 'I', 'was', 'a', 'lot', 'of', 'n@@', 'on@@', '-@@', 'l@@', 'ine', 'st@@', 'or@@', 'y.', '</s>']
2024-05-28 12:44:41,345 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:44:41,345 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:44:41,345 - INFO - joeynmt.training - 	Hypothesis: The first thing that I want to be a lot of that I want to be a lot of time to be a lot of that I was a lot of that I was a lot of that I was a lot of non-line story.
2024-05-28 12:44:45,017 - INFO - joeynmt.training - Epoch   2, Step:     6600, Batch Loss:     2.445567, Batch Acc: 0.285670, Tokens per Sec:    19002, Lr: 0.000300
2024-05-28 12:44:48,897 - INFO - joeynmt.training - Epoch   2, Step:     6700, Batch Loss:     2.483525, Batch Acc: 0.289203, Tokens per Sec:    19093, Lr: 0.000300
2024-05-28 12:44:52,464 - INFO - joeynmt.training - Epoch   2, Step:     6800, Batch Loss:     2.519860, Batch Acc: 0.289169, Tokens per Sec:    19108, Lr: 0.000300
2024-05-28 12:44:56,336 - INFO - joeynmt.training - Epoch   2, Step:     6900, Batch Loss:     2.475233, Batch Acc: 0.297272, Tokens per Sec:    18000, Lr: 0.000300
2024-05-28 12:45:00,317 - INFO - joeynmt.training - Epoch   2, Step:     7000, Batch Loss:     2.437952, Batch Acc: 0.293052, Tokens per Sec:    18426, Lr: 0.000300
2024-05-28 12:45:00,317 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:45:00,317 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:45:29,153 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.45, ppl:  11.60, acc:   0.29, generation: 28.8176[sec], evaluation: 0.0000[sec]
2024-05-28 12:45:29,153 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:45:29,220 - INFO - joeynmt.helpers - delete models/bpe-subword/4500.ckpt
2024-05-28 12:45:29,221 - INFO - joeynmt.training - Example #0
2024-05-28 12:45:29,221 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:45:29,221 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:45:29,222 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'thing', 'I', 'was', 'the', 'same', 'st@@', 'or@@', 'y,', 'the', 'most', 'f@@', 'ar', 'to', 'the', 'first', 'one', 'of', 'the', 'most', 'most', 'important', 'of', 'the', 'most', 'most', 'important', 'in', 'the', 'last', '1@@', '0@@', ',000', 'years', 'ag@@', 'o,', 'the', 'first', 'one', 'of', 'the', 'most', 'most', 'most', 'of', 'the', 'most', 'most', 'most', 'most', 'of', 'the', 'most', 'most', 'most', 'of', 'the', 'most', 'most', 'most', 'of', 'the', 'most', 'most', 'most', 'of', 'the', 'most', 'most', 'most', 'of', 'the', 'most', 'most', 'important', 'in', 'the', 'last', '1@@', '00', 'mil@@', 'lion', 'dol@@', 'lar@@', 's', 'in', 'the', 'last', '1@@', '00', 'mil@@', 'lion', 'dol@@', 'lar@@', 's', 'in', 'the', 'last', '1@@', '0@@', '.', '</s>']
2024-05-28 12:45:29,222 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:45:29,222 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:45:29,222 - INFO - joeynmt.training - 	Hypothesis: The first thing I was the same story, the most far to the first one of the most most important of the most most important in the last 10,000 years ago, the first one of the most most most of the most most most most of the most most most of the most most most of the most most most of the most most most of the most most important in the last 100 million dollars in the last 100 million dollars in the last 10.
2024-05-28 12:45:29,222 - INFO - joeynmt.training - Example #1
2024-05-28 12:45:29,222 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:45:29,222 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:45:29,222 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'most', 'most', 'important', 'thing', 'that', 'is', 'not', 'the', 'same', 'thing', 'that', 'is', 'not', 'the', 'same', 'thing', 'that', 'is', 'not', 'the', 'same', 'thing@@', '.', '</s>']
2024-05-28 12:45:29,223 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:45:29,223 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:45:29,223 - INFO - joeynmt.training - 	Hypothesis: But this is the most most important thing that is not the same thing that is not the same thing that is not the same thing.
2024-05-28 12:45:29,223 - INFO - joeynmt.training - Example #2
2024-05-28 12:45:29,223 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:45:29,223 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:45:29,223 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'one', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'a', 'b@@', 'ad', 'of', 'the', 'con@@', 'd@@', 'iti@@', 'on@@', 'al', 'con@@', 'd@@', 'iti@@', 'on@@', 'al', 'con@@', 'd@@', 'iti@@', 'on@@', 'al', 'con@@', 'd@@', 'iti@@', 'on@@', 'al', 'of', 'the', 'worl@@', 'd.', '</s>']
2024-05-28 12:45:29,224 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:45:29,224 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:45:29,224 - INFO - joeynmt.training - 	Hypothesis: The first one of the future of a bad of the conditional conditional conditional conditional of the world.
2024-05-28 12:45:29,224 - INFO - joeynmt.training - Example #3
2024-05-28 12:45:29,224 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:45:29,224 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:45:29,224 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'thing', 'that', 'they', 'can', 'be', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'al@@', 'an@@', 'ce.', '</s>']
2024-05-28 12:45:29,225 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:45:29,225 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:45:29,225 - INFO - joeynmt.training - 	Hypothesis: The first thing that they can be the best of the balance.
2024-05-28 12:45:29,225 - INFO - joeynmt.training - Example #4
2024-05-28 12:45:29,225 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:45:29,225 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:45:29,225 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'one', 'of', 'the', 'b@@', 'est', 'thing', 'to', 'do', 'to', 'do', 'with', 'a', 'few', 'years', 'ag@@', 'o,', 'a', 'little', 'bit', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'in', 'the', 'last', '1@@', '0@@', '.', '</s>']
2024-05-28 12:45:29,225 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:45:29,225 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:45:29,225 - INFO - joeynmt.training - 	Hypothesis: The first one of the best thing to do to do with a few years ago, a little bit of the first time of the first time in the last 10.
2024-05-28 12:45:33,094 - INFO - joeynmt.training - Epoch   2, Step:     7100, Batch Loss:     2.453176, Batch Acc: 0.295025, Tokens per Sec:    17868, Lr: 0.000300
2024-05-28 12:45:37,165 - INFO - joeynmt.training - Epoch   2, Step:     7200, Batch Loss:     2.391984, Batch Acc: 0.299197, Tokens per Sec:    17456, Lr: 0.000300
2024-05-28 12:45:41,200 - INFO - joeynmt.training - Epoch   2, Step:     7300, Batch Loss:     2.424313, Batch Acc: 0.303043, Tokens per Sec:    17123, Lr: 0.000300
2024-05-28 12:45:45,275 - INFO - joeynmt.training - Epoch   2, Step:     7400, Batch Loss:     2.357186, Batch Acc: 0.296391, Tokens per Sec:    17384, Lr: 0.000300
2024-05-28 12:45:49,414 - INFO - joeynmt.training - Epoch   2, Step:     7500, Batch Loss:     2.316761, Batch Acc: 0.302916, Tokens per Sec:    17676, Lr: 0.000300
2024-05-28 12:45:49,443 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:45:49,449 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:46:35,046 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.42, ppl:  11.24, acc:   0.30, generation: 45.5309[sec], evaluation: 0.0000[sec]
2024-05-28 12:46:35,159 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:46:35,275 - INFO - joeynmt.helpers - delete models/bpe-subword/5000.ckpt
2024-05-28 12:46:35,359 - INFO - joeynmt.training - Example #0
2024-05-28 12:46:35,364 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:46:35,364 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:46:35,364 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'thing', 'I', 'was', 'the', 'same', 'time', 'of', 'these', 're@@', 'sear@@', 'ch', 'to', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'worl@@', 'd,', 'in', 'the', 'worl@@', 'd,', 'in', 'the', 'worl@@', 'd,', 'and', 'the', 'same', 'tim@@', 'e,', 'the', 'same', 'way', 'of', 'the', 'worl@@', 'd,', 'and', 'the', 'same', 'tim@@', 'e,', 'the', 'same', 'of', 'the', 'worl@@', 'd,', 'and', 'the', 'same', 'tim@@', 'e.', '</s>']
2024-05-28 12:46:35,365 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:46:35,369 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:46:35,373 - INFO - joeynmt.training - 	Hypothesis: The first thing I was the same time of these research to the best of the best of the best of the world, in the world, in the world, and the same time, the same way of the world, and the same time, the same of the world, and the same time.
2024-05-28 12:46:35,390 - INFO - joeynmt.training - Example #1
2024-05-28 12:46:35,394 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:46:35,395 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:46:35,395 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'the', 'b@@', 'est', 'of', 'the', 'world', 'is', 'that', 'the', 'same', 'thing', 'is', 'that', 'is', 'not', 'the', 'same', 'way', 'that', 'is', 'not', 'just', 'to', 'be', 'able', 'to', 'be', 'able', 'to', 'be', 'able', 'to', 'be', 'able', 'to', 'be', 'able', 'to', 'be', 'able', 'to', 'be', 'able', 'to', 'be', 'able', 'to', 're@@', 'co@@', 'g@@', 'n@@', 'iz@@', 'e', 'to', 'be', 'able', 'to', 'be', 'able', 'to', 'be', 'able', 'to', 'be', 'able', 'to', 'be', 'able', 'to', 're@@', 'co@@', '.', '</s>']
2024-05-28 12:46:35,395 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:46:35,399 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:46:35,403 - INFO - joeynmt.training - 	Hypothesis: But the best of the world is that the same thing is that is not the same way that is not just to be able to be able to be able to be able to be able to be able to be able to be able to recognize to be able to be able to be able to be able to be able to reco.
2024-05-28 12:46:35,407 - INFO - joeynmt.training - Example #2
2024-05-28 12:46:35,423 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:46:35,423 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:46:35,423 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'worl@@', 'd,', 'the', 'same', 'way', 'that', 'the', 'world', 'is', 'the', 'worl@@', 'd.', '</s>']
2024-05-28 12:46:35,423 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:46:35,448 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:46:35,452 - INFO - joeynmt.training - 	Hypothesis: The best of the best of the best of the world, the same way that the world is the world.
2024-05-28 12:46:35,456 - INFO - joeynmt.training - Example #3
2024-05-28 12:46:35,460 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:46:35,460 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:46:35,460 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'thing', 'to', 'do', 'with', 'the', 'f@@', 'ut@@', 'u@@', 're.', '</s>']
2024-05-28 12:46:35,460 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:46:35,463 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:46:35,467 - INFO - joeynmt.training - 	Hypothesis: The first thing to do with the future.
2024-05-28 12:46:35,490 - INFO - joeynmt.training - Example #4
2024-05-28 12:46:35,619 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:46:35,620 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:46:35,620 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'thing', 'I', 'want', 'to', 'do', 'to', 'be', 'a', 'little', 'bit', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'worl@@', 'd.', '</s>']
2024-05-28 12:46:35,620 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:46:35,706 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:46:35,754 - INFO - joeynmt.training - 	Hypothesis: The first of the best of the best thing I want to do to be a little bit of the best of the best of the world.
2024-05-28 12:46:39,573 - INFO - joeynmt.training - Epoch   2, Step:     7600, Batch Loss:     2.425778, Batch Acc: 0.303027, Tokens per Sec:    15949, Lr: 0.000300
2024-05-28 12:46:43,411 - INFO - joeynmt.training - Epoch   2, Step:     7700, Batch Loss:     2.303398, Batch Acc: 0.302995, Tokens per Sec:    18754, Lr: 0.000300
2024-05-28 12:46:47,413 - INFO - joeynmt.training - Epoch   2, Step:     7800, Batch Loss:     2.265242, Batch Acc: 0.306012, Tokens per Sec:    17944, Lr: 0.000300
2024-05-28 12:46:51,433 - INFO - joeynmt.training - Epoch   2, Step:     7900, Batch Loss:     2.275088, Batch Acc: 0.313393, Tokens per Sec:    17409, Lr: 0.000300
2024-05-28 12:46:55,545 - INFO - joeynmt.training - Epoch   2, Step:     8000, Batch Loss:     2.301592, Batch Acc: 0.315795, Tokens per Sec:    17482, Lr: 0.000300
2024-05-28 12:46:55,566 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:46:55,673 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:47:24,454 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.39, ppl:  10.86, acc:   0.31, generation: 28.7284[sec], evaluation: 0.0000[sec]
2024-05-28 12:47:24,477 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:47:24,572 - INFO - joeynmt.helpers - delete models/bpe-subword/5500.ckpt
2024-05-28 12:47:24,680 - INFO - joeynmt.training - Example #0
2024-05-28 12:47:24,749 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:47:24,749 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:47:24,749 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'thing', 'I', 'was', 'the', 'first', 'time', 'of', 'these', 'things', 'that', 'the', 'first', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'first', 'time', 'of', 'the', '1@@', '00', 'mil@@', 'lion', 'years', 'ag@@', 'o,', 'the', '1@@', '00', 'mil@@', 'lion', 'dol@@', 'lar@@', 's', 'of', 'the', '1@@', '00', 'mil@@', 'lion', 'dol@@', 'lar@@', 's', 'in', 'the', '1@@', '00', 'mil@@', 'lion', 'dol@@', 'lar@@', 's', 'in', 'the', '19@@', 'th', 'cent@@', 'ur@@', 'y.', '</s>']
2024-05-28 12:47:24,750 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:47:24,887 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:47:24,982 - INFO - joeynmt.training - 	Hypothesis: The first thing I was the first time of these things that the first future of the future of the future of the first time of the 100 million years ago, the 100 million dollars of the 100 million dollars in the 100 million dollars in the 19th century.
2024-05-28 12:47:25,028 - INFO - joeynmt.training - Example #1
2024-05-28 12:47:25,032 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:47:25,032 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:47:25,032 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'other', 'things', 'that', 'is', 'that', 'the', 'other', 'other', 'thing@@', 's,', 'but', "it's", 'not', 'the', 'b@@', 'est', 'of', 'the', 'bra@@', 'in.', '</s>']
2024-05-28 12:47:25,032 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:47:25,036 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:47:25,057 - INFO - joeynmt.training - 	Hypothesis: But this is the future of the other things that is that the other other things, but it's not the best of the brain.
2024-05-28 12:47:25,061 - INFO - joeynmt.training - Example #2
2024-05-28 12:47:25,065 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:47:25,065 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:47:25,065 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'f@@', 'ut@@', 'ure', 'is', 'a', 'very', 'f@@', 'ar', 'in', 'a', 'con@@', 'sum@@', 'p@@', 'tion', 'of', 'the', 'worl@@', 'd,', 'the', 'worl@@', 'd.', '</s>']
2024-05-28 12:47:25,065 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:47:25,069 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:47:25,097 - INFO - joeynmt.training - 	Hypothesis: The future is a very far in a consumption of the world, the world.
2024-05-28 12:47:25,100 - INFO - joeynmt.training - Example #3
2024-05-28 12:47:25,104 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:47:25,104 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:47:25,104 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'st@@', 'ate', 'of', 'the', 'f@@', 'ut@@', 'ure', 'and', 'the', 'f@@', 'ut@@', 'ure', 'and', 'the', 'b@@', 'est', 'st@@', 'and@@', 'ar@@', 'd.', '</s>']
2024-05-28 12:47:25,105 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:47:25,108 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:47:25,112 - INFO - joeynmt.training - 	Hypothesis: The first state of the future and the future and the best standard.
2024-05-28 12:47:25,115 - INFO - joeynmt.training - Example #4
2024-05-28 12:47:25,119 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:47:25,119 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:47:25,119 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'st@@', 'ory', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'other', 'thing', 'you', 'can', 'do', 'a', 'c@@', 'ou@@', 'ple', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', '1@@', '00', 'years', 'ag@@', 'o,', '1@@', ',@@', '00@@', '0@@', '-@@', 'year@@', '-@@', 'old', 'year@@', '-@@', 'old', 'year@@', '-@@', 'old', 'year@@', '.', '</s>']
2024-05-28 12:47:25,120 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:47:25,123 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:47:25,126 - INFO - joeynmt.training - 	Hypothesis: The first story of the future of the other thing you can do a couple of the future of the 100 years ago, 1,000-year-old year-old year-old year.
2024-05-28 12:47:29,076 - INFO - joeynmt.training - Epoch   2, Step:     8100, Batch Loss:     2.246352, Batch Acc: 0.318511, Tokens per Sec:    15797, Lr: 0.000300
2024-05-28 12:47:33,171 - INFO - joeynmt.training - Epoch   2, Step:     8200, Batch Loss:     2.423348, Batch Acc: 0.318002, Tokens per Sec:    17241, Lr: 0.000300
2024-05-28 12:47:36,949 - INFO - joeynmt.training - Epoch   2, Step:     8300, Batch Loss:     2.239882, Batch Acc: 0.317264, Tokens per Sec:    19076, Lr: 0.000300
2024-05-28 12:47:40,672 - INFO - joeynmt.training - Epoch   2, Step:     8400, Batch Loss:     2.325734, Batch Acc: 0.320919, Tokens per Sec:    19902, Lr: 0.000300
2024-05-28 12:47:44,421 - INFO - joeynmt.training - Epoch   2, Step:     8500, Batch Loss:     2.322283, Batch Acc: 0.322409, Tokens per Sec:    19055, Lr: 0.000300
2024-05-28 12:47:44,425 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:47:44,428 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:48:03,116 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.35, ppl:  10.53, acc:   0.32, generation: 18.6686[sec], evaluation: 0.0000[sec]
2024-05-28 12:48:03,136 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:48:03,230 - INFO - joeynmt.helpers - delete models/bpe-subword/6000.ckpt
2024-05-28 12:48:03,245 - INFO - joeynmt.training - Example #0
2024-05-28 12:48:03,264 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:48:03,264 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:48:03,264 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'thing', 'I', 'was', 'in', 'this', 'p@@', 'ho@@', 'to@@', 'grap@@', 'h@@', 'y', 'to', 'the', 'p@@', 'ati@@', 'ent', 'of', 'the', 'p@@', 'ati@@', 'ent', 'of', 'the', 'p@@', 'ati@@', 'ent', 'of', 'the', 'worl@@', 'd,', 'in', 'the', 'last', '1@@', '00', 'year@@', 's,', 'the', 'first', 'tim@@', 'e,', 'the', 'first', 'time', 'in', 'the', 'last', '1@@', '0@@', ',', 'the', 'first', 'tim@@', 'e.', '</s>']
2024-05-28 12:48:03,265 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:48:03,269 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:48:03,272 - INFO - joeynmt.training - 	Hypothesis: The first thing I was in this photography to the patient of the patient of the patient of the world, in the last 100 years, the first time, the first time in the last 10, the first time.
2024-05-28 12:48:03,276 - INFO - joeynmt.training - Example #1
2024-05-28 12:48:03,280 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:48:03,280 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:48:03,280 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'st@@', 're@@', 'et', 'of', 'this', 'is', 'the', 'most', 'important', 'thing', 'that', 'is', 'not', 'the', 'most', 'important', 'thing', 'that', 'is', 'not', 'going', 'to', 'be', 'the', 'p@@', 'ati@@', 'ent@@', 's.', '</s>']
2024-05-28 12:48:03,281 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:48:03,298 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:48:03,394 - INFO - joeynmt.training - 	Hypothesis: But this is the street of this is the most important thing that is not the most important thing that is not going to be the patients.
2024-05-28 12:48:03,431 - INFO - joeynmt.training - Example #2
2024-05-28 12:48:03,475 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:48:03,475 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:48:03,475 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'p@@', 'ho@@', 'to@@', 'grap@@', 'h@@', 's', 'of', 'a', 'little', 'bit', 'of', 'a', 'b@@', 'ea@@', 'u@@', 'ti@@', 'ful', 'con@@', 'vers@@', 'ation', 'of', 'our', 'worl@@', 'd.', '</s>']
2024-05-28 12:48:03,476 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:48:03,495 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:48:03,527 - INFO - joeynmt.training - 	Hypothesis: The photographs of a little bit of a beautiful conversation of our world.
2024-05-28 12:48:03,653 - INFO - joeynmt.training - Example #3
2024-05-28 12:48:03,679 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:48:03,679 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:48:03,679 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'a', 'little', 'bit', 'of', 'the', 'p@@', 'ati@@', 'ents', 'and', 'the', 'p@@', 'aren@@', 't@@', 's.', '</s>']
2024-05-28 12:48:03,680 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:48:03,735 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:48:03,738 - INFO - joeynmt.training - 	Hypothesis: It was a little bit of the patients and the parents.
2024-05-28 12:48:03,742 - INFO - joeynmt.training - Example #4
2024-05-28 12:48:03,745 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:48:03,745 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:48:03,745 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'b@@', 'est', 'thing', 'is', 'that', 'I', 'want', 'to', 'do', 'with', 'a', 'little', 'bit', 'of', 'a', 'little', 'bit', 'of', 'the', 'p@@', 'ast', 'to', 'the', 'first', 'time', 'to', 'the', 'first', 'time', 'to', 'the', '19@@', '9@@', '0@@', '.', '</s>']
2024-05-28 12:48:03,746 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:48:03,749 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:48:03,752 - INFO - joeynmt.training - 	Hypothesis: The best thing is that I want to do with a little bit of a little bit of the past to the first time to the first time to the 1990.
2024-05-28 12:48:07,304 - INFO - joeynmt.training - Epoch   2, Step:     8600, Batch Loss:     2.370276, Batch Acc: 0.324797, Tokens per Sec:    17067, Lr: 0.000300
2024-05-28 12:48:10,984 - INFO - joeynmt.training - Epoch   2, Step:     8700, Batch Loss:     2.401380, Batch Acc: 0.324129, Tokens per Sec:    19363, Lr: 0.000300
2024-05-28 12:48:14,959 - INFO - joeynmt.training - Epoch   2, Step:     8800, Batch Loss:     2.230227, Batch Acc: 0.322612, Tokens per Sec:    18041, Lr: 0.000300
2024-05-28 12:48:19,099 - INFO - joeynmt.training - Epoch   2, Step:     8900, Batch Loss:     2.431576, Batch Acc: 0.327739, Tokens per Sec:    16920, Lr: 0.000300
2024-05-28 12:48:23,127 - INFO - joeynmt.training - Epoch   2, Step:     9000, Batch Loss:     2.252256, Batch Acc: 0.329556, Tokens per Sec:    17454, Lr: 0.000300
2024-05-28 12:48:23,132 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:48:23,135 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:48:45,961 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.33, ppl:  10.29, acc:   0.32, generation: 22.8046[sec], evaluation: 0.0000[sec]
2024-05-28 12:48:46,041 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:48:46,171 - INFO - joeynmt.helpers - delete models/bpe-subword/6500.ckpt
2024-05-28 12:48:46,212 - INFO - joeynmt.training - Example #0
2024-05-28 12:48:46,217 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:48:46,217 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:48:46,217 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'was', 'I', 'was', 'the', 'same', 's@@', 'ha@@', 'red', 'to', 'these', 'st@@', 're@@', 'et', 'to', 'the', 's@@', 'am@@', 'ple', 'of', 'the', 'f@@', 'ut@@', 'u@@', 're,', 'the', 'most', 'f@@', 'our', 'bil@@', 'lion', 'dol@@', 'lar@@', 's', 'in', 'the', 'last', 'few', 'years', 'ag@@', 'o,', 'the', 'same', 'tim@@', 'e,', 'the', 'most', 'f@@', 'our', 'bil@@', 'lion', 'dol@@', 'lar@@', 's', 'in', 'the', 'last', '1@@', '0@@', ',', 'the', 'f@@', 'our', 'bil@@', 'lion', 'dol@@', 'lar@@', 's', 'in', 'the', 'last', 'f@@', 'our', 'bil@@', 'lion', 'dol@@', 'lar@@', 's', 'of', 'the', 'f@@', 'ut@@', 'u@@', 're.', '</s>']
2024-05-28 12:48:46,218 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:48:46,221 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:48:46,225 - INFO - joeynmt.training - 	Hypothesis: The first was I was the same shared to these street to the sample of the future, the most four billion dollars in the last few years ago, the same time, the most four billion dollars in the last 10, the four billion dollars in the last four billion dollars of the future.
2024-05-28 12:48:46,228 - INFO - joeynmt.training - Example #1
2024-05-28 12:48:46,232 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:48:46,232 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:48:46,232 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'in@@', 'ten@@', 'tion', 'of', 'these', 'problem@@', 's', 'are', 'not', 'the', 'problem@@', 's', 'of', 'the', 'problem@@', ',', 'which', 'is', 'not', 'the', 'same', 'st@@', 're@@', 'et', 'of', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:48:46,232 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:48:46,255 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:48:46,279 - INFO - joeynmt.training - 	Hypothesis: But this is the intention of these problems are not the problems of the problem, which is not the same street of the same.
2024-05-28 12:48:46,283 - INFO - joeynmt.training - Example #2
2024-05-28 12:48:46,286 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:48:46,286 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:48:46,286 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'in@@', 'vest@@', 'ment', 'of', 'the', 'f@@', 'ut@@', 'u@@', 're,', 'the', 'in@@', 'cl@@', 'u@@', 'ding', 'that', 'the', 'world', 'is', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'technolog@@', 'y.', '</s>']
2024-05-28 12:48:46,287 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:48:46,290 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:48:46,294 - INFO - joeynmt.training - 	Hypothesis: The investment of the future, the including that the world is the world of the world of the world of technology.
2024-05-28 12:48:46,297 - INFO - joeynmt.training - Example #3
2024-05-28 12:48:46,300 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:48:46,300 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:48:46,300 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'ned', 'out', 'the', 'st@@', 're@@', 'et', 'and', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:48:46,301 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:48:46,305 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:48:46,308 - INFO - joeynmt.training - 	Hypothesis: It turned out the street and the same.
2024-05-28 12:48:46,312 - INFO - joeynmt.training - Example #4
2024-05-28 12:48:46,447 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:48:46,447 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:48:46,447 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'st@@', 're@@', 'et', 'of', 'the', 's@@', 'itu@@', 'ation', 'that', 'you', 'would', 'have', 'to', 'be', 'a', 'st@@', 'ory', 'to', 'be', 'a', 'st@@', 're@@', 'et', 'in', 'the', 'last', '1@@', '0@@', ',', 'the', 'last', '1@@', '0@@', ',', 'in', 'the', 'last', '1@@', '0@@', '.', '</s>']
2024-05-28 12:48:46,448 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:48:46,550 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:48:46,640 - INFO - joeynmt.training - 	Hypothesis: The street of the situation that you would have to be a story to be a street in the last 10, the last 10, in the last 10.
2024-05-28 12:48:49,692 - INFO - joeynmt.training - Epoch   2: total training loss 11012.77
2024-05-28 12:48:49,735 - INFO - joeynmt.training - EPOCH 3
2024-05-28 12:48:49,989 - INFO - joeynmt.training - Epoch   3, Step:     9100, Batch Loss:     2.298250, Batch Acc: 0.328090, Tokens per Sec:    20116, Lr: 0.000300
2024-05-28 12:48:53,698 - INFO - joeynmt.training - Epoch   3, Step:     9200, Batch Loss:     2.206046, Batch Acc: 0.337937, Tokens per Sec:    18361, Lr: 0.000300
2024-05-28 12:48:57,330 - INFO - joeynmt.training - Epoch   3, Step:     9300, Batch Loss:     2.371073, Batch Acc: 0.337474, Tokens per Sec:    19971, Lr: 0.000300
2024-05-28 12:49:00,571 - INFO - joeynmt.training - Epoch   3, Step:     9400, Batch Loss:     2.213151, Batch Acc: 0.339614, Tokens per Sec:    22626, Lr: 0.000300
2024-05-28 12:49:04,208 - INFO - joeynmt.training - Epoch   3, Step:     9500, Batch Loss:     2.259947, Batch Acc: 0.340104, Tokens per Sec:    19526, Lr: 0.000300
2024-05-28 12:49:04,308 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:49:04,335 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:49:34,479 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.31, ppl:  10.08, acc:   0.33, generation: 30.0787[sec], evaluation: 0.0000[sec]
2024-05-28 12:49:34,484 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:49:34,602 - INFO - joeynmt.helpers - delete models/bpe-subword/7000.ckpt
2024-05-28 12:49:34,660 - INFO - joeynmt.training - Example #0
2024-05-28 12:49:34,718 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:49:34,718 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:49:34,718 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'thing', 'I', 'was', 'the', 'same', 'st@@', 'ory', 'of', 'these', 're@@', 'ce@@', 'i@@', 'ved', 'to', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'first', 'time', 'was', 'the', 'first', 'three', 'mil@@', 'lion', 'years', 'ag@@', 'o', 'was', 'the', 'last', '10', 'year@@', 's,', 'was', '1@@', '5', 'mil@@', 'lion', 'years', 'ag@@', 'o.', '</s>']
2024-05-28 12:49:34,719 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:49:34,800 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:49:34,840 - INFO - joeynmt.training - 	Hypothesis: The first thing I was the same story of these received to the best of the best of the first time was the first three million years ago was the last 10 years, was 15 million years ago.
2024-05-28 12:49:34,906 - INFO - joeynmt.training - Example #1
2024-05-28 12:49:34,923 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:49:34,923 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:49:34,923 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'that', 'this', 'con@@', 'cep@@', 't', 'of', 'this', 'is', 'the', 'most', 'important', 'thing', 'that', 'is', 'not', 'the', 'same', 'as', 'a', 'm@@', 'ach@@', 'in@@', 'e.', '</s>']
2024-05-28 12:49:34,923 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:49:34,971 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:49:35,006 - INFO - joeynmt.training - 	Hypothesis: But this is that this concept of this is the most important thing that is not the same as a machine.
2024-05-28 12:49:35,047 - INFO - joeynmt.training - Example #2
2024-05-28 12:49:35,060 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:49:35,060 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:49:35,060 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'b@@', 'est', 'r@@', 'ang@@', 'e', 'of', 'the', 'b@@', 'est', 'that', 'has', 'a', 'glob@@', 'al', 'con@@', 'nec@@', 'tion', 'of', 'the', 'glob@@', 'al', 'of', 'the', 'glob@@', 'al', 'worl@@', 'd.', '</s>']
2024-05-28 12:49:35,060 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:49:35,064 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:49:35,068 - INFO - joeynmt.training - 	Hypothesis: The best range of the best that has a global connection of the global of the global world.
2024-05-28 12:49:35,091 - INFO - joeynmt.training - Example #3
2024-05-28 12:49:35,094 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:49:35,094 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:49:35,094 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'n@@', 's', 'out', 'of', 'the', 'b@@', 'est', 'and', 'the', 'st@@', 're@@', 'et', 'and', 'the', 'b@@', 'est', 'and', 'the', 'b@@', 'est', 'of', 'the', 'w@@', 'in@@', 'do@@', '.', '</s>']
2024-05-28 12:49:35,095 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:49:35,100 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:49:35,155 - INFO - joeynmt.training - 	Hypothesis: It turns out of the best and the street and the best and the best of the windo.
2024-05-28 12:49:35,159 - INFO - joeynmt.training - Example #4
2024-05-28 12:49:35,163 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:49:35,163 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:49:35,163 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'sec@@', 'ond', 're@@', 't@@', 't@@', 'on', 'that', 'the', 'st@@', 'ory', 'that', 'you', 'would', 'have', 'a', 'little', 'bit', 'of', 'what', 'you', 'can', 'do', 'with', 'the', 'last', 'f@@', 'our', 'years', 'ag@@', 'o.', '</s>']
2024-05-28 12:49:35,164 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:49:35,179 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:49:35,183 - INFO - joeynmt.training - 	Hypothesis: The second retton that the story that you would have a little bit of what you can do with the last four years ago.
2024-05-28 12:49:39,144 - INFO - joeynmt.training - Epoch   3, Step:     9600, Batch Loss:     2.308554, Batch Acc: 0.336501, Tokens per Sec:    15308, Lr: 0.000300
2024-05-28 12:49:43,014 - INFO - joeynmt.training - Epoch   3, Step:     9700, Batch Loss:     2.303213, Batch Acc: 0.345516, Tokens per Sec:    18406, Lr: 0.000300
2024-05-28 12:49:47,155 - INFO - joeynmt.training - Epoch   3, Step:     9800, Batch Loss:     2.263839, Batch Acc: 0.343570, Tokens per Sec:    17270, Lr: 0.000300
2024-05-28 12:49:51,298 - INFO - joeynmt.training - Epoch   3, Step:     9900, Batch Loss:     2.228251, Batch Acc: 0.350868, Tokens per Sec:    17269, Lr: 0.000300
2024-05-28 12:49:55,397 - INFO - joeynmt.training - Epoch   3, Step:    10000, Batch Loss:     2.326843, Batch Acc: 0.346710, Tokens per Sec:    17050, Lr: 0.000300
2024-05-28 12:49:55,514 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:49:55,569 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:50:21,881 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.29, ppl:   9.84, acc:   0.34, generation: 26.2336[sec], evaluation: 0.0000[sec]
2024-05-28 12:50:21,910 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:50:22,006 - INFO - joeynmt.helpers - delete models/bpe-subword/7500.ckpt
2024-05-28 12:50:22,120 - INFO - joeynmt.training - Example #0
2024-05-28 12:50:22,180 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:50:22,180 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:50:22,180 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'was', 'the', 'most', 'of', 'these', 'two', 'of', 'these', 'c@@', 'y@@', 'cl@@', 'ing', 'to', 'the', 'f@@', 'ut@@', 'u@@', 're,', 'the', 'most', 'of', 'the', 'most', 'of', 'the', 'most', 'of', 'the', 'most', 'of', 'the', 'most', 'of', 'the', 'most', 'f@@', 'our', 'mil@@', 'lion', 'years', 'ag@@', 'o', 'was', '1@@', '00', 'mil@@', 'lion', 'dol@@', 'lar@@', 's', 'of', 'the', 'mil@@', 'lion', 'dol@@', 'lar@@', 's', 'in', 'the', '1@@', '8@@', 'th', 'cent@@', 'ur@@', 'y.', '</s>']
2024-05-28 12:50:22,180 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:50:22,229 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:50:22,253 - INFO - joeynmt.training - 	Hypothesis: The first was the most of these two of these cycling to the future, the most of the most of the most of the most of the most of the most four million years ago was 100 million dollars of the million dollars in the 18th century.
2024-05-28 12:50:22,297 - INFO - joeynmt.training - Example #1
2024-05-28 12:50:22,354 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:50:22,354 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:50:22,354 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'that', 'this', 'in@@', 'cl@@', 'u@@', 'ding', 'the', 'most', 'important', 'is', 'that', 'the', 'most', 'important', 'is', 'that', 'the', 'most', 'of', 'the', 'most', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'st@@', 'or@@', 'y.', '</s>']
2024-05-28 12:50:22,355 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:50:22,398 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:50:22,465 - INFO - joeynmt.training - 	Hypothesis: But this is that this including the most important is that the most important is that the most of the most of the best of the best of the best of the best of the story.
2024-05-28 12:50:22,538 - INFO - joeynmt.training - Example #2
2024-05-28 12:50:22,632 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:50:22,633 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:50:22,633 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'b@@', 'est', 'r@@', 'ul@@', 'es,', 'in', 'a', 'c@@', 'ou@@', 'ple', 'of', 'a', 'new', 'new', 'new', 'that', 'the', 'glob@@', 'al', 'worl@@', 'd@@', "'s", 'glob@@', 'al', 'system@@', '.', '</s>']
2024-05-28 12:50:22,633 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:50:22,656 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:50:22,660 - INFO - joeynmt.training - 	Hypothesis: The best rules, in a couple of a new new new that the global world's global system.
2024-05-28 12:50:22,663 - INFO - joeynmt.training - Example #3
2024-05-28 12:50:22,667 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:50:22,667 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:50:22,667 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['They', 'are', 'the', 'b@@', 'est', 'and', 'the', 'b@@', 'est', 'and', 'the', 'b@@', 'est', 'and', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'it.', '</s>']
2024-05-28 12:50:22,667 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:50:22,670 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:50:22,674 - INFO - joeynmt.training - 	Hypothesis: They are the best and the best and the best and the best of the best of it.
2024-05-28 12:50:22,677 - INFO - joeynmt.training - Example #4
2024-05-28 12:50:22,681 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:50:22,681 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:50:22,681 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'sec@@', 'ond', 'is', 'the', 'f@@', 'ut@@', 'u@@', 're,', 'who', 'would', 'have', 'a', 'little', 'bit', 'of', 'the', 'b@@', 'est', 'to', 'the', 'f@@', 'ut@@', 'ure', 'of', 'what', 'happen@@', 'ed', 'in', 'the', 'last', '1@@', '00', 'years', 'ag@@', 'o.', '</s>']
2024-05-28 12:50:22,681 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:50:22,713 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:50:22,716 - INFO - joeynmt.training - 	Hypothesis: The second is the future, who would have a little bit of the best to the future of what happened in the last 100 years ago.
2024-05-28 12:50:26,525 - INFO - joeynmt.training - Epoch   3, Step:    10100, Batch Loss:     2.186604, Batch Acc: 0.345903, Tokens per Sec:    14800, Lr: 0.000300
2024-05-28 12:50:30,472 - INFO - joeynmt.training - Epoch   3, Step:    10200, Batch Loss:     2.248778, Batch Acc: 0.349410, Tokens per Sec:    17957, Lr: 0.000300
2024-05-28 12:50:34,455 - INFO - joeynmt.training - Epoch   3, Step:    10300, Batch Loss:     2.203476, Batch Acc: 0.352293, Tokens per Sec:    18002, Lr: 0.000300
2024-05-28 12:50:37,930 - INFO - joeynmt.training - Epoch   3, Step:    10400, Batch Loss:     2.301474, Batch Acc: 0.356229, Tokens per Sec:    20739, Lr: 0.000300
2024-05-28 12:50:41,457 - INFO - joeynmt.training - Epoch   3, Step:    10500, Batch Loss:     2.250273, Batch Acc: 0.357618, Tokens per Sec:    20672, Lr: 0.000300
2024-05-28 12:50:41,526 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:50:41,544 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:51:10,909 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.25, ppl:   9.46, acc:   0.35, generation: 29.3429[sec], evaluation: 0.0000[sec]
2024-05-28 12:51:10,914 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:51:11,010 - INFO - joeynmt.helpers - delete models/bpe-subword/8000.ckpt
2024-05-28 12:51:11,065 - INFO - joeynmt.training - Example #0
2024-05-28 12:51:11,080 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:51:11,080 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:51:11,080 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'thing', 'I', 'was', 'the', 'same', 's@@', 'am@@', 'ed', 'for', 'these', 's@@', 'am@@', 'e,', 'for', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'b@@', 'est', 'in', 'the', 'last', 'y@@', 'ear', 'of', 'the', 'last', 'year@@', ',', 'the', 'last', 'year@@', ',', 'the', 'last', 'year@@', ',', 'the', 'last', 'year@@', ',', 'the', 'last', 'year@@', ',', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'is@@', 'h@@', '.', '</s>']
2024-05-28 12:51:11,081 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:51:11,154 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:51:11,239 - INFO - joeynmt.training - 	Hypothesis: The first thing I was the same samed for these same, for the future of the best in the last year of the last year, the last year, the last year, the last year, the last year, the future of the future of the future of the future of the future of the future of the future of the future of the future of the future of the fish.
2024-05-28 12:51:11,275 - INFO - joeynmt.training - Example #1
2024-05-28 12:51:11,334 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:51:11,335 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:51:11,335 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'problem@@', 's', 'of', 'the', 'problem@@', 's', 'of', 'these', 'problem@@', 's', 'are', 'not', 'the', 'problem@@', 's', 'of', 'the', 'problem@@', 's', 'of', 'the', 'problem@@', 's', 'of', 'the', 'problem@@', '.', '</s>']
2024-05-28 12:51:11,335 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:51:11,361 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:51:11,383 - INFO - joeynmt.training - 	Hypothesis: But this is the problems of the problems of these problems are not the problems of the problems of the problems of the problem.
2024-05-28 12:51:11,387 - INFO - joeynmt.training - Example #2
2024-05-28 12:51:11,440 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:51:11,440 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:51:11,440 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'b@@', 'est', 'r@@', 'ul@@', 'e,', 'a', 'b@@', 'ea@@', 'u@@', 'ti@@', 'ful', 'system@@', ',', 'which', 'is', 'the', 'glob@@', 'al', 'system@@', 's', 'of', 'the', 'glob@@', 'al', 'system@@', '.', '</s>']
2024-05-28 12:51:11,441 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:51:11,488 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:51:11,497 - INFO - joeynmt.training - 	Hypothesis: The best rule, a beautiful system, which is the global systems of the global system.
2024-05-28 12:51:11,501 - INFO - joeynmt.training - Example #3
2024-05-28 12:51:11,504 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:51:11,504 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:51:11,504 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'is', 'the', 'b@@', 'est', 'way', 'to', 're@@', 'ach', 'the', 'b@@', 'est', 'st@@', 'or@@', 'y.', '</s>']
2024-05-28 12:51:11,504 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:51:11,508 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:51:11,512 - INFO - joeynmt.training - 	Hypothesis: It is the best way to reach the best story.
2024-05-28 12:51:11,515 - INFO - joeynmt.training - Example #4
2024-05-28 12:51:11,520 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:51:11,520 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:51:11,520 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'sec@@', 'ond', 'thing', 'that', 'you', 'can', 'see', 'that', 'you', 'would', 'have', 'a', 'little', 'bit', 'of', 'a', 'b@@', 'ea@@', 'u@@', 'ti@@', 'ful', 'st@@', 'ic', 'st@@', 're@@', 'et', 'in', 'the', 'last', '1@@', '0@@', ',000', 'year@@', 's.', '</s>']
2024-05-28 12:51:11,520 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:51:11,574 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:51:11,622 - INFO - joeynmt.training - 	Hypothesis: The second thing that you can see that you would have a little bit of a beautiful stic street in the last 10,000 years.
2024-05-28 12:51:14,896 - INFO - joeynmt.training - Epoch   3, Step:    10600, Batch Loss:     2.153178, Batch Acc: 0.354699, Tokens per Sec:    17599, Lr: 0.000300
2024-05-28 12:51:18,697 - INFO - joeynmt.training - Epoch   3, Step:    10700, Batch Loss:     2.167825, Batch Acc: 0.356320, Tokens per Sec:    18197, Lr: 0.000300
2024-05-28 12:51:22,680 - INFO - joeynmt.training - Epoch   3, Step:    10800, Batch Loss:     2.114277, Batch Acc: 0.359325, Tokens per Sec:    18140, Lr: 0.000300
2024-05-28 12:51:26,755 - INFO - joeynmt.training - Epoch   3, Step:    10900, Batch Loss:     2.107193, Batch Acc: 0.355965, Tokens per Sec:    17629, Lr: 0.000300
2024-05-28 12:51:30,843 - INFO - joeynmt.training - Epoch   3, Step:    11000, Batch Loss:     2.018386, Batch Acc: 0.363324, Tokens per Sec:    17322, Lr: 0.000300
2024-05-28 12:51:30,848 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:51:30,853 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:52:16,973 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.24, ppl:   9.35, acc:   0.35, generation: 46.0983[sec], evaluation: 0.0000[sec]
2024-05-28 12:52:16,985 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:52:17,078 - INFO - joeynmt.helpers - delete models/bpe-subword/8500.ckpt
2024-05-28 12:52:17,162 - INFO - joeynmt.training - Example #0
2024-05-28 12:52:17,177 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:52:17,177 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:52:17,177 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'time', 'I', 'was', 'the', 'two', 'of', 'these', 'two', 'of', 'the', 'b@@', 'est', 'to', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'bi@@', 'gg@@', 'est', 'of', 'the', 'most', 'b@@', 'est', 'b@@', 'est', 'mil@@', 'lion', 'dol@@', 'lar@@', 's', 'in', 'the', 'last', 'mil@@', 'lion', 'dol@@', 'lar@@', 's', 'in', 'the', 'ro@@', 'om@@', ',', 'the', 'mil@@', 'it@@', 'ary', 're@@', 'sear@@', 'ch@@', ',', 'the', 'b@@', 'est', 'b@@', 'ro@@', 'k@@', 'en', 'of', 'the', 's@@', 'ha@@', 'red', 'three', 'or', 'three', 'or', 'mil@@', 'lion', 'dol@@', 'lar@@', 's', 'in', 'the', 'ro@@', 'om@@', '.', '</s>']
2024-05-28 12:52:17,177 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:52:17,181 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:52:17,184 - INFO - joeynmt.training - 	Hypothesis: The first time I was the two of these two of the best to the best of the best of the best of the biggest of the most best best million dollars in the last million dollars in the room, the military research, the best broken of the shared three or three or million dollars in the room.
2024-05-28 12:52:17,188 - INFO - joeynmt.training - Example #1
2024-05-28 12:52:17,192 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:52:17,192 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:52:17,192 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'in@@', 'no@@', 'v@@', 'ation', 'of', 'the', 'problem@@', 's', 'of', 'the', 'problem@@', 's', 'of', 'the', 'problem@@', 's', 'of', 'the', 'most', 'important', 'of', 'the', 'b@@', 'est', 'r@@', 'ul@@', 'e', 'of', 'the', 'b@@', 'est', 'r@@', 'ul@@', 'es.', '</s>']
2024-05-28 12:52:17,192 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:52:17,197 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:52:17,201 - INFO - joeynmt.training - 	Hypothesis: But this is the innovation of the problems of the problems of the problems of the most important of the best rule of the best rules.
2024-05-28 12:52:17,204 - INFO - joeynmt.training - Example #2
2024-05-28 12:52:17,208 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:52:17,208 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:52:17,208 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'B@@', 'r@@', 'it@@', 'is@@', 'h', 'is', 'the', 'b@@', 'est', 'that', 'in', 'a', 'n@@', 'ur@@', 'se', 'of', 'the', 'plan@@', 'et', 'system@@', '.', '</s>']
2024-05-28 12:52:17,208 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:52:17,240 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:52:17,316 - INFO - joeynmt.training - 	Hypothesis: The British is the best that in a nurse of the planet system.
2024-05-28 12:52:17,399 - INFO - joeynmt.training - Example #3
2024-05-28 12:52:17,437 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:52:17,437 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:52:17,437 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'the', 'b@@', 'est', 'and', 'the', 'b@@', 'est', 'and', 'the', 'st@@', 'ate', 'of', 'the', 'st@@', 're@@', 'et@@', 's.', '</s>']
2024-05-28 12:52:17,438 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:52:17,499 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:52:17,633 - INFO - joeynmt.training - 	Hypothesis: It was the best and the best and the state of the streets.
2024-05-28 12:52:17,692 - INFO - joeynmt.training - Example #4
2024-05-28 12:52:17,770 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:52:17,770 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:52:17,770 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'U@@', '.@@', 'S@@', '.', 'I', 'will', 'be', 'the', 'st@@', 'ate', 'that', 'you', 'have', 'a', 'b@@', 'ea@@', 'u@@', 'ti@@', 'ful', 'st@@', '-@@', 's@@', 'ha@@', 'red', 'st@@', 'ate', 'in', 'the', 'last', '1@@', '5', 'years', 'ag@@', 'o,', '</s>']
2024-05-28 12:52:17,771 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:52:17,802 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:52:17,826 - INFO - joeynmt.training - 	Hypothesis: The U.S. I will be the state that you have a beautiful st-shared state in the last 15 years ago,
2024-05-28 12:52:21,903 - INFO - joeynmt.training - Epoch   3, Step:    11100, Batch Loss:     2.147884, Batch Acc: 0.359796, Tokens per Sec:    14919, Lr: 0.000300
2024-05-28 12:52:25,935 - INFO - joeynmt.training - Epoch   3, Step:    11200, Batch Loss:     2.106319, Batch Acc: 0.362137, Tokens per Sec:    17811, Lr: 0.000300
2024-05-28 12:52:29,931 - INFO - joeynmt.training - Epoch   3, Step:    11300, Batch Loss:     2.221950, Batch Acc: 0.365750, Tokens per Sec:    18308, Lr: 0.000300
2024-05-28 12:52:33,711 - INFO - joeynmt.training - Epoch   3, Step:    11400, Batch Loss:     2.271118, Batch Acc: 0.363961, Tokens per Sec:    19271, Lr: 0.000300
2024-05-28 12:52:37,537 - INFO - joeynmt.training - Epoch   3, Step:    11500, Batch Loss:     2.279639, Batch Acc: 0.374819, Tokens per Sec:    19236, Lr: 0.000300
2024-05-28 12:52:37,542 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:52:37,546 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:53:24,646 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.21, ppl:   9.14, acc:   0.36, generation: 47.0767[sec], evaluation: 0.0000[sec]
2024-05-28 12:53:24,650 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:53:24,740 - INFO - joeynmt.helpers - delete models/bpe-subword/9000.ckpt
2024-05-28 12:53:24,754 - INFO - joeynmt.training - Example #0
2024-05-28 12:53:24,841 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:53:24,841 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:53:24,841 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'last', 'y@@', 'ear', 'I', 'was', 'the', 'most', 'f@@', 'un@@', 'ding', 'to', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'ar@@', 'd', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'dol@@', 'lar@@', 's', 'in', 'the', 'last', 'three', 'mil@@', 'lion', 'dol@@', 'lar@@', 's', 'in', 'the', 'last', '1@@', '0@@', ',000', 'dol@@', 'lar@@', 's', 'in', 'a', 'mil@@', 'lion', 'dol@@', 'lar@@', 's', 'in', 'a', 'mil@@', 'lion', 'dol@@', 'lar@@', 's', 'in', 'a', 'mil@@', 'lion', 'dol@@', 'lar@@', 's', 'in', 'a', 'mil@@', 'lion', 'dol@@', 'lar@@', 's', 'in', 'a', '1@@', '0@@', '-@@', 'year@@', '-@@', 'old', 'mil@@', 'lion', 'dol@@', 'lar@@', 's', 'a', 'mil@@', 'lion', 'dol@@', 'lar@@', 's', 'in', 'a', 'mil@@', 'lion', 'dol@@', 'lar@@', 's']
2024-05-28 12:53:24,841 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:53:24,869 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:53:24,903 - INFO - joeynmt.training - 	Hypothesis: And the last year I was the most funding to the best of the best of the bard of the best of the best of the last three million dollars in the last three million dollars in the last 10,000 dollars in a million dollars in a million dollars in a million dollars in a million dollars in a 10-year-old million dollars a million dollars in a million dollars
2024-05-28 12:53:24,971 - INFO - joeynmt.training - Example #1
2024-05-28 12:53:25,065 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:53:25,066 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:53:25,066 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'ex@@', 'p@@', 'ect@@', 's', 'of', 'the', 'same', 'problem@@', 's', 'of', 'these', 'problem@@', 's', 'are', 'not', 'the', 'same', 'thing@@', '.', '</s>']
2024-05-28 12:53:25,066 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:53:25,179 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:53:25,184 - INFO - joeynmt.training - 	Hypothesis: But this is the expects of the same problems of these problems are not the same thing.
2024-05-28 12:53:25,187 - INFO - joeynmt.training - Example #2
2024-05-28 12:53:25,204 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:53:25,204 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:53:25,204 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'of', 'pol@@', 'ice', 'is', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'glob@@', 'al', 'system@@', '.', '</s>']
2024-05-28 12:53:25,204 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:53:25,208 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:53:25,211 - INFO - joeynmt.training - 	Hypothesis: The police of police is the best of the best of the best of the future of the global system.
2024-05-28 12:53:25,214 - INFO - joeynmt.training - Example #3
2024-05-28 12:53:25,218 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:53:25,218 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:53:25,218 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 're@@', 'pres@@', 'ent@@', 'ation', 'and', 'the', 'b@@', 'est', 'st@@', 'or@@', 'y.', '</s>']
2024-05-28 12:53:25,218 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:53:25,222 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:53:25,225 - INFO - joeynmt.training - 	Hypothesis: She representation and the best story.
2024-05-28 12:53:25,230 - INFO - joeynmt.training - Example #4
2024-05-28 12:53:25,233 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:53:25,233 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:53:25,233 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'U@@', '.@@', 'S@@', '.', 'The', 'first', 'thing', 'that', 'I', 'would', 'have', 'a', 'little', 'bit', 'of', 'you', 'would', 'have', 'a', 'little', 'bit', 'of', 'the', 'last', 'f@@', 'ut@@', 'ure', 'of', 'what', 'it', 'was', 'the', 'last', '1@@', '0@@', ',000', 'years', 'ag@@', 'o.', '</s>']
2024-05-28 12:53:25,233 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:53:25,236 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:53:25,260 - INFO - joeynmt.training - 	Hypothesis: The U.S. The first thing that I would have a little bit of you would have a little bit of the last future of what it was the last 10,000 years ago.
2024-05-28 12:53:28,653 - INFO - joeynmt.training - Epoch   3, Step:    11600, Batch Loss:     2.107821, Batch Acc: 0.367995, Tokens per Sec:    17947, Lr: 0.000300
2024-05-28 12:53:31,593 - INFO - joeynmt.training - Epoch   3, Step:    11700, Batch Loss:     2.056442, Batch Acc: 0.365082, Tokens per Sec:    24202, Lr: 0.000300
2024-05-28 12:53:34,652 - INFO - joeynmt.training - Epoch   3, Step:    11800, Batch Loss:     2.115263, Batch Acc: 0.371938, Tokens per Sec:    23284, Lr: 0.000300
2024-05-28 12:53:38,490 - INFO - joeynmt.training - Epoch   3, Step:    11900, Batch Loss:     2.115296, Batch Acc: 0.373732, Tokens per Sec:    18597, Lr: 0.000300
2024-05-28 12:53:42,481 - INFO - joeynmt.training - Epoch   3, Step:    12000, Batch Loss:     2.138144, Batch Acc: 0.372733, Tokens per Sec:    18172, Lr: 0.000300
2024-05-28 12:53:42,509 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:53:42,618 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:54:15,668 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.18, ppl:   8.86, acc:   0.37, generation: 33.0115[sec], evaluation: 0.0000[sec]
2024-05-28 12:54:15,676 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:54:15,771 - INFO - joeynmt.helpers - delete models/bpe-subword/9500.ckpt
2024-05-28 12:54:15,806 - INFO - joeynmt.training - Example #0
2024-05-28 12:54:15,825 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:54:15,825 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:54:15,825 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'time', 'we', 'went', 'to', 'the', 'two', 'sec@@', 're@@', 't', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'worl@@', 'd@@', "'s", 'lar@@', 'g@@', 'est', 'bil@@', 'li@@', 'ons', 'of', 'mil@@', 'lion', 'years', 'ag@@', 'o', 'was', 'the', 'last', '20', 'year@@', 's,', 'the', 'p@@', 'ap@@', 'er', 'than', '4@@', '00', 'mil@@', 'lion', 'years', 'ag@@', 'o,', 'the', 'f@@', 'our', 'bil@@', 'lion', 'years', 'ag@@', 'o.', '</s>']
2024-05-28 12:54:15,826 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:54:15,829 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:54:15,832 - INFO - joeynmt.training - 	Hypothesis: And the first time we went to the two secret of the future of the best of the best of the world's largest billions of million years ago was the last 20 years, the paper than 400 million years ago, the four billion years ago.
2024-05-28 12:54:15,835 - INFO - joeynmt.training - Example #1
2024-05-28 12:54:15,839 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:54:15,839 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:54:15,839 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'b@@', 'est', 'of', 'the', 'problem@@', 's', 'of', 'this', 'problem@@', 's', 'of', 'the', 'problem@@', 's', 'of', 'the', 'b@@', 'est', 'problem@@', 's.', '</s>']
2024-05-28 12:54:15,840 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:54:15,843 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:54:15,858 - INFO - joeynmt.training - 	Hypothesis: But this is the best of the problems of this problems of the problems of the best problems.
2024-05-28 12:54:15,862 - INFO - joeynmt.training - Example #2
2024-05-28 12:54:15,865 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:54:15,865 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:54:15,865 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'b@@', 'est', 'b@@', 'on@@', 'e,', 'in', 'a', 'way', 'that', 'the', 'way', 'that', 'the', 'glob@@', 'al', 'system@@', ',', 'which', 'is', 'the', 'glob@@', 'al', 'system@@', '.', '</s>']
2024-05-28 12:54:15,866 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:54:15,892 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:54:15,898 - INFO - joeynmt.training - 	Hypothesis: The best bone, in a way that the way that the global system, which is the global system.
2024-05-28 12:54:15,902 - INFO - joeynmt.training - Example #3
2024-05-28 12:54:15,922 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:54:15,923 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:54:15,923 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['He', 'has', 'been', 're@@', 'ally,', 'the', 'b@@', 'est', 'way', 'to', 'the', 'st@@', 'ory', 'of', 'the', 'st@@', 're@@', 'et.', '</s>']
2024-05-28 12:54:15,923 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:54:15,964 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:54:16,044 - INFO - joeynmt.training - 	Hypothesis: He has been really, the best way to the story of the street.
2024-05-28 12:54:16,068 - INFO - joeynmt.training - Example #4
2024-05-28 12:54:16,119 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:54:16,119 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:54:16,119 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'sec@@', 'ond', 'is', 'the', 're@@', 'sear@@', 'ch', 'that', 'you', 'will', 'be', 'a', 'little', 'bit', 'of', 'a', 'f@@', 'ut@@', 'ure', 'of', 'the', 'last', 'f@@', 'our', 'years', 'ag@@', 'o,', '</s>']
2024-05-28 12:54:16,119 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:54:16,183 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:54:16,271 - INFO - joeynmt.training - 	Hypothesis: The second is the research that you will be a little bit of a future of the last four years ago,
2024-05-28 12:54:20,221 - INFO - joeynmt.training - Epoch   3, Step:    12100, Batch Loss:     2.050447, Batch Acc: 0.376314, Tokens per Sec:    16118, Lr: 0.000300
2024-05-28 12:54:24,090 - INFO - joeynmt.training - Epoch   3, Step:    12200, Batch Loss:     2.149289, Batch Acc: 0.379926, Tokens per Sec:    18543, Lr: 0.000300
2024-05-28 12:54:27,439 - INFO - joeynmt.training - Epoch   3, Step:    12300, Batch Loss:     2.212863, Batch Acc: 0.381209, Tokens per Sec:    21321, Lr: 0.000300
2024-05-28 12:54:31,519 - INFO - joeynmt.training - Epoch   3, Step:    12400, Batch Loss:     2.231368, Batch Acc: 0.378585, Tokens per Sec:    17963, Lr: 0.000300
2024-05-28 12:54:35,620 - INFO - joeynmt.training - Epoch   3, Step:    12500, Batch Loss:     2.154102, Batch Acc: 0.382955, Tokens per Sec:    17275, Lr: 0.000300
2024-05-28 12:54:35,664 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:54:35,720 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:55:13,986 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.16, ppl:   8.63, acc:   0.37, generation: 38.1844[sec], evaluation: 0.0000[sec]
2024-05-28 12:55:13,991 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:55:14,083 - INFO - joeynmt.helpers - delete models/bpe-subword/10000.ckpt
2024-05-28 12:55:14,155 - INFO - joeynmt.training - Example #0
2024-05-28 12:55:14,194 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:55:14,195 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:55:14,195 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'one', 'of', 'the', 'sec@@', 'ond', 'one', 'of', 'these', 'two', 'sec@@', 'on@@', 'd@@', '-@@', 'l@@', 'ine', 're@@', 'sear@@', 'ch', 'for', 'the', 'l@@', 'and', 'of', 'the', 'l@@', 'and', 'of', 'the', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'ag@@', 'o,', 'three', 'mil@@', 'lion', 'years', 'ag@@', 'o,', 'the', 'last', 'year@@', ',', 'the', 'last', 'three', 'years', 'ag@@', 'o,', 'the', 'p@@', 'ast', 'of', 'the', 'c@@', 'ou@@', 'ple', 'of', 'the', 'c@@', 'ou@@', 'ple', 'of', 'a', 'mil@@', 'lion', 'years', 'ag@@', 'o.', '</s>']
2024-05-28 12:55:14,195 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:55:14,274 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:55:14,334 - INFO - joeynmt.training - 	Hypothesis: And the one of the second one of these two second-line research for the land of the land of the most of the last three million years ago, three million years ago, the last year, the last three years ago, the past of the couple of the couple of a million years ago.
2024-05-28 12:55:14,388 - INFO - joeynmt.training - Example #1
2024-05-28 12:55:14,405 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:55:14,405 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:55:14,405 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'res@@', 'ul@@', 'ts', 'of', 'the', 'prob@@', 'le@@', 'm', 'of', 'this', 'prob@@', 'le@@', 'm', 'is', 'that', 'the', 'prob@@', 'le@@', 'm', 'is', 'that', 'the', 'b@@', 'ab@@', 'y.', '</s>']
2024-05-28 12:55:14,406 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:55:14,460 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:55:14,530 - INFO - joeynmt.training - 	Hypothesis: But this is the results of the problem of this problem is that the problem is that the baby.
2024-05-28 12:55:14,536 - INFO - joeynmt.training - Example #2
2024-05-28 12:55:14,540 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:55:14,540 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:55:14,540 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'of', 'the', 'pol@@', 'ice', 'of', 'the', 'pol@@', 'ice', 'that', 'is', 'the', 'f@@', 'as@@', 'hi@@', 'on', 'the', 'plan@@', 'et.', '</s>']
2024-05-28 12:55:14,541 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:55:14,544 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:55:14,548 - INFO - joeynmt.training - 	Hypothesis: The police of the police of the police that is the fashion the planet.
2024-05-28 12:55:14,551 - INFO - joeynmt.training - Example #3
2024-05-28 12:55:14,555 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:55:14,555 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:55:14,555 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['He', 'was', 'ex@@', 'act@@', 'ly', 'the', 's@@', 'li@@', 'ght@@', 'ly', 'and', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:55:14,556 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:55:14,560 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:55:14,563 - INFO - joeynmt.training - 	Hypothesis: He was exactly the slightly and the same.
2024-05-28 12:55:14,625 - INFO - joeynmt.training - Example #4
2024-05-28 12:55:14,657 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:55:14,657 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:55:14,657 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'sec@@', 'ond', 'of', 'the', 'c@@', 'ity', 'of', 'the', 'st@@', 're@@', 'et', 'that', 'I', 'want', 'to', 'show', 'you', 'a', 'f@@', 'ast@@', 'er', 'in', 'the', 'last', '10', 'years', 'ag@@', 'o,', 'the', 'last', '10', 'year@@', 's.', '</s>']
2024-05-28 12:55:14,657 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:55:14,695 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:55:14,788 - INFO - joeynmt.training - 	Hypothesis: The second of the city of the street that I want to show you a faster in the last 10 years ago, the last 10 years.
2024-05-28 12:55:18,939 - INFO - joeynmt.training - Epoch   3, Step:    12600, Batch Loss:     2.191725, Batch Acc: 0.381451, Tokens per Sec:    14480, Lr: 0.000300
2024-05-28 12:55:23,112 - INFO - joeynmt.training - Epoch   3, Step:    12700, Batch Loss:     2.031393, Batch Acc: 0.382474, Tokens per Sec:    17570, Lr: 0.000300
2024-05-28 12:55:27,246 - INFO - joeynmt.training - Epoch   3, Step:    12800, Batch Loss:     2.129180, Batch Acc: 0.386056, Tokens per Sec:    17167, Lr: 0.000300
2024-05-28 12:55:31,389 - INFO - joeynmt.training - Epoch   3, Step:    12900, Batch Loss:     2.087558, Batch Acc: 0.387076, Tokens per Sec:    17514, Lr: 0.000300
2024-05-28 12:55:35,528 - INFO - joeynmt.training - Epoch   3, Step:    13000, Batch Loss:     2.200856, Batch Acc: 0.391090, Tokens per Sec:    17270, Lr: 0.000300
2024-05-28 12:55:35,567 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:55:35,577 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:56:01,520 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.13, ppl:   8.41, acc:   0.38, generation: 25.9212[sec], evaluation: 0.0000[sec]
2024-05-28 12:56:01,576 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:56:01,714 - INFO - joeynmt.helpers - delete models/bpe-subword/10500.ckpt
2024-05-28 12:56:01,777 - INFO - joeynmt.training - Example #0
2024-05-28 12:56:01,781 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:56:01,781 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:56:01,781 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'one', 'I', 'as@@', 'ked', 'these', 'two', 't@@', 'y@@', 'p@@', 'ical', 're@@', 'sear@@', 'ch@@', 'er', 'to', 'the', 'b@@', 'est', 'of', 'the', 'pol@@', 'ice', 'of', 'the', 'worl@@', 'd@@', "'s", 'l@@', 'ine', 'that', 'was', 'the', 'same', 'm@@', 'y@@', 'th@@', 'es@@', 'i@@', 'al', 'for', 'the', 'last', '4@@', '0', 'mil@@', 'lion', 'years', 'ag@@', 'o', 'with', 'the', 'si@@', 'x', 'of', 'the', 's@@', 'ha@@', 'pe', 'of', '4@@', '0', 'percent', 'of', 'the', 'c@@', 'ase', 'of', 'the', 'c@@', 'ell@@', 's', 'of', 'the', 'c@@', 'ell@@', '.', '</s>']
2024-05-28 12:56:01,782 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:56:01,786 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:56:01,789 - INFO - joeynmt.training - 	Hypothesis: And the first one I asked these two typical researcher to the best of the police of the world's line that was the same mythesial for the last 40 million years ago with the six of the shape of 40 percent of the case of the cells of the cell.
2024-05-28 12:56:01,793 - INFO - joeynmt.training - Example #1
2024-05-28 12:56:01,797 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:56:01,797 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:56:01,797 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'in@@', 'cl@@', 'u@@', 'ding', 'these', 'problem@@', 's', 'of', 'problem@@', 's', 'that', 'problem@@', 's', 'is', 'not', 'the', 'same', 'thing', 'is', 'not', 'the', 'b@@', 'est', 'st@@', 'or@@', 'y.', '</s>']
2024-05-28 12:56:01,797 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:56:01,823 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:56:01,850 - INFO - joeynmt.training - 	Hypothesis: But this including these problems of problems that problems is not the same thing is not the best story.
2024-05-28 12:56:01,854 - INFO - joeynmt.training - Example #2
2024-05-28 12:56:01,857 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:56:01,857 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:56:01,857 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'of', 'pol@@', 'ic@@', 'y', 'pol@@', 'ic@@', 'y,', 'the', 'in@@', 'cl@@', 'u@@', 'ding', 'the', 'pro@@', 'c@@', 'ess', 'syst@@', 'em', 'that', 'has', 'the', 'plan@@', 'et.', '</s>']
2024-05-28 12:56:01,858 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:56:01,861 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:56:01,864 - INFO - joeynmt.training - 	Hypothesis: The police of policy policy, the including the process system that has the planet.
2024-05-28 12:56:01,868 - INFO - joeynmt.training - Example #3
2024-05-28 12:56:01,872 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:56:01,872 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:56:01,872 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'is', 'ex@@', 'act@@', 'ly', 'the', 'same', 'thing', 'and', 're@@', 'duc@@', 'ing', 'the', 'ch@@', 'ar@@', 'ac@@', 'ter@@', '.', '</s>']
2024-05-28 12:56:01,873 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:56:01,876 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:56:01,919 - INFO - joeynmt.training - 	Hypothesis: It is exactly the same thing and reducing the character.
2024-05-28 12:56:01,923 - INFO - joeynmt.training - Example #4
2024-05-28 12:56:01,928 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:56:01,928 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:56:01,928 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'sec@@', 'ond', 'thing', 'that', 'you', 'can', 'see', 'you', 'have', 'a', 'st@@', 'ory', 'will', 'be', 'a', 're@@', 'qu@@', 'i@@', 're@@', 'ment@@', '.', '</s>']
2024-05-28 12:56:01,928 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:56:01,945 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:56:01,949 - INFO - joeynmt.training - 	Hypothesis: The second thing that you can see you have a story will be a requirement.
2024-05-28 12:56:05,553 - INFO - joeynmt.training - Epoch   3, Step:    13100, Batch Loss:     2.062997, Batch Acc: 0.387474, Tokens per Sec:    17786, Lr: 0.000300
2024-05-28 12:56:08,913 - INFO - joeynmt.training - Epoch   3, Step:    13200, Batch Loss:     2.146604, Batch Acc: 0.392036, Tokens per Sec:    21647, Lr: 0.000300
2024-05-28 12:56:12,100 - INFO - joeynmt.training - Epoch   3, Step:    13300, Batch Loss:     2.058950, Batch Acc: 0.392276, Tokens per Sec:    22792, Lr: 0.000300
2024-05-28 12:56:15,544 - INFO - joeynmt.training - Epoch   3, Step:    13400, Batch Loss:     2.137824, Batch Acc: 0.396977, Tokens per Sec:    21120, Lr: 0.000300
2024-05-28 12:56:18,945 - INFO - joeynmt.training - Epoch   3, Step:    13500, Batch Loss:     1.926930, Batch Acc: 0.399313, Tokens per Sec:    21494, Lr: 0.000300
2024-05-28 12:56:18,992 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:56:18,995 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:56:41,992 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.11, ppl:   8.24, acc:   0.39, generation: 22.9745[sec], evaluation: 0.0000[sec]
2024-05-28 12:56:41,998 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:56:42,125 - INFO - joeynmt.helpers - delete models/bpe-subword/11000.ckpt
2024-05-28 12:56:42,162 - INFO - joeynmt.training - Example #0
2024-05-28 12:56:42,166 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:56:42,167 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:56:42,167 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'th@@', 'ir@@', 'd', 'of', 'these', 'two', 'sec@@', 'on@@', 'd@@', '-@@', 're@@', '-@@', 'de@@', '-@@', 're@@', 'f@@', 'ine', 'in@@', 'cl@@', 'u@@', 'ding', 'the', 'b@@', 'on@@', 'es', 'that', 'the', 'most', 'of', 'the', 'b@@', 'est', 'that', 'the', 'most', 'popul@@', 'ation', 'of', 'the', 'most', 'three', 'mil@@', 'lion', 'years', 'ag@@', 'o,', 'the', 'b@@', 'est', 'of', 'the', 'last', '4@@', '0', 'percent', 'of', 'the', 's@@', 'our@@', 'ce', 'of', 'the', 'c@@', 'ase', 'of', 'the', 'c@@', 'ase', 'of', 'the', 'c@@', 'ase', 'of', 'the', 'c@@', 'ase', 'of', 'the', 'c@@', 'ase', 'of', 'the', 'c@@', 'ase', 'of', 'the', 'c@@', 'ase', 'of', 'the', 'c@@', 'ase', 'of', 'the', 'c@@', 'ase', 'of', 'the', 'c@@', 'ase', 'of', 'the', 'c@@', 'ase', 'of', 'the', 'c@@', 'ase', 'of', 'the', 'c@@', 'ase']
2024-05-28 12:56:42,167 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:56:42,170 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:56:42,173 - INFO - joeynmt.training - 	Hypothesis: And the third of these two second-re-de-refine including the bones that the most of the best that the most population of the most three million years ago, the best of the last 40 percent of the source of the case of the case of the case of the case of the case of the case of the case of the case of the case of the case of the case of the case of the case
2024-05-28 12:56:42,177 - INFO - joeynmt.training - Example #1
2024-05-28 12:56:42,180 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:56:42,180 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:56:42,180 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'in@@', 'vis@@', 'i@@', 'ble', 'problem@@', 's', 'that', 'the', 'problem@@', 's', 'is', 'that', 'the', 'problem@@', 's', 'of', 'the', 'problem@@', 's', 'of', 'the', 'b@@', 'ab@@', 'y', 'of', 'the', 'm@@', 'ach@@', 'in@@', 'e.', '</s>']
2024-05-28 12:56:42,181 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:56:42,205 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:56:42,208 - INFO - joeynmt.training - 	Hypothesis: But this is the invisible problems that the problems is that the problems of the problems of the baby of the machine.
2024-05-28 12:56:42,212 - INFO - joeynmt.training - Example #2
2024-05-28 12:56:42,216 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:56:42,216 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:56:42,216 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is', 'the', 'pol@@', 'ice', 'is', 'that', 'the', 'way', 'of', 'a', 'kind', 'of', 'a', 'system@@', ',', 'the', 're@@', 'fl@@', 'ec@@', 'tion', 'of', 'system@@', '.', '</s>']
2024-05-28 12:56:42,216 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:56:42,220 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:56:42,224 - INFO - joeynmt.training - 	Hypothesis: The police is the police is that the way of a kind of a system, the reflection of system.
2024-05-28 12:56:42,228 - INFO - joeynmt.training - Example #3
2024-05-28 12:56:42,262 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:56:42,262 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:56:42,262 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'cit@@', 'ing', 'the', 'c@@', 'ell@@', '.', '</s>']
2024-05-28 12:56:42,263 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:56:42,278 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:56:42,281 - INFO - joeynmt.training - 	Hypothesis: She was exciting the cell.
2024-05-28 12:56:42,284 - INFO - joeynmt.training - Example #4
2024-05-28 12:56:42,288 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:56:42,288 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:56:42,288 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'sec@@', 'ond', 're@@', 't', 'the', 'p@@', 'ho@@', 'to@@', 'grap@@', 'h', 'that', 'I', 'will', 'be', 'a', 'st@@', 'ory', 'to', 'be', 'a', 're@@', 'f@@', 'ec@@', 'ted', 'to', 'what', 'it', 'was', 'a', 're@@', 'mo@@', 've@@', 'ment', 'in', 'the', 'last', '10', 'year@@', 's.', '</s>']
2024-05-28 12:56:42,289 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:56:42,292 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:56:42,298 - INFO - joeynmt.training - 	Hypothesis: The second ret the photograph that I will be a story to be a refected to what it was a removement in the last 10 years.
2024-05-28 12:56:45,810 - INFO - joeynmt.training - Epoch   3, Step:    13600, Batch Loss:     2.155438, Batch Acc: 0.395418, Tokens per Sec:    18674, Lr: 0.000300
2024-05-28 12:56:46,987 - INFO - joeynmt.training - Epoch   3: total training loss 9840.79
2024-05-28 12:56:47,046 - INFO - joeynmt.training - EPOCH 4
2024-05-28 12:56:49,403 - INFO - joeynmt.training - Epoch   4, Step:    13700, Batch Loss:     2.091678, Batch Acc: 0.406876, Tokens per Sec:    21678, Lr: 0.000300
2024-05-28 12:56:52,436 - INFO - joeynmt.training - Epoch   4, Step:    13800, Batch Loss:     2.057541, Batch Acc: 0.408893, Tokens per Sec:    24023, Lr: 0.000300
2024-05-28 12:56:56,437 - INFO - joeynmt.training - Epoch   4, Step:    13900, Batch Loss:     2.039767, Batch Acc: 0.409025, Tokens per Sec:    17993, Lr: 0.000300
2024-05-28 12:57:00,401 - INFO - joeynmt.training - Epoch   4, Step:    14000, Batch Loss:     2.021103, Batch Acc: 0.415872, Tokens per Sec:    17923, Lr: 0.000300
2024-05-28 12:57:00,421 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:57:00,431 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:57:40,089 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.08, ppl:   7.99, acc:   0.40, generation: 39.6346[sec], evaluation: 0.0000[sec]
2024-05-28 12:57:40,094 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:57:40,201 - INFO - joeynmt.helpers - delete models/bpe-subword/11500.ckpt
2024-05-28 12:57:40,277 - INFO - joeynmt.training - Example #0
2024-05-28 12:57:40,281 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:57:40,282 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:57:40,282 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'one', 'I', 'was', 'the', 'two', 'sec@@', 're@@', 'ts', 'for', 'these', 'two', 'sec@@', 're@@', 'ts', 'for', 'the', 'l@@', 'ine', 'of', 'the', 'o@@', 'ce@@', 'an@@', 's,', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'year@@', ',', 'the', 'first', 'three', 'year@@', 's,', 'the', 'first', 'of', 'the', 'last', 'year@@', ',', 'and', 'the', 'last', '4@@', '0', 'percent', 'of', 'the', 'last', '4@@', '0', 'percent', 'of', 'the', 'c@@', 'ase', 'of', 'the', 'c@@', 'ase', 'of', 'the', 'c@@', 'ase', 'of', 'the', 'c@@', 'ase', 'of', 'the', 'c@@', 'ase', 'of', 'the', 'c@@', 'ou@@', 'ple', 'of', 'sec@@', 'on@@', 'd.', '</s>']
2024-05-28 12:57:40,282 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:57:40,286 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:57:40,289 - INFO - joeynmt.training - 	Hypothesis: The first one I was the two secrets for these two secrets for the line of the oceans, the first of the first of the first year, the first three years, the first of the last year, and the last 40 percent of the last 40 percent of the case of the case of the case of the case of the case of the couple of second.
2024-05-28 12:57:40,294 - INFO - joeynmt.training - Example #1
2024-05-28 12:57:40,297 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:57:40,297 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:57:40,297 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'things', 'that', 'are', 'the', 'problem@@', 's', 'of', 'the', 'problem@@', 's', 'of', 'the', 'problem@@', 's', 'of', 'the', 'prob@@', 'le@@', 'm', 'of', 'the', 'problem@@', '.', '</s>']
2024-05-28 12:57:40,298 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:57:40,301 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:57:40,304 - INFO - joeynmt.training - 	Hypothesis: But this is the things that are the problems of the problems of the problems of the problem of the problem.
2024-05-28 12:57:40,308 - INFO - joeynmt.training - Example #2
2024-05-28 12:57:40,312 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:57:40,312 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:57:40,312 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'of', 'the', 'pol@@', 'ic@@', 'y', 'that', 'is', 'the', 'way', 'that', 'the', 'l@@', 'im@@', 'b', 'of', 'the', 'pro@@', 'c@@', 'ess', 'system@@', '.', '</s>']
2024-05-28 12:57:40,312 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:57:40,330 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:57:40,337 - INFO - joeynmt.training - 	Hypothesis: The police of the policy that is the way that the limb of the process system.
2024-05-28 12:57:40,341 - INFO - joeynmt.training - Example #3
2024-05-28 12:57:40,345 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:57:40,345 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:57:40,345 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'is', 'ex@@', 'cit@@', 'ing', 'the', 'c@@', 'ase', 'and', 'it', 'is', 'the', 'con@@', 't@@', 'ent.', '</s>']
2024-05-28 12:57:40,346 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:57:40,349 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:57:40,355 - INFO - joeynmt.training - 	Hypothesis: She is exciting the case and it is the content.
2024-05-28 12:57:40,359 - INFO - joeynmt.training - Example #4
2024-05-28 12:57:40,362 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:57:40,362 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:57:40,363 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'U@@', '.@@', 'S@@', '.', 'The', 'next', 'thing', 'that', 'I', 'will', 'be', 'a', 'st@@', 'ory', 'on', 'what', 'I', 'will', 'be', 'a', 'st@@', 'ory', 'on', 'what', 'was', 'a', 'sec@@', 'ond', 'to', 'what', 'was', 'a', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 12:57:40,363 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:57:40,398 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:57:40,402 - INFO - joeynmt.training - 	Hypothesis: The U.S. The next thing that I will be a story on what I will be a story on what was a second to what was a 25 years.
2024-05-28 12:57:43,860 - INFO - joeynmt.training - Epoch   4, Step:    14100, Batch Loss:     2.029449, Batch Acc: 0.408562, Tokens per Sec:    19320, Lr: 0.000300
2024-05-28 12:57:47,829 - INFO - joeynmt.training - Epoch   4, Step:    14200, Batch Loss:     2.077332, Batch Acc: 0.412512, Tokens per Sec:    17900, Lr: 0.000300
2024-05-28 12:57:51,804 - INFO - joeynmt.training - Epoch   4, Step:    14300, Batch Loss:     2.137743, Batch Acc: 0.410639, Tokens per Sec:    18334, Lr: 0.000300
2024-05-28 12:57:55,888 - INFO - joeynmt.training - Epoch   4, Step:    14400, Batch Loss:     2.057253, Batch Acc: 0.420998, Tokens per Sec:    17679, Lr: 0.000300
2024-05-28 12:57:59,980 - INFO - joeynmt.training - Epoch   4, Step:    14500, Batch Loss:     2.003245, Batch Acc: 0.419426, Tokens per Sec:    17483, Lr: 0.000300
2024-05-28 12:57:59,985 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:57:59,988 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:58:27,375 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.06, ppl:   7.82, acc:   0.40, generation: 27.3628[sec], evaluation: 0.0000[sec]
2024-05-28 12:58:27,392 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:58:27,477 - INFO - joeynmt.helpers - delete models/bpe-subword/12000.ckpt
2024-05-28 12:58:27,488 - INFO - joeynmt.training - Example #0
2024-05-28 12:58:27,492 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:58:27,492 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:58:27,492 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'next', 'day', 'I', 'got', 'this', 'on', 'the', 'di@@', 'g@@', 'it@@', 'iz@@', 'ed', 'to', 'the', 'f@@', 'un@@', 'g@@', 'er', 'to', 'the', 'b@@', 'est', 'of', 'the', 'pol@@', 'ice', 'that', 'the', 'most', 'of', 'the', 'mon@@', 'ey', 'that', 'the', 'last', '10', 'years', 'of', 'the', 'last', 'year@@', ',', 'that', 'was', 'the', 'last', '4@@', '0', 'percent', 'of', 'the', '4@@', '0@@', 's', 'of', 'the', 'gro@@', 'und', 'with', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'fi@@', 've', 'percent', 'of', 'the', 'mic@@', 'ro@@', '-@@', 'fi@@', 've', 'percent', 'of', 'the', 'c@@', 'ar', 'to', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'E@@', 'ar@@', 'th', 'of', 'the', 'E@@', 'n@@', 'g@@', 'li@@', 's@@', 'h', 'of', 'the', 'E@@', 'ar@@', 'th', 'of', 'the', 'E@@', 'ar@@', 'th', 'of', 'the', 'E@@']
2024-05-28 12:58:27,493 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:58:27,496 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:58:27,501 - INFO - joeynmt.training - 	Hypothesis: And the next day I got this on the digitized to the funger to the best of the police that the most of the money that the last 10 years of the last year, that was the last 40 percent of the 40s of the ground with the future of the five percent of the micro-five percent of the car to the future of the Earth of the English of the Earth of the Earth of the E
2024-05-28 12:58:27,505 - INFO - joeynmt.training - Example #1
2024-05-28 12:58:27,508 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:58:27,508 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:58:27,508 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'other', 'thing', 'that', 'is', 'the', 'reas@@', 'on', 'that', 'the', 'prob@@', 'le@@', 'm', 'because', 'of', 'this', 'is', 'the', 'b@@', 'ab@@', 'i@@', 'es', 'of', 'the', 'b@@', 'ab@@', 'i@@', 'es', 'of', 'the', 'b@@', 'ar@@', '.', '</s>']
2024-05-28 12:58:27,509 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:58:27,512 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:58:27,516 - INFO - joeynmt.training - 	Hypothesis: But this is the other thing that is the reason that the problem because of this is the babies of the babies of the bar.
2024-05-28 12:58:27,520 - INFO - joeynmt.training - Example #2
2024-05-28 12:58:27,566 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:58:27,566 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:58:27,566 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'of', 'the', 'pol@@', 'ice', 'of', 'the', 'b@@', 'est', 'way', 'that', 'the', 'f@@', 'ut@@', 'ure', 'syst@@', 'em', 'that', 'the', 'glob@@', 'al', 'syst@@', 'em', 'of', 'the', 'glob@@', 'al', 'syst@@', 'em', 'of', 'the', 'plan@@', 'et.', '</s>']
2024-05-28 12:58:27,566 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:58:27,598 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:58:27,648 - INFO - joeynmt.training - 	Hypothesis: The police of the police of the best way that the future system that the global system of the global system of the planet.
2024-05-28 12:58:27,725 - INFO - joeynmt.training - Example #3
2024-05-28 12:58:27,792 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:58:27,792 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:58:27,793 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'cit@@', 'ing', 'and', 'they', 'are', 'con@@', 'nec@@', 'ted', 'to', 'the', 'r@@', 'ac@@', 'e.', '</s>']
2024-05-28 12:58:27,793 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:58:27,835 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:58:27,867 - INFO - joeynmt.training - 	Hypothesis: She was exciting and they are connected to the race.
2024-05-28 12:58:27,986 - INFO - joeynmt.training - Example #4
2024-05-28 12:58:28,005 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:58:28,005 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:58:28,005 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'sec@@', 'ond', 'is', 'the', 'di@@', 'g@@', 'it@@', 'al', 'that', 'I', 'will', 'show', 'you', 'a', 'little', 'bit', 'about', 'a', 'f@@', 'as@@', 'cin@@', 'ating', 'to', 'the', 'next', '2@@', '5', 'years', 'ag@@', 'o,', '</s>']
2024-05-28 12:58:28,005 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:58:28,056 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:58:28,088 - INFO - joeynmt.training - 	Hypothesis: The second is the digital that I will show you a little bit about a fascinating to the next 25 years ago,
2024-05-28 12:58:31,634 - INFO - joeynmt.training - Epoch   4, Step:    14600, Batch Loss:     2.190629, Batch Acc: 0.414188, Tokens per Sec:    16553, Lr: 0.000300
2024-05-28 12:58:34,950 - INFO - joeynmt.training - Epoch   4, Step:    14700, Batch Loss:     1.902508, Batch Acc: 0.417829, Tokens per Sec:    21552, Lr: 0.000300
2024-05-28 12:58:38,169 - INFO - joeynmt.training - Epoch   4, Step:    14800, Batch Loss:     1.996462, Batch Acc: 0.417955, Tokens per Sec:    22182, Lr: 0.000300
2024-05-28 12:58:42,085 - INFO - joeynmt.training - Epoch   4, Step:    14900, Batch Loss:     2.120509, Batch Acc: 0.420598, Tokens per Sec:    18551, Lr: 0.000300
2024-05-28 12:58:45,805 - INFO - joeynmt.training - Epoch   4, Step:    15000, Batch Loss:     2.019543, Batch Acc: 0.423097, Tokens per Sec:    19064, Lr: 0.000300
2024-05-28 12:58:45,864 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:58:45,915 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:59:10,653 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.03, ppl:   7.64, acc:   0.41, generation: 24.6976[sec], evaluation: 0.0000[sec]
2024-05-28 12:59:10,658 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:59:10,752 - INFO - joeynmt.helpers - delete models/bpe-subword/12500.ckpt
2024-05-28 12:59:10,764 - INFO - joeynmt.training - Example #0
2024-05-28 12:59:10,788 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:59:10,788 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:59:10,788 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'th@@', 'ir@@', 'd', 'I', 'loo@@', 'ked', 'at', 'these', 'two', 'sec@@', 'ur@@', 'ity', 'of', 'the', 'de@@', 'mon@@', 'str@@', 'ate', 'of', 'the', 'f@@', 'ar@@', 'm@@', 'er', 'in', 'the', 'last', 'few', 'year@@', 's,', 'the', 'most', 'popul@@', 'ation', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', '4@@', '8', 'mil@@', 'lion', 'years', 'of', 'the', 'f@@', 'ut@@', 'u@@', 're,', 'that', 'was', 'a', 'little', 'bit', 'of', '4@@', '0', 'percent', 'of', 'the', 'f@@', 'ut@@', 'u@@', 're.', '</s>']
2024-05-28 12:59:10,789 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:59:10,793 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:59:10,796 - INFO - joeynmt.training - 	Hypothesis: And the third I looked at these two security of the demonstrate of the farmer in the last few years, the most population of the last three million years of the last 48 million years of the future, that was a little bit of 40 percent of the future.
2024-05-28 12:59:10,827 - INFO - joeynmt.training - Example #1
2024-05-28 12:59:10,896 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:59:10,896 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:59:10,896 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'ser@@', 'i@@', 'es', 'of', 'this', 'speci@@', 'es', 'that', 'are', 'speci@@', 'es', 'because', 'the', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'look', 'at', 'the', 'to@@', 'ol@@', 's.', '</s>']
2024-05-28 12:59:10,896 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:59:10,971 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:59:11,046 - INFO - joeynmt.training - 	Hypothesis: But this is the series of this species that are species because the problem because it doesn't look at the tools.
2024-05-28 12:59:11,108 - INFO - joeynmt.training - Example #2
2024-05-28 12:59:11,216 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:59:11,216 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:59:11,216 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'pol@@', 'ice', 'in', 'a', 'bo@@', 'o@@', 'k,', 'in@@', 'cl@@', 'u@@', 'ding', 'a', 'way', 'that', 'the', 'f@@', 'ut@@', 'u@@', 're.', '</s>']
2024-05-28 12:59:11,217 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:59:11,220 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:59:11,227 - INFO - joeynmt.training - 	Hypothesis: The police police in a book, including a way that the future.
2024-05-28 12:59:11,231 - INFO - joeynmt.training - Example #3
2024-05-28 12:59:11,235 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:59:11,235 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:59:11,235 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 's@@', 'us@@', 'p@@', 'ed', 'and', 'they', 'are', 'able', 'to', 're@@', 'ach', 'the', 'r@@', 'ac@@', 'e.', '</s>']
2024-05-28 12:59:11,236 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:59:11,239 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:59:11,271 - INFO - joeynmt.training - 	Hypothesis: She susped and they are able to reach the race.
2024-05-28 12:59:11,328 - INFO - joeynmt.training - Example #4
2024-05-28 12:59:11,332 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:59:11,332 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:59:11,332 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'sec@@', 'ond', 're@@', 'li@@', 'gi@@', 'ous', 'di@@', 'vers@@', 'ity', 'that', 'you', 'want', 'to', 'show', 'you', 'a', 'little', 'bit', 'about', 'what', 'it', 'was', 'a', 'f@@', 'ast@@', 'er', 'to', 'what', 'it', 'was', 'in@@', 'de@@', 'pen@@', 'dent', 'on', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 12:59:11,332 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:59:11,336 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:59:11,340 - INFO - joeynmt.training - 	Hypothesis: The second religious diversity that you want to show you a little bit about what it was a faster to what it was independent on the last 25 years.
2024-05-28 12:59:14,763 - INFO - joeynmt.training - Epoch   4, Step:    15100, Batch Loss:     2.070827, Batch Acc: 0.420291, Tokens per Sec:    17342, Lr: 0.000300
2024-05-28 12:59:18,660 - INFO - joeynmt.training - Epoch   4, Step:    15200, Batch Loss:     2.065448, Batch Acc: 0.426322, Tokens per Sec:    18648, Lr: 0.000300
2024-05-28 12:59:22,493 - INFO - joeynmt.training - Epoch   4, Step:    15300, Batch Loss:     1.977445, Batch Acc: 0.419032, Tokens per Sec:    18011, Lr: 0.000300
2024-05-28 12:59:26,163 - INFO - joeynmt.training - Epoch   4, Step:    15400, Batch Loss:     1.956696, Batch Acc: 0.430061, Tokens per Sec:    19651, Lr: 0.000300
2024-05-28 12:59:30,041 - INFO - joeynmt.training - Epoch   4, Step:    15500, Batch Loss:     1.952430, Batch Acc: 0.432983, Tokens per Sec:    18736, Lr: 0.000300
2024-05-28 12:59:30,046 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:59:30,049 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:59:49,160 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.00, ppl:   7.41, acc:   0.42, generation: 19.0451[sec], evaluation: 0.0000[sec]
2024-05-28 12:59:49,165 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:59:49,256 - INFO - joeynmt.helpers - delete models/bpe-subword/13000.ckpt
2024-05-28 12:59:49,315 - INFO - joeynmt.training - Example #0
2024-05-28 12:59:49,359 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 12:59:49,359 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 12:59:49,359 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'th@@', 'ir@@', 'd', 'was', 'the', 'p@@', 'ur@@', 'b@@', 'an', 're@@', 'sear@@', 'ch@@', ',', 'for', 'the', 'l@@', 'ine', 'of', 'the', 'l@@', 'ine', 'of', 'the', 'pol@@', 'l@@', 'en', 'of', 'the', 'l@@', 'ine', 'of', 'the', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'ag@@', 'o,', 'the', 'last', '4@@', '8', 'mil@@', 'lion', 'years', 'of', 'the', 'f@@', 'un@@', 'ded', 'of', '4@@', '0', 'percent', 'of', 'the', 'f@@', 'un@@', 'n@@', 'y', 'of', '4@@', '5', 'percent', 'of', 'the', 'f@@', 'un@@', 'n@@', 'y', 'of', 'the', 'f@@', 'un@@', 'n@@', 'y', 'of', 'the', 'last', '20', 'percent', 'of', 'the', 'last', '20', 'percent', 'of', 'the', 'next', '20', 'percent', 'of', 'the', 'next', '20', 'percent', 'of', 'the', 'next', '20', 'percent', 'of', 'the', 'p@@', 'ast@@', '.', '</s>']
2024-05-28 12:59:49,359 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:59:49,472 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:59:49,538 - INFO - joeynmt.training - 	Hypothesis: The third was the purban research, for the line of the line of the pollen of the line of the most of the last three million years ago, the last 48 million years of the funded of 40 percent of the funny of 45 percent of the funny of the funny of the last 20 percent of the last 20 percent of the next 20 percent of the next 20 percent of the next 20 percent of the past.
2024-05-28 12:59:49,621 - INFO - joeynmt.training - Example #1
2024-05-28 12:59:49,669 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:59:49,669 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 12:59:49,670 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'ob@@', 'j@@', 'ec@@', 'tive', 'is@@', 'su@@', 'es', 'of', 'this', 'problem@@', 's', 'that', 'are', 'not', 'ar@@', 'gu@@', 'es', 'of', 'the', 'b@@', 'ro@@', 'th@@', 'er@@', 's.', '</s>']
2024-05-28 12:59:49,670 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:59:49,674 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:59:49,677 - INFO - joeynmt.training - 	Hypothesis: But this is the objective issues of this problems that are not argues of the brothers.
2024-05-28 12:59:49,680 - INFO - joeynmt.training - Example #2
2024-05-28 12:59:49,684 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 12:59:49,684 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 12:59:49,684 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'pol@@', 'l@@', 'en', 'in', 'a', 'way', 'of', 'ho@@', 'p@@', 'e,', 'the', 'wh@@', 'ole', 'system@@', ',', 'the', 'wh@@', 'ole', 'system@@', '.', '</s>']
2024-05-28 12:59:49,684 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:59:49,688 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:59:49,691 - INFO - joeynmt.training - 	Hypothesis: The police pollen in a way of hope, the whole system, the whole system.
2024-05-28 12:59:49,694 - INFO - joeynmt.training - Example #3
2024-05-28 12:59:49,736 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 12:59:49,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:59:49,736 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'is', 'ex@@', 'c@@', 'ell@@', 'ent', 'and', 'it', 'is', 'the', 'r@@', 'ul@@', 'e', 'and', 'the', 'r@@', 'ul@@', 'e.', '</s>']
2024-05-28 12:59:49,736 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:59:49,740 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:59:49,744 - INFO - joeynmt.training - 	Hypothesis: It is excellent and it is the rule and the rule.
2024-05-28 12:59:49,748 - INFO - joeynmt.training - Example #4
2024-05-28 12:59:49,751 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 12:59:49,751 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 12:59:49,751 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'U@@', '.@@', 'K@@', '.', 'The', 'en@@', 'vir@@', 'on@@', 'ment@@', 'al', 're@@', 'li@@', 'gi@@', 'on', 'you', 'will', 'be', 'a', 'little', 'bit', 'of', 'what', 'was', 'in@@', 'no@@', 'v@@', 'ation', 'to', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 12:59:49,752 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:59:49,756 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:59:49,761 - INFO - joeynmt.training - 	Hypothesis: The U.K. The environmental religion you will be a little bit of what was innovation to the last 25 years.
2024-05-28 12:59:53,569 - INFO - joeynmt.training - Epoch   4, Step:    15600, Batch Loss:     1.874841, Batch Acc: 0.430312, Tokens per Sec:    15893, Lr: 0.000300
2024-05-28 12:59:57,714 - INFO - joeynmt.training - Epoch   4, Step:    15700, Batch Loss:     1.903639, Batch Acc: 0.428620, Tokens per Sec:    17487, Lr: 0.000300
2024-05-28 13:00:01,640 - INFO - joeynmt.training - Epoch   4, Step:    15800, Batch Loss:     2.018794, Batch Acc: 0.430064, Tokens per Sec:    18300, Lr: 0.000300
2024-05-28 13:00:05,399 - INFO - joeynmt.training - Epoch   4, Step:    15900, Batch Loss:     2.029073, Batch Acc: 0.436605, Tokens per Sec:    18877, Lr: 0.000300
2024-05-28 13:00:08,985 - INFO - joeynmt.training - Epoch   4, Step:    16000, Batch Loss:     2.024692, Batch Acc: 0.438241, Tokens per Sec:    21107, Lr: 0.000300
2024-05-28 13:00:09,040 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:00:09,095 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:00:22,830 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.97, ppl:   7.19, acc:   0.43, generation: 13.6459[sec], evaluation: 0.0000[sec]
2024-05-28 13:00:22,847 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:00:22,960 - INFO - joeynmt.helpers - delete models/bpe-subword/13500.ckpt
2024-05-28 13:00:22,970 - INFO - joeynmt.training - Example #0
2024-05-28 13:00:22,992 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:00:22,992 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:00:22,992 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'th@@', 'ir@@', 'd', 'of', 'the', 'di@@', 'a@@', 'ma@@', 'z@@', 'ed', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'de@@', 'mon@@', 'str@@', 'ate', 'of', 'the', 'b@@', 'est', 'of', 'the', 'pol@@', 'ice', 'of', 'the', 'most', 'of', 'the', 'most', 'important', 'of', 'the', 'most', 'of', 'the', 'last', 'three', 'of', 'years', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'mic@@', 'ro@@', '-@@', 'si@@', 'ze', 'of', 'the', 'mic@@', 'ros@@', 'cop@@', 'e,', 'the', 'lar@@', 'g@@', 'est', 'of', 'the', 'mic@@', 'ros@@', 'cop@@', 'e.', '</s>']
2024-05-28 13:00:22,993 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:00:22,997 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:00:23,000 - INFO - joeynmt.training - 	Hypothesis: And the third of the diamazed to demonstrate the demonstrate of the best of the police of the most of the most important of the most of the last three of years of the future of the micro-size of the microscope, the largest of the microscope.
2024-05-28 13:00:23,004 - INFO - joeynmt.training - Example #1
2024-05-28 13:00:23,008 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:00:23,008 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:00:23,008 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'ex@@', 'pen@@', 'si@@', 've', 'of', 'the', 'things', 'that', 'the', 'prob@@', 'le@@', 'm', 'because', 'the', 'prob@@', 'le@@', 'm', 'because', "it's", 'not', 'ar@@', 'gu@@', 'e', 'of', 'the', 'b@@', 'om@@', 'b@@', '.', '</s>']
2024-05-28 13:00:23,008 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:00:23,012 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:00:23,015 - INFO - joeynmt.training - 	Hypothesis: But this is the expensive of the things that the problem because the problem because it's not argue of the bomb.
2024-05-28 13:00:23,019 - INFO - joeynmt.training - Example #2
2024-05-28 13:00:23,215 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:00:23,215 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:00:23,215 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'of', 'pol@@', 'l@@', 'en', 'in', 'a', 'way', 'of', 'ma@@', 'king', 'the', 'f@@', 'un@@', 'n@@', 'y', 'that', 'is', 'the', 'glob@@', 'al', 'system@@', '.', '</s>']
2024-05-28 13:00:23,215 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:00:23,333 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:00:23,392 - INFO - joeynmt.training - 	Hypothesis: The police of pollen in a way of making the funny that is the global system.
2024-05-28 13:00:23,467 - INFO - joeynmt.training - Example #3
2024-05-28 13:00:23,602 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:00:23,602 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:00:23,602 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'cit@@', 'ed', 'and', 'they', 'can', 'use', 'the', 'de@@', 'ad', 'and', 'con@@', 'nec@@', 'tion.', '</s>']
2024-05-28 13:00:23,602 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:00:23,606 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:00:23,609 - INFO - joeynmt.training - 	Hypothesis: She was excited and they can use the dead and connection.
2024-05-28 13:00:23,648 - INFO - joeynmt.training - Example #4
2024-05-28 13:00:23,652 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:00:23,652 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:00:23,652 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'sec@@', 'ond', 'di@@', 'a@@', 'vi@@', 'g@@', 'ate', 'of', 'the', 'di@@', 'a@@', 'ma@@', 'z@@', 'ing', 'will', 'be', 'a', 'little', 'bit', 'of', 'what', 'was', 'in@@', 't@@', 'am@@', 'i@@', 'd@@', 'd@@', 'am@@', 'ed', 'on', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:00:23,653 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:00:23,655 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:00:23,659 - INFO - joeynmt.training - 	Hypothesis: The second diavigate of the diamazing will be a little bit of what was intamiddamed on the last 25 years.
2024-05-28 13:00:26,469 - INFO - joeynmt.training - Epoch   4, Step:    16100, Batch Loss:     2.017320, Batch Acc: 0.433876, Tokens per Sec:    19412, Lr: 0.000300
2024-05-28 13:00:29,635 - INFO - joeynmt.training - Epoch   4, Step:    16200, Batch Loss:     1.874888, Batch Acc: 0.436481, Tokens per Sec:    22699, Lr: 0.000300
2024-05-28 13:00:33,295 - INFO - joeynmt.training - Epoch   4, Step:    16300, Batch Loss:     1.821887, Batch Acc: 0.435650, Tokens per Sec:    19379, Lr: 0.000300
2024-05-28 13:00:37,409 - INFO - joeynmt.training - Epoch   4, Step:    16400, Batch Loss:     2.094539, Batch Acc: 0.440750, Tokens per Sec:    17018, Lr: 0.000300
2024-05-28 13:00:41,464 - INFO - joeynmt.training - Epoch   4, Step:    16500, Batch Loss:     2.126727, Batch Acc: 0.438409, Tokens per Sec:    16949, Lr: 0.000300
2024-05-28 13:00:41,468 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:00:41,471 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:01:03,959 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.97, ppl:   7.15, acc:   0.43, generation: 22.4656[sec], evaluation: 0.0000[sec]
2024-05-28 13:01:04,020 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:01:04,181 - INFO - joeynmt.helpers - delete models/bpe-subword/14000.ckpt
2024-05-28 13:01:04,247 - INFO - joeynmt.training - Example #0
2024-05-28 13:01:04,282 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:01:04,282 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:01:04,282 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'th@@', 'ir@@', 'd', 'I', 'ar@@', 'ri@@', 'ved', 'these', 'two', 'de@@', 'gre@@', 'es', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'loo@@', 'd', 'of', 'the', 'most', 'most', 'of', 'the', 'most', 'most', 'of', 'the', 'most', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'worl@@', 'd@@', "'s", 'a', 'very', 'd@@', 'imen@@', 'sion@@', 'al', 'st@@', 'ate', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'ut@@', 'u@@', 're.', '</s>']
2024-05-28 13:01:04,283 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:01:04,301 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:01:04,362 - INFO - joeynmt.training - 	Hypothesis: And the third I arrived these two degrees to demonstrate the best of the best of the blood of the most most of the most most of the most three million years of the world's a very dimensional state of the future of the future of the future.
2024-05-28 13:01:04,450 - INFO - joeynmt.training - Example #1
2024-05-28 13:01:04,505 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:01:04,505 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:01:04,505 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'ser@@', 'i@@', 'es', 'of', 'this', 'prob@@', 'le@@', 'm', 'because', 'the', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'ar@@', 'gu@@', 'e', 'the', 'b@@', 'ab@@', 'y', 'of', 'the', 'b@@', 'ab@@', 'y.', '</s>']
2024-05-28 13:01:04,506 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:01:04,574 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:01:04,613 - INFO - joeynmt.training - 	Hypothesis: But this is the series of this problem because the problem because it doesn't argue the baby of the baby.
2024-05-28 13:01:04,742 - INFO - joeynmt.training - Example #2
2024-05-28 13:01:04,768 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:01:04,769 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:01:04,769 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'of', 'the', 'pol@@', 'ice', 'of', 'a', 'w@@', 'in@@', 'do@@', 'w,', 'the', 'im@@', 'medi@@', 'at@@', 'ely', 'system@@', '.', '</s>']
2024-05-28 13:01:04,769 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:01:04,773 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:01:04,776 - INFO - joeynmt.training - 	Hypothesis: The police of the police of a window, the immediately system.
2024-05-28 13:01:04,779 - INFO - joeynmt.training - Example #3
2024-05-28 13:01:04,799 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:01:04,800 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:01:04,800 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'cit@@', 'ing', 'the', 'w@@', 'in@@', 'do@@', 'w', 'and', 'they', 'can', 'r@@', 'un', 'the', 'w@@', 'in@@', 'do@@', 'w', 'of', 'the', 'v@@', 'ari@@', 'et@@', 'y.', '</s>']
2024-05-28 13:01:04,800 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:01:04,813 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:01:04,820 - INFO - joeynmt.training - 	Hypothesis: She was exciting the window and they can run the window of the variety.
2024-05-28 13:01:04,823 - INFO - joeynmt.training - Example #4
2024-05-28 13:01:04,827 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:01:04,827 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:01:04,827 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'sec@@', 'ond', 'di@@', 'a@@', 'ma@@', 'z@@', 'ing', 'that', 'you', 'will', 'be', 'a', 'little', 'bit', 'of', 'the', 'f@@', 'ast@@', 'er', 'will', 'be', 'a', 'f@@', 'ast@@', 'er', 'on', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:01:04,827 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:01:04,831 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:01:04,835 - INFO - joeynmt.training - 	Hypothesis: The second diamazing that you will be a little bit of the faster will be a faster on the last 25 years.
2024-05-28 13:01:08,636 - INFO - joeynmt.training - Epoch   4, Step:    16600, Batch Loss:     1.857250, Batch Acc: 0.438065, Tokens per Sec:    15384, Lr: 0.000300
2024-05-28 13:01:12,634 - INFO - joeynmt.training - Epoch   4, Step:    16700, Batch Loss:     1.916626, Batch Acc: 0.441224, Tokens per Sec:    17447, Lr: 0.000300
2024-05-28 13:01:16,752 - INFO - joeynmt.training - Epoch   4, Step:    16800, Batch Loss:     1.783005, Batch Acc: 0.443934, Tokens per Sec:    17516, Lr: 0.000300
2024-05-28 13:01:20,978 - INFO - joeynmt.training - Epoch   4, Step:    16900, Batch Loss:     2.021373, Batch Acc: 0.439954, Tokens per Sec:    17384, Lr: 0.000300
2024-05-28 13:01:24,786 - INFO - joeynmt.training - Epoch   4, Step:    17000, Batch Loss:     2.066007, Batch Acc: 0.449876, Tokens per Sec:    19389, Lr: 0.000300
2024-05-28 13:01:24,855 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:01:24,947 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:01:48,948 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.94, ppl:   6.99, acc:   0.44, generation: 23.9528[sec], evaluation: 0.0000[sec]
2024-05-28 13:01:48,952 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:01:49,047 - INFO - joeynmt.helpers - delete models/bpe-subword/14500.ckpt
2024-05-28 13:01:49,055 - INFO - joeynmt.training - Example #0
2024-05-28 13:01:49,072 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:01:49,072 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:01:49,072 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'ar@@', 'gu@@', 'ed', 'these', 'two', 'sec@@', 'ond', 'di@@', 'a@@', 'vi@@', 'd', 'to', 'de@@', 'mon@@', 'str@@', 'ation', 'to', 'de@@', 'mon@@', 'str@@', 'ation', 'that', 'the', 'p@@', 'ag@@', 'e,', 'the', 'most', 'of', 'the', 'worl@@', 'd,', 'the', 'most', 'mon@@', 'ey', 'that', 'the', 'most', 'three', 'mil@@', 'lion', 'years', 'ag@@', 'o', 'was', 'a', 'm@@', 'ess@@', 'age', 'of', 'the', 'lar@@', 'ge', 'of', 'a', 'mil@@', 'lion', 'years', 'ag@@', 'o.', '</s>']
2024-05-28 13:01:49,073 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:01:49,076 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:01:49,079 - INFO - joeynmt.training - 	Hypothesis: And I was argued these two second diavid to demonstration to demonstration that the page, the most of the world, the most money that the most three million years ago was a message of the large of a million years ago.
2024-05-28 13:01:49,082 - INFO - joeynmt.training - Example #1
2024-05-28 13:01:49,097 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:01:49,097 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:01:49,097 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'ser@@', 'i@@', 'es', 'of', 'the', 'problem@@', 's', 'of', 'the', 'prob@@', 'le@@', 'm', 'because', 'the', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'ar@@', 'gu@@', 'e', 'the', 'ar@@', 't', 'of', 'the', 'prob@@', 'le@@', 'm', 'of', 'the', 't@@', 'as@@', 'k', 'of', 'the', 'prob@@', 'le@@', 'm', 'of', 'the', 'ar@@', 't', 'of', 'the', 'prob@@', 'le@@', 'm', 'of', 'the', 'prob@@', 'le@@', 'm', 'of', 'the', 'prob@@', 'le@@', 'm', 'of', 'the', 'problem@@', 's', 'of', 'the', 't@@', 'y@@', 'p@@', 'es', 'of', 'the', 'w@@', 'in@@', 'do@@', 'w', 'that', 'the', 'w@@', 'in@@', 'do@@', 'w', 'this', 're@@', 'u@@', 'ge@@', 'd@@', 's.', '</s>']
2024-05-28 13:01:49,098 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:01:49,101 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:01:49,119 - INFO - joeynmt.training - 	Hypothesis: But this is the series of the problems of the problem because the problem because it doesn't argue the art of the problem of the task of the problem of the art of the problem of the problem of the problem of the problems of the types of the window that the window this reugeds.
2024-05-28 13:01:49,123 - INFO - joeynmt.training - Example #2
2024-05-28 13:01:49,126 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:01:49,126 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:01:49,126 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'l@@', 'en', 'of', 'pol@@', 'l@@', 'en', 'in', 'a', 'way', 'of', 'ho@@', 'p@@', 'e,', 'the', 'im@@', 'medi@@', 'at@@', 'ely', 'glob@@', 'al', 'econom@@', 'ic', 'system@@', '.', '</s>']
2024-05-28 13:01:49,127 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:01:49,159 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:01:49,174 - INFO - joeynmt.training - 	Hypothesis: The pollen of pollen in a way of hope, the immediately global economic system.
2024-05-28 13:01:49,177 - INFO - joeynmt.training - Example #3
2024-05-28 13:01:49,181 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:01:49,181 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:01:49,181 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'ex@@', 'cit@@', 'ing', 'and', 'the', 'com@@', 'es', 'and', 'contr@@', 'ol', 'and', 'contr@@', 'ol', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:01:49,182 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:01:49,207 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:01:49,211 - INFO - joeynmt.training - 	Hypothesis: It was exciting and the comes and control and control and contract.
2024-05-28 13:01:49,215 - INFO - joeynmt.training - Example #4
2024-05-28 13:01:49,218 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:01:49,218 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:01:49,218 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'sec@@', 'ond', 'de@@', 'mo@@', 'cr@@', 'ac@@', 'y', 'that', "I'm", 'going', 'to', 'show', 'you', 'that', "I'm", 'going', 'to', 'be', 'a', 'f@@', 'ast@@', 'er', 'on', 'what', 'it', 'was', 'going', 'to', 'be', 'a', 'f@@', 'un@@', 'ded', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:01:49,219 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:01:49,236 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:01:49,240 - INFO - joeynmt.training - 	Hypothesis: The second democracy that I'm going to show you that I'm going to be a faster on what it was going to be a funded in the last 25 years.
2024-05-28 13:01:52,783 - INFO - joeynmt.training - Epoch   4, Step:    17100, Batch Loss:     1.936152, Batch Acc: 0.449232, Tokens per Sec:    18670, Lr: 0.000300
2024-05-28 13:01:56,769 - INFO - joeynmt.training - Epoch   4, Step:    17200, Batch Loss:     2.132734, Batch Acc: 0.441626, Tokens per Sec:    17658, Lr: 0.000300
2024-05-28 13:02:00,769 - INFO - joeynmt.training - Epoch   4, Step:    17300, Batch Loss:     1.835836, Batch Acc: 0.448103, Tokens per Sec:    17921, Lr: 0.000300
2024-05-28 13:02:04,838 - INFO - joeynmt.training - Epoch   4, Step:    17400, Batch Loss:     1.947236, Batch Acc: 0.448589, Tokens per Sec:    17682, Lr: 0.000300
2024-05-28 13:02:08,861 - INFO - joeynmt.training - Epoch   4, Step:    17500, Batch Loss:     1.947700, Batch Acc: 0.445005, Tokens per Sec:    17719, Lr: 0.000300
2024-05-28 13:02:08,888 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:02:08,892 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:02:34,221 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.85, acc:   0.45, generation: 25.3078[sec], evaluation: 0.0000[sec]
2024-05-28 13:02:34,242 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:02:34,347 - INFO - joeynmt.helpers - delete models/bpe-subword/15000.ckpt
2024-05-28 13:02:34,374 - INFO - joeynmt.training - Example #0
2024-05-28 13:02:34,378 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:02:34,378 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:02:34,378 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'th@@', 'ir@@', 'd', 'of', 'these', 'two', 'of', 'the', 'p@@', 'sy@@', 'ch@@', 'o@@', 'ic@@', '-@@', 'de@@', 'mon@@', 'str@@', 'ate', 'to', 'the', 'b@@', 'ri@@', 'ef@@', 'ly', 'de@@', 'mon@@', 'str@@', 'ate', 'of', 'the', 'b@@', 'est', 'of', 'the', 'most', 'popul@@', 'ation', 'of', 'the', 'most', 'mon@@', 'ey', 'has', 'been', 'a', 'big', 'de@@', 'si@@', 're', 'of', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'lar@@', 'g@@', 'est', 'f@@', 'our', 'percent', 'of', 'the', 'f@@', 'our@@', '.', '</s>']
2024-05-28 13:02:34,378 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:02:34,382 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:02:34,386 - INFO - joeynmt.training - 	Hypothesis: And the third of these two of the psychoic-demonstrate to the briefly demonstrate of the best of the most population of the most money has been a big desire of the future of the four percent of the four percent of the four percent of the largest four percent of the four.
2024-05-28 13:02:34,416 - INFO - joeynmt.training - Example #1
2024-05-28 13:02:34,421 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:02:34,421 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:02:34,421 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'ser@@', 'i@@', 'es', 'of', 'this', 'speci@@', 'al', 'prob@@', 'le@@', 'm', 'that', 'is', 'not', 'the', 'speci@@', 'al', 'prob@@', 'le@@', 'm', 'that', "doesn't", 'have', 'ar@@', 'gu@@', 'ed', 'the', 'gr@@', 'ou@@', 'p@@', '.', '</s>']
2024-05-28 13:02:34,422 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:02:34,427 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:02:34,459 - INFO - joeynmt.training - 	Hypothesis: But this is the series of this special problem that is not the special problem that doesn't have argued the group.
2024-05-28 13:02:34,463 - INFO - joeynmt.training - Example #2
2024-05-28 13:02:34,467 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:02:34,467 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:02:34,467 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'of', 'the', 'pol@@', 'ice', 'of', 'the', 'pol@@', 'e,', 'the', 'im@@', 'medi@@', 'at@@', 'ely', 'that', 'the', 'res@@', 'ul@@', 't', 'of', 'the', 'glob@@', 'al', 'system@@', '.', '</s>']
2024-05-28 13:02:34,468 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:02:34,471 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:02:34,478 - INFO - joeynmt.training - 	Hypothesis: The police of the police of the pole, the immediately that the result of the global system.
2024-05-28 13:02:34,482 - INFO - joeynmt.training - Example #3
2024-05-28 13:02:34,486 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:02:34,486 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:02:34,486 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'ex@@', 'tin@@', 'c@@', 'tion', 'and', 'the', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:02:34,487 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:02:34,490 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:02:34,494 - INFO - joeynmt.training - 	Hypothesis: She extinction and the contract.
2024-05-28 13:02:34,516 - INFO - joeynmt.training - Example #4
2024-05-28 13:02:34,520 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:02:34,520 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:02:34,521 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'pi@@', 'ec@@', 'e', 'of', 'the', 'ph@@', 'ys@@', 'ical', 'sp@@', 'e@@', 'ed', 'that', "I'm", 'going', 'to', 'show', 'you', 'a', 'de@@', 'ta@@', 'il@@', ',', 'the', 'next', '2@@', '5', 'years', 'ag@@', 'o.', '</s>']
2024-05-28 13:02:34,521 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:02:34,566 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:02:34,571 - INFO - joeynmt.training - 	Hypothesis: The next piece of the physical speed that I'm going to show you a detail, the next 25 years ago.
2024-05-28 13:02:38,017 - INFO - joeynmt.training - Epoch   4, Step:    17600, Batch Loss:     1.813100, Batch Acc: 0.452912, Tokens per Sec:    19131, Lr: 0.000300
2024-05-28 13:02:41,314 - INFO - joeynmt.training - Epoch   4, Step:    17700, Batch Loss:     1.851809, Batch Acc: 0.455600, Tokens per Sec:    21100, Lr: 0.000300
2024-05-28 13:02:44,664 - INFO - joeynmt.training - Epoch   4, Step:    17800, Batch Loss:     1.797328, Batch Acc: 0.456886, Tokens per Sec:    21519, Lr: 0.000300
2024-05-28 13:02:48,009 - INFO - joeynmt.training - Epoch   4, Step:    17900, Batch Loss:     2.120691, Batch Acc: 0.456187, Tokens per Sec:    21563, Lr: 0.000300
2024-05-28 13:02:51,397 - INFO - joeynmt.training - Epoch   4, Step:    18000, Batch Loss:     1.830893, Batch Acc: 0.456992, Tokens per Sec:    21480, Lr: 0.000300
2024-05-28 13:02:51,402 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:02:51,407 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:03:17,730 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.75, acc:   0.45, generation: 26.3015[sec], evaluation: 0.0000[sec]
2024-05-28 13:03:17,752 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:03:17,836 - INFO - joeynmt.helpers - delete models/bpe-subword/15500.ckpt
2024-05-28 13:03:17,855 - INFO - joeynmt.training - Example #0
2024-05-28 13:03:17,892 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:03:17,892 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:03:17,892 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'ar@@', 'gu@@', 'e', 'I', 'ar@@', 'gu@@', 'e', 'these', 'two', 'sec@@', 'ond', 'de@@', 'mon@@', 'str@@', 'ate', 'in', 'the', 'f@@', 'ar@@', 'mer@@', ',', 'the', 'most', 'in@@', 'side', 'of', 'the', 'most', 'popul@@', 'ar', 'l@@', 'ine', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'f@@', 'ut@@', 'u@@', 're,', 'was', 'a', 'sm@@', 'all', 's@@', 'li@@', 'ght@@', 'ly', 'f@@', 'our', 'mic@@', 'ros@@', 'cop@@', 'e,', 'it', 'was', 'a', 'sm@@', 'all', 'st@@', 'ate', 'of', '4@@', '0', 'percent', 'of', 'the', 'mic@@', 'ros@@', 'cop@@', 'e.', '</s>']
2024-05-28 13:03:17,893 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:03:17,897 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:03:17,900 - INFO - joeynmt.training - 	Hypothesis: And I argue I argue these two second demonstrate in the farmer, the most inside of the most popular line of the last three million years of the future, was a small slightly four microscope, it was a small state of 40 percent of the microscope.
2024-05-28 13:03:17,903 - INFO - joeynmt.training - Example #1
2024-05-28 13:03:17,907 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:03:17,907 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:03:17,907 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'im@@', 'medi@@', 'at@@', 'ely', 'un@@', 'ex@@', 'p@@', 'ec@@', 'ted', 'speci@@', 'al', 'problem@@', 's', 'that', 'not', 'ar@@', 'gu@@', 'e', 'that', 'not', 'ar@@', 'gu@@', 'e', 'the', 'f@@', 'ar@@', 'mer@@', '.', '</s>']
2024-05-28 13:03:17,908 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:03:17,911 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:03:17,915 - INFO - joeynmt.training - 	Hypothesis: But this is the immediately unexpected special problems that not argue that not argue the farmer.
2024-05-28 13:03:17,919 - INFO - joeynmt.training - Example #2
2024-05-28 13:03:17,962 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:03:17,962 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:03:17,962 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'pol@@', 'l@@', 'en', 'is', 'the', 'in@@', 'side', 'of', 'a', 'way', 'that', 'the', 'f@@', 'ut@@', 'ure', 'system@@', ',', 'the', 'im@@', 'plic@@', 'ation', 'of', 'the', 'f@@', 'ut@@', 'u@@', 're.', '</s>']
2024-05-28 13:03:17,962 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:03:17,966 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:03:17,969 - INFO - joeynmt.training - 	Hypothesis: The police pollen is the inside of a way that the future system, the implication of the future.
2024-05-28 13:03:17,972 - INFO - joeynmt.training - Example #3
2024-05-28 13:03:17,976 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:03:17,976 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:03:17,976 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'ex@@', 'tin@@', 'c@@', 't', 'and', 'ex@@', 'tin@@', 'c@@', 't', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:03:17,976 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:03:17,990 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:03:18,016 - INFO - joeynmt.training - 	Hypothesis: She extinct and extinct and contract.
2024-05-28 13:03:18,020 - INFO - joeynmt.training - Example #4
2024-05-28 13:03:18,023 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:03:18,023 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:03:18,023 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'U@@', '.@@', 'S@@', '.', 'I', 'will', 'look', 'at', 'the', 'f@@', 'ast@@', 'er', 'that', "I'm", 'going', 'to', 'show', 'you', 'a', 'will', 'be', 'a', 'f@@', 'ast@@', 'er', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:03:18,024 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:03:18,027 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:03:18,052 - INFO - joeynmt.training - 	Hypothesis: The U.S. I will look at the faster that I'm going to show you a will be a faster in the last 25 years.
2024-05-28 13:03:21,445 - INFO - joeynmt.training - Epoch   4, Step:    18100, Batch Loss:     1.894645, Batch Acc: 0.457778, Tokens per Sec:    19283, Lr: 0.000300
2024-05-28 13:03:24,387 - INFO - joeynmt.training - Epoch   4: total training loss 8858.69
2024-05-28 13:03:24,391 - INFO - joeynmt.training - EPOCH 5
2024-05-28 13:03:25,459 - INFO - joeynmt.training - Epoch   5, Step:    18200, Batch Loss:     1.820998, Batch Acc: 0.465739, Tokens per Sec:    19056, Lr: 0.000300
2024-05-28 13:03:29,668 - INFO - joeynmt.training - Epoch   5, Step:    18300, Batch Loss:     1.862754, Batch Acc: 0.469879, Tokens per Sec:    16890, Lr: 0.000300
2024-05-28 13:03:33,813 - INFO - joeynmt.training - Epoch   5, Step:    18400, Batch Loss:     1.887944, Batch Acc: 0.470370, Tokens per Sec:    17305, Lr: 0.000300
2024-05-28 13:03:37,818 - INFO - joeynmt.training - Epoch   5, Step:    18500, Batch Loss:     1.744549, Batch Acc: 0.465828, Tokens per Sec:    17233, Lr: 0.000300
2024-05-28 13:03:37,823 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:03:37,827 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:04:07,163 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.62, acc:   0.46, generation: 29.2930[sec], evaluation: 0.0000[sec]
2024-05-28 13:04:07,167 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:04:07,255 - INFO - joeynmt.helpers - delete models/bpe-subword/16000.ckpt
2024-05-28 13:04:07,276 - INFO - joeynmt.training - Example #0
2024-05-28 13:04:07,280 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:04:07,280 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:04:07,280 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'sho@@', 'wn', 'these', 'two', 'de@@', 'gre@@', 'e', 'di@@', 'a@@', 'th@@', 's', 'to', 'de@@', 'mon@@', 'str@@', 'ation', 'to', 'the', 'mon@@', 'str@@', 'ai@@', 'ght', 'of', 'the', 'pol@@', 'ice', 'of', 'the', 'mon@@', 'ey', 'that', 'the', 'ma@@', 'in', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'mon@@', 'ey', 'of', 'the', 'm@@', 'en', 'of', '4@@', '0', 'percent', 'of', 'the', 'm@@', 'en', 's@@', 'qu@@', 'are', 'a', 'little', 'bit', 'of', '4@@', '0', 'percent', 'of', 'the', 'm@@', 'en', 's@@', 'qu@@', 'are', 'a', 'few', 'percent', 'of', 'the', 'm@@', 'en', 's@@', 'at@@', 'ell@@', 'ite', 'a', 'few', 'percent', 'of', 'the', 'next', '20', 'percent', 'of', 'the', 'next', '20', 'percent', 'of', 'the', 'next', '20', 'percent', 'of', 'these', 'two', 'percent', 'of', 'the', 'p@@', 'ast', 'three']
2024-05-28 13:04:07,281 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:04:07,284 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:04:07,291 - INFO - joeynmt.training - 	Hypothesis: And I was shown these two degree diaths to demonstration to the monstraight of the police of the money that the main the last three million years of the money of the men of 40 percent of the men square a little bit of 40 percent of the men square a few percent of the men satellite a few percent of the next 20 percent of the next 20 percent of the next 20 percent of these two percent of the past three
2024-05-28 13:04:07,294 - INFO - joeynmt.training - Example #1
2024-05-28 13:04:07,297 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:04:07,297 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:04:07,298 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'hear@@', 't', 'of', 'this', 'problem@@', 's', 'that', 'the', 'prob@@', 'le@@', 'm', 'because', 'the', 'prob@@', 'le@@', 'm', 'of', 'the', 'prob@@', 'le@@', 'm', 'of', 'the', 'b@@', 'os@@', '.', '</s>']
2024-05-28 13:04:07,298 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:04:07,302 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:04:07,306 - INFO - joeynmt.training - 	Hypothesis: But this is the heart of this problems that the problem because the problem of the problem of the bos.
2024-05-28 13:04:07,310 - INFO - joeynmt.training - Example #2
2024-05-28 13:04:07,344 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:04:07,344 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:04:07,344 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'l@@', 'y@@', 'n@@', 'am@@', ',', 'the', 'hear@@', 't,', 'the', 'hear@@', 't', 'of', 'the', 'c@@', 'ar', 'system@@', ',', 'the', 'hear@@', 't', 'of', 'the', 'c@@', 'ar', 'system@@', '.', '</s>']
2024-05-28 13:04:07,344 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:04:07,348 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:04:07,351 - INFO - joeynmt.training - 	Hypothesis: The pollynam, the heart, the heart of the car system, the heart of the car system.
2024-05-28 13:04:07,354 - INFO - joeynmt.training - Example #3
2024-05-28 13:04:07,358 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:04:07,358 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:04:07,358 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'cit@@', 'ing', 'and', 'the', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:04:07,358 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:04:07,363 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:04:07,369 - INFO - joeynmt.training - 	Hypothesis: She was exciting and the contract.
2024-05-28 13:04:07,373 - INFO - joeynmt.training - Example #4
2024-05-28 13:04:07,377 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:04:07,377 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:04:07,377 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'sec@@', 'ond', 're@@', 't', 'that', 'I', 'will', 'show', 'you', 'that', "I'm", 'going', 'to', 'show', 'you', 'a', 'st@@', 'ory', 'will', 'be', 'a', 'f@@', 'ast@@', 'er', 'on', 'what', 'was', 'in@@', 'tu@@', 'iti@@', 'on', 'to', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:04:07,378 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:04:07,381 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:04:07,385 - INFO - joeynmt.training - 	Hypothesis: The second ret that I will show you that I'm going to show you a story will be a faster on what was intuition to the last 25 years.
2024-05-28 13:04:10,745 - INFO - joeynmt.training - Epoch   5, Step:    18600, Batch Loss:     1.883600, Batch Acc: 0.470491, Tokens per Sec:    19528, Lr: 0.000300
2024-05-28 13:04:14,425 - INFO - joeynmt.training - Epoch   5, Step:    18700, Batch Loss:     1.788807, Batch Acc: 0.475164, Tokens per Sec:    19328, Lr: 0.000300
2024-05-28 13:04:18,425 - INFO - joeynmt.training - Epoch   5, Step:    18800, Batch Loss:     1.667992, Batch Acc: 0.476496, Tokens per Sec:    17921, Lr: 0.000300
2024-05-28 13:04:22,397 - INFO - joeynmt.training - Epoch   5, Step:    18900, Batch Loss:     1.682968, Batch Acc: 0.470755, Tokens per Sec:    18078, Lr: 0.000300
2024-05-28 13:04:26,462 - INFO - joeynmt.training - Epoch   5, Step:    19000, Batch Loss:     1.725577, Batch Acc: 0.469944, Tokens per Sec:    17385, Lr: 0.000300
2024-05-28 13:04:26,483 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:04:26,486 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:05:15,202 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.55, acc:   0.46, generation: 48.4674[sec], evaluation: 0.0000[sec]
2024-05-28 13:05:15,234 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:05:18,560 - INFO - joeynmt.helpers - delete models/bpe-subword/16500.ckpt
2024-05-28 13:05:18,578 - INFO - joeynmt.training - Example #0
2024-05-28 13:05:18,583 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:05:18,583 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:05:18,583 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'got', 'these', 'two', 'of', 'the', 'p@@', 'ast', 'di@@', 'a@@', 'th@@', 's', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'as', 'the', 'in@@', 'jur@@', 'y', 'to', 'the', 'b@@', 'ro@@', 'ke', 'of', 'the', 'pol@@', 'ice', 'that', 'the', 'ma@@', 'in', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'f@@', 'our', 'bil@@', 'lion', 'years', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'last', '20', 'percent', 'of', 'the', 'th@@', 'ir@@', 'd', 'of', 'the', 'th@@', 'ir@@', 'd', 'of', 'the', 'th@@', 'ir@@', 'd', 'of', 'the', 'p@@', 'ast', 'year@@', '.', '</s>']
2024-05-28 13:05:18,584 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:05:18,587 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:05:18,591 - INFO - joeynmt.training - 	Hypothesis: I got these two of the past diaths to demonstrate as the injury to the broke of the police that the main the last three million years of the last three million years of the four percent of the four billion years of the four percent of the four percent of the four percent of the four percent of the four percent of the last 20 percent of the third of the third of the third of the past year.
2024-05-28 13:05:18,619 - INFO - joeynmt.training - Example #1
2024-05-28 13:05:18,623 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:05:18,623 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:05:18,623 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'im@@', 'pro@@', 've', 'speci@@', 'al', 'problem@@', 's', 'that', 'is', 'not', 'the', 'f@@', 'is@@', 'h', 'of', 'the', 'b@@', 'os@@', 's', 'of', 'the', 'b@@', 'os@@', '.', '</s>']
2024-05-28 13:05:18,624 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:05:18,628 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:05:18,631 - INFO - joeynmt.training - 	Hypothesis: But this is the improve special problems that is not the fish of the boss of the bos.
2024-05-28 13:05:18,634 - INFO - joeynmt.training - Example #2
2024-05-28 13:05:18,638 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:05:18,638 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:05:18,638 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'pol@@', 'l@@', 'en', 'is', 'the', 'pol@@', 'ic@@', 'y', 'of', 'the', 'cl@@', 'im@@', 'ate', 'system@@', ',', 'the', 'glob@@', 'al', 'system@@', '.', '</s>']
2024-05-28 13:05:18,639 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:05:18,642 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:05:18,663 - INFO - joeynmt.training - 	Hypothesis: The police pollen is the policy of the climate system, the global system.
2024-05-28 13:05:18,667 - INFO - joeynmt.training - Example #3
2024-05-28 13:05:18,671 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:05:18,671 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:05:18,671 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'ex@@', 'tin@@', 'c@@', 't', 'and', 'they', 'can', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:05:18,672 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:05:18,675 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:05:18,678 - INFO - joeynmt.training - 	Hypothesis: She extinct and they can contract.
2024-05-28 13:05:18,680 - INFO - joeynmt.training - Example #4
2024-05-28 13:05:18,714 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:05:18,714 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:05:18,714 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'sec@@', 'ond', 'di@@', 'a@@', 'th@@', 's', 'that', "I'm", 'going', 'to', 'show', 'you', 'a', 'f@@', 'ast@@', 'er', 'will', 'be', 'a', 'f@@', 'ast@@', 'er', 'to', 'what', 'happen@@', 's', 'to', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:05:18,715 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:05:18,732 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:05:18,738 - INFO - joeynmt.training - 	Hypothesis: The second diaths that I'm going to show you a faster will be a faster to what happens to the last 25 years.
2024-05-28 13:05:22,803 - INFO - joeynmt.training - Epoch   5, Step:    19100, Batch Loss:     1.985037, Batch Acc: 0.469933, Tokens per Sec:     9184, Lr: 0.000300
2024-05-28 13:05:26,920 - INFO - joeynmt.training - Epoch   5, Step:    19200, Batch Loss:     1.853484, Batch Acc: 0.474296, Tokens per Sec:    17328, Lr: 0.000300
2024-05-28 13:05:31,000 - INFO - joeynmt.training - Epoch   5, Step:    19300, Batch Loss:     1.602125, Batch Acc: 0.468066, Tokens per Sec:    17493, Lr: 0.000300
2024-05-28 13:05:35,105 - INFO - joeynmt.training - Epoch   5, Step:    19400, Batch Loss:     1.878333, Batch Acc: 0.469810, Tokens per Sec:    17449, Lr: 0.000300
2024-05-28 13:05:39,134 - INFO - joeynmt.training - Epoch   5, Step:    19500, Batch Loss:     1.790802, Batch Acc: 0.477340, Tokens per Sec:    17634, Lr: 0.000300
2024-05-28 13:05:39,155 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:05:39,175 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:06:11,002 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.86, ppl:   6.40, acc:   0.46, generation: 31.8051[sec], evaluation: 0.0000[sec]
2024-05-28 13:06:11,006 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:06:11,093 - INFO - joeynmt.helpers - delete models/bpe-subword/17000.ckpt
2024-05-28 13:06:11,104 - INFO - joeynmt.training - Example #0
2024-05-28 13:06:11,145 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:06:11,145 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:06:11,145 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'got', 'these', 'two', 'of', 'the', 'sec@@', 'ond', 'di@@', 'a@@', 'th@@', 'le@@', 'f@@', 't', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'as', 'a', 're@@', 'por@@', 't', 'of', 'the', 'pol@@', 'ice', 'of', 'the', 'b@@', 'est', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 's@@', 'li@@', 'de', 'of', '4@@', '8', 'percent', 'of', 'the', 's@@', 'li@@', 'ght@@', 'ly', '50', 'percent', 'of', 'the', 'big', 'st@@', 'ate', 'of', 'a', 'few', 'percent', 'of', 'the', 'big', 'st@@', 'ate', 'of', 'the', 'big', 'st@@', 'ate', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'st@@', 'ate', 'of', 'the', 'th@@', 'ir@@', 'd', 'of', 'the', 'th@@', 'ir@@', 'd', 'of', 'the', 'th@@', 'ir@@', 'd@@', 'ri@@', 'ven', 'percent', 'of', 'the', 'to@@', 'p']
2024-05-28 13:06:11,145 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:06:11,152 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:06:11,156 - INFO - joeynmt.training - 	Hypothesis: And I got these two of the second diathleft to demonstrate as a report of the police of the best of the last three million years of the last three million years of the slide of 48 percent of the slightly 50 percent of the big state of a few percent of the big state of the big state of the four percent of the state of the third of the third of the thirdriven percent of the top
2024-05-28 13:06:11,160 - INFO - joeynmt.training - Example #1
2024-05-28 13:06:11,163 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:06:11,163 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:06:11,163 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'im@@', 'medi@@', 'at@@', 'ely', 'un@@', 'us@@', 'u@@', 'al', 'is@@', 'su@@', 'es', 'because', 'the', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'ar@@', 'gu@@', 'e', 'the', 'b@@', 'om@@', 'b@@', 's.', '</s>']
2024-05-28 13:06:11,164 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:06:11,201 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:06:11,226 - INFO - joeynmt.training - 	Hypothesis: But this is the immediately unusual issues because the problem because it doesn't argue the bombs.
2024-05-28 13:06:11,229 - INFO - joeynmt.training - Example #2
2024-05-28 13:06:11,233 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:06:11,233 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:06:11,233 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'of', 'pol@@', 'l@@', 'y@@', 's,', 'in', 'a', 'way', 'that', 'b@@', 'ro@@', 'ad@@', ',', 'the', 'hear@@', 't', 'of', 'the', 'cl@@', 'im@@', 'ate', 'system@@', '.', '</s>']
2024-05-28 13:06:11,233 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:06:11,237 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:06:11,240 - INFO - joeynmt.training - 	Hypothesis: The police of pollys, in a way that broad, the heart of the climate system.
2024-05-28 13:06:11,244 - INFO - joeynmt.training - Example #3
2024-05-28 13:06:11,248 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:06:11,248 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:06:11,248 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'n@@', 's', 'out', 'to', 'the', 'v@@', 'ari@@', 'ous', 'and', 'can@@', '.', '</s>']
2024-05-28 13:06:11,248 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:06:11,252 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:06:11,255 - INFO - joeynmt.training - 	Hypothesis: It turns out to the various and can.
2024-05-28 13:06:11,267 - INFO - joeynmt.training - Example #4
2024-05-28 13:06:11,290 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:06:11,290 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:06:11,290 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'di@@', 'a@@', 'ff@@', 'ect', 'that', 'the', 'di@@', 'a@@', 'ff@@', 'ect', 'that', 'you', 'will', 'have', 'a', 'will', 'be', 'a', 'f@@', 'ast@@', 'er', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:06:11,290 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:06:11,298 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:06:11,302 - INFO - joeynmt.training - 	Hypothesis: The diaffect that the diaffect that you will have a will be a faster in the last 25 years.
2024-05-28 13:06:14,852 - INFO - joeynmt.training - Epoch   5, Step:    19600, Batch Loss:     1.701589, Batch Acc: 0.468189, Tokens per Sec:    18431, Lr: 0.000300
2024-05-28 13:06:18,838 - INFO - joeynmt.training - Epoch   5, Step:    19700, Batch Loss:     1.869462, Batch Acc: 0.470136, Tokens per Sec:    17887, Lr: 0.000300
2024-05-28 13:06:22,297 - INFO - joeynmt.training - Epoch   5, Step:    19800, Batch Loss:     1.951705, Batch Acc: 0.471588, Tokens per Sec:    20963, Lr: 0.000300
2024-05-28 13:06:26,098 - INFO - joeynmt.training - Epoch   5, Step:    19900, Batch Loss:     1.826056, Batch Acc: 0.476844, Tokens per Sec:    18908, Lr: 0.000300
2024-05-28 13:06:30,031 - INFO - joeynmt.training - Epoch   5, Step:    20000, Batch Loss:     1.732500, Batch Acc: 0.474012, Tokens per Sec:    18144, Lr: 0.000300
2024-05-28 13:06:30,035 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:06:30,039 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:06:48,681 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.38, acc:   0.47, generation: 18.6205[sec], evaluation: 0.0000[sec]
2024-05-28 13:06:48,700 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:06:48,795 - INFO - joeynmt.helpers - delete models/bpe-subword/17500.ckpt
2024-05-28 13:06:48,828 - INFO - joeynmt.training - Example #0
2024-05-28 13:06:48,832 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:06:48,832 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:06:48,832 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'got', 'these', 'two', 'sec@@', 'ond', 'de@@', 'mon@@', 'str@@', 'ated', 'to', 'the', 'f@@', 'ly', 'to', 'the', 'f@@', 'ly', 'to', 'the', 'b@@', 'est', 'of', 'the', 'pol@@', 'l@@', 'ine', 'that', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'was', 'a', 'very', 's@@', 'mar@@', 't', 'of', '4@@', '8', 'percent', 'of', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'percent', 'of', 'the', 'f@@', 'our', 'mic@@', 'e,', 'it', 'was', 'a', 'little', 'bit', 'of', '4@@', '8', 'percent', 'of', 'the', 'f@@', 'our', 'mil@@', 'lion', 'years', 'ol@@', 'd.', '</s>']
2024-05-28 13:06:48,832 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:06:48,888 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:06:48,892 - INFO - joeynmt.training - 	Hypothesis: And I got these two second demonstrated to the fly to the fly to the best of the polline that the last three million years of the last three million years was a very smart of 48 percent of the size of 48 percent of the four mice, it was a little bit of 48 percent of the four million years old.
2024-05-28 13:06:48,896 - INFO - joeynmt.training - Example #1
2024-05-28 13:06:48,899 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:06:48,899 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:06:48,899 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'ser@@', 'i@@', 'ous', 'prob@@', 'le@@', 'm', 'of', 'this', 'speci@@', 'al', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'ar@@', 'gu@@', 'e', 'the', 'b@@', 'ro@@', 'k@@', 'en', 'that', "doesn't", 'have', 'the', 'b@@', 'ro@@', 'k@@', 'en', 'of', 'the', 'b@@', 'ro@@', 'k@@', 'en', 'of', 'the', 'b@@', 'ro@@', 'k@@', 'en', 'of', 'the', 'b@@', 'os@@', 's.', '</s>']
2024-05-28 13:06:48,900 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:06:48,905 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:06:48,909 - INFO - joeynmt.training - 	Hypothesis: But this is the serious problem of this special problem because it doesn't argue the broken that doesn't have the broken of the broken of the broken of the boss.
2024-05-28 13:06:48,950 - INFO - joeynmt.training - Example #2
2024-05-28 13:06:48,953 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:06:48,953 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:06:48,953 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'l@@', 'y@@', '-@@', 'st@@', 'er@@', 'ing', 'thing@@', 's,', 'in', 'the', 'hear@@', 't', 'of', 'the', 'cl@@', 'im@@', 'ate', 'system@@', '.', '</s>']
2024-05-28 13:06:48,954 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:06:48,958 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:06:48,961 - INFO - joeynmt.training - 	Hypothesis: The polly-stering things, in the heart of the climate system.
2024-05-28 13:06:48,965 - INFO - joeynmt.training - Example #3
2024-05-28 13:06:49,003 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:06:49,003 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:06:49,003 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'ten@@', 'd', 'to', 'the', 'v@@', 'ar@@', 'd', 'v@@', 'ar@@', 'd.', '</s>']
2024-05-28 13:06:49,004 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:06:49,077 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:06:49,081 - INFO - joeynmt.training - 	Hypothesis: She was extend to the vard vard.
2024-05-28 13:06:49,085 - INFO - joeynmt.training - Example #4
2024-05-28 13:06:49,089 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:06:49,089 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:06:49,089 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'U@@', 'r@@', 'ing', 'of', 'the', 'di@@', 'a@@', 'ff@@', 'ect', 'that', "I'm", 'going', 'to', 'show', 'you', 'a', 'will', 'be', 'a', 'f@@', 'ast@@', 'er', 'on', 'what', 'he', 'was', 'in@@', 't@@', 'am@@', 'pl@@', 'i@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:06:49,089 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:06:49,093 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:06:49,301 - INFO - joeynmt.training - 	Hypothesis: The Uring of the diaffect that I'm going to show you a will be a faster on what he was intamplied in the last 25 years.
2024-05-28 13:06:52,965 - INFO - joeynmt.training - Epoch   5, Step:    20100, Batch Loss:     1.896760, Batch Acc: 0.473868, Tokens per Sec:    17021, Lr: 0.000300
2024-05-28 13:06:56,714 - INFO - joeynmt.training - Epoch   5, Step:    20200, Batch Loss:     2.005459, Batch Acc: 0.475346, Tokens per Sec:    18705, Lr: 0.000300
2024-05-28 13:07:00,588 - INFO - joeynmt.training - Epoch   5, Step:    20300, Batch Loss:     1.721267, Batch Acc: 0.474907, Tokens per Sec:    18145, Lr: 0.000300
2024-05-28 13:07:04,511 - INFO - joeynmt.training - Epoch   5, Step:    20400, Batch Loss:     1.716142, Batch Acc: 0.479588, Tokens per Sec:    18257, Lr: 0.000300
2024-05-28 13:07:08,554 - INFO - joeynmt.training - Epoch   5, Step:    20500, Batch Loss:     1.576438, Batch Acc: 0.474503, Tokens per Sec:    18018, Lr: 0.000300
2024-05-28 13:07:08,570 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:07:08,586 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:07:36,791 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.83, ppl:   6.21, acc:   0.47, generation: 28.1826[sec], evaluation: 0.0000[sec]
2024-05-28 13:07:36,795 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:07:36,882 - INFO - joeynmt.helpers - delete models/bpe-subword/18000.ckpt
2024-05-28 13:07:36,890 - INFO - joeynmt.training - Example #0
2024-05-28 13:07:36,911 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:07:36,911 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:07:36,911 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'th@@', 'ir@@', 'd', 'ar@@', 't', 'these', 'two', 'of', 'the', 'sec@@', 'ond', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'f@@', 'ar@@', 'm', 'of', 'the', 'pol@@', 'l@@', 'er', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'f@@', 'our', 'mic@@', 'ros@@', 'cop@@', 'e,', 'it', 'was', 'sm@@', 'all@@', ',', 'it', 'se@@', 'em@@', 'ed', 'by', '4@@', '8', 'percent', 'of', 'the', 'mic@@', 'ros@@', 'cop@@', 'e.', '</s>']
2024-05-28 13:07:36,912 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:07:36,916 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:07:36,919 - INFO - joeynmt.training - 	Hypothesis: The third art these two of the second to demonstrate the farm of the poller of the last three million years of the last three million years of the last three million years of the four microscope, it was small, it seemed by 48 percent of the microscope.
2024-05-28 13:07:36,971 - INFO - joeynmt.training - Example #1
2024-05-28 13:07:36,974 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:07:36,974 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:07:36,974 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ity', 'of', 'the', 'problem@@', 's', 'of', 'the', 'problem@@', 's', 'that', 'speci@@', 'al', 'problem@@', 's', 'because', "it's", 'not', 'the', 'ar@@', 'r@@', 'ang@@', 'e', 'of', 'the', 'b@@', 'loc@@', 'k', 'of', 'the', 'b@@', 'os@@', '.', '</s>']
2024-05-28 13:07:36,975 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:07:36,979 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:07:36,982 - INFO - joeynmt.training - 	Hypothesis: But this mornity of the problems of the problems that special problems because it's not the arrange of the block of the bos.
2024-05-28 13:07:36,986 - INFO - joeynmt.training - Example #2
2024-05-28 13:07:36,989 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:07:36,989 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:07:36,989 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'l@@', 'en', 'is', 'in', 'a', 'way', 'of', 'ho@@', 'p@@', 'e,', 'the', 'in@@', 'cl@@', 'u@@', 'ding', 'glob@@', 'al', 'system@@', '.', '</s>']
2024-05-28 13:07:36,990 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:07:36,993 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:07:36,996 - INFO - joeynmt.training - 	Hypothesis: The pollen is in a way of hope, the including global system.
2024-05-28 13:07:37,015 - INFO - joeynmt.training - Example #3
2024-05-28 13:07:37,018 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:07:37,018 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:07:37,018 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he@@', "'s", 'ex@@', 'ten@@', 'si@@', 've', 'and', 'they', 'can', 'be', 'able', 'to', 'be', 'able', 'to', 'be', 'se@@', 'e@@', 'ing', 'to', 'the', 'do@@', 'wn@@', '.', '</s>']
2024-05-28 13:07:37,019 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:07:37,022 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:07:37,026 - INFO - joeynmt.training - 	Hypothesis: She's extensive and they can be able to be able to be seeing to the down.
2024-05-28 13:07:37,029 - INFO - joeynmt.training - Example #4
2024-05-28 13:07:37,032 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:07:37,032 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:07:37,032 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'di@@', 'a@@', 'ff@@', 'ect@@', 'ing', 'that', 'the', 'di@@', 'a@@', 'ff@@', ',', "I'm", 'going', 'to', 'show', 'you', 'a', 'f@@', 'ast@@', 'er', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:07:37,032 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:07:37,035 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:07:37,039 - INFO - joeynmt.training - 	Hypothesis: The next diaffecting that the diaff, I'm going to show you a faster in the last 25 years.
2024-05-28 13:07:40,485 - INFO - joeynmt.training - Epoch   5, Step:    20600, Batch Loss:     1.731791, Batch Acc: 0.478796, Tokens per Sec:    18897, Lr: 0.000300
2024-05-28 13:07:43,997 - INFO - joeynmt.training - Epoch   5, Step:    20700, Batch Loss:     1.862196, Batch Acc: 0.475094, Tokens per Sec:    20168, Lr: 0.000300
2024-05-28 13:07:47,386 - INFO - joeynmt.training - Epoch   5, Step:    20800, Batch Loss:     1.681706, Batch Acc: 0.476709, Tokens per Sec:    21369, Lr: 0.000300
2024-05-28 13:07:50,971 - INFO - joeynmt.training - Epoch   5, Step:    20900, Batch Loss:     1.848065, Batch Acc: 0.478087, Tokens per Sec:    19878, Lr: 0.000300
2024-05-28 13:07:54,301 - INFO - joeynmt.training - Epoch   5, Step:    21000, Batch Loss:     1.872579, Batch Acc: 0.481401, Tokens per Sec:    21885, Lr: 0.000300
2024-05-28 13:07:54,325 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:07:54,329 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:08:53,362 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.82, ppl:   6.16, acc:   0.47, generation: 59.0091[sec], evaluation: 0.0000[sec]
2024-05-28 13:08:53,366 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:08:53,517 - INFO - joeynmt.helpers - delete models/bpe-subword/18500.ckpt
2024-05-28 13:08:53,535 - INFO - joeynmt.training - Example #0
2024-05-28 13:08:53,539 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:08:53,539 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:08:53,539 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'th@@', 'ir@@', 'd', 'of', 'the', 'sec@@', 'ond', 'di@@', 'a@@', 'th@@', 'le@@', 'te@@', 's', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'as', 'a', 'pol@@', 'ice', 'that', 'the', 'most', 'of', 'the', 'most', 'of', 'the', 'worl@@', 'd@@', "'s", 'first', 'one', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'f@@', 'our', 'bil@@', 'lion', 'years', 'of', 'the', 'big', 's@@', 'li@@', 'ght@@', 'ly', 'l@@', 'ong', 'fo@@', 'od', 'of', '4@@', '8', 'percent', 'of', 'the', 'little', 'bit', 'of', 'the', 'little', 'bit', 'of', 'the', 'sm@@', 'all@@', 'po@@', 'x', 'of', 'the', 'm@@', 'ou@@', 'th', 'of', 'the', 'last', 'year@@', '.', '</s>']
2024-05-28 13:08:53,540 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:08:53,544 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:08:53,547 - INFO - joeynmt.training - 	Hypothesis: And the third of the second diathletes to demonstrate as a police that the most of the most of the world's first one of the last three million years of the four billion years of the big slightly long food of 48 percent of the little bit of the little bit of the smallpox of the mouth of the last year.
2024-05-28 13:08:53,593 - INFO - joeynmt.training - Example #1
2024-05-28 13:08:53,597 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:08:53,597 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:08:53,597 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'im@@', 'medi@@', 'ate', 'of', 'this', 'speci@@', 'al', 'problem@@', 's', 'that', 'speci@@', 'al', 'problem@@', 's', 'that', "doesn't", 'look', 'at', 'the', 'gr@@', 'ou@@', 'p', 'of', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'b@@', 'ri@@', 'd@@', 'ge', 'of', 'the', 'g@@', 'ar@@', 'den@@', '.', '</s>']
2024-05-28 13:08:53,597 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:08:53,601 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:08:53,605 - INFO - joeynmt.training - 	Hypothesis: But this is the immediate of this special problems that special problems that doesn't look at the group of the gross of the gross of the bridge of the garden.
2024-05-28 13:08:53,609 - INFO - joeynmt.training - Example #2
2024-05-28 13:08:53,613 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:08:53,613 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:08:53,613 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'pol@@', 'l@@', 'en', 'is', 'in', 'a', 'wa@@', 'y,', 'from', 'a', 'way', 'of', 'buil@@', 'ding', 'the', 'hear@@', 't', 'of', 'the', 'cl@@', 'im@@', 'ate', 'system@@', '.', '</s>']
2024-05-28 13:08:53,613 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:08:53,616 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:08:53,620 - INFO - joeynmt.training - 	Hypothesis: The police pollen is in a way, from a way of building the heart of the climate system.
2024-05-28 13:08:53,624 - INFO - joeynmt.training - Example #3
2024-05-28 13:08:53,665 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:08:53,665 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:08:53,665 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'ten@@', 'ding', 'and', 'the', 'contr@@', 'act', 'of', 'the', 'contr@@', 'ac@@', 'tion', 'of', 'the', 'v@@', 'ari@@', 'ous', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:08:53,666 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:08:53,685 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:08:53,689 - INFO - joeynmt.training - 	Hypothesis: She was extending and the contract of the contraction of the various contract.
2024-05-28 13:08:53,693 - INFO - joeynmt.training - Example #4
2024-05-28 13:08:53,697 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:08:53,697 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:08:53,697 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ma@@', 'the@@', 'mat@@', 'ical', 'di@@', 'a@@', 'th@@', 's', 'that', 'will', 'be', 'a', 'qu@@', 'ick@@', 'ly', 'de@@', 'f@@', 'ine', 'will', 'be', 'a', 'qu@@', 'ick@@', 'ly', 'se@@', 't', 'of', 'what', 'was', 'in@@', 't@@', 'am@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:08:53,697 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:08:53,701 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:08:53,705 - INFO - joeynmt.training - 	Hypothesis: The mathematical diaths that will be a quickly define will be a quickly set of what was intamed in the last 25 years.
2024-05-28 13:08:57,671 - INFO - joeynmt.training - Epoch   5, Step:    21100, Batch Loss:     1.774508, Batch Acc: 0.482125, Tokens per Sec:    16687, Lr: 0.000300
2024-05-28 13:09:01,712 - INFO - joeynmt.training - Epoch   5, Step:    21200, Batch Loss:     1.788761, Batch Acc: 0.484791, Tokens per Sec:    17449, Lr: 0.000300
2024-05-28 13:09:05,299 - INFO - joeynmt.training - Epoch   5, Step:    21300, Batch Loss:     1.774109, Batch Acc: 0.482838, Tokens per Sec:    19751, Lr: 0.000300
2024-05-28 13:09:08,992 - INFO - joeynmt.training - Epoch   5, Step:    21400, Batch Loss:     1.732712, Batch Acc: 0.483695, Tokens per Sec:    18899, Lr: 0.000300
2024-05-28 13:09:13,049 - INFO - joeynmt.training - Epoch   5, Step:    21500, Batch Loss:     1.858269, Batch Acc: 0.478604, Tokens per Sec:    18412, Lr: 0.000300
2024-05-28 13:09:13,071 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:09:13,075 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:09:44,340 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.81, ppl:   6.12, acc:   0.48, generation: 31.2441[sec], evaluation: 0.0000[sec]
2024-05-28 13:09:44,389 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:09:44,480 - INFO - joeynmt.helpers - delete models/bpe-subword/19000.ckpt
2024-05-28 13:09:44,504 - INFO - joeynmt.training - Example #0
2024-05-28 13:09:44,508 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:09:44,508 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:09:44,508 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'th@@', 'ir@@', 'd', 'of', 'the', 'sec@@', 'ond', 'di@@', 'a@@', 'th@@', 'o@@', '-@@', 'de@@', 'mon@@', 'str@@', 'ate', 'to', 'the', 'f@@', 'ut@@', 'ure', 'that', 'the', 'ma@@', 'in', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'been', 'a', 'big', 'st@@', 'at@@', 'us', 'of', 'the', 'last', 'three', 'percent', 'of', 'the', 'm@@', 'ou@@', 'th', 'of', 'a', 'little', 'bit', 'of', 'a', 'little', 'bit', 'of', 'a', 'little', 'bit', 'of', 'a', 'little', 'bit', 'of', 'a', 'little', 'bit', 'of', 'a', 'little', 'bit', 'of', 'a', 'little', 'bit', 'of', 'a', 'few', 'percent', 'of', 'the', 'year@@', 's.', '</s>']
2024-05-28 13:09:44,509 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:09:44,513 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:09:44,516 - INFO - joeynmt.training - 	Hypothesis: And the third of the second diatho-demonstrate to the future that the main the last three million years of the last three million years of been a big status of the last three percent of the mouth of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a few percent of the years.
2024-05-28 13:09:44,519 - INFO - joeynmt.training - Example #1
2024-05-28 13:09:44,591 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:09:44,591 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:09:44,591 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'the', 'mor@@', 'n@@', 'ity', 'of', 'this', 'speci@@', 'al', 'prob@@', 'le@@', 'm', 'because', 'of', 'this', 'prob@@', 'le@@', 'm', 'is', 'that', 'not', 'ar@@', 'gu@@', 'e', 'of', 'the', 'b@@', 'ab@@', 'i@@', 'es.', '</s>']
2024-05-28 13:09:44,591 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:09:44,603 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:09:44,607 - INFO - joeynmt.training - 	Hypothesis: But this morning, the mornity of this special problem because of this problem is that not argue of the babies.
2024-05-28 13:09:44,611 - INFO - joeynmt.training - Example #2
2024-05-28 13:09:44,616 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:09:44,616 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:09:44,616 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'pol@@', 'l@@', 'en', 'is', 'in', 'a', 'way', 'that', 'the', 'hear@@', 't', 'of', 'the', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'system@@', '.', '</s>']
2024-05-28 13:09:44,617 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:09:44,621 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:09:44,624 - INFO - joeynmt.training - 	Hypothesis: The police pollen is in a way that the heart of the heart of the global system.
2024-05-28 13:09:44,628 - INFO - joeynmt.training - Example #3
2024-05-28 13:09:44,631 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:09:44,631 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:09:44,631 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'ten@@', 'ded', 'and', 'the', 'contr@@', 'act', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:09:44,631 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:09:44,635 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:09:44,638 - INFO - joeynmt.training - 	Hypothesis: She was extended and the contract and contract.
2024-05-28 13:09:44,642 - INFO - joeynmt.training - Example #4
2024-05-28 13:09:44,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:09:44,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:09:44,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ma@@', 'in', 'the', 'di@@', 'a@@', 'th@@', 's', 'that', "I'm", 'going', 'to', 'show', 'you', 'a', 'f@@', 'ast@@', 'ast@@', 'er', 'will', 'be', 'a', 'f@@', 'ast@@', 'ast@@', 'er', 'in', 'the', 'last', '2@@', '5', 'years', 'of', 'what', 'it', 'was', 'going', 'to', 'be', 'in', 'the', 'last', '2@@', '5', 'years', 'of', 'years', 'of', 'year@@', 's.', '</s>']
2024-05-28 13:09:44,645 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:09:44,648 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:09:44,694 - INFO - joeynmt.training - 	Hypothesis: The main the diaths that I'm going to show you a fastaster will be a fastaster in the last 25 years of what it was going to be in the last 25 years of years of years.
2024-05-28 13:09:48,773 - INFO - joeynmt.training - Epoch   5, Step:    21600, Batch Loss:     1.807743, Batch Acc: 0.480686, Tokens per Sec:    16421, Lr: 0.000300
2024-05-28 13:09:52,890 - INFO - joeynmt.training - Epoch   5, Step:    21700, Batch Loss:     1.912302, Batch Acc: 0.484873, Tokens per Sec:    17651, Lr: 0.000300
2024-05-28 13:09:56,874 - INFO - joeynmt.training - Epoch   5, Step:    21800, Batch Loss:     1.878375, Batch Acc: 0.481807, Tokens per Sec:    18046, Lr: 0.000300
2024-05-28 13:10:00,759 - INFO - joeynmt.training - Epoch   5, Step:    21900, Batch Loss:     1.701115, Batch Acc: 0.481840, Tokens per Sec:    18172, Lr: 0.000300
2024-05-28 13:10:04,529 - INFO - joeynmt.training - Epoch   5, Step:    22000, Batch Loss:     1.681935, Batch Acc: 0.488609, Tokens per Sec:    19428, Lr: 0.000300
2024-05-28 13:10:04,598 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:10:04,709 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:10:37,186 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.79, ppl:   6.02, acc:   0.48, generation: 32.4560[sec], evaluation: 0.0000[sec]
2024-05-28 13:10:37,190 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:10:37,287 - INFO - joeynmt.helpers - delete models/bpe-subword/19500.ckpt
2024-05-28 13:10:37,388 - INFO - joeynmt.training - Example #0
2024-05-28 13:10:37,407 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:10:37,407 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:10:37,407 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'next', 'y@@', 'ear', 'I', 'ar@@', 'gu@@', 'ed', 'these', 'two', 'de@@', 'mon@@', 'str@@', 'ate', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'f@@', 'ar@@', 'mer@@', 's', 'that', 'the', 'most', 'of', 'the', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'years', 'of', 'been', 'd@@', 'imen@@', 'si@@', 'on,', 'the', 'last', '4@@', '8', 'mil@@', 'lion', 'years', 'of', 'st@@', 'at@@', 'em@@', 'ent', '--', 'the', 'sm@@', 'all', 'st@@', 'ate', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'lar@@', 'ge', 'of', 'the', 'mic@@', 'e.', '</s>']
2024-05-28 13:10:37,407 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:10:37,411 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:10:37,414 - INFO - joeynmt.training - 	Hypothesis: And the next year I argued these two demonstrate to demonstrate the farmers that the most of the most of the last three million years of years of been dimension, the last 48 million years of statement -- the small state of the four percent of the large of the mice.
2024-05-28 13:10:37,418 - INFO - joeynmt.training - Example #1
2024-05-28 13:10:37,421 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:10:37,421 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:10:37,421 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'this', 'is', 'the', 'ser@@', 'i@@', 'ous', 'problem@@', 's', 'because', 'of', 'this', 'is', 'the', 'bi@@', 'g@@', ',', 'because', 'it', "doesn't", 'look', 'at', 'the', 'bo@@', 'o@@', 'k@@', 's.', '</s>']
2024-05-28 13:10:37,421 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:10:37,425 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:10:37,429 - INFO - joeynmt.training - 	Hypothesis: But this morning, this is the serious problems because of this is the big, because it doesn't look at the books.
2024-05-28 13:10:37,433 - INFO - joeynmt.training - Example #2
2024-05-28 13:10:37,436 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:10:37,436 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:10:37,436 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['C@@', 'al@@', 'o@@', 't', 'is', 'in', 'a', 'pol@@', 'ice', 'is', 'that', 'the', 'hear@@', 't', 'of', 'the', 'cl@@', 'im@@', 'ate', 'system@@', '.', '</s>']
2024-05-28 13:10:37,437 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:10:37,440 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:10:37,447 - INFO - joeynmt.training - 	Hypothesis: Calot is in a police is that the heart of the climate system.
2024-05-28 13:10:37,471 - INFO - joeynmt.training - Example #3
2024-05-28 13:10:37,475 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:10:37,475 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:10:37,475 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'p@@', 'ec@@', 'ted', 'and', 'they', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:10:37,476 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:10:37,479 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:10:37,484 - INFO - joeynmt.training - 	Hypothesis: She was expected and they contract.
2024-05-28 13:10:37,487 - INFO - joeynmt.training - Example #4
2024-05-28 13:10:37,491 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:10:37,491 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:10:37,491 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'sec@@', 'ond', 'di@@', 'a@@', 'ff@@', 'ect@@', 's', 'that', "I'm", 'going', 'to', 'show', 'you', 'a', 'f@@', 'ast@@', 'er', 'will', 'be', 'a', 'f@@', 'ast@@', 'er', 'in', 'the', 'last', '2@@', '5', 'years', 'ag@@', 'o.', '</s>']
2024-05-28 13:10:37,491 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:10:37,495 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:10:37,499 - INFO - joeynmt.training - 	Hypothesis: The second diaffects that I'm going to show you a faster will be a faster in the last 25 years ago.
2024-05-28 13:10:41,058 - INFO - joeynmt.training - Epoch   5, Step:    22100, Batch Loss:     1.569659, Batch Acc: 0.490157, Tokens per Sec:    18610, Lr: 0.000300
2024-05-28 13:10:44,725 - INFO - joeynmt.training - Epoch   5, Step:    22200, Batch Loss:     1.847330, Batch Acc: 0.477766, Tokens per Sec:    19911, Lr: 0.000300
2024-05-28 13:10:48,442 - INFO - joeynmt.training - Epoch   5, Step:    22300, Batch Loss:     1.902633, Batch Acc: 0.480634, Tokens per Sec:    18832, Lr: 0.000300
2024-05-28 13:10:52,578 - INFO - joeynmt.training - Epoch   5, Step:    22400, Batch Loss:     1.859843, Batch Acc: 0.488491, Tokens per Sec:    17432, Lr: 0.000300
2024-05-28 13:10:56,706 - INFO - joeynmt.training - Epoch   5, Step:    22500, Batch Loss:     1.789378, Batch Acc: 0.486768, Tokens per Sec:    17373, Lr: 0.000300
2024-05-28 13:10:56,725 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:10:56,729 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:11:23,459 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.79, ppl:   5.99, acc:   0.48, generation: 26.7067[sec], evaluation: 0.0000[sec]
2024-05-28 13:11:23,475 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:11:23,608 - INFO - joeynmt.helpers - delete models/bpe-subword/20000.ckpt
2024-05-28 13:11:23,621 - INFO - joeynmt.training - Example #0
2024-05-28 13:11:23,669 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:11:23,669 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:11:23,669 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'last', 'last', 'last', 'two', 'of', 'the', 'sec@@', 'ond', 'de@@', 'mon@@', 'str@@', 'ate', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'de@@', 'mon@@', 'str@@', 'ate', 'of', 'the', 'pol@@', 'ar', 'r@@', 'ang@@', 'e', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'f@@', 'our@@', 'th', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'lar@@', 'ge', 'of', 'f@@', 'our', 'percent', 'of', 'the', 'mic@@', 'e,', 'the', 'sm@@', 'all', 's@@', 'et@@', 'ting', 'f@@', 'our', 'percent', 'of', 'the', 'f@@', 'our@@', 'th', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'ch@@', 'ance', 'of', 'the', 'ch@@', 'ance', 'of', 'the', 'sec@@', 'ond', 'thing', 'that', 'we', 'sho@@', 'w@@', 'ed', 'these', 'two', 'percent']
2024-05-28 13:11:23,670 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:11:23,673 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:11:23,677 - INFO - joeynmt.training - 	Hypothesis: And the last last last two of the second demonstrate to demonstrate the demonstrate of the polar range of the last three million years of years of the last three million years of the fourth of the four percent of the large of four percent of the mice, the small setting four percent of the fourth of the four percent of the four percent of the chance of the chance of the second thing that we showed these two percent
2024-05-28 13:11:23,731 - INFO - joeynmt.training - Example #1
2024-05-28 13:11:23,752 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:11:23,752 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:11:23,752 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ity', 'of', 'ser@@', 'i@@', 'ous', 'ser@@', 'i@@', 'ous', 'speci@@', 'al', 'is@@', 'su@@', 'es', 'because', 'it', "doesn't", 'look', 'at', 'the', 'gr@@', 'ou@@', 'p@@', '.', '</s>']
2024-05-28 13:11:23,753 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:11:23,767 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:11:23,770 - INFO - joeynmt.training - 	Hypothesis: But this mornity of serious serious special issues because it doesn't look at the group.
2024-05-28 13:11:23,773 - INFO - joeynmt.training - Example #2
2024-05-28 13:11:23,777 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:11:23,777 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:11:23,777 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'l@@', 'er', 'is', 'in', 'a', 'way', 'of', 'n@@', 'et@@', 'work', 'of', 'the', 'n@@', 'et@@', 'work', 'of', 'the', 'glob@@', 'al', 'system@@', '.', '</s>']
2024-05-28 13:11:23,777 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:11:23,781 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:11:23,784 - INFO - joeynmt.training - 	Hypothesis: The poller is in a way of network of the network of the global system.
2024-05-28 13:11:23,791 - INFO - joeynmt.training - Example #3
2024-05-28 13:11:23,795 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:11:23,795 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:11:23,795 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'has', 'ex@@', 'tin@@', 'c@@', 't', 'and', 'sh@@', "e's", 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:11:23,796 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:11:23,830 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:11:23,834 - INFO - joeynmt.training - 	Hypothesis: She has extinct and she's contract.
2024-05-28 13:11:23,838 - INFO - joeynmt.training - Example #4
2024-05-28 13:11:23,841 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:11:23,841 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:11:23,841 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'di@@', 'a@@', 'pos@@', 'iti@@', 'on', 'that', "I'm", 'going', 'to', 'show', 'you', 'that', "I'm", 'going', 'to', 'show', 'you', 'what', 'it', 'was', 'in@@', 't@@', 'am@@', 'pl@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:11:23,842 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:11:23,846 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:11:23,849 - INFO - joeynmt.training - 	Hypothesis: The next diaposition that I'm going to show you that I'm going to show you what it was intampled in the last 25 years.
2024-05-28 13:11:27,756 - INFO - joeynmt.training - Epoch   5, Step:    22600, Batch Loss:     1.820194, Batch Acc: 0.486183, Tokens per Sec:    16904, Lr: 0.000300
2024-05-28 13:11:31,553 - INFO - joeynmt.training - Epoch   5, Step:    22700, Batch Loss:     1.687617, Batch Acc: 0.491292, Tokens per Sec:    19447, Lr: 0.000300
2024-05-28 13:11:31,758 - INFO - joeynmt.training - Epoch   5: total training loss 8131.43
2024-05-28 13:11:31,762 - INFO - joeynmt.training - EPOCH 6
2024-05-28 13:11:35,325 - INFO - joeynmt.training - Epoch   6, Step:    22800, Batch Loss:     1.624643, Batch Acc: 0.503042, Tokens per Sec:    19628, Lr: 0.000300
2024-05-28 13:11:39,442 - INFO - joeynmt.training - Epoch   6, Step:    22900, Batch Loss:     1.727347, Batch Acc: 0.494979, Tokens per Sec:    17285, Lr: 0.000300
2024-05-28 13:11:43,588 - INFO - joeynmt.training - Epoch   6, Step:    23000, Batch Loss:     1.644078, Batch Acc: 0.505947, Tokens per Sec:    18010, Lr: 0.000300
2024-05-28 13:11:43,593 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:11:43,597 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:12:36,346 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.78, ppl:   5.93, acc:   0.48, generation: 52.7249[sec], evaluation: 0.0000[sec]
2024-05-28 13:12:36,380 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:12:36,495 - INFO - joeynmt.helpers - delete models/bpe-subword/20500.ckpt
2024-05-28 13:12:36,527 - INFO - joeynmt.training - Example #0
2024-05-28 13:12:36,539 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:12:36,539 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:12:36,539 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'th@@', 'ir@@', 'd', 'of', 'the', 'sec@@', 'ond', 'di@@', 'a@@', 'th@@', 'le@@', 'te@@', 's', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'f@@', 'ut@@', 'ure', 'of', 'the', 'pol@@', 'ar', 'pol@@', 'ar', 'that', 'the', 'big', 'pol@@', 'ar', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', '4@@', '8', 'percent', 'of', 'the', 'f@@', 'our', 'm@@', 'en', 'in', 'f@@', 'our', 'mic@@', 'e,', 'the', 'little', 's@@', 'li@@', 'de', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 's@@', 'li@@', 'de', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 's@@', 'ou@@', 'th@@', 'er@@', 'n', 'of', 'the', 'th@@', 'ir@@', 'd', 'of', 'the', 'th@@', 'ir@@', 'd', 'of', 'the', 'th@@', 'ir@@', 'd', 'of', 'the', 'sec@@', 'ond', 'to', 'the', 'sec@@', 'ond', 'to', 'the', 'b@@', 'e.', '</s>']
2024-05-28 13:12:36,540 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:12:36,548 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:12:36,554 - INFO - joeynmt.training - 	Hypothesis: And the third of the second diathletes to demonstrate the future of the polar polar that the big polar of the last three million years of the last 48 percent of the four men in four mice, the little slide of the four percent of the slide of the four percent of the southern of the third of the third of the third of the second to the second to the be.
2024-05-28 13:12:36,557 - INFO - joeynmt.training - Example #1
2024-05-28 13:12:36,560 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:12:36,561 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:12:36,561 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'this', 'is', 'the', 'speci@@', 'al', 'problem@@', 's', 'because', 'of', 'this', 'prob@@', 'le@@', 'm', 'is', 'that', 'not', 'ar@@', 'gu@@', 'e', 'the', 'b@@', 'ro@@', 'k@@', 'en', 'gr@@', 'ou@@', 'p@@', '.', '</s>']
2024-05-28 13:12:36,561 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:12:36,567 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:12:36,589 - INFO - joeynmt.training - 	Hypothesis: But this morning, this is the special problems because of this problem is that not argue the broken group.
2024-05-28 13:12:36,592 - INFO - joeynmt.training - Example #2
2024-05-28 13:12:36,596 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:12:36,596 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:12:36,596 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is', 'that', 'the', 'hear@@', 't', 'of', 'the', 'cl@@', 'im@@', 'ate', 'system@@', ',', 'the', 'hear@@', 't', 'of', 'the', 'cl@@', 'im@@', 'ate', 'system@@', '.', '</s>']
2024-05-28 13:12:36,597 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:12:36,601 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:12:36,604 - INFO - joeynmt.training - 	Hypothesis: The police is that the heart of the climate system, the heart of the climate system.
2024-05-28 13:12:36,622 - INFO - joeynmt.training - Example #3
2024-05-28 13:12:36,626 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:12:36,627 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:12:36,627 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'n@@', 's', 'out', 'the', 's@@', 'ou@@', 'l', 'and', 'they', 'contr@@', 'ol', 'and', 'the', 'de@@', 'gre@@', 'e.', '</s>']
2024-05-28 13:12:36,627 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:12:36,649 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:12:36,652 - INFO - joeynmt.training - 	Hypothesis: It turns out the soul and they control and the degree.
2024-05-28 13:12:36,656 - INFO - joeynmt.training - Example #4
2024-05-28 13:12:36,659 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:12:36,659 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:12:36,659 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'di@@', 'a@@', 'th@@', 'le@@', 'te@@', 's', 'that', 'you', 'look', 'at', 'the', 'to@@', 'p', 'of', 'what', 'it', 'was', 'going', 'to', 'show', 'you', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:12:36,660 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:12:36,664 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:12:36,667 - INFO - joeynmt.training - 	Hypothesis: The next diathletes that you look at the top of what it was going to show you in the last 25 years.
2024-05-28 13:12:40,773 - INFO - joeynmt.training - Epoch   6, Step:    23100, Batch Loss:     1.659141, Batch Acc: 0.502965, Tokens per Sec:    16468, Lr: 0.000300
2024-05-28 13:12:44,852 - INFO - joeynmt.training - Epoch   6, Step:    23200, Batch Loss:     1.929169, Batch Acc: 0.499545, Tokens per Sec:    17275, Lr: 0.000300
2024-05-28 13:12:48,975 - INFO - joeynmt.training - Epoch   6, Step:    23300, Batch Loss:     1.699843, Batch Acc: 0.501483, Tokens per Sec:    17270, Lr: 0.000300
2024-05-28 13:12:52,740 - INFO - joeynmt.training - Epoch   6, Step:    23400, Batch Loss:     1.756185, Batch Acc: 0.496252, Tokens per Sec:    18938, Lr: 0.000300
2024-05-28 13:12:56,765 - INFO - joeynmt.training - Epoch   6, Step:    23500, Batch Loss:     1.715672, Batch Acc: 0.500205, Tokens per Sec:    17244, Lr: 0.000300
2024-05-28 13:12:56,818 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:12:56,822 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:13:33,403 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.78, ppl:   5.90, acc:   0.49, generation: 36.5595[sec], evaluation: 0.0000[sec]
2024-05-28 13:13:33,409 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:13:33,497 - INFO - joeynmt.helpers - delete models/bpe-subword/21000.ckpt
2024-05-28 13:13:33,509 - INFO - joeynmt.training - Example #0
2024-05-28 13:13:33,513 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:13:33,513 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:13:33,513 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'of', 'di@@', 'a@@', 'th@@', 'le@@', 'te@@', 's', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'p@@', 'er', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'years', 'of', 'been', 'a', 'sm@@', 'all', 's@@', 'et@@', 't@@', 'l@@', 'ed', 'by', '4@@', '8', 'percent', 'of', 'the', 'sm@@', 'all', 'st@@', 'at@@', 'es', 'of', 'f@@', 'our', 'percent', 'of', 'the', 'sm@@', 'all', 'st@@', 'at@@', 'es', 'with', '4@@', '8', 'percent', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'di@@', 'a@@', 'th@@', 'ro@@', 'om@@']
2024-05-28 13:13:33,514 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:13:33,517 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:13:33,521 - INFO - joeynmt.training - 	Hypothesis: The next year I showed these two of diathletes to demonstrate the per of the last three million years of the last three million years of years of been a small settled by 48 percent of the small states of four percent of the small states with 48 percent of the four percent of the four percent of the four percent of the four percent of the four percent of the four percent of the diathroom
2024-05-28 13:13:33,554 - INFO - joeynmt.training - Example #1
2024-05-28 13:13:33,560 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:13:33,560 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:13:33,560 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'the', 'speci@@', 'al', 'problem@@', 's', 'because', 'of', 'this', 'problem@@', 's', 'because', 'it', "doesn't", 'look', 'at', 'the', 'gr@@', 'ou@@', 'p@@', '.', '</s>']
2024-05-28 13:13:33,560 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:13:33,564 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:13:33,569 - INFO - joeynmt.training - 	Hypothesis: But this morning, the special problems because of this problems because it doesn't look at the group.
2024-05-28 13:13:33,573 - INFO - joeynmt.training - Example #2
2024-05-28 13:13:33,630 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:13:33,630 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:13:33,630 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'l@@', 'ine', 'is', 'the', 'pol@@', 'l@@', 'ing', 'is', 'the', 'same', 'hear@@', 't', 'of', 'the', 'cl@@', 'im@@', 'ate', 'system@@', '.', '</s>']
2024-05-28 13:13:33,630 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:13:33,634 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:13:33,638 - INFO - joeynmt.training - 	Hypothesis: The polline is the polling is the same heart of the climate system.
2024-05-28 13:13:33,641 - INFO - joeynmt.training - Example #3
2024-05-28 13:13:33,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:13:33,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:13:33,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'cit@@', 'ed', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:13:33,646 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:13:33,649 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:13:33,653 - INFO - joeynmt.training - 	Hypothesis: She was excited and contraction and contract.
2024-05-28 13:13:33,657 - INFO - joeynmt.training - Example #4
2024-05-28 13:13:33,679 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:13:33,679 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:13:33,679 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'di@@', 'a@@', 'pos@@', 'iti@@', 'on', 'that', 'I', 'will', 'show', 'you', 'a', 'f@@', 'ast@@', 'er', 'that', 'I', 'will', 'show', 'you', 'a', 'f@@', 'ast@@', 'er', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:13:33,679 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:13:33,683 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:13:33,686 - INFO - joeynmt.training - 	Hypothesis: The first diaposition that I will show you a faster that I will show you a faster in the last 25 years.
2024-05-28 13:13:37,361 - INFO - joeynmt.training - Epoch   6, Step:    23600, Batch Loss:     1.707068, Batch Acc: 0.499082, Tokens per Sec:    18190, Lr: 0.000300
2024-05-28 13:13:41,207 - INFO - joeynmt.training - Epoch   6, Step:    23700, Batch Loss:     1.613162, Batch Acc: 0.503209, Tokens per Sec:    18762, Lr: 0.000300
2024-05-28 13:13:44,896 - INFO - joeynmt.training - Epoch   6, Step:    23800, Batch Loss:     1.528579, Batch Acc: 0.498539, Tokens per Sec:    19523, Lr: 0.000300
2024-05-28 13:13:48,928 - INFO - joeynmt.training - Epoch   6, Step:    23900, Batch Loss:     1.643514, Batch Acc: 0.504177, Tokens per Sec:    17743, Lr: 0.000300
2024-05-28 13:13:53,117 - INFO - joeynmt.training - Epoch   6, Step:    24000, Batch Loss:     1.568146, Batch Acc: 0.499518, Tokens per Sec:    17690, Lr: 0.000300
2024-05-28 13:13:53,125 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:13:53,142 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:14:25,651 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.76, ppl:   5.82, acc:   0.49, generation: 32.4860[sec], evaluation: 0.0000[sec]
2024-05-28 13:14:25,694 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:14:25,831 - INFO - joeynmt.helpers - delete models/bpe-subword/21500.ckpt
2024-05-28 13:14:25,847 - INFO - joeynmt.training - Example #0
2024-05-28 13:14:25,851 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:14:25,851 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:14:25,851 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'th@@', 'ir@@', 'd', 'of', 'these', 'two', 'di@@', 'a@@', 'ff@@', 'ect@@', 's', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'de@@', 'mon@@', 'str@@', 'ate', 'of', 'the', 'pol@@', 'ar', 'pol@@', 'ar', 'that', 'the', 'maj@@', 'or@@', 'ity', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'lar@@', 'ge', 'st@@', 'ate', 'f@@', 'our', 'percent', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'lar@@', 'ge', 'st@@', 'ate', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 's@@', 'qu@@', 'are', 'with', '4@@', '8', 'percent', 'of', 'the', 'sec@@', 'on@@', 'd.', '</s>']
2024-05-28 13:14:25,852 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:14:25,856 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:14:25,860 - INFO - joeynmt.training - 	Hypothesis: And the third of these two diaffects to demonstrate the demonstrate of the polar polar that the majority of the last three million years of the last three million years of the four percent of the four percent of the large state four percent of the four percent of the large state of the four percent of the four percent of the four percent of the four percent of the square with 48 percent of the second.
2024-05-28 13:14:25,864 - INFO - joeynmt.training - Example #1
2024-05-28 13:14:25,868 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:14:25,868 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:14:25,868 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'this', 'speci@@', 'al', 'problem@@', 's', 'that', 'the', 'speci@@', 'al', 'prob@@', 'le@@', 'm', 'because', 'not', 'the', 'f@@', 'ar@@', 'mer@@', '.', '</s>']
2024-05-28 13:14:25,868 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:14:25,872 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:14:25,875 - INFO - joeynmt.training - 	Hypothesis: But this morning, this special problems that the special problem because not the farmer.
2024-05-28 13:14:25,879 - INFO - joeynmt.training - Example #2
2024-05-28 13:14:25,916 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:14:25,916 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:14:25,916 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'l@@', 'ine', 'pol@@', 'ar', 'is', 'that', 'the', 'hear@@', 't', 'of', 'the', 'hear@@', 't', 'that', 'the', 'b@@', 'ro@@', 'k@@', 'en', 'the', 'glob@@', 'al', 'system@@', '.', '</s>']
2024-05-28 13:14:25,917 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:14:25,920 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:14:25,924 - INFO - joeynmt.training - 	Hypothesis: The polline polar is that the heart of the heart that the broken the global system.
2024-05-28 13:14:25,927 - INFO - joeynmt.training - Example #3
2024-05-28 13:14:25,963 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:14:25,963 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:14:25,963 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'ten@@', 'ded', 'and', 'contr@@', 'ac@@', 'ts', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:14:25,964 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:14:25,978 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:14:25,982 - INFO - joeynmt.training - 	Hypothesis: She was extended and contracts and contract.
2024-05-28 13:14:25,985 - INFO - joeynmt.training - Example #4
2024-05-28 13:14:26,004 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:14:26,004 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:14:26,004 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ma@@', 's@@', 's', 'of', 'the', 'di@@', 'a@@', 'ff@@', 'ect', 'that', 'you', 'would', 'show', 'you', 'a', 'f@@', 'ast@@', 'er', 'will', 'be', 'a', 'qu@@', 'ick@@', 'ly', 'on', 'what', 'was', 'in@@', 't@@', 'am@@', 'pl@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:14:26,005 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:14:26,009 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:14:26,016 - INFO - joeynmt.training - 	Hypothesis: The mass of the diaffect that you would show you a faster will be a quickly on what was intampled in the last 25 years.
2024-05-28 13:14:29,918 - INFO - joeynmt.training - Epoch   6, Step:    24100, Batch Loss:     1.662287, Batch Acc: 0.500394, Tokens per Sec:    17116, Lr: 0.000300
2024-05-28 13:14:33,859 - INFO - joeynmt.training - Epoch   6, Step:    24200, Batch Loss:     1.724761, Batch Acc: 0.496941, Tokens per Sec:    18309, Lr: 0.000300
2024-05-28 13:14:37,641 - INFO - joeynmt.training - Epoch   6, Step:    24300, Batch Loss:     1.664722, Batch Acc: 0.501075, Tokens per Sec:    18591, Lr: 0.000300
2024-05-28 13:14:41,561 - INFO - joeynmt.training - Epoch   6, Step:    24400, Batch Loss:     1.892506, Batch Acc: 0.504714, Tokens per Sec:    18328, Lr: 0.000300
2024-05-28 13:14:45,192 - INFO - joeynmt.training - Epoch   6, Step:    24500, Batch Loss:     1.752688, Batch Acc: 0.504653, Tokens per Sec:    19855, Lr: 0.000300
2024-05-28 13:14:45,206 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:14:45,214 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:15:19,025 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.75, ppl:   5.78, acc:   0.49, generation: 33.7887[sec], evaluation: 0.0000[sec]
2024-05-28 13:15:19,030 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:15:19,126 - INFO - joeynmt.helpers - delete models/bpe-subword/22000.ckpt
2024-05-28 13:15:19,140 - INFO - joeynmt.training - Example #0
2024-05-28 13:15:19,144 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:15:19,144 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:15:19,144 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'last', 'last', 'y@@', 'ear', 'I', 'ar@@', 'gu@@', 'e', 'these', 'two', 'of', 'the', 'sec@@', 'ond', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'as', 'the', 'most', 'of', 'the', 'pol@@', 'l@@', 'ing', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', '4@@', '0', 'percent', 'of', 'the', 'gro@@', 'und', 'of', 'the', 'f@@', 'our@@', 'th', 'of', 'the', 'f@@', 'our@@', 'th', 'of', 'the', 'f@@', 'our@@', '-@@', 'si@@', 'de.', '</s>']
2024-05-28 13:15:19,145 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:15:19,149 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:15:19,153 - INFO - joeynmt.training - 	Hypothesis: And the last last year I argue these two of the second to demonstrate as the most of the polling of the last three million years of the last three million years of the last three million years of the last 40 percent of the ground of the fourth of the fourth of the four-side.
2024-05-28 13:15:19,157 - INFO - joeynmt.training - Example #1
2024-05-28 13:15:19,195 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:15:19,195 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:15:19,195 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'this', 'is', 'speci@@', 'al', 'speci@@', 'es', 'of', 'this', 'speci@@', 'al', 'problem@@', 's', 'because', 'of', 'this', 'is', 'not', 'the', 'f@@', 'ar@@', 'mer@@', 's.', '</s>']
2024-05-28 13:15:19,196 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:15:19,202 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:15:19,208 - INFO - joeynmt.training - 	Hypothesis: But this morning, this is special species of this special problems because of this is not the farmers.
2024-05-28 13:15:19,212 - INFO - joeynmt.training - Example #2
2024-05-28 13:15:19,216 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:15:19,216 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:15:19,216 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'l@@', 'y@@', '-@@', 'pol@@', 'ar', 'pol@@', 'l@@', 'ing', 'system@@', ',', 'the', 'wh@@', 'e@@', 'ther', 'the', 'buil@@', 'ding', 'system@@', '.', '</s>']
2024-05-28 13:15:19,217 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:15:19,221 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:15:19,225 - INFO - joeynmt.training - 	Hypothesis: The polly-polar polling system, the whether the building system.
2024-05-28 13:15:19,228 - INFO - joeynmt.training - Example #3
2024-05-28 13:15:19,231 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:15:19,231 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:15:19,231 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'ten@@', 'ded', 'to', 'be', 'able', 'to', 'look', 'at', 'the', 'bo@@', 't@@', 'to@@', 'm', 'of', 'the', 'v@@', 'ari@@', 'ous', 'ne@@', 'w@@', 's.', '</s>']
2024-05-28 13:15:19,232 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:15:19,236 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:15:19,265 - INFO - joeynmt.training - 	Hypothesis: She was extended to be able to look at the bottom of the various news.
2024-05-28 13:15:19,269 - INFO - joeynmt.training - Example #4
2024-05-28 13:15:19,275 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:15:19,275 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:15:19,275 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'sec@@', 'ond', 'of', 'the', 'di@@', 'a@@', 'ff@@', 'ec@@', 'ted', 'to', 'show', 'you', 'that', 'you', 'can', 'look', 'at', 'the', 'f@@', 'ast', 'of', 'what', 'happen@@', 'ed', 'on', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:15:19,276 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:15:19,280 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:15:19,284 - INFO - joeynmt.training - 	Hypothesis: The second of the diaffected to show you that you can look at the fast of what happened on the last 25 years.
2024-05-28 13:15:22,798 - INFO - joeynmt.training - Epoch   6, Step:    24600, Batch Loss:     1.788420, Batch Acc: 0.495646, Tokens per Sec:    18531, Lr: 0.000300
2024-05-28 13:15:26,687 - INFO - joeynmt.training - Epoch   6, Step:    24700, Batch Loss:     1.870348, Batch Acc: 0.502917, Tokens per Sec:    17607, Lr: 0.000300
2024-05-28 13:15:30,386 - INFO - joeynmt.training - Epoch   6, Step:    24800, Batch Loss:     1.715550, Batch Acc: 0.502124, Tokens per Sec:    19747, Lr: 0.000300
2024-05-28 13:15:34,152 - INFO - joeynmt.training - Epoch   6, Step:    24900, Batch Loss:     1.734047, Batch Acc: 0.503263, Tokens per Sec:    19266, Lr: 0.000300
2024-05-28 13:15:38,063 - INFO - joeynmt.training - Epoch   6, Step:    25000, Batch Loss:     1.666622, Batch Acc: 0.507806, Tokens per Sec:    18863, Lr: 0.000300
2024-05-28 13:15:38,067 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:15:38,071 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:16:21,286 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.72, acc:   0.49, generation: 43.1930[sec], evaluation: 0.0000[sec]
2024-05-28 13:16:21,291 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:16:21,392 - INFO - joeynmt.helpers - delete models/bpe-subword/22500.ckpt
2024-05-28 13:16:21,403 - INFO - joeynmt.training - Example #0
2024-05-28 13:16:21,411 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:16:21,411 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:16:21,411 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'th@@', 'ir@@', 'd', 'thing', 'I', 'ar@@', 'gu@@', 'ed', 'these', 'two', 'di@@', 'a@@', 'th@@', 'le@@', 'tic', 'di@@', 'a@@', 'th@@', 'le@@', 't', 'as', 'the', 'most', 'of', 'the', 'most', 'of', 'the', 'most', 'maj@@', 'or@@', 'ity', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'f@@', 'our', 'bil@@', 'lion', 'years', 'of', 'the', 's@@', 'li@@', 'de', 'of', 'f@@', 'our', 'percent', 'of', 'the', 'lar@@', 'ge', 'of', 'f@@', 'our', 'percent', 'of', 'the', 'lar@@', 'ge', 'of', 'f@@', 'our', 'percent', 'of', 'the', 'lar@@', 'ge', 'of', 'f@@', 'our', 'percent', 'of', 'the', 'big', 'st@@', 'at@@', 'em@@', 'ent.', '</s>']
2024-05-28 13:16:21,412 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:16:21,436 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:16:21,469 - INFO - joeynmt.training - 	Hypothesis: And the third thing I argued these two diathletic diathlet as the most of the most of the most majority of the last three million years of the last three million years of the four billion years of the slide of four percent of the large of four percent of the large of four percent of the large of four percent of the big statement.
2024-05-28 13:16:21,473 - INFO - joeynmt.training - Example #1
2024-05-28 13:16:21,476 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:16:21,476 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:16:21,477 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'the', 'hear@@', 't', 'of', 'this', 'speci@@', 'al', 'problem@@', 's', 'because', 'it', "doesn't", 'look', 'at', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'b@@', 'ro@@', 'k@@', 's.', '</s>']
2024-05-28 13:16:21,477 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:16:21,481 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:16:21,484 - INFO - joeynmt.training - 	Hypothesis: But this morning, the heart of this special problems because it doesn't look at the gross of the broks.
2024-05-28 13:16:21,546 - INFO - joeynmt.training - Example #2
2024-05-28 13:16:21,550 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:16:21,550 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:16:21,550 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['C@@', 'al@@', 'o@@', 'pol@@', 'ar', 'pol@@', 'l@@', 'ar', 'is', 'in', 'a', 'way', 'that', 'the', 'cl@@', 'im@@', 'ate', 'syst@@', 'em', 'that', 'the', 'cl@@', 'im@@', 'ate', 'system@@', '.', '</s>']
2024-05-28 13:16:21,551 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:16:21,554 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:16:21,558 - INFO - joeynmt.training - 	Hypothesis: Calopolar pollar is in a way that the climate system that the climate system.
2024-05-28 13:16:21,562 - INFO - joeynmt.training - Example #3
2024-05-28 13:16:21,565 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:16:21,565 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:16:21,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'tin@@', 'c@@', 'tion', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:16:21,565 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:16:21,593 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:16:21,608 - INFO - joeynmt.training - 	Hypothesis: She was extinction and contraction and contract.
2024-05-28 13:16:21,612 - INFO - joeynmt.training - Example #4
2024-05-28 13:16:21,616 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:16:21,616 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:16:21,616 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'U@@', 'r@@', 'ag@@', 'e,', 'the', 'di@@', 'a@@', 'th@@', 's', 'that', "I'm", 'going', 'to', 'show', 'you', 'a', 'f@@', 'ast@@', 'ast@@', 'est', 'on', 'what', 'was', 'in@@', 't@@', 'am@@', 'pl@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:16:21,617 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:16:21,621 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:16:21,624 - INFO - joeynmt.training - 	Hypothesis: The Urage, the diaths that I'm going to show you a fastastest on what was intampled in the last 25 years.
2024-05-28 13:16:25,377 - INFO - joeynmt.training - Epoch   6, Step:    25100, Batch Loss:     1.522346, Batch Acc: 0.507205, Tokens per Sec:    17169, Lr: 0.000300
2024-05-28 13:16:29,187 - INFO - joeynmt.training - Epoch   6, Step:    25200, Batch Loss:     1.662858, Batch Acc: 0.500057, Tokens per Sec:    18320, Lr: 0.000300
2024-05-28 13:16:33,159 - INFO - joeynmt.training - Epoch   6, Step:    25300, Batch Loss:     1.841659, Batch Acc: 0.510182, Tokens per Sec:    17246, Lr: 0.000300
2024-05-28 13:16:36,764 - INFO - joeynmt.training - Epoch   6, Step:    25400, Batch Loss:     1.702936, Batch Acc: 0.501295, Tokens per Sec:    19739, Lr: 0.000300
2024-05-28 13:16:40,537 - INFO - joeynmt.training - Epoch   6, Step:    25500, Batch Loss:     1.625345, Batch Acc: 0.502735, Tokens per Sec:    18686, Lr: 0.000300
2024-05-28 13:16:40,541 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:16:40,544 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:17:08,289 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.71, acc:   0.49, generation: 27.7235[sec], evaluation: 0.0000[sec]
2024-05-28 13:17:08,303 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:17:08,437 - INFO - joeynmt.helpers - delete models/bpe-subword/23000.ckpt
2024-05-28 13:17:08,494 - INFO - joeynmt.training - Example #0
2024-05-28 13:17:08,498 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:17:08,498 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:17:08,498 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 'x@@', 'i@@', 'es', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'mo@@', 'tion', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'that', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'year@@', 's,', 'it', 'was', 'sm@@', 'all@@', ',', 'the', 'si@@', 'ze', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'b@@', 'loo@@', 'd', 'of', 'f@@', 'our', 'percent', 'of', 'the', 'b@@', 'ab@@', 'y', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'b@@', 'ab@@', 'i@@', 'es', 'of', 'the', 'last', 'year@@', '.', '</s>']
2024-05-28 13:17:08,498 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:17:08,502 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:17:08,506 - INFO - joeynmt.training - 	Hypothesis: And the year I showed these two diaxies to demonstrate the motion of the last three million years that the last three million years of the last three million years of the last three years, it was small, the size of the four percent of the blood of four percent of the baby of the four percent of the babies of the last year.
2024-05-28 13:17:08,509 - INFO - joeynmt.training - Example #1
2024-05-28 13:17:08,531 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:17:08,532 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:17:08,532 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'this', 'is', 'the', 'speci@@', 'al', 'problem@@', 's', 'because', 'of', 'this', 'prob@@', 'le@@', 'm', 'of', 'this', 'is@@', 'su@@', 'e', 'of', 'the', 'b@@', 'loo@@', 'd', 'of', 'the', 'b@@', 'loo@@', 'd', 'of', 'the', 'b@@', 'loo@@', 'd', 'of', 'the', 'b@@', 'ad', 'of', 'the', 'b@@', 'ad', 'of', 'the', 'b@@', 'ad', 'of', 'the', 'b@@', 'ad', 'of', 'the', 'b@@', 'ad', 'of', 'the', 'hear@@', 't', 'of', 'this', 'mor@@', 'n@@', 'ing.', '</s>']
2024-05-28 13:17:08,532 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:17:08,550 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:17:08,553 - INFO - joeynmt.training - 	Hypothesis: But this morning, this is the special problems because of this problem of this issue of the blood of the blood of the blood of the bad of the bad of the bad of the bad of the bad of the heart of this morning.
2024-05-28 13:17:08,556 - INFO - joeynmt.training - Example #2
2024-05-28 13:17:08,561 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:17:08,561 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:17:08,561 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'pol@@', 'ar', 'is', 'is', 'in', 'a', 'wa@@', 'y,', 'the', 'hear@@', 't', 'of', 'the', 'cl@@', 'im@@', 'ate', 'system@@', '.', '</s>']
2024-05-28 13:17:08,561 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:17:08,565 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:17:08,568 - INFO - joeynmt.training - 	Hypothesis: The polar polar is is in a way, the heart of the climate system.
2024-05-28 13:17:08,572 - INFO - joeynmt.training - Example #3
2024-05-28 13:17:08,575 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:17:08,576 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:17:08,576 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'tin@@', 'c@@', 'tion', 'and', 'they', 'have', 'to', 'be', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:17:08,576 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:17:08,580 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:17:08,583 - INFO - joeynmt.training - 	Hypothesis: She was extinction and they have to be contract.
2024-05-28 13:17:08,626 - INFO - joeynmt.training - Example #4
2024-05-28 13:17:08,629 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:17:08,629 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:17:08,629 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'U@@', 'r@@', 'u@@', 'th@@', 'er@@', "'s", 'di@@', 'a@@', 'x@@', ',', 'I', 'will', 'show', 'you', 'a', 'f@@', 'ast@@', 'er', 'will', 'be', 'a', 'f@@', 'ast@@', 'er', 'on', 'what', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:17:08,629 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:17:08,633 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:17:08,637 - INFO - joeynmt.training - 	Hypothesis: The Uruther's diax, I will show you a faster will be a faster on what happened in the last 25 years.
2024-05-28 13:17:12,462 - INFO - joeynmt.training - Epoch   6, Step:    25600, Batch Loss:     1.665694, Batch Acc: 0.498046, Tokens per Sec:    16978, Lr: 0.000300
2024-05-28 13:17:16,240 - INFO - joeynmt.training - Epoch   6, Step:    25700, Batch Loss:     1.691450, Batch Acc: 0.501440, Tokens per Sec:    19002, Lr: 0.000300
2024-05-28 13:17:20,125 - INFO - joeynmt.training - Epoch   6, Step:    25800, Batch Loss:     1.637662, Batch Acc: 0.502952, Tokens per Sec:    18773, Lr: 0.000300
2024-05-28 13:17:23,954 - INFO - joeynmt.training - Epoch   6, Step:    25900, Batch Loss:     1.525212, Batch Acc: 0.504246, Tokens per Sec:    18821, Lr: 0.000300
2024-05-28 13:17:27,842 - INFO - joeynmt.training - Epoch   6, Step:    26000, Batch Loss:     1.653703, Batch Acc: 0.500431, Tokens per Sec:    17938, Lr: 0.000300
2024-05-28 13:17:27,847 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:17:27,851 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:17:54,967 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.71, acc:   0.49, generation: 27.0939[sec], evaluation: 0.0000[sec]
2024-05-28 13:17:54,972 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:18:20,994 - INFO - joeynmt.helpers - delete models/bpe-subword/23500.ckpt
2024-05-28 13:18:21,032 - INFO - joeynmt.training - Example #0
2024-05-28 13:18:21,036 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:18:21,036 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:18:21,036 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'th@@', 'ir@@', 'd', 'of', 'these', 'two', 'de@@', 'm@@', 'and', 'these', 'two', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'de@@', 'mon@@', 'str@@', 'ate', 'of', 'the', 'pol@@', 'ar', 'pol@@', 'ar', 'that', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'that', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'b@@', 'loc@@', 'k', 'of', 'f@@', 'our', 'bil@@', 'lion', 'years', 'of', 'the', 'lar@@', 'ge', 'st@@', 'ate', 'of', 'f@@', 'our', 'percent', 'of', 'the', 'lar@@', 'ge', 'st@@', 'ate', 'of', 'a', 'few', 'percent', 'percent', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'big', 'st@@', 'ate', 'of', 'a', 'few', 'percent', 'of', 'the', 'big', 'st@@', 'ate', 'of', 'the', 'b@@', 'ro@@', 'wn', 'of', 'the', 'b@@', 'on@@', 'es', 'of', 'the']
2024-05-28 13:18:21,037 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:18:21,041 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:18:21,044 - INFO - joeynmt.training - 	Hypothesis: And the third of these two demand these two to demonstrate that the demonstrate of the polar polar that the last three million years that the last three million years of the last three million years of the block of four billion years of the large state of four percent of the large state of a few percent percent of the four percent of the big state of a few percent of the big state of the brown of the bones of the
2024-05-28 13:18:21,048 - INFO - joeynmt.training - Example #1
2024-05-28 13:18:21,052 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:18:21,052 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:18:21,052 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'this', 'is', 'speci@@', 'al', 'speci@@', 'es', 'of', 'this', 'speci@@', 'es', 'that', "don't", 'show', 'that', 'the', 'gr@@', 'os@@', 's', 'that', "don't", 'show', 'the', 'g@@', 'ar@@', 'den@@', '.', '</s>']
2024-05-28 13:18:21,052 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:18:21,084 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:18:21,087 - INFO - joeynmt.training - 	Hypothesis: But this morning, this is special species of this species that don't show that the gross that don't show the garden.
2024-05-28 13:18:21,090 - INFO - joeynmt.training - Example #2
2024-05-28 13:18:21,094 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:18:21,094 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:18:21,094 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'l@@', 'er', 'pol@@', 'l@@', 'er', 'is', 'in', 'a', 'way', 'that', 'the', 'cl@@', 'im@@', 'ate', 'system@@', ',', 'the', 'hear@@', 't', 'system@@', '.', '</s>']
2024-05-28 13:18:21,094 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:18:21,098 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:18:21,102 - INFO - joeynmt.training - 	Hypothesis: The poller poller is in a way that the climate system, the heart system.
2024-05-28 13:18:21,106 - INFO - joeynmt.training - Example #3
2024-05-28 13:18:21,109 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:18:21,109 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:18:21,109 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'ex@@', 'ten@@', 'ded', 'to', 'be', 'a', 'b@@', 'unc@@', 'h', 'of', 'w@@', 'in@@', 'do@@', 'w.', '</s>']
2024-05-28 13:18:21,110 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:18:21,114 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:18:21,117 - INFO - joeynmt.training - 	Hypothesis: It was extended to be a bunch of window.
2024-05-28 13:18:21,121 - INFO - joeynmt.training - Example #4
2024-05-28 13:18:21,146 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:18:21,146 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:18:21,146 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'of', 'all@@', '-@@', 'a@@', 'pos@@', 'iti@@', 've', 'that', 'you', 'look', 'at', 'it', 'that', 'I', 'will', 'show', 'you', 'that', 'it', 'would', 'be', 'a', 'qu@@', 'ic@@', 'k', 'on', 'what', 'he', 'was', 'in@@', 't@@', 'am@@', 'pl@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:18:21,147 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:18:21,151 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:18:21,155 - INFO - joeynmt.training - 	Hypothesis: The first of all-apositive that you look at it that I will show you that it would be a quick on what he was intampled in the last 25 years.
2024-05-28 13:18:25,060 - INFO - joeynmt.training - Epoch   6, Step:    26100, Batch Loss:     1.671818, Batch Acc: 0.503036, Tokens per Sec:     2338, Lr: 0.000300
2024-05-28 13:18:29,192 - INFO - joeynmt.training - Epoch   6, Step:    26200, Batch Loss:     1.707096, Batch Acc: 0.510733, Tokens per Sec:    17324, Lr: 0.000300
2024-05-28 13:18:33,252 - INFO - joeynmt.training - Epoch   6, Step:    26300, Batch Loss:     1.774711, Batch Acc: 0.510824, Tokens per Sec:    17064, Lr: 0.000300
2024-05-28 13:18:37,383 - INFO - joeynmt.training - Epoch   6, Step:    26400, Batch Loss:     1.575383, Batch Acc: 0.506367, Tokens per Sec:    17624, Lr: 0.000300
2024-05-28 13:18:41,447 - INFO - joeynmt.training - Epoch   6, Step:    26500, Batch Loss:     1.760780, Batch Acc: 0.507029, Tokens per Sec:    18111, Lr: 0.000300
2024-05-28 13:18:41,458 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:18:41,462 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:19:12,452 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.72, ppl:   5.59, acc:   0.50, generation: 30.9674[sec], evaluation: 0.0000[sec]
2024-05-28 13:19:12,484 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:19:13,800 - INFO - joeynmt.helpers - delete models/bpe-subword/24000.ckpt
2024-05-28 13:19:13,980 - INFO - joeynmt.training - Example #0
2024-05-28 13:19:13,984 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:19:13,984 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:19:13,984 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'sho@@', 'wn', 'to', 'these', 'two', 'di@@', 'a@@', 'pos@@', 'ed', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'f@@', 'ear', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'mo@@', 'tion', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'f@@', 'our', 'bil@@', 'lion', 'years', 'of', 'the', 'big', 'st@@', 'ate', '4@@', '0', 'percent', 'of', 'the', 'lar@@', 'ge', 'of', 'f@@', 'our', 'percent', 'of', 'the', 'lar@@', 'ge', 'an@@', 'al@@', 'y@@', 'z@@', 'ed', 'for', '4@@', '8', 'percent', 'of', 'the', 'last', 'percent', 'of', 'the', 'ear@@', 'ly', 'ag@@', 'e.', '</s>']
2024-05-28 13:19:13,985 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:19:13,989 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:19:13,992 - INFO - joeynmt.training - 	Hypothesis: And I was shown to these two diaposed to demonstrate the fear to demonstrate the motion of the last three million years of the last three million years of the last three million years of the four billion years of the big state 40 percent of the large of four percent of the large analyzed for 48 percent of the last percent of the early age.
2024-05-28 13:19:13,997 - INFO - joeynmt.training - Example #1
2024-05-28 13:19:14,005 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:19:14,005 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:19:14,005 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'this', 'is', 'speci@@', 'al', 'speci@@', 'al', 'of', 'this', 'speci@@', 'al', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'look', 'at', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'b@@', 'ro@@', 'k@@', 'en@@', '.', '</s>']
2024-05-28 13:19:14,005 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:19:14,022 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:19:14,025 - INFO - joeynmt.training - 	Hypothesis: But this morning, this is special special of this special problem because it doesn't look at the gross of the gross of the broken.
2024-05-28 13:19:14,029 - INFO - joeynmt.training - Example #2
2024-05-28 13:19:14,032 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:19:14,032 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:19:14,032 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['C@@', 'al@@', 'o@@', 't', 'is', 'from', 'a', 'way', 'that', 'the', 'hear@@', 't', 'of', 'a', 'glob@@', 'al', 'system@@', ',', 'the', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'system@@', '.', '</s>']
2024-05-28 13:19:14,033 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:19:14,036 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:19:14,040 - INFO - joeynmt.training - 	Hypothesis: Calot is from a way that the heart of a global system, the heart of the global system.
2024-05-28 13:19:14,043 - INFO - joeynmt.training - Example #3
2024-05-28 13:19:14,047 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:19:14,047 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:19:14,047 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'pan@@', 'ded', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:19:14,048 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:19:14,075 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:19:14,078 - INFO - joeynmt.training - 	Hypothesis: She was expanded and contraction and contract.
2024-05-28 13:19:14,083 - INFO - joeynmt.training - Example #4
2024-05-28 13:19:14,086 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:19:14,087 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:19:14,087 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'p@@', 'ast', 'di@@', 'a@@', 'pos@@', 'iti@@', 'on', 'that', "I'm", 'looking', 'at', 'a', 'qu@@', 'ic@@', 'k', 'of', 'qu@@', 'ick@@', 'ly', 'going', 'to', 'be', 'a', 'qu@@', 'ic@@', 'k', 'at', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:19:14,087 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:19:14,091 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:19:14,115 - INFO - joeynmt.training - 	Hypothesis: The past diaposition that I'm looking at a quick of quickly going to be a quick at the last 25 years.
2024-05-28 13:19:17,824 - INFO - joeynmt.training - Epoch   6, Step:    26600, Batch Loss:     1.728574, Batch Acc: 0.504079, Tokens per Sec:    13430, Lr: 0.000300
2024-05-28 13:19:21,624 - INFO - joeynmt.training - Epoch   6, Step:    26700, Batch Loss:     1.652048, Batch Acc: 0.504924, Tokens per Sec:    18973, Lr: 0.000300
2024-05-28 13:19:25,513 - INFO - joeynmt.training - Epoch   6, Step:    26800, Batch Loss:     1.638369, Batch Acc: 0.501142, Tokens per Sec:    18824, Lr: 0.000300
2024-05-28 13:19:29,424 - INFO - joeynmt.training - Epoch   6, Step:    26900, Batch Loss:     1.715934, Batch Acc: 0.503334, Tokens per Sec:    17482, Lr: 0.000300
2024-05-28 13:19:33,574 - INFO - joeynmt.training - Epoch   6, Step:    27000, Batch Loss:     1.717687, Batch Acc: 0.507057, Tokens per Sec:    17008, Lr: 0.000300
2024-05-28 13:19:33,578 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:19:33,582 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:20:01,981 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.54, acc:   0.50, generation: 28.3757[sec], evaluation: 0.0000[sec]
2024-05-28 13:20:01,998 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:20:44,827 - INFO - joeynmt.helpers - delete models/bpe-subword/24500.ckpt
2024-05-28 13:20:44,975 - INFO - joeynmt.training - Example #0
2024-05-28 13:20:44,979 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:20:44,980 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:20:44,980 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'last', 'time', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'de@@', 'm@@', 'and', 'the', 'next', 'c@@', 'y@@', 'c@@', 'le', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'way', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'a', 'sm@@', 'all', 'st@@', 'at@@', 'es', 'of', 'a', 'sm@@', 'all', 'st@@', 'at@@', 'es', 'of', 'a', 'sm@@', 'all', 's@@', 'ou@@', 'th@@', 'er@@', 'n', 'of', 'a', 'sm@@', 'all', 'percent', 'of', 'the', 's@@', 'ou@@', 'th@@', '.', '</s>']
2024-05-28 13:20:44,980 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:20:44,984 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:20:44,988 - INFO - joeynmt.training - 	Hypothesis: And the last time I showed these two demand the next cycle to demonstrate the way of the last three million years of the last three million years of the last three million years of the last three million years of a small states of a small states of a small southern of a small percent of the south.
2024-05-28 13:20:44,993 - INFO - joeynmt.training - Example #1
2024-05-28 13:20:44,997 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:20:44,997 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:20:44,997 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'this', 'is', 'speci@@', 'al', 'speci@@', 'es', 'because', 'of', 'this', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'look', 'at', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'bl@@', 'ac@@', 'k', 'of', 'the', 'bl@@', 'ac@@', 'k', 'of', 'the', 'b@@', 'ab@@', 'y.', '</s>']
2024-05-28 13:20:44,997 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:20:45,025 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:20:45,043 - INFO - joeynmt.training - 	Hypothesis: But this morning, this is special species because of this problem because it doesn't look at the gross of the black of the black of the baby.
2024-05-28 13:20:45,047 - INFO - joeynmt.training - Example #2
2024-05-28 13:20:45,050 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:20:45,050 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:20:45,050 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'l@@', 'ine', 'is', 'in', 'a', 'wa@@', 'y,', 'the', 'hear@@', 't', 'of', 'a', 'world', 'that', 'the', 'hear@@', 't', 'of', 'the', 'cl@@', 'im@@', 'ate', 'system@@', '.', '</s>']
2024-05-28 13:20:45,051 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:20:45,054 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:20:45,058 - INFO - joeynmt.training - 	Hypothesis: The polline is in a way, the heart of a world that the heart of the climate system.
2024-05-28 13:20:45,061 - INFO - joeynmt.training - Example #3
2024-05-28 13:20:45,064 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:20:45,064 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:20:45,064 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'p@@', 'and@@', 'ing', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:20:45,064 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:20:45,068 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:20:45,072 - INFO - joeynmt.training - 	Hypothesis: She was expanding and contraction and contract.
2024-05-28 13:20:45,075 - INFO - joeynmt.training - Example #4
2024-05-28 13:20:45,079 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:20:45,079 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:20:45,079 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'di@@', 'a@@', 'pos@@', 'iti@@', 'on', 'that', 'is', 'a', 'f@@', 'ast@@', 'er', 'that', 'I', 'look', 'at', 'what', 'it', 'was', 'a', 'f@@', 'ast@@', 'er', 'than', 'what', 'it', 'was', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:20:45,080 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:20:45,084 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:20:45,087 - INFO - joeynmt.training - 	Hypothesis: The next diaposition that is a faster that I look at what it was a faster than what it was the last 25 years.
2024-05-28 13:20:48,264 - INFO - joeynmt.training - Epoch   6, Step:    27100, Batch Loss:     1.628528, Batch Acc: 0.503214, Tokens per Sec:     1554, Lr: 0.000300
2024-05-28 13:20:51,481 - INFO - joeynmt.training - Epoch   6, Step:    27200, Batch Loss:     1.516285, Batch Acc: 0.498567, Tokens per Sec:    21403, Lr: 0.000300
2024-05-28 13:20:52,866 - INFO - joeynmt.training - Epoch   6: total training loss 7707.84
2024-05-28 13:20:52,870 - INFO - joeynmt.training - EPOCH 7
2024-05-28 13:20:54,748 - INFO - joeynmt.training - Epoch   7, Step:    27300, Batch Loss:     1.720660, Batch Acc: 0.510900, Tokens per Sec:    22439, Lr: 0.000300
2024-05-28 13:20:57,741 - INFO - joeynmt.training - Epoch   7, Step:    27400, Batch Loss:     1.572662, Batch Acc: 0.519384, Tokens per Sec:    23285, Lr: 0.000300
2024-05-28 13:21:00,986 - INFO - joeynmt.training - Epoch   7, Step:    27500, Batch Loss:     1.473318, Batch Acc: 0.524818, Tokens per Sec:    21843, Lr: 0.000300
2024-05-28 13:21:00,998 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:21:01,001 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:21:10,054 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.56, acc:   0.50, generation: 9.0314[sec], evaluation: 0.0000[sec]
2024-05-28 13:21:29,054 - INFO - joeynmt.helpers - delete models/bpe-subword/25000.ckpt
2024-05-28 13:21:29,163 - INFO - joeynmt.training - Example #0
2024-05-28 13:21:29,169 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:21:29,414 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:21:29,415 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 'pos@@', 'iti@@', 've', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'way', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'big', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'that', 'in', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'f@@', 'our', 'mil@@', 'lion', 'years', 'of', 'a', 'little', 'st@@', 'ate', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 's@@', 'ou@@', 'th@@', 'er@@', 'n', 'of', 'a', 'little', 'bit', 'of', 'f@@', 'our', 'percent', 'of', 'the', 's@@', 'ou@@', 'th@@', 'er@@', 'n', 'of', 'the', 'last', 'percent', 'of', 'the', 's@@', 'ou@@', 'th@@', 'er@@', 'n', 'of', 'the', 's@@', 'ou@@', 'th@@', 'er@@', 'n', 'of', 'the', 's@@', 'li@@', 'ght@@', 'ly']
2024-05-28 13:21:29,415 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:21:29,420 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:21:29,606 - INFO - joeynmt.training - 	Hypothesis: And the year I showed these two diapositive to demonstrate the way to demonstrate the big of the last three million years that in the last three million years of the last three million years of the four million years of a little state of the four percent of the southern of a little bit of four percent of the southern of the last percent of the southern of the southern of the slightly
2024-05-28 13:21:29,610 - INFO - joeynmt.training - Example #1
2024-05-28 13:21:29,614 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:21:29,614 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:21:29,614 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'ob@@', 'vi@@', 'ous', 'd@@', 'ri@@', 'ving', 'this', 'speci@@', 'al', 'is@@', 'su@@', 'es', 'because', 'not', 'look', 'at', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'g@@', 'ar@@', 'den@@', '.', '</s>']
2024-05-28 13:21:29,615 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:21:29,618 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:21:29,622 - INFO - joeynmt.training - 	Hypothesis: But this is the obvious driving this special issues because not look at the gross of the gross of the garden.
2024-05-28 13:21:29,625 - INFO - joeynmt.training - Example #2
2024-05-28 13:21:29,628 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:21:29,629 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:21:29,629 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'is', 'is', 'in', 'a', 'wa@@', 'y,', 'the', 'hear@@', 't', 'of', 'the', 'world', 'that', 'the', 'hear@@', 't', 'of', 'glob@@', 'al', 'system@@', '.', '</s>']
2024-05-28 13:21:29,629 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:21:29,636 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:21:29,640 - INFO - joeynmt.training - 	Hypothesis: The polar is is in a way, the heart of the world that the heart of global system.
2024-05-28 13:21:29,773 - INFO - joeynmt.training - Example #3
2024-05-28 13:21:29,908 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:21:30,046 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:21:30,046 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'tin@@', 'c@@', 't', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:21:30,046 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:21:30,051 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:21:30,201 - INFO - joeynmt.training - 	Hypothesis: She was extinct and contraction and contract.
2024-05-28 13:21:30,285 - INFO - joeynmt.training - Example #4
2024-05-28 13:21:30,289 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:21:30,289 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:21:30,289 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'di@@', 'a@@', 'pos@@', 'iti@@', 'on', 'that', 'I', 'will', 'look', 'at', 'the', 'f@@', 'ast', 'will', 'be', 'a', 'qu@@', 'ic@@', 'k', 'of', 'what', 'was', 'going', 'on', 'on', 'at', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:21:30,289 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:21:30,296 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:21:30,300 - INFO - joeynmt.training - 	Hypothesis: The next diaposition that I will look at the fast will be a quick of what was going on on at the last 25 years.
2024-05-28 13:21:33,814 - INFO - joeynmt.training - Epoch   7, Step:    27600, Batch Loss:     1.803407, Batch Acc: 0.520178, Tokens per Sec:     3024, Lr: 0.000300
2024-05-28 13:21:37,868 - INFO - joeynmt.training - Epoch   7, Step:    27700, Batch Loss:     1.741568, Batch Acc: 0.519664, Tokens per Sec:    17133, Lr: 0.000300
2024-05-28 13:21:41,779 - INFO - joeynmt.training - Epoch   7, Step:    27800, Batch Loss:     1.575636, Batch Acc: 0.524228, Tokens per Sec:    18213, Lr: 0.000300
2024-05-28 13:21:45,533 - INFO - joeynmt.training - Epoch   7, Step:    27900, Batch Loss:     1.793936, Batch Acc: 0.521238, Tokens per Sec:    19607, Lr: 0.000300
2024-05-28 13:21:49,639 - INFO - joeynmt.training - Epoch   7, Step:    28000, Batch Loss:     1.721158, Batch Acc: 0.520720, Tokens per Sec:    17554, Lr: 0.000300
2024-05-28 13:21:49,647 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:21:49,653 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:22:10,473 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.52, acc:   0.50, generation: 20.7966[sec], evaluation: 0.0000[sec]
2024-05-28 13:22:10,478 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:22:11,531 - INFO - joeynmt.helpers - delete models/bpe-subword/25500.ckpt
2024-05-28 13:22:11,828 - INFO - joeynmt.training - Example #0
2024-05-28 13:22:11,846 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:22:11,846 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:22:11,846 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'y@@', 'ear', 'of', 'the', 'y@@', 'ear', 'of', 'these', 'two', 'de@@', 'mon@@', 'str@@', 'ate', 's@@', 'uch', 'as', 'the', 'en@@', 'tr@@', 'al', 'mo@@', 'tion', 'of', 'the', 'most', 'of', 'the', 'most', 'three', 'mil@@', 'lion', 'years', 'that', 'in', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'big', 'st@@', 'at@@', 'es', 'of', 'the', 'big', 'st@@', 'at@@', 'es', 'of', 'f@@', 'our', 'percent', 'of', 'the', 'lar@@', 'g@@', 'est', 'st@@', 'ate', 'of', '4@@', '8', 'percent', 'of', 'the', 't@@', 'y@@', 'pe', 'of', 'f@@', 'our', 'percent', 'of', 'the', 'last', 'percent', 'of', 'the', 'to@@', 'p', 'of', 'the', 'last', 'percent', 'of', 'the', 'to@@', 'p', 'of', 'the', 'h@@', 'un@@', 'dre@@', 'd', 'percent', 'of', 'the', 'sec@@', 'on@@', 'd@@', '-@@']
2024-05-28 13:22:11,846 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:22:11,850 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:22:11,853 - INFO - joeynmt.training - 	Hypothesis: And the year of the year of these two demonstrate such as the entral motion of the most of the most three million years that in the last three million years of the last three million years of the big states of the big states of four percent of the largest state of 48 percent of the type of four percent of the last percent of the top of the last percent of the top of the hundred percent of the second-
2024-05-28 13:22:11,857 - INFO - joeynmt.training - Example #1
2024-05-28 13:22:11,861 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:22:11,861 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:22:11,861 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'this', 'mor@@', 'n@@', 'ing,', 'because', 'of', 'this', 'speci@@', 'al', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'look', 'at', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'gu@@', 'y.', '</s>']
2024-05-28 13:22:11,862 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:22:11,890 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:22:11,906 - INFO - joeynmt.training - 	Hypothesis: But this morning, this morning, because of this special problem because it doesn't look at the gross of the guy.
2024-05-28 13:22:11,910 - INFO - joeynmt.training - Example #2
2024-05-28 13:22:11,913 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:22:11,913 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:22:11,913 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'pol@@', 'ar', 'is', 'in', 'a', 'wa@@', 'y,', 'the', 'hear@@', 't', 'of', 'a', 'glob@@', 'al', 'system@@', ',', 'the', 'hear@@', 't', 'of', 'glob@@', 'al', 'system@@', '.', '</s>']
2024-05-28 13:22:11,914 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:22:11,918 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:22:11,921 - INFO - joeynmt.training - 	Hypothesis: The polar polar is in a way, the heart of a global system, the heart of global system.
2024-05-28 13:22:11,925 - INFO - joeynmt.training - Example #3
2024-05-28 13:22:11,929 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:22:11,929 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:22:11,929 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'tin@@', 'c@@', 't', 'and', 'the', 'contr@@', 'ac@@', 'tion', 'and', 'the', 'contr@@', 'ac@@', 'tion.', '</s>']
2024-05-28 13:22:11,929 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:22:11,932 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:22:11,956 - INFO - joeynmt.training - 	Hypothesis: She was extinct and the contraction and the contraction.
2024-05-28 13:22:11,960 - INFO - joeynmt.training - Example #4
2024-05-28 13:22:11,964 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:22:11,965 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:22:11,965 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'U@@', 'r@@', 'im@@', 'ate', 'of', 'the', 'di@@', 'a@@', 'pos@@', 'ing', 'that', 'you', 'will', 'be', 'a', 'qu@@', 'ic@@', 'k', 'on', 'what', 'was', 'going', 'on', 'on', 'what', 'was', 'in@@', 't@@', 'am@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'years', 'of', 'the', 'last', '2@@', '5', 'years', 'of', 'the', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:22:11,965 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:22:11,969 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:22:11,973 - INFO - joeynmt.training - 	Hypothesis: The Urimate of the diaposing that you will be a quick on what was going on on what was intamed in the last 25 years of the last 25 years of the 25 years.
2024-05-28 13:22:15,857 - INFO - joeynmt.training - Epoch   7, Step:    28100, Batch Loss:     1.542507, Batch Acc: 0.521312, Tokens per Sec:    13598, Lr: 0.000300
2024-05-28 13:22:19,979 - INFO - joeynmt.training - Epoch   7, Step:    28200, Batch Loss:     1.620879, Batch Acc: 0.517890, Tokens per Sec:    17461, Lr: 0.000300
2024-05-28 13:22:24,078 - INFO - joeynmt.training - Epoch   7, Step:    28300, Batch Loss:     1.748182, Batch Acc: 0.513816, Tokens per Sec:    17010, Lr: 0.000300
2024-05-28 13:22:28,116 - INFO - joeynmt.training - Epoch   7, Step:    28400, Batch Loss:     1.760930, Batch Acc: 0.520022, Tokens per Sec:    17569, Lr: 0.000300
2024-05-28 13:22:32,169 - INFO - joeynmt.training - Epoch   7, Step:    28500, Batch Loss:     1.756072, Batch Acc: 0.515035, Tokens per Sec:    17939, Lr: 0.000300
2024-05-28 13:22:32,174 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:22:32,178 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:22:59,372 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.49, acc:   0.50, generation: 27.1712[sec], evaluation: 0.0000[sec]
2024-05-28 13:22:59,386 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:23:00,411 - INFO - joeynmt.helpers - delete models/bpe-subword/26000.ckpt
2024-05-28 13:23:00,572 - INFO - joeynmt.training - Example #0
2024-05-28 13:23:00,582 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:23:00,582 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:23:00,582 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', '-@@', 's@@', 'li@@', 'de', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'these', 'two', 'and', 'the', 'in@@', 'side', 'of', 'the', 'pol@@', 'ar', 'that', 'the', 'most', 'of', 'the', 'pol@@', 'ar', 'that', 'the', 'most', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'ol@@', 'd,', 'it', 'was', 'a', 'little', 'bit', 'of', 'the', 'great', 'st@@', 'ate', 'of', '4@@', '8', 'percent', 'of', 'the', 'great', 'st@@', 'ate', 'with', '4@@', '8', 'percent', 'of', 'the', 'h@@', 'and@@', 's.', '</s>']
2024-05-28 13:23:00,582 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:23:00,586 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:23:00,590 - INFO - joeynmt.training - 	Hypothesis: I showed these two dia-slide to demonstrate these two and the inside of the polar that the most of the polar that the most three million years of the last three million years of the last three million years old, it was a little bit of the great state of 48 percent of the great state with 48 percent of the hands.
2024-05-28 13:23:00,597 - INFO - joeynmt.training - Example #1
2024-05-28 13:23:00,634 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:23:00,635 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:23:00,635 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'the', 'mor@@', 'ning', 'of', 'this', 'speci@@', 'al', 'problem@@', 's', 'because', 'the', 'prob@@', 'le@@', 'm', 'is', 'that', 'not', 'sho@@', 'w@@', 'ed', 'the', 'gr@@', 'os@@', 's@@', 'e.', '</s>']
2024-05-28 13:23:00,635 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:23:00,644 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:23:00,648 - INFO - joeynmt.training - 	Hypothesis: But this morning, the morning of this special problems because the problem is that not showed the grosse.
2024-05-28 13:23:00,651 - INFO - joeynmt.training - Example #2
2024-05-28 13:23:00,655 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:23:00,655 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:23:00,656 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'pol@@', 'ar', 'is', 'in', 'a', 'wa@@', 'y,', 'the', 'hear@@', 't', 'of', 'a', 'cl@@', 'im@@', 'ate', 'system@@', ',', 'the', 'cl@@', 'im@@', 'ate', 'system@@', '.', '</s>']
2024-05-28 13:23:00,656 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:23:00,676 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:23:00,680 - INFO - joeynmt.training - 	Hypothesis: The polar polar is in a way, the heart of a climate system, the climate system.
2024-05-28 13:23:00,689 - INFO - joeynmt.training - Example #3
2024-05-28 13:23:00,692 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:23:00,692 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:23:00,692 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'ten@@', 'ded', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:23:00,693 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:23:00,697 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:23:00,713 - INFO - joeynmt.training - 	Hypothesis: She was extended and contraction and contract.
2024-05-28 13:23:00,717 - INFO - joeynmt.training - Example #4
2024-05-28 13:23:00,721 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:23:00,721 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:23:00,721 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'U@@', 'r@@', 'up@@', 'p@@', 'er', 'that', 'I', 'will', 'look', 'at', 'that', 'I', 'will', 'show', 'you', 'that', 'I', 'will', 'be', 'a', 'qu@@', 'ic@@', 'k', 'on', 'what', 'was', 'in@@', 't@@', 'un@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:23:00,721 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:23:00,725 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:23:00,729 - INFO - joeynmt.training - 	Hypothesis: The Urupper that I will look at that I will show you that I will be a quick on what was intuned in the last 25 years.
2024-05-28 13:23:04,640 - INFO - joeynmt.training - Epoch   7, Step:    28600, Batch Loss:     1.530432, Batch Acc: 0.516992, Tokens per Sec:    13503, Lr: 0.000300
2024-05-28 13:23:08,424 - INFO - joeynmt.training - Epoch   7, Step:    28700, Batch Loss:     1.736620, Batch Acc: 0.522394, Tokens per Sec:    18799, Lr: 0.000300
2024-05-28 13:23:12,023 - INFO - joeynmt.training - Epoch   7, Step:    28800, Batch Loss:     1.697551, Batch Acc: 0.519723, Tokens per Sec:    19641, Lr: 0.000300
2024-05-28 13:23:15,436 - INFO - joeynmt.training - Epoch   7, Step:    28900, Batch Loss:     1.686550, Batch Acc: 0.516383, Tokens per Sec:    20798, Lr: 0.000300
2024-05-28 13:23:18,586 - INFO - joeynmt.training - Epoch   7, Step:    29000, Batch Loss:     1.893914, Batch Acc: 0.510827, Tokens per Sec:    22705, Lr: 0.000300
2024-05-28 13:23:18,590 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:23:18,594 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:23:29,752 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.47, acc:   0.50, generation: 11.1375[sec], evaluation: 0.0000[sec]
2024-05-28 13:23:29,756 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:24:18,814 - INFO - joeynmt.helpers - delete models/bpe-subword/26500.ckpt
2024-05-28 13:24:21,301 - INFO - joeynmt.training - Example #0
2024-05-28 13:24:21,366 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:24:21,481 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:24:21,481 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 'po@@', 'is@@', 'ing', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'way', 'of', 'de@@', 'mon@@', 'str@@', 'ate', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'that', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'was', 'd@@', 'imen@@', 'si@@', 'on,', 'it', 'was', 'sm@@', 'all', 's@@', 'qu@@', 'are', 'f@@', 'our', 'sm@@', 'all', 's@@', 'qu@@', 'are', 'with', '4@@', '8', 'percent', 'of', 'the', 'hi@@', 'gh@@', '-@@', 'h@@', 'un@@', 'dre@@', 'd', 'percent', 'of', 'the', 's@@', 'li@@', 'de', 'of', 'f@@', 'our', 'percent', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 'ex@@', 'cit@@', 'ed', 'about', '4@@', '0', 'percent', 'of', 'the', 'de@@', 'mon@@', 'str@@', 'ate', 'of', 'the', 'di@@', 'a@@', 'de@@', 's', 'of', 'the', 'di@@', 'a@@', 'th@@']
2024-05-28 13:24:21,482 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:24:21,486 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:24:21,490 - INFO - joeynmt.training - 	Hypothesis: And the year I showed these two diapoising to demonstrate the way of demonstrate of the last three million years that the last three million years was dimension, it was small square four small square with 48 percent of the high-hundred percent of the slide of four percent of the four percent of the excited about 40 percent of the demonstrate of the diades of the diath
2024-05-28 13:24:21,493 - INFO - joeynmt.training - Example #1
2024-05-28 13:24:21,498 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:24:21,498 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:24:21,498 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'the', 'mor@@', 'ning', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'look', 'at', 'the', 'gr@@', 'os@@', 's', 'because', 'it', "doesn't", 'look', 'like', 'the', 'gr@@', 'os@@', '.', '</s>']
2024-05-28 13:24:21,498 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:24:21,548 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:24:21,673 - INFO - joeynmt.training - 	Hypothesis: But this morning, the morning of this particular problem because it doesn't look at the gross because it doesn't look like the gros.
2024-05-28 13:24:21,677 - INFO - joeynmt.training - Example #2
2024-05-28 13:24:21,680 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:24:21,680 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:24:21,681 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['C@@', 'al@@', 'o@@', 'te', 'is', '--', 'in', 'a', 'wa@@', 'y,', 'the', 'hear@@', 't', 'of', 'the', 'cl@@', 'im@@', 'ate', 'system@@', '.', '</s>']
2024-05-28 13:24:21,681 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:24:21,685 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:24:21,690 - INFO - joeynmt.training - 	Hypothesis: Calote is -- in a way, the heart of the climate system.
2024-05-28 13:24:21,693 - INFO - joeynmt.training - Example #3
2024-05-28 13:24:21,720 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:24:21,720 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:24:21,720 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'ten@@', 'ded', 'and', 'can@@', ',', 'and', 'they', 'can', 'be', 'able', 'to', 'see', 'the', 'v@@', 'ari@@', 'ous', 'and', 'the', 'contr@@', 'ac@@', 'tion.', '</s>']
2024-05-28 13:24:21,721 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:24:21,727 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:24:21,731 - INFO - joeynmt.training - 	Hypothesis: She was extended and can, and they can be able to see the various and the contraction.
2024-05-28 13:24:21,734 - INFO - joeynmt.training - Example #4
2024-05-28 13:24:21,739 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:24:21,739 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:24:21,739 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'ght@@', 'ly', 'the', 'di@@', 'a@@', 'po@@', 'is@@', 'ing', 'you', 'that', 'will', 'be', 'a', 'qu@@', 'ic@@', 'k', 'on', 'what', 'happen@@', 'ed', 'is', 'in@@', 'no@@', 'v@@', 'ative', 'of', 'what', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:24:21,739 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:24:21,743 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:24:21,746 - INFO - joeynmt.training - 	Hypothesis: The next slightly the diapoising you that will be a quick on what happened is innovative of what happened in the last 25 years.
2024-05-28 13:24:25,631 - INFO - joeynmt.training - Epoch   7, Step:    29100, Batch Loss:     1.525525, Batch Acc: 0.516406, Tokens per Sec:     1294, Lr: 0.000300
2024-05-28 13:24:28,823 - INFO - joeynmt.training - Epoch   7, Step:    29200, Batch Loss:     1.679897, Batch Acc: 0.518044, Tokens per Sec:    22565, Lr: 0.000300
2024-05-28 13:24:32,113 - INFO - joeynmt.training - Epoch   7, Step:    29300, Batch Loss:     1.610946, Batch Acc: 0.523034, Tokens per Sec:    22162, Lr: 0.000300
2024-05-28 13:24:35,843 - INFO - joeynmt.training - Epoch   7, Step:    29400, Batch Loss:     1.577869, Batch Acc: 0.516367, Tokens per Sec:    18973, Lr: 0.000300
2024-05-28 13:24:39,764 - INFO - joeynmt.training - Epoch   7, Step:    29500, Batch Loss:     1.472762, Batch Acc: 0.516451, Tokens per Sec:    17336, Lr: 0.000300
2024-05-28 13:24:39,777 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:24:39,782 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:24:51,303 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.45, acc:   0.51, generation: 11.4992[sec], evaluation: 0.0000[sec]
2024-05-28 13:24:51,308 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:24:52,524 - INFO - joeynmt.helpers - delete models/bpe-subword/27500.ckpt
2024-05-28 13:24:52,613 - INFO - joeynmt.training - Example #0
2024-05-28 13:24:52,618 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:24:52,618 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:24:52,618 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'the', 'next', 'we@@', 'e@@', 'k', 'of', 'the', 'sec@@', 'ond', 'di@@', 'a@@', 'pos@@', 'iti@@', 've', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'maj@@', 'or', 'or', 'to', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'that', 'the', 'big', 'st@@', 'ate', 'of', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'big', 'st@@', 'ate', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'h@@', 'and', 'the', 'st@@', 'ate', '4@@', '8', 'percent', 'of', 'the', 'st@@', 'ate', 'of', 'the', 'E@@', 'ar@@', 'th', 'of', 'the', 'E@@', 'n@@', 'g@@', 'li@@', 's@@', 'h', 'of', 'the', 'sec@@', 'on@@', 'd@@', '-@@', '-@@', 'year@@', '-@@', 'old', 'bo@@', 'th']
2024-05-28 13:24:52,618 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:24:52,622 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:24:52,625 - INFO - joeynmt.training - 	Hypothesis: And I was the next week of the second diapositive to demonstrate the major or to the last three million years that the big state of three million years of the last three million years of the big state of the size of the size of the size of the size of the size of the hand the state 48 percent of the state of the Earth of the English of the second--year-old both
2024-05-28 13:24:52,631 - INFO - joeynmt.training - Example #1
2024-05-28 13:24:52,636 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:24:52,636 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:24:52,636 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ity', 'of', 'this', 'problem@@', 's', 'of', 'this', 'problem@@', 's', 'because', 'it', "doesn't", 'look', 'because', 'it', "doesn't", 'look', 'at', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'g@@', 'am@@', 'e.', '</s>']
2024-05-28 13:24:52,636 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:24:52,640 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:24:52,654 - INFO - joeynmt.training - 	Hypothesis: But this mornity of this problems of this problems because it doesn't look because it doesn't look at the gross of the game.
2024-05-28 13:24:52,657 - INFO - joeynmt.training - Example #2
2024-05-28 13:24:52,660 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:24:52,660 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:24:52,660 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'is', 'in', 'a', 'wa@@', 'y,', 'the', 'hear@@', 't', 'of', 'the', 'cl@@', 'im@@', 'ate', 'system@@', ',', 'the', 'hear@@', 't', 'of', 'glob@@', 'al', 'system@@', '.', '</s>']
2024-05-28 13:24:52,661 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:24:52,664 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:24:52,668 - INFO - joeynmt.training - 	Hypothesis: The polar is in a way, the heart of the climate system, the heart of global system.
2024-05-28 13:24:52,671 - INFO - joeynmt.training - Example #3
2024-05-28 13:24:52,675 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:24:52,675 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:24:52,675 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'ex@@', 'ten@@', 'ds', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'they', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:24:52,675 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:24:52,696 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:24:52,701 - INFO - joeynmt.training - 	Hypothesis: She extends and contraction and contraction and they contract.
2024-05-28 13:24:52,909 - INFO - joeynmt.training - Example #4
2024-05-28 13:24:52,913 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:24:52,913 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:24:52,913 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'di@@', 'a@@', 'pos@@', 'iti@@', 've', 'that', 'I', 'will', 'show', 'you', 'a', 'qu@@', 'ic@@', 'k', 'that', 'I', 'would', 'be', 'a', 'qu@@', 'ic@@', 'k', 'of', 'what', 'was', 'going', 'on', 'on', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:24:52,914 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:24:52,917 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:24:52,921 - INFO - joeynmt.training - 	Hypothesis: The next diapositive that I will show you a quick that I would be a quick of what was going on on in the last 25 years.
2024-05-28 13:24:56,156 - INFO - joeynmt.training - Epoch   7, Step:    29600, Batch Loss:     1.767430, Batch Acc: 0.522945, Tokens per Sec:    14685, Lr: 0.000300
2024-05-28 13:24:59,475 - INFO - joeynmt.training - Epoch   7, Step:    29700, Batch Loss:     1.556196, Batch Acc: 0.518426, Tokens per Sec:    20471, Lr: 0.000300
2024-05-28 13:25:02,977 - INFO - joeynmt.training - Epoch   7, Step:    29800, Batch Loss:     1.788163, Batch Acc: 0.523208, Tokens per Sec:    19878, Lr: 0.000300
2024-05-28 13:25:06,363 - INFO - joeynmt.training - Epoch   7, Step:    29900, Batch Loss:     1.665476, Batch Acc: 0.512815, Tokens per Sec:    20937, Lr: 0.000300
2024-05-28 13:25:10,097 - INFO - joeynmt.training - Epoch   7, Step:    30000, Batch Loss:     1.459658, Batch Acc: 0.525508, Tokens per Sec:    19791, Lr: 0.000300
2024-05-28 13:25:10,101 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:25:10,105 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:25:21,054 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.41, acc:   0.51, generation: 10.9189[sec], evaluation: 0.0000[sec]
2024-05-28 13:25:21,058 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:25:22,986 - INFO - joeynmt.helpers - delete models/bpe-subword/27000.ckpt
2024-05-28 13:25:23,178 - INFO - joeynmt.training - Example #0
2024-05-28 13:25:23,185 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:25:23,185 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:25:23,185 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'went', 'to', 'the', 'we@@', 'i@@', 'ght', 'of', 'these', 'two', 'di@@', 'a@@', 'pos@@', 'iti@@', 'on', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'as', 'a', 'way', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'mo@@', 'st@@', 'ly', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'mar@@', 'ri@@', 'ed', 'by', '4@@', '8', 'percent', 'of', 'the', 'lar@@', 'ge', 'of', 'mar@@', 'ri@@', 'ed', 'by', '4@@', '0', 'percent', 'of', 'the', 's@@', 'hap@@', 'ed', 'with', '4@@', '0', 'percent', 'of', 'the', 'lar@@', 'ge', 'of', 'a', 'few', 'percent', 'of', 'the', 's@@', 'at@@', 'ell@@', 'ite', 'of', 'the', 'm@@', 'ou@@', 'th', 'of', 'the', 's@@', 'at@@', 't@@', 'ac@@', 'k', 'of', 'the', 'di@@', 'a@@', 'po@@', 't@@', 't@@', 'on@@', 'i@@', 'ght', 'of', 'the']
2024-05-28 13:25:23,185 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:25:23,344 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:25:23,344 - INFO - joeynmt.training - 	Hypothesis: And I went to the weight of these two diaposition to demonstrate as a way to demonstrate the mostly of the last three million years of the last three million years of married by 48 percent of the large of married by 40 percent of the shaped with 40 percent of the large of a few percent of the satellite of the mouth of the sattack of the diapottonight of the
2024-05-28 13:25:23,344 - INFO - joeynmt.training - Example #1
2024-05-28 13:25:23,344 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:25:23,344 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:25:23,344 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'this', 'speci@@', 'al', 'problem@@', 's', 'of', 'this', 'speci@@', 'al', 'problem@@', 's', 'because', 'not', 'loo@@', 'ks', 'like', 'not', 'loo@@', 'ked', 'like', 'gr@@', 'os@@', 's', 'and', 'not', 'look', 'at', 'the', 'gr@@', 'os@@', '.', '</s>']
2024-05-28 13:25:23,344 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:25:23,344 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:25:23,344 - INFO - joeynmt.training - 	Hypothesis: But this morning, this special problems of this special problems because not looks like not looked like gross and not look at the gros.
2024-05-28 13:25:23,344 - INFO - joeynmt.training - Example #2
2024-05-28 13:25:23,345 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:25:23,345 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:25:23,345 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'pol@@', 'ar', 'is', 'is', 'in', 'a', 'way', 'that', 'the', 'hear@@', 't', 'of', 'the', 'buil@@', 'ding', 'system@@', '.', '</s>']
2024-05-28 13:25:23,345 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:25:23,345 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:25:23,345 - INFO - joeynmt.training - 	Hypothesis: The polar polar is is in a way that the heart of the building system.
2024-05-28 13:25:23,345 - INFO - joeynmt.training - Example #3
2024-05-28 13:25:23,345 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:25:23,345 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:25:23,345 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'tin@@', 'c@@', 'tion', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:25:23,346 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:25:23,346 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:25:23,346 - INFO - joeynmt.training - 	Hypothesis: She was extinction and contraction and contract.
2024-05-28 13:25:23,346 - INFO - joeynmt.training - Example #4
2024-05-28 13:25:23,346 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:25:23,346 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:25:23,346 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'U@@', 'r@@', 'im@@', 'p@@', 's', 'that', 'I', 'would', 'look', 'at', 'the', 'bo@@', 't@@', 'to@@', 'm', 'that', 'I', 'would', 'show', 'you', 'the', 'qu@@', 'ic@@', 'k', 'of', 'what', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:25:23,347 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:25:23,423 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:25:23,423 - INFO - joeynmt.training - 	Hypothesis: The Urimps that I would look at the bottom that I would show you the quick of what happened in the last 25 years.
2024-05-28 13:25:26,631 - INFO - joeynmt.training - Epoch   7, Step:    30100, Batch Loss:     1.677117, Batch Acc: 0.516930, Tokens per Sec:    12560, Lr: 0.000300
2024-05-28 13:25:29,736 - INFO - joeynmt.training - Epoch   7, Step:    30200, Batch Loss:     1.653518, Batch Acc: 0.520207, Tokens per Sec:    23121, Lr: 0.000300
2024-05-28 13:25:32,874 - INFO - joeynmt.training - Epoch   7, Step:    30300, Batch Loss:     1.627197, Batch Acc: 0.522525, Tokens per Sec:    22709, Lr: 0.000300
2024-05-28 13:25:35,836 - INFO - joeynmt.training - Epoch   7, Step:    30400, Batch Loss:     1.745159, Batch Acc: 0.515650, Tokens per Sec:    23622, Lr: 0.000300
2024-05-28 13:25:39,081 - INFO - joeynmt.training - Epoch   7, Step:    30500, Batch Loss:     1.797716, Batch Acc: 0.516536, Tokens per Sec:    21999, Lr: 0.000300
2024-05-28 13:25:39,085 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:25:39,089 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:25:52,182 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.40, acc:   0.50, generation: 13.0718[sec], evaluation: 0.0000[sec]
2024-05-28 13:25:52,213 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:25:53,130 - INFO - joeynmt.helpers - delete models/bpe-subword/28000.ckpt
2024-05-28 13:25:53,311 - INFO - joeynmt.training - Example #0
2024-05-28 13:25:53,316 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:25:53,317 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:25:53,317 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 'pos@@', 'ed', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'these', 'di@@', 'a@@', 'pos@@', 'iti@@', 've', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'bi@@', 'gg@@', 'est', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'big', 'st@@', 'at@@', 'es', 'of', 'the', 'last', '4@@', '8', 'st@@', 'at@@', 'es', 'of', 'lar@@', 'g@@', 'ely', 's@@', 'li@@', 'ght@@', 'ly', 'to', '4@@', '8', 'percent', 'of', 'the', 's@@', 'l@@', 'am@@', '.', '</s>']
2024-05-28 13:25:53,317 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:25:53,321 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:25:53,325 - INFO - joeynmt.training - 	Hypothesis: And I showed these two diaposed to demonstrate these diapositive to demonstrate the biggest of the last three million years of the last three million years of big states of the last 48 states of largely slightly to 48 percent of the slam.
2024-05-28 13:25:53,334 - INFO - joeynmt.training - Example #1
2024-05-28 13:25:53,377 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:25:53,377 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:25:53,377 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'that', 'is', 'the', 'mor@@', 'ning', 'of', 'this', 'is', 'speci@@', 'al', 'speci@@', 'al', 'of', 'this', 'speci@@', 'al', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'look', 'at', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'g@@', 'ar@@', 'den@@', '.', '</s>']
2024-05-28 13:25:53,378 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:25:53,387 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:25:53,391 - INFO - joeynmt.training - 	Hypothesis: But that is the morning of this is special special of this special problem because it doesn't look at the gross of the gross of the garden.
2024-05-28 13:25:53,394 - INFO - joeynmt.training - Example #2
2024-05-28 13:25:53,402 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:25:53,402 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:25:53,402 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'l@@', 'ar', 'is', 'in', 'a', 'wa@@', 'y,', 'the', 'hear@@', 't', 'of', 'the', 'cl@@', 'im@@', 'ate', 'system@@', ',', 'the', 'hear@@', 't', 'of', 'the', 'cl@@', 'im@@', 'ate', 'system@@', '.', '</s>']
2024-05-28 13:25:53,402 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:25:53,406 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:25:53,410 - INFO - joeynmt.training - 	Hypothesis: The pollar is in a way, the heart of the climate system, the heart of the climate system.
2024-05-28 13:25:53,413 - INFO - joeynmt.training - Example #3
2024-05-28 13:25:53,417 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:25:53,417 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:25:53,418 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'p@@', 'ec@@', 'ted', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:25:53,418 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:25:53,421 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:25:53,461 - INFO - joeynmt.training - 	Hypothesis: She was expected and contract.
2024-05-28 13:25:53,464 - INFO - joeynmt.training - Example #4
2024-05-28 13:25:53,468 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:25:53,468 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:25:53,468 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'U@@', 'r@@', 'u@@', 'ma@@', 'r', 'that', 'I', 'will', 'show', 'you', 'that', 'I', 'will', 'show', 'you', 'that', 'I', 'will', 'show', 'you', 'the', 'f@@', 'ast@@', 'er', 'on', 'the', 'last', '2@@', '5', 'years', 'of', 'what', 'was', 'happen@@', 'ing', 'in', 'the', 'last', '2@@', '5', 'years', 'of', 'the', 'last', '2@@', '5', 'years', 'of', 'years', 'of', 'year@@', 's.', '</s>']
2024-05-28 13:25:53,469 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:25:53,523 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:25:53,534 - INFO - joeynmt.training - 	Hypothesis: The Urumar that I will show you that I will show you that I will show you the faster on the last 25 years of what was happening in the last 25 years of the last 25 years of years of years.
2024-05-28 13:25:57,055 - INFO - joeynmt.training - Epoch   7, Step:    30600, Batch Loss:     1.521305, Batch Acc: 0.523255, Tokens per Sec:    14809, Lr: 0.000300
2024-05-28 13:26:00,719 - INFO - joeynmt.training - Epoch   7, Step:    30700, Batch Loss:     1.709134, Batch Acc: 0.520197, Tokens per Sec:    19482, Lr: 0.000300
2024-05-28 13:26:03,994 - INFO - joeynmt.training - Epoch   7, Step:    30800, Batch Loss:     1.609021, Batch Acc: 0.524586, Tokens per Sec:    21632, Lr: 0.000300
2024-05-28 13:26:07,753 - INFO - joeynmt.training - Epoch   7, Step:    30900, Batch Loss:     1.574113, Batch Acc: 0.519731, Tokens per Sec:    18175, Lr: 0.000300
2024-05-28 13:26:11,289 - INFO - joeynmt.training - Epoch   7, Step:    31000, Batch Loss:     1.557554, Batch Acc: 0.523961, Tokens per Sec:    20480, Lr: 0.000300
2024-05-28 13:26:11,314 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:26:11,318 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:26:23,866 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.33, acc:   0.51, generation: 12.5259[sec], evaluation: 0.0000[sec]
2024-05-28 13:26:23,878 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:26:25,940 - INFO - joeynmt.helpers - delete models/bpe-subword/28500.ckpt
2024-05-28 13:26:26,192 - INFO - joeynmt.training - Example #0
2024-05-28 13:26:26,196 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:26:26,196 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:26:26,196 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'last', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 'th@@', 'le@@', 't', 'di@@', 'a@@', 'th@@', 'ro@@', 'om', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'most', 'of', 'the', 'pol@@', 'ar', 'pol@@', 'ar', 'that', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'was', 'd@@', 'imen@@', 'sion', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 's@@', 'at@@', 'ell@@', 'it@@', 'es', 'were', 'sm@@', 'all', 's@@', 'uch', 'as', 'lar@@', 'g@@', 'ely', 's@@', 'ha@@', 'red', 'with', '4@@', '0', 'percent', 'of', 'the', 'sm@@', 'all', 'st@@', 'at@@', 'es', 'of', 'the', 'last', 'y@@', 'ear', 'of', '4@@', '0', 'percent', 'of', 'the', 'di@@', 'a@@', 'th@@', 'le@@', 'te@@', 'd.', '</s>']
2024-05-28 13:26:26,197 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:26:26,200 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:26:26,204 - INFO - joeynmt.training - 	Hypothesis: And the last year I showed these two diathlet diathroom to demonstrate the most of the polar polar that most of the last three million years was dimension of the last three million years of the satellites were small such as largely shared with 40 percent of the small states of the last year of 40 percent of the diathleted.
2024-05-28 13:26:26,209 - INFO - joeynmt.training - Example #1
2024-05-28 13:26:26,212 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:26:26,212 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:26:26,212 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'the', 'mor@@', 'ning', 'of', 'this', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'look', 'at', 'the', 'gr@@', 'os@@', 's@@', 'il@@', 'en@@', 'ce.', '</s>']
2024-05-28 13:26:26,213 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:26:26,216 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:26:26,220 - INFO - joeynmt.training - 	Hypothesis: But this morning, the morning of this problem because it doesn't look at the grossilence.
2024-05-28 13:26:26,224 - INFO - joeynmt.training - Example #2
2024-05-28 13:26:26,238 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:26:26,238 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:26:26,238 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'pol@@', 'ar', 'pol@@', 'ar', 'is', 'is', 'in', 'a', 'wa@@', 'y,', 'the', 'hear@@', 't', 'of', 'the', 'cl@@', 'im@@', 'ate', 'system@@', '.', '</s>']
2024-05-28 13:26:26,238 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:26:26,242 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:26:26,246 - INFO - joeynmt.training - 	Hypothesis: The polar polar polar is is in a way, the heart of the climate system.
2024-05-28 13:26:26,266 - INFO - joeynmt.training - Example #3
2024-05-28 13:26:26,271 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:26:26,271 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:26:26,271 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'is', 'ex@@', 'p@@', 'ect@@', 'ing', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:26:26,271 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:26:26,276 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:26:26,279 - INFO - joeynmt.training - 	Hypothesis: She is expecting and contraction and contract.
2024-05-28 13:26:26,283 - INFO - joeynmt.training - Example #4
2024-05-28 13:26:26,287 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:26:26,287 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:26:26,287 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'di@@', 'a@@', 'it@@', 'al', 'di@@', 'a@@', 'it@@', 'ation', 'that', "I'm", 'going', 'to', 'show', 'you', 'the', 'f@@', 'ast', 'will', 'be', 'a', 'f@@', 'ast', 'to', 'what', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:26:26,288 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:26:26,293 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:26:26,298 - INFO - joeynmt.training - 	Hypothesis: The next diaital diaitation that I'm going to show you the fast will be a fast to what happened in the last 25 years.
2024-05-28 13:26:30,298 - INFO - joeynmt.training - Epoch   7, Step:    31100, Batch Loss:     1.514054, Batch Acc: 0.520861, Tokens per Sec:    11264, Lr: 0.000300
2024-05-28 13:26:34,077 - INFO - joeynmt.training - Epoch   7, Step:    31200, Batch Loss:     1.734706, Batch Acc: 0.520337, Tokens per Sec:    18202, Lr: 0.000300
2024-05-28 13:26:37,793 - INFO - joeynmt.training - Epoch   7, Step:    31300, Batch Loss:     1.549090, Batch Acc: 0.521971, Tokens per Sec:    19134, Lr: 0.000300
2024-05-28 13:26:41,667 - INFO - joeynmt.training - Epoch   7, Step:    31400, Batch Loss:     1.604653, Batch Acc: 0.518498, Tokens per Sec:    18228, Lr: 0.000300
2024-05-28 13:26:45,573 - INFO - joeynmt.training - Epoch   7, Step:    31500, Batch Loss:     1.765061, Batch Acc: 0.521870, Tokens per Sec:    17784, Lr: 0.000300
2024-05-28 13:26:45,578 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:26:45,583 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:26:59,862 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.34, acc:   0.51, generation: 14.2428[sec], evaluation: 0.0000[sec]
2024-05-28 13:26:59,946 - INFO - joeynmt.helpers - delete models/bpe-subword/29000.ckpt
2024-05-28 13:26:59,960 - INFO - joeynmt.training - Example #0
2024-05-28 13:26:59,965 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:26:59,965 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:26:59,965 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 'pos@@', 'ed', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'b@@', 'ri@@', 'd@@', 'ge', 'of', 'the', 'pol@@', 'ar', 'that', 'the', 'last', 'three', 'years', 'of', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'ma@@', 'king', 'a', 'sm@@', 'all', 's@@', 'li@@', 'de', 'of', 'f@@', 'our', 'percent', 'of', 'the', 'lar@@', 'ge', 'of', 'f@@', 'our', 'percent', 'of', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 13:26:59,965 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:26:59,969 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:26:59,987 - INFO - joeynmt.training - 	Hypothesis: And the year I showed these two diaposed to demonstrate the bridge of the polar that the last three years of years of the last three million years of the last three million years of making a small slide of four percent of the large of four percent of the same.
2024-05-28 13:26:59,991 - INFO - joeynmt.training - Example #1
2024-05-28 13:26:59,994 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:26:59,994 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:26:59,994 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'this', 'mor@@', 'n@@', 'ing,', 'because', 'of', 'this', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'look', 'at', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'f@@', 'ro@@', 'z@@', 'en', 'gr@@', 'os@@', 's', 'of', 'the', 'f@@', 'lo@@', 'or.', '</s>']
2024-05-28 13:26:59,995 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:26:59,998 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:27:00,002 - INFO - joeynmt.training - 	Hypothesis: But this morning, this morning, because of this problem because it doesn't look at the gross of the frozen gross of the floor.
2024-05-28 13:27:00,005 - INFO - joeynmt.training - Example #2
2024-05-28 13:27:00,034 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:27:00,034 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:27:00,034 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'is', 'is', 'in', 'a', 'way', 'of', 'a', 'way', 'that', 'the', 'hear@@', 't', 'of', 'the', 'cl@@', 'im@@', 'ate', 'system@@', '.', '</s>']
2024-05-28 13:27:00,034 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:27:00,038 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:27:00,046 - INFO - joeynmt.training - 	Hypothesis: The polar is is in a way of a way that the heart of the climate system.
2024-05-28 13:27:00,049 - INFO - joeynmt.training - Example #3
2024-05-28 13:27:00,053 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:27:00,053 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:27:00,053 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'p@@', 'ec@@', 'ted', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:27:00,053 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:27:00,056 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:27:00,060 - INFO - joeynmt.training - 	Hypothesis: She was expected and contraction and contract.
2024-05-28 13:27:00,065 - INFO - joeynmt.training - Example #4
2024-05-28 13:27:00,083 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:27:00,083 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:27:00,083 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'b@@', 'ut@@', 't@@', 'on', 'that', 'the', 'di@@', 'a@@', 'pos@@', 'iti@@', 'on', 'that', 'I', 'will', 'show', 'you', 'the', 'f@@', 'ast@@', 'er', 'will', 'be', 'a', 'qu@@', 'ic@@', 'k', 'at', 'what', 'was', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:27:00,084 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:27:00,099 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:27:00,104 - INFO - joeynmt.training - 	Hypothesis: The button that the diaposition that I will show you the faster will be a quick at what was happened in the last 25 years.
2024-05-28 13:27:03,555 - INFO - joeynmt.training - Epoch   7, Step:    31600, Batch Loss:     1.695356, Batch Acc: 0.521273, Tokens per Sec:    19819, Lr: 0.000300
2024-05-28 13:27:07,317 - INFO - joeynmt.training - Epoch   7, Step:    31700, Batch Loss:     1.596005, Batch Acc: 0.527598, Tokens per Sec:    19435, Lr: 0.000300
2024-05-28 13:27:10,762 - INFO - joeynmt.training - Epoch   7: total training loss 7432.43
2024-05-28 13:27:10,767 - INFO - joeynmt.training - EPOCH 8
2024-05-28 13:27:11,127 - INFO - joeynmt.training - Epoch   8, Step:    31800, Batch Loss:     1.651371, Batch Acc: 0.533700, Tokens per Sec:    15856, Lr: 0.000300
2024-05-28 13:27:14,795 - INFO - joeynmt.training - Epoch   8, Step:    31900, Batch Loss:     1.665020, Batch Acc: 0.538450, Tokens per Sec:    19794, Lr: 0.000300
2024-05-28 13:27:18,778 - INFO - joeynmt.training - Epoch   8, Step:    32000, Batch Loss:     1.585834, Batch Acc: 0.540362, Tokens per Sec:    18090, Lr: 0.000300
2024-05-28 13:27:18,783 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:27:18,786 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:27:31,987 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.31, acc:   0.51, generation: 13.1767[sec], evaluation: 0.0000[sec]
2024-05-28 13:27:32,010 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:27:32,158 - INFO - joeynmt.helpers - delete models/bpe-subword/29500.ckpt
2024-05-28 13:27:32,175 - INFO - joeynmt.training - Example #0
2024-05-28 13:27:32,185 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:27:32,185 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:27:32,185 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 'pos@@', 'ed', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'w@@', 'in@@', 'ning', 'of', 'the', 'pol@@', 'ar', 'of', 'the', 'pol@@', 'ar', 'that', 'the', 'big', 'pol@@', 'ar', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'big', 'st@@', 'at@@', 'es', 'of', '4@@', '8', 'percent', 'of', 'the', 'lar@@', 'ge', 'of', 'the', 'lar@@', 'ge', 'of', '4@@', '0', 'percent', 'of', 'the', 'lar@@', 'ge', 'of', '4@@', '0', 'percent', 'of', 'the', 'big', 'st@@', 'ate', 'of', '4@@', '0', 'percent', 'of', 'the', 'big', 'st@@', 'ate', 'of', 'the', 's@@', 'li@@', 'ght@@', 'ly', 'l@@', 'ed', 'of', 'the', 's@@', 'li@@', 'ght@@', 'ly', 'to', 'the', 'sec@@', 'ond', 'of', 'the', 's@@']
2024-05-28 13:27:32,186 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:27:32,190 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:27:32,194 - INFO - joeynmt.training - 	Hypothesis: The year I showed these two diaposed to demonstrate the winning of the polar of the polar that the big polar of the last three million years of the last three million years of the big states of 48 percent of the large of the large of 40 percent of the large of 40 percent of the big state of 40 percent of the big state of the slightly led of the slightly to the second of the s
2024-05-28 13:27:32,197 - INFO - joeynmt.training - Example #1
2024-05-28 13:27:32,201 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:27:32,201 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:27:32,201 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'this', 'is', 'the', 'speci@@', 'al', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'is@@', 'su@@', 'e', 'because', 'it', "doesn't", 'look', 'like', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'w@@', 'ell@@', '.', '</s>']
2024-05-28 13:27:32,201 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:27:32,205 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:27:32,208 - INFO - joeynmt.training - 	Hypothesis: But this morning, this is the special of this particular issue because it doesn't look like the gross of the gross of the gross of the gross of the gross of the well.
2024-05-28 13:27:32,212 - INFO - joeynmt.training - Example #2
2024-05-28 13:27:32,216 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:27:32,216 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:27:32,216 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'is', 'is', 'in', 'a', 'way', 'of', 'the', 'bo@@', 't@@', 'to@@', 'm', 'that', 'the', 'cl@@', 'im@@', 'ate', 'system@@', '.', '</s>']
2024-05-28 13:27:32,217 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:27:32,264 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:27:32,267 - INFO - joeynmt.training - 	Hypothesis: The polar is is in a way of the bottom that the climate system.
2024-05-28 13:27:32,271 - INFO - joeynmt.training - Example #3
2024-05-28 13:27:32,274 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:27:32,274 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:27:32,274 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'p@@', 'ec@@', 'ted', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 'tion.', '</s>']
2024-05-28 13:27:32,275 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:27:32,278 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:27:32,282 - INFO - joeynmt.training - 	Hypothesis: She was expected and contraction and contraction.
2024-05-28 13:27:32,288 - INFO - joeynmt.training - Example #4
2024-05-28 13:27:32,292 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:27:32,292 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:27:32,293 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'wh@@', 'ole', 'of', 'the', 'di@@', 'a@@', 'pos@@', 'iti@@', 'on', 'that', 'I', 'will', 'look', 'at', 'what', 'it', 'would', 'be', 'a', 'qu@@', 'ick@@', 'ly', 'se@@', 've@@', 're@@', 'ly', 'on', 'what', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:27:32,293 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:27:32,296 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:27:32,300 - INFO - joeynmt.training - 	Hypothesis: The next whole of the diaposition that I will look at what it would be a quickly severely on what happened in the last 25 years.
2024-05-28 13:27:35,759 - INFO - joeynmt.training - Epoch   8, Step:    32100, Batch Loss:     1.521937, Batch Acc: 0.531742, Tokens per Sec:    18994, Lr: 0.000300
2024-05-28 13:27:39,431 - INFO - joeynmt.training - Epoch   8, Step:    32200, Batch Loss:     1.783206, Batch Acc: 0.532889, Tokens per Sec:    19435, Lr: 0.000300
2024-05-28 13:27:42,652 - INFO - joeynmt.training - Epoch   8, Step:    32300, Batch Loss:     1.470783, Batch Acc: 0.538569, Tokens per Sec:    22489, Lr: 0.000300
2024-05-28 13:27:46,609 - INFO - joeynmt.training - Epoch   8, Step:    32400, Batch Loss:     1.535400, Batch Acc: 0.534133, Tokens per Sec:    18056, Lr: 0.000300
2024-05-28 13:27:50,678 - INFO - joeynmt.training - Epoch   8, Step:    32500, Batch Loss:     1.621875, Batch Acc: 0.533105, Tokens per Sec:    17554, Lr: 0.000300
2024-05-28 13:27:50,686 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:27:50,690 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:28:07,974 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.27, acc:   0.52, generation: 17.2262[sec], evaluation: 0.0000[sec]
2024-05-28 13:28:07,997 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:28:08,093 - INFO - joeynmt.helpers - delete models/bpe-subword/30000.ckpt
2024-05-28 13:28:08,158 - INFO - joeynmt.training - Example #0
2024-05-28 13:28:08,196 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:28:08,196 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:28:08,196 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'way', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'l@@', 'and', 'that', 'the', 'big', 'pol@@', 'ar', 'from', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'was', 'the', 'si@@', 'ze', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'de@@', 'gre@@', 'e', 'of', 'f@@', 'our', 'percent', 'of', 'the', 'big', 'st@@', 'at@@', 'es', 'in', '4@@', '0', 'percent', 'of', 'the', 's@@', 'at@@', 'ell@@', 'ite', 'st@@', 'at@@', 'us', 'with', '4@@', '8', 'percent', 'of', 'the', 'f@@', 'our', 'percent', 'of', 'the', 's@@', 'li@@', 'de', 'of', 'the', 'year@@', '.', '</s>']
2024-05-28 13:28:08,197 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:28:08,212 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:28:08,216 - INFO - joeynmt.training - 	Hypothesis: And the year I showed these two slide to demonstrate the way to demonstrate the land that the big polar from the last three million years was the size of the last three million years of the degree of four percent of the big states in 40 percent of the satellite status with 48 percent of the four percent of the slide of the year.
2024-05-28 13:28:08,219 - INFO - joeynmt.training - Example #1
2024-05-28 13:28:08,223 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:28:08,223 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:28:08,223 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'this', 'is', 'the', 'ser@@', 'i@@', 'ous', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'look', 'at', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'gu@@', 'y', 'not', 'look', 'at', 'the', 'gu@@', 'y', 'that', 'the', 'gu@@', 'y', 'is', 'the', 'g@@', 'am@@', 'e.', '</s>']
2024-05-28 13:28:08,224 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:28:08,228 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:28:08,231 - INFO - joeynmt.training - 	Hypothesis: But this morning, this is the serious problem because it doesn't look at the gross of the guy not look at the guy that the guy is the game.
2024-05-28 13:28:08,235 - INFO - joeynmt.training - Example #2
2024-05-28 13:28:08,238 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:28:08,238 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:28:08,238 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'pol@@', 'ar', 'pol@@', 'ar', 'is', 'is', 'is', 'in', 'a', 'way', 'that', 'the', 'hear@@', 't', 'of', 'the', 'buil@@', 'ding', 'syst@@', 'em', 'of', 'the', 'cl@@', 'im@@', 'ate', 'system@@', '.', '</s>']
2024-05-28 13:28:08,239 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:28:08,242 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:28:08,255 - INFO - joeynmt.training - 	Hypothesis: The polar polar polar is is is in a way that the heart of the building system of the climate system.
2024-05-28 13:28:08,258 - INFO - joeynmt.training - Example #3
2024-05-28 13:28:08,262 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:28:08,262 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:28:08,262 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'ex@@', 'p@@', 'ect@@', 's', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:28:08,263 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:28:08,266 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:28:08,270 - INFO - joeynmt.training - 	Hypothesis: She expects and contraction and contraction and contract.
2024-05-28 13:28:08,274 - INFO - joeynmt.training - Example #4
2024-05-28 13:28:08,278 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:28:08,278 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:28:08,278 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'f@@', 'ut@@', 'ure', 'of', 'the', 'di@@', 'a@@', 'pos@@', 'iti@@', 'on', 'that', 'I', 'will', 'show', 'you', 'that', 'I', 'will', 'be', 'a', 'f@@', 'ast@@', '-@@', 've@@', 'get@@', 'able', 've@@', 'get@@', 'able', 'to', 'what', 'it', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:28:08,278 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:28:08,282 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:28:08,285 - INFO - joeynmt.training - 	Hypothesis: The future of the diaposition that I will show you that I will be a fast-vegetable vegetable to what it happened in the last 25 years.
2024-05-28 13:28:11,801 - INFO - joeynmt.training - Epoch   8, Step:    32600, Batch Loss:     1.529471, Batch Acc: 0.531200, Tokens per Sec:    18001, Lr: 0.000300
2024-05-28 13:28:14,981 - INFO - joeynmt.training - Epoch   8, Step:    32700, Batch Loss:     1.619943, Batch Acc: 0.532579, Tokens per Sec:    22805, Lr: 0.000300
2024-05-28 13:28:17,896 - INFO - joeynmt.training - Epoch   8, Step:    32800, Batch Loss:     1.462517, Batch Acc: 0.533239, Tokens per Sec:    23601, Lr: 0.000300
2024-05-28 13:28:20,606 - INFO - joeynmt.training - Epoch   8, Step:    32900, Batch Loss:     1.581063, Batch Acc: 0.531424, Tokens per Sec:    25941, Lr: 0.000300
2024-05-28 13:28:23,362 - INFO - joeynmt.training - Epoch   8, Step:    33000, Batch Loss:     1.513024, Batch Acc: 0.534116, Tokens per Sec:    27000, Lr: 0.000300
2024-05-28 13:28:23,368 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:28:23,371 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:28:32,955 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.24, acc:   0.52, generation: 9.5618[sec], evaluation: 0.0000[sec]
2024-05-28 13:28:32,960 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:28:33,082 - INFO - joeynmt.helpers - delete models/bpe-subword/30500.ckpt
2024-05-28 13:28:33,089 - INFO - joeynmt.training - Example #0
2024-05-28 13:28:33,108 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:28:33,108 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:28:33,108 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'was', 'a', 'y@@', 'ear', 'of', 'these', 'two', 'di@@', 'a@@', 'po@@', 't@@', '-@@', 's@@', 'li@@', 'de', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'as', 'the', 'most', 'of', 'the', 'last', 'c@@', 'ou@@', 'ple', 'of', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'this', 'big', 'st@@', 'at@@', 'es', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'ol@@', 'd,', 'it', 'was', 'like', '4@@', '8', 'percent', 'of', 'the', 'lar@@', 'ge', 'of', 'the', 'lar@@', 'ge', 'of', '4@@', '0', 'percent', 'of', 'the', 's@@', 'li@@', 'ght', 'of', 'the', 'last', 'few', 'percent', 'percent', 'of', 'the', 's@@', 'li@@', 'ght@@', 'ly', 'l@@', 'ate', 'of', 'the', 's@@', 'li@@', 'de', 'of', 'the', 's@@', 'our@@', 'ce', 'of', 'the', 's@@', 'li@@', 'ght@@', 'ly', 'di@@', 'a@@', 'ma@@', 'z@@', 'ed', 'by', 'the']
2024-05-28 13:28:33,109 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:28:33,113 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:28:33,116 - INFO - joeynmt.training - 	Hypothesis: I was a year of these two diapot-slide to demonstrate as the most of the last couple of years of the last three million years of this big states of the last three million years old, it was like 48 percent of the large of the large of 40 percent of the slight of the last few percent percent of the slightly late of the slide of the source of the slightly diamazed by the
2024-05-28 13:28:33,119 - INFO - joeynmt.training - Example #1
2024-05-28 13:28:33,123 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:28:33,123 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:28:33,123 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'de@@', 'si@@', 're', 'of', 'this', 'problem@@', 's', 'because', 'it', "doesn't", 'look', 'at', 'this', 'speci@@', 'al', 'speci@@', 'al', 'gr@@', 'os@@', 's', 'because', 'it', "doesn't", 'look', 'like', 'the', 'g@@', 'ar@@', 'den@@', '.', '</s>']
2024-05-28 13:28:33,123 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:28:33,127 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:28:33,131 - INFO - joeynmt.training - 	Hypothesis: But this desire of this problems because it doesn't look at this special special gross because it doesn't look like the garden.
2024-05-28 13:28:33,134 - INFO - joeynmt.training - Example #2
2024-05-28 13:28:33,137 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:28:33,137 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:28:33,137 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'pol@@', 'ar', 'is', 'is', 'in', 'a', 'way', 'of', 'the', 'hear@@', 't', 'of', 'the', 'cl@@', 'im@@', 'ate', 'system@@', '.', '</s>']
2024-05-28 13:28:33,138 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:28:33,142 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:28:33,145 - INFO - joeynmt.training - 	Hypothesis: The polar polar is is in a way of the heart of the climate system.
2024-05-28 13:28:33,149 - INFO - joeynmt.training - Example #3
2024-05-28 13:28:33,174 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:28:33,174 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:28:33,174 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'p@@', 'ec@@', 'ted', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:28:33,175 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:28:33,188 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:28:33,211 - INFO - joeynmt.training - 	Hypothesis: She was expected and contraction and contract.
2024-05-28 13:28:33,214 - INFO - joeynmt.training - Example #4
2024-05-28 13:28:33,217 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:28:33,217 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:28:33,217 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'thing', 'I', 'will', 'be', 'the', 'di@@', 'a@@', 'pos@@', 'iti@@', 've', 'that', 'I', 'will', 'be', 'a', 'qu@@', 'ic@@', 'k', 'of', 'what', 'happen@@', 'ed', 'on', 'the', 'last', '2@@', '5', 'years', 'of', 'years', 'of', 'what', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:28:33,218 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:28:33,222 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:28:33,225 - INFO - joeynmt.training - 	Hypothesis: The next thing I will be the diapositive that I will be a quick of what happened on the last 25 years of years of what happened in the last 25 years.
2024-05-28 13:28:35,930 - INFO - joeynmt.training - Epoch   8, Step:    33100, Batch Loss:     1.581022, Batch Acc: 0.534365, Tokens per Sec:    24255, Lr: 0.000300
2024-05-28 13:28:38,629 - INFO - joeynmt.training - Epoch   8, Step:    33200, Batch Loss:     1.614022, Batch Acc: 0.533167, Tokens per Sec:    26132, Lr: 0.000300
2024-05-28 13:28:41,358 - INFO - joeynmt.training - Epoch   8, Step:    33300, Batch Loss:     1.626794, Batch Acc: 0.532286, Tokens per Sec:    26860, Lr: 0.000300
2024-05-28 13:28:44,177 - INFO - joeynmt.training - Epoch   8, Step:    33400, Batch Loss:     1.534320, Batch Acc: 0.534250, Tokens per Sec:    25835, Lr: 0.000300
2024-05-28 13:28:47,746 - INFO - joeynmt.training - Epoch   8, Step:    33500, Batch Loss:     1.678418, Batch Acc: 0.529357, Tokens per Sec:    20054, Lr: 0.000300
2024-05-28 13:28:47,751 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:28:47,754 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:29:09,959 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.26, acc:   0.52, generation: 22.1829[sec], evaluation: 0.0000[sec]
2024-05-28 13:29:10,087 - INFO - joeynmt.helpers - delete models/bpe-subword/31500.ckpt
2024-05-28 13:29:10,106 - INFO - joeynmt.training - Example #0
2024-05-28 13:29:10,110 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:29:10,110 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:29:10,110 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'y@@', 'ear', 'I', 'ar@@', 'gu@@', 'ed', 'these', 'two', 's@@', 'mar@@', 't', 's@@', 'li@@', 'de', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'pol@@', 'ar', 'of', 'the', 'pol@@', 'ar', 'that', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'ol@@', 'd,', 'it', 'was', 'a', 'little', 'bit', 'of', 'f@@', 'our@@', 'th', 'of', 'the', 'last', 'percent', 'of', 'the', 'last', 'few', 'percent', 'of', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 13:29:10,110 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:29:10,114 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:29:10,119 - INFO - joeynmt.training - 	Hypothesis: And the year I argued these two smart slide to demonstrate the polar of the polar that most of the last three million years of the last three million years of the last three million years old, it was a little bit of fourth of the last percent of the last few percent of the same.
2024-05-28 13:29:10,123 - INFO - joeynmt.training - Example #1
2024-05-28 13:29:10,127 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:29:10,127 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:29:10,127 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'ning', 'of', 'this', 'is', 'speci@@', 'al', 'speci@@', 'al', 'is@@', 'su@@', 'es', 'because', 'it', "doesn't", 'look', 'at', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'gu@@', 'y', 'no@@', 'thing', 'that', "doesn't", 'look', 'like', 'the', 'g@@', 'os@@', 'si@@', 'on.', '</s>']
2024-05-28 13:29:10,128 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:29:10,163 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:29:10,167 - INFO - joeynmt.training - 	Hypothesis: But this morning of this is special special issues because it doesn't look at the gross of the guy nothing that doesn't look like the gossion.
2024-05-28 13:29:10,170 - INFO - joeynmt.training - Example #2
2024-05-28 13:29:10,174 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:29:10,174 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:29:10,174 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'is', 'is', 'a', 'way', 'of', 'part', 'is', 'a', 'way', 'that', 'the', 'buil@@', 'ding', 'of', 'glob@@', 'al', 'buil@@', 'd@@', 'ing.', '</s>']
2024-05-28 13:29:10,174 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:29:10,178 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:29:10,181 - INFO - joeynmt.training - 	Hypothesis: The polar is is a way of part is a way that the building of global building.
2024-05-28 13:29:10,186 - INFO - joeynmt.training - Example #3
2024-05-28 13:29:10,189 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:29:10,189 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:29:10,189 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'tin@@', 'c@@', 't', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:29:10,189 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:29:10,193 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:29:10,196 - INFO - joeynmt.training - 	Hypothesis: She was extinct and contraction and contract.
2024-05-28 13:29:10,218 - INFO - joeynmt.training - Example #4
2024-05-28 13:29:10,222 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:29:10,222 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:29:10,222 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'uni@@', 'ver@@', 'se', 'of', 'the', 'di@@', 'a@@', 'pos@@', 'ing', 'that', 'I', 'will', 'show', 'you', 'the', 'f@@', 'ast@@', 'er', 'will', 'be', 'a', 'qu@@', 'ic@@', 'k', 'at', 'what', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:29:10,223 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:29:10,229 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:29:10,233 - INFO - joeynmt.training - 	Hypothesis: The universe of the diaposing that I will show you the faster will be a quick at what happened in the last 25 years.
2024-05-28 13:29:13,686 - INFO - joeynmt.training - Epoch   8, Step:    33600, Batch Loss:     1.578624, Batch Acc: 0.526676, Tokens per Sec:    18950, Lr: 0.000300
2024-05-28 13:29:17,134 - INFO - joeynmt.training - Epoch   8, Step:    33700, Batch Loss:     1.576005, Batch Acc: 0.528909, Tokens per Sec:    20702, Lr: 0.000300
2024-05-28 13:29:20,523 - INFO - joeynmt.training - Epoch   8, Step:    33800, Batch Loss:     1.525395, Batch Acc: 0.535198, Tokens per Sec:    20962, Lr: 0.000300
2024-05-28 13:29:23,927 - INFO - joeynmt.training - Epoch   8, Step:    33900, Batch Loss:     1.750087, Batch Acc: 0.530495, Tokens per Sec:    21112, Lr: 0.000300
2024-05-28 13:29:27,344 - INFO - joeynmt.training - Epoch   8, Step:    34000, Batch Loss:     1.641530, Batch Acc: 0.532540, Tokens per Sec:    21280, Lr: 0.000300
2024-05-28 13:29:27,348 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:29:27,352 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:30:09,416 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.21, acc:   0.52, generation: 42.0410[sec], evaluation: 0.0000[sec]
2024-05-28 13:30:09,421 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:30:09,533 - INFO - joeynmt.helpers - delete models/bpe-subword/31000.ckpt
2024-05-28 13:30:09,558 - INFO - joeynmt.training - Example #0
2024-05-28 13:30:09,562 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:30:09,562 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:30:09,562 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 'x@@', 'i@@', 'p@@', 'p@@', 'ed', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'pol@@', 'ar', 'of', 'the', 'pol@@', 'ar', 'pol@@', 'ar', 'from', 'the', 'most', 'three', 'mil@@', 'lion', 'years', 'of', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'mar@@', 'ri@@', 'ed', 'by', '4@@', '8', 'percent', 'of', 'the', 'lar@@', 'g@@', 'e,', 'it', 'was', 'a', 'little', 'bit', 'of', '4@@', '8', 'percent', 'of', 'the', 'lar@@', 'g@@', 'e,', 'it', 'was', 'a', 'little', 'bit', 'of', '4@@', '8', 'percent', 'of', 'the', 'b@@', 'ab@@', 'y', 'of', 'the', 'm@@', 'ou@@', 'se', 'of', 'these', 'two', 'percent', 'of', 'the', 's@@', 'li@@', 'ght@@', 'ly', 'sho@@', 'o@@', 't@@', 'ting', 'with', 'the', 'sec@@']
2024-05-28 13:30:09,563 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:30:09,566 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:30:09,570 - INFO - joeynmt.training - 	Hypothesis: And I showed these two diaxipped to demonstrate the polar of the polar polar from the most three million years of years of the last three million years of the last three million years of married by 48 percent of the large, it was a little bit of 48 percent of the large, it was a little bit of 48 percent of the baby of the mouse of these two percent of the slightly shootting with the sec
2024-05-28 13:30:09,573 - INFO - joeynmt.training - Example #1
2024-05-28 13:30:09,577 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:30:09,577 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:30:09,577 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'because', 'it', 'is', 'the', 'speci@@', 'al', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'look', 'at', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'gr@@', 'os@@', '.', '</s>']
2024-05-28 13:30:09,577 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:30:09,581 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:30:09,604 - INFO - joeynmt.training - 	Hypothesis: But this morning, because it is the special problem because it doesn't look at the gross of the gross of the gros.
2024-05-28 13:30:09,608 - INFO - joeynmt.training - Example #2
2024-05-28 13:30:09,612 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:30:09,612 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:30:09,612 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'is', 'is', 'in', 'is', 'in', 'a', 'way', 'that', 'the', 'cl@@', 'im@@', 'ate', 'system@@', ',', 'the', 'hear@@', 't', 'system@@', '.', '</s>']
2024-05-28 13:30:09,612 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:30:09,616 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:30:09,619 - INFO - joeynmt.training - 	Hypothesis: The polar is is in is in a way that the climate system, the heart system.
2024-05-28 13:30:09,623 - INFO - joeynmt.training - Example #3
2024-05-28 13:30:09,626 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:30:09,627 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:30:09,627 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'p@@', 'ec@@', 'ted', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:30:09,627 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:30:09,655 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:30:09,674 - INFO - joeynmt.training - 	Hypothesis: She was expected and contraction and contract.
2024-05-28 13:30:09,678 - INFO - joeynmt.training - Example #4
2024-05-28 13:30:09,683 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:30:09,683 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:30:09,683 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'm@@', 'y@@', 'th@@', ',', 'I', 'will', 'show', 'you', 'that', 'I', 'will', 'show', 'you', 'that', 'it', 'will', 'be', 'a', 'qu@@', 'ic@@', 'k', 'at', 'what', 'it', 'was', 'going', 'to', 'be', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:30:09,683 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:30:09,687 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:30:09,690 - INFO - joeynmt.training - 	Hypothesis: The myth, I will show you that I will show you that it will be a quick at what it was going to be in the last 25 years.
2024-05-28 13:30:13,542 - INFO - joeynmt.training - Epoch   8, Step:    34100, Batch Loss:     1.576979, Batch Acc: 0.527986, Tokens per Sec:    17182, Lr: 0.000300
2024-05-28 13:30:17,421 - INFO - joeynmt.training - Epoch   8, Step:    34200, Batch Loss:     1.459658, Batch Acc: 0.535005, Tokens per Sec:    18476, Lr: 0.000300
2024-05-28 13:30:21,249 - INFO - joeynmt.training - Epoch   8, Step:    34300, Batch Loss:     1.583627, Batch Acc: 0.532883, Tokens per Sec:    18690, Lr: 0.000300
2024-05-28 13:30:25,273 - INFO - joeynmt.training - Epoch   8, Step:    34400, Batch Loss:     1.573031, Batch Acc: 0.535292, Tokens per Sec:    17543, Lr: 0.000300
2024-05-28 13:30:29,314 - INFO - joeynmt.training - Epoch   8, Step:    34500, Batch Loss:     1.632018, Batch Acc: 0.533511, Tokens per Sec:    17280, Lr: 0.000300
2024-05-28 13:30:29,319 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:30:29,323 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:30:48,598 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.19, acc:   0.52, generation: 19.2509[sec], evaluation: 0.0000[sec]
2024-05-28 13:30:48,633 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:30:48,732 - INFO - joeynmt.helpers - delete models/bpe-subword/32000.ckpt
2024-05-28 13:30:48,760 - INFO - joeynmt.training - Example #0
2024-05-28 13:30:48,764 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:30:48,764 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:30:48,765 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 'x@@', 'ed', 'di@@', 'a@@', 'pos@@', 'iti@@', 've', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'l@@', 'ine', 'of', 'the', 'l@@', 'ine', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'was', 'the', 'd@@', 'imen@@', 'sion', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'mar@@', 'ri@@', 'ed', 'by', '4@@', '0', 'percent', 'of', 'the', 'lar@@', 'ge', 'of', 'f@@', 'our@@', 'th', 'of', 'the', 'last', '4@@', '0', 'percent', 'of', 'the', 'last', '4@@', '0', 'percent', 'of', 'the', 'last', '4@@', '0', 'percent', 'of', 'the', 'last', '4@@', '0', 'percent', 'of', 'the', 'next', 'few', 'percent', 'percent', 'of', 'these', 'two', 'percent', 'of', 'the', 'sec@@', 'ond', 'di@@', 'a@@', 'x@@', '.', '</s>']
2024-05-28 13:30:48,765 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:30:48,768 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:30:48,772 - INFO - joeynmt.training - 	Hypothesis: I showed these two diaxed diapositive to demonstrate the line of the line of the last three million years of the last three million years was the dimension of the last three million years of married by 40 percent of the large of fourth of the last 40 percent of the last 40 percent of the last 40 percent of the last 40 percent of the next few percent percent of these two percent of the second diax.
2024-05-28 13:30:48,776 - INFO - joeynmt.training - Example #1
2024-05-28 13:30:48,827 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:30:48,827 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:30:48,827 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'this', 'mor@@', 'ning', 'of', 'this', 'speci@@', 'al', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'look', 'at', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'g@@', 'os@@', 'si@@', 'l', 'of', 'the', 'g@@', 'os@@', 'si@@', 'l', 'gu@@', 'y.', '</s>']
2024-05-28 13:30:48,828 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:30:48,831 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:30:48,835 - INFO - joeynmt.training - 	Hypothesis: But this morning, this morning of this special problem because it doesn't look at the gross of the gossil of the gossil guy.
2024-05-28 13:30:48,838 - INFO - joeynmt.training - Example #2
2024-05-28 13:30:48,842 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:30:48,842 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:30:48,842 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'bo@@', 't@@', 'to@@', 'm', 'is', 'a', 'wa@@', 'y,', 'the', 'hear@@', 't', 'of', 'a', 'kind', 'of', 'hear@@', 't', 'that', 'the', 'cl@@', 'im@@', 'ate', 'system@@', '.', '</s>']
2024-05-28 13:30:48,842 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:30:48,845 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:30:48,849 - INFO - joeynmt.training - 	Hypothesis: The bottom is a way, the heart of a kind of heart that the climate system.
2024-05-28 13:30:48,852 - INFO - joeynmt.training - Example #3
2024-05-28 13:30:48,856 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:30:48,856 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:30:48,856 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'p@@', 'ect@@', 'ing', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:30:48,857 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:30:48,860 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:30:48,863 - INFO - joeynmt.training - 	Hypothesis: She was expecting and contraction and contract.
2024-05-28 13:30:48,866 - INFO - joeynmt.training - Example #4
2024-05-28 13:30:48,890 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:30:48,890 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:30:48,890 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'm@@', 'ea@@', 'l', 'of', 'the', 's@@', 'li@@', 'de', 'that', 'I', 'will', 'show', 'you', 'a', 'f@@', 'ast@@', 'est', 'to', 'what', 'was', 'a', 'qu@@', 'ic@@', 'k', 'on', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:30:48,890 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:30:48,894 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:30:48,897 - INFO - joeynmt.training - 	Hypothesis: The meal of the slide that I will show you a fastest to what was a quick on the last 25 years.
2024-05-28 13:30:52,662 - INFO - joeynmt.training - Epoch   8, Step:    34600, Batch Loss:     1.656719, Batch Acc: 0.532064, Tokens per Sec:    17509, Lr: 0.000300
2024-05-28 13:30:56,345 - INFO - joeynmt.training - Epoch   8, Step:    34700, Batch Loss:     1.605749, Batch Acc: 0.532922, Tokens per Sec:    19032, Lr: 0.000300
2024-05-28 13:31:00,185 - INFO - joeynmt.training - Epoch   8, Step:    34800, Batch Loss:     1.379613, Batch Acc: 0.538207, Tokens per Sec:    18974, Lr: 0.000300
2024-05-28 13:31:03,641 - INFO - joeynmt.training - Epoch   8, Step:    34900, Batch Loss:     1.639587, Batch Acc: 0.530241, Tokens per Sec:    20312, Lr: 0.000300
2024-05-28 13:31:07,042 - INFO - joeynmt.training - Epoch   8, Step:    35000, Batch Loss:     1.695127, Batch Acc: 0.532343, Tokens per Sec:    21073, Lr: 0.000300
2024-05-28 13:31:07,052 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:31:07,056 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:31:36,209 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.15, acc:   0.52, generation: 29.1312[sec], evaluation: 0.0000[sec]
2024-05-28 13:31:36,214 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:31:36,360 - INFO - joeynmt.helpers - delete models/bpe-subword/32500.ckpt
2024-05-28 13:31:36,430 - INFO - joeynmt.training - Example #0
2024-05-28 13:31:36,434 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:31:36,445 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:31:36,445 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 'po@@', 't@@', 'ent', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'pol@@', 'ar', 'of', 'the', 'pol@@', 'ar', 'pol@@', 'ar', 'pol@@', 'ar', 'pol@@', 'ar', 'that', 'the', 'maj@@', 'or@@', 'ity', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'was', 'd@@', 'imen@@', 'sion', 'of', 'the', 'last', '4@@', '0', 'percent', 'of', 'the', 'lar@@', 'ge', 'st@@', 'at@@', 'es', 'of', 'lar@@', 'g@@', 'e,', 'it', 's@@', 'we@@', 'at@@', 's.', '</s>']
2024-05-28 13:31:36,445 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:31:36,460 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:31:36,464 - INFO - joeynmt.training - 	Hypothesis: And I showed these two diapotent to demonstrate the polar of the polar polar polar polar that the majority of the last three million years was dimension of the last 40 percent of the large states of large, it sweats.
2024-05-28 13:31:36,467 - INFO - joeynmt.training - Example #1
2024-05-28 13:31:36,470 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:31:36,470 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:31:36,470 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'this', 'is', 'the', 'speci@@', 'al', 'of', 'this', 'speci@@', 'al', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'look', 'at', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'g@@', 'ol@@', 'd.', '</s>']
2024-05-28 13:31:36,471 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:31:36,475 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:31:36,478 - INFO - joeynmt.training - 	Hypothesis: But this morning, this is the special of this special problem because it doesn't look at the gross of the gold.
2024-05-28 13:31:36,482 - INFO - joeynmt.training - Example #2
2024-05-28 13:31:36,485 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:31:36,485 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:31:36,485 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'is', 'the', 'pol@@', 'ar', 'is', 'is', 'in', 'a', 'way', 'that', 'the', 'cl@@', 'im@@', 'ate', 'system@@', ',', 'the', 'hear@@', 't', 'of', 'the', 'cl@@', 'im@@', 'ate', 'system@@', '.', '</s>']
2024-05-28 13:31:36,486 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:31:36,489 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:31:36,492 - INFO - joeynmt.training - 	Hypothesis: The polar is the polar is is in a way that the climate system, the heart of the climate system.
2024-05-28 13:31:36,495 - INFO - joeynmt.training - Example #3
2024-05-28 13:31:36,498 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:31:36,498 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:31:36,498 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'ex@@', 'p@@', 'ect@@', 's', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 'tion.', '</s>']
2024-05-28 13:31:36,499 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:31:36,504 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:31:36,548 - INFO - joeynmt.training - 	Hypothesis: She expects and contraction and contraction.
2024-05-28 13:31:36,551 - INFO - joeynmt.training - Example #4
2024-05-28 13:31:36,556 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:31:36,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:31:36,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ma@@', 'in', 'the', 'di@@', 'a@@', 'pos@@', 'iti@@', 've', 'that', 'I', 'will', 'show', 'you', 'the', 'f@@', 'ast', 'will', 'be', 'a', 'f@@', 'ast@@', '-@@', 've@@', 'd@@', 'd@@', 'l@@', 'ed', 'on', 'what', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:31:36,556 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:31:36,560 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:31:36,563 - INFO - joeynmt.training - 	Hypothesis: The main the diapositive that I will show you the fast will be a fast-veddled on what happened in the last 25 years.
2024-05-28 13:31:39,908 - INFO - joeynmt.training - Epoch   8, Step:    35100, Batch Loss:     1.591989, Batch Acc: 0.532790, Tokens per Sec:    19285, Lr: 0.000300
2024-05-28 13:31:43,604 - INFO - joeynmt.training - Epoch   8, Step:    35200, Batch Loss:     1.613658, Batch Acc: 0.532487, Tokens per Sec:    18676, Lr: 0.000300
2024-05-28 13:31:47,469 - INFO - joeynmt.training - Epoch   8, Step:    35300, Batch Loss:     1.604075, Batch Acc: 0.533735, Tokens per Sec:    18334, Lr: 0.000300
2024-05-28 13:31:51,310 - INFO - joeynmt.training - Epoch   8, Step:    35400, Batch Loss:     1.597318, Batch Acc: 0.527861, Tokens per Sec:    18736, Lr: 0.000300
2024-05-28 13:31:54,670 - INFO - joeynmt.training - Epoch   8, Step:    35500, Batch Loss:     1.599790, Batch Acc: 0.531117, Tokens per Sec:    21678, Lr: 0.000300
2024-05-28 13:31:54,670 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:31:54,670 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:32:24,363 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.13, acc:   0.52, generation: 29.6749[sec], evaluation: 0.0000[sec]
2024-05-28 13:32:24,364 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:32:24,685 - INFO - joeynmt.helpers - delete models/bpe-subword/33500.ckpt
2024-05-28 13:32:24,695 - INFO - joeynmt.training - Example #0
2024-05-28 13:32:24,695 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:32:24,695 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:32:24,695 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 'pos@@', 'iti@@', 've', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'qu@@', 'o@@', 'te', 'of', 'the', 'pol@@', 'ar', 'that', 'the', 'most', 'of', 'the', 'most', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'mar@@', 'ri@@', 'ed', 'by', '4@@', '8', 'percent', 'of', 'the', 'big', 'st@@', 'ate', 'of', 'the', 'lar@@', 'ge', 'of', 'sc@@', 'en@@', 'es', 'of', 'a', '4@@', '0', 'percent', 'of', 'the', 's@@', 'li@@', 'ght', 'of', 'the', 's@@', 'qu@@', 'are', 'with', '4@@', '0', 'percent', 'of', 'the', 'year@@', '.', '</s>']
2024-05-28 13:32:24,695 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:32:24,696 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:32:24,696 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two diapositive to demonstrate the quote of the polar that the most of the most three million years of the last three million years of married by 48 percent of the big state of the large of scenes of a 40 percent of the slight of the square with 40 percent of the year.
2024-05-28 13:32:24,696 - INFO - joeynmt.training - Example #1
2024-05-28 13:32:24,696 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:32:24,696 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:32:24,696 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'mor@@', 'ning', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'look', 'at', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'gu@@', 'y', 'of', 'the', 'gu@@', 'y', 'of', 'the', 'gu@@', 'y', 'of', 'the', 'gu@@', 'y', 'of', 'the', 'gu@@', 'y', 'of', 'the', 'd@@', 'y@@', 'n@@', 'am@@', 'ic@@', 's', 'of', 'the', 'mor@@', 'ning', 'of', 'the', 'mor@@', 'ning', 'of', 'the', 'mor@@', 'ning', 'of', 'the', 'mor@@', 'ning', 'of', 'the', 'mor@@', 'ning', 'of', 'the', 'mor@@', 'ning', 'of', 'the', 'mor@@', 'ning', 'of', 'this', 'mor@@', 'ning', 'of', 'the', 'mor@@', 'mor@@', 'ning', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'is@@', 'su@@', 'es', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'is@@', 'su@@', 'es', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'is@@']
2024-05-28 13:32:24,696 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:32:24,696 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:32:24,696 - INFO - joeynmt.training - 	Hypothesis: But this mormorning of this particular problem because it doesn't look at the gross of the gross of the guy of the guy of the guy of the guy of the guy of the dynamics of the morning of the morning of the morning of the morning of the morning of the morning of the morning of this morning of the mormorning of this particular issues of this particular issues of this particular is
2024-05-28 13:32:24,696 - INFO - joeynmt.training - Example #2
2024-05-28 13:32:24,697 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:32:24,697 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:32:24,697 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'bo@@', 't@@', 'to@@', 'm', 'of', 'the', 'pol@@', 'ar', 'is', 'in', 'a', 'wa@@', 'y,', 'the', 'hear@@', 't', 'of', 'the', 'cl@@', 'im@@', 'ate', 'system@@', ',', 'the', 'hear@@', 't', 'system@@', '.', '</s>']
2024-05-28 13:32:24,697 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:32:24,697 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:32:24,697 - INFO - joeynmt.training - 	Hypothesis: The bottom of the polar is in a way, the heart of the climate system, the heart system.
2024-05-28 13:32:24,697 - INFO - joeynmt.training - Example #3
2024-05-28 13:32:24,697 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:32:24,697 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:32:24,697 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'p@@', 'ect@@', 'ing', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:32:24,698 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:32:24,698 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:32:24,698 - INFO - joeynmt.training - 	Hypothesis: She was expecting and contraction and contract.
2024-05-28 13:32:24,698 - INFO - joeynmt.training - Example #4
2024-05-28 13:32:24,698 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:32:24,698 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:32:24,698 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'U@@', 'r@@', 'ing', 'of', 'the', 's@@', 'li@@', 'de', 'that', 'I', 'will', 'show', 'it', 'it', 'will', 'be', 'a', 'qu@@', 'ic@@', 'k', 'on', 'what', 'was', 'in@@', 't@@', 'am@@', 'ed', 'in', 'what', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:32:24,698 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:32:24,699 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:32:24,699 - INFO - joeynmt.training - 	Hypothesis: The Uring of the slide that I will show it it will be a quick on what was intamed in what happened in the last 25 years.
2024-05-28 13:32:28,327 - INFO - joeynmt.training - Epoch   8, Step:    35600, Batch Loss:     1.594469, Batch Acc: 0.528123, Tokens per Sec:    17689, Lr: 0.000300
2024-05-28 13:32:32,152 - INFO - joeynmt.training - Epoch   8, Step:    35700, Batch Loss:     1.568658, Batch Acc: 0.539154, Tokens per Sec:    18297, Lr: 0.000300
2024-05-28 13:32:36,241 - INFO - joeynmt.training - Epoch   8, Step:    35800, Batch Loss:     1.378241, Batch Acc: 0.532870, Tokens per Sec:    17434, Lr: 0.000300
2024-05-28 13:32:40,222 - INFO - joeynmt.training - Epoch   8, Step:    35900, Batch Loss:     1.480447, Batch Acc: 0.532082, Tokens per Sec:    17969, Lr: 0.000300
2024-05-28 13:32:44,290 - INFO - joeynmt.training - Epoch   8, Step:    36000, Batch Loss:     1.772735, Batch Acc: 0.530495, Tokens per Sec:    17217, Lr: 0.000300
2024-05-28 13:32:44,290 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:32:44,290 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:33:11,223 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.12, acc:   0.52, generation: 26.9147[sec], evaluation: 0.0000[sec]
2024-05-28 13:33:11,224 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:33:11,382 - INFO - joeynmt.helpers - delete models/bpe-subword/33000.ckpt
2024-05-28 13:33:11,421 - INFO - joeynmt.training - Example #0
2024-05-28 13:33:11,421 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:33:11,421 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:33:11,421 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 'pos@@', 'iti@@', 've', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'pol@@', 'ar', 'of', 'the', 'pol@@', 'ar', 'pol@@', 'ar', 'that', 'the', 'big', 'pol@@', 'ar', 'from', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'big', 'd@@', 'imen@@', 'sion', 'of', 'the', '4@@', '8', 'percent', 'of', 'the', 'big', '4@@', '8', 'percent', 'of', 'the', 'lar@@', 'ge', 'of', 'f@@', 'our', 'percent', 'of', 'the', 'big', 'st@@', 'at@@', 'es', 'of', 'the', '4@@', '0', 'percent', 'of', 'the', 'big', '4@@', '8', 'percent', 'of', 'the', 'a@@', 'w@@', 'ful', 'coun@@', 't@@', 's.', '</s>']
2024-05-28 13:33:11,422 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:33:11,422 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:33:11,422 - INFO - joeynmt.training - 	Hypothesis: And the year I showed these two diapositive to demonstrate the polar of the polar polar that the big polar from the last three million years of the last three million years of the big dimension of the 48 percent of the big 48 percent of the large of four percent of the big states of the 40 percent of the big 48 percent of the awful counts.
2024-05-28 13:33:11,422 - INFO - joeynmt.training - Example #1
2024-05-28 13:33:11,422 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:33:11,422 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:33:11,422 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'this', 'is', 'speci@@', 'al', 'speci@@', 'al', 'problem@@', 's', 'because', 'it', "doesn't", 'look', 'at', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'gu@@', 'y.', '</s>']
2024-05-28 13:33:11,422 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:33:11,423 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:33:11,423 - INFO - joeynmt.training - 	Hypothesis: But this morning, this is special special problems because it doesn't look at the gross of the gross of the guy.
2024-05-28 13:33:11,423 - INFO - joeynmt.training - Example #2
2024-05-28 13:33:11,423 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:33:11,423 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:33:11,423 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'is', 'from', 'is', 'from', 'a', 'wa@@', 'y,', 'the', 'hear@@', 't', 'of', 'the', 'cl@@', 'im@@', 'ate', 'system@@', ',', 'the', 'hear@@', 't', 'of', 'the', 'cl@@', 'im@@', 'ate', 'system@@', '.', '</s>']
2024-05-28 13:33:11,423 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:33:11,423 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:33:11,423 - INFO - joeynmt.training - 	Hypothesis: The polar is from is from a way, the heart of the climate system, the heart of the climate system.
2024-05-28 13:33:11,423 - INFO - joeynmt.training - Example #3
2024-05-28 13:33:11,423 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:33:11,423 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:33:11,424 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'p@@', 'ec@@', 'ted', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:33:11,424 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:33:11,424 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:33:11,424 - INFO - joeynmt.training - 	Hypothesis: She was expected and contraction and contract.
2024-05-28 13:33:11,424 - INFO - joeynmt.training - Example #4
2024-05-28 13:33:11,424 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:33:11,424 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:33:11,424 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'U@@', 'r@@', 'im@@', 'ate', 'that', 'the', 'di@@', 'a@@', 'x@@', 'ing', 'that', 'I', 'will', 'show', 'you', 'a', 'qu@@', 'ic@@', 'k', 'of', 'what', 'was', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:33:11,425 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:33:11,425 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:33:11,425 - INFO - joeynmt.training - 	Hypothesis: The Urimate that the diaxing that I will show you a quick of what was happened in the last 25 years.
2024-05-28 13:33:15,371 - INFO - joeynmt.training - Epoch   8, Step:    36100, Batch Loss:     1.503234, Batch Acc: 0.532665, Tokens per Sec:    17671, Lr: 0.000300
2024-05-28 13:33:19,427 - INFO - joeynmt.training - Epoch   8, Step:    36200, Batch Loss:     1.526397, Batch Acc: 0.532613, Tokens per Sec:    17176, Lr: 0.000300
2024-05-28 13:33:23,483 - INFO - joeynmt.training - Epoch   8, Step:    36300, Batch Loss:     1.538895, Batch Acc: 0.534285, Tokens per Sec:    17884, Lr: 0.000300
2024-05-28 13:33:24,720 - INFO - joeynmt.training - Epoch   8: total training loss 7184.50
2024-05-28 13:33:24,720 - INFO - joeynmt.training - EPOCH 9
2024-05-28 13:33:27,639 - INFO - joeynmt.training - Epoch   9, Step:    36400, Batch Loss:     1.376793, Batch Acc: 0.554034, Tokens per Sec:    16970, Lr: 0.000300
2024-05-28 13:33:31,749 - INFO - joeynmt.training - Epoch   9, Step:    36500, Batch Loss:     1.375929, Batch Acc: 0.544143, Tokens per Sec:    17774, Lr: 0.000300
2024-05-28 13:33:31,750 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:33:31,750 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:33:50,374 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.09, acc:   0.52, generation: 18.6044[sec], evaluation: 0.0000[sec]
2024-05-28 13:33:50,374 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:33:50,474 - INFO - joeynmt.helpers - delete models/bpe-subword/34000.ckpt
2024-05-28 13:33:50,483 - INFO - joeynmt.training - Example #0
2024-05-28 13:33:50,483 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:33:50,483 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:33:50,483 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'sec@@', 'ond', 's@@', 'li@@', 'ght@@', 'ly', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'pol@@', 'ar', 'of', 'the', 'pol@@', 'ar', 'of', 'the', 'pol@@', 'ar', 'that', 'the', 'maj@@', 'or@@', 'ity', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'mar@@', 'ri@@', 'ed', 'by', '4@@', '0', 'percent', 'of', 'the', 'lar@@', 'ge', 'sc@@', 'en@@', 'ed', 'with', 'a', 'little', 'bit', 'of', 'a', 'little', 'bit', 'of', 'f@@', 'our@@', 'th', 's@@', 'uch', 'a', 'little', 'bit', 'of', '4@@', '0', 'percent', 'of', 'the', 'si@@', 'ze', 'of', 'these', 'sec@@', 'on@@', 'd@@', 's.', '</s>']
2024-05-28 13:33:50,484 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:33:50,484 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:33:50,484 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these second slightly to demonstrate the polar of the polar of the polar that the majority of the last three million years of years of the last three million years of married by 40 percent of the large scened with a little bit of a little bit of fourth such a little bit of 40 percent of the size of these seconds.
2024-05-28 13:33:50,484 - INFO - joeynmt.training - Example #1
2024-05-28 13:33:50,484 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:33:50,484 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:33:50,484 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'the', 'ser@@', 'i@@', 'ous', 'prob@@', 'le@@', 'm', 'of', 'this', 'speci@@', 'al', 'is@@', 'su@@', 'e', 'because', 'it', "doesn't", 'look', 'at', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'gu@@', 'y.', '</s>']
2024-05-28 13:33:50,484 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:33:50,484 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:33:50,484 - INFO - joeynmt.training - 	Hypothesis: But this morning, the serious problem of this special issue because it doesn't look at the gross of the guy.
2024-05-28 13:33:50,484 - INFO - joeynmt.training - Example #2
2024-05-28 13:33:50,485 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:33:50,485 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:33:50,485 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'is', 'the', 'pol@@', 'ar', 'is', 'in', 'a', 'way', 'that', 'the', 'b@@', 'ab@@', 'y', 'of', 'the', 'cl@@', 'im@@', 'ate', 'system@@', '.', '</s>']
2024-05-28 13:33:50,485 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:33:50,485 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:33:50,485 - INFO - joeynmt.training - 	Hypothesis: The polar is the polar is in a way that the baby of the climate system.
2024-05-28 13:33:50,485 - INFO - joeynmt.training - Example #3
2024-05-28 13:33:50,485 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:33:50,485 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:33:50,485 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'pan@@', 'sion', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:33:50,486 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:33:50,486 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:33:50,486 - INFO - joeynmt.training - 	Hypothesis: She was expansion and contraction and contraction and contract.
2024-05-28 13:33:50,486 - INFO - joeynmt.training - Example #4
2024-05-28 13:33:50,486 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:33:50,486 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:33:50,486 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'U@@', 'r@@', 'h@@', 'y@@', 'th@@', 'm', 'I', 'will', 'show', 'you', 'that', 'I', 'will', 'show', 'you', 'the', 'f@@', 'ast', 'of', 'what', 'happen@@', 's', 'to', 'be', 'a', 'qu@@', 'ic@@', 'k', 'on', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:33:50,487 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:33:50,487 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:33:50,487 - INFO - joeynmt.training - 	Hypothesis: The Urhythm I will show you that I will show you the fast of what happens to be a quick on the last 25 years.
2024-05-28 13:33:54,007 - INFO - joeynmt.training - Epoch   9, Step:    36600, Batch Loss:     1.513955, Batch Acc: 0.547076, Tokens per Sec:    19418, Lr: 0.000300
2024-05-28 13:33:57,853 - INFO - joeynmt.training - Epoch   9, Step:    36700, Batch Loss:     1.705408, Batch Acc: 0.546955, Tokens per Sec:    18722, Lr: 0.000300
2024-05-28 13:34:01,752 - INFO - joeynmt.training - Epoch   9, Step:    36800, Batch Loss:     1.548286, Batch Acc: 0.545524, Tokens per Sec:    18173, Lr: 0.000300
2024-05-28 13:34:05,773 - INFO - joeynmt.training - Epoch   9, Step:    36900, Batch Loss:     1.257438, Batch Acc: 0.548019, Tokens per Sec:    17396, Lr: 0.000300
2024-05-28 13:34:09,514 - INFO - joeynmt.training - Epoch   9, Step:    37000, Batch Loss:     1.377946, Batch Acc: 0.543194, Tokens per Sec:    18829, Lr: 0.000300
2024-05-28 13:34:09,514 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:34:09,514 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:34:24,468 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.13, acc:   0.52, generation: 14.9355[sec], evaluation: 0.0000[sec]
2024-05-28 13:34:24,567 - INFO - joeynmt.helpers - delete models/bpe-subword/34500.ckpt
2024-05-28 13:34:24,607 - INFO - joeynmt.training - Example #0
2024-05-28 13:34:24,608 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:34:24,608 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:34:24,608 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'y@@', 'ear', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 'pos@@', 'iti@@', 've', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'pol@@', 'ar', 'that', 'the', 'maj@@', 'or@@', 'ity', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'mar@@', 'ri@@', 'ed', 'f@@', 'our', 'sm@@', 'all', 's@@', 'et@@', 's', 'sm@@', 'all', 'sor@@', 'ts', 'of', 'the', 'big', 'st@@', 'ate', 'of', 'the', 's@@', 'am@@', 'e,', 'it', 'sm@@', 'all@@', ',', 'it', 'was', 'sm@@', 'all', 'b@@', 'ea@@', 'u@@', 'ti@@', 'ful', '4@@', '8', 'percent', 'of', 'the', 's@@', 'li@@', 'ght@@', 'ly', 'ar@@', 'ri@@', 'ved', 'these', 'two', 'di@@', 'a@@', 'de@@', 'm@@', 'and', 'the', 'p@@', 'ur@@', 't', 'of', 'the']
2024-05-28 13:34:24,609 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:34:24,609 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:34:24,609 - INFO - joeynmt.training - 	Hypothesis: And the year year, I showed these two diapositive to demonstrate the polar that the majority of the last three million years of the last three million years of the last three million years of married four small sets small sorts of the big state of the same, it small, it was small beautiful 48 percent of the slightly arrived these two diademand the purt of the
2024-05-28 13:34:24,609 - INFO - joeynmt.training - Example #1
2024-05-28 13:34:24,609 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:34:24,609 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:34:24,609 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'this', 'is', 'the', 'speci@@', 'al', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'is', 'speci@@', 'al', 'because', 'it', "doesn't", 'look', 'at', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'gu@@', 'y', 'is', 'not', 'the', 'gu@@', 'y', 'sho@@', 'p@@', '.', '</s>']
2024-05-28 13:34:24,609 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:34:24,609 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:34:24,609 - INFO - joeynmt.training - 	Hypothesis: But this morning, this is the special of this particular is special because it doesn't look at the gross of the guy is not the guy shop.
2024-05-28 13:34:24,610 - INFO - joeynmt.training - Example #2
2024-05-28 13:34:24,610 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:34:24,610 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:34:24,610 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['C@@', 'al@@', 'o@@', 't@@', "'s", 'pol@@', 'ar', 'is', 'in', 'a', 'wa@@', 'y,', 'the', 'hear@@', 't', 'that', 'the', 'cl@@', 'im@@', 'ate', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.', '</s>']
2024-05-28 13:34:24,610 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:34:24,610 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:34:24,610 - INFO - joeynmt.training - 	Hypothesis: Calot's polar is in a way, the heart that the climate of the global climate system.
2024-05-28 13:34:24,610 - INFO - joeynmt.training - Example #3
2024-05-28 13:34:24,610 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:34:24,610 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:34:24,610 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'p@@', 'ec@@', 'ted', 'and', 'the', 'contr@@', 'ac@@', 'tion', 'and', 'the', 'contr@@', 'ac@@', 'tion', 'of', 'the', 'se@@', 'at@@', 'er.', '</s>']
2024-05-28 13:34:24,611 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:34:24,611 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:34:24,611 - INFO - joeynmt.training - 	Hypothesis: She was expected and the contraction and the contraction of the seater.
2024-05-28 13:34:24,611 - INFO - joeynmt.training - Example #4
2024-05-28 13:34:24,611 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:34:24,611 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:34:24,611 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'U@@', 'r@@', 'up@@', 'p@@', 'er', 'that', 'I', 'will', 'show', 'you', 'that', 'I', 'will', 'show', 'you', 'will', 'show', 'it', 'be', 'a', 'qu@@', 'ic@@', 'k', 'at', 'what', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:34:24,612 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:34:24,612 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:34:24,612 - INFO - joeynmt.training - 	Hypothesis: The Urupper that I will show you that I will show you will show it be a quick at what happened in the last 25 years.
2024-05-28 13:34:28,239 - INFO - joeynmt.training - Epoch   9, Step:    37100, Batch Loss:     1.389721, Batch Acc: 0.543695, Tokens per Sec:    19202, Lr: 0.000300
2024-05-28 13:34:31,670 - INFO - joeynmt.training - Epoch   9, Step:    37200, Batch Loss:     1.749310, Batch Acc: 0.541031, Tokens per Sec:    20940, Lr: 0.000300
2024-05-28 13:34:35,137 - INFO - joeynmt.training - Epoch   9, Step:    37300, Batch Loss:     1.429680, Batch Acc: 0.543559, Tokens per Sec:    20746, Lr: 0.000300
2024-05-28 13:34:38,899 - INFO - joeynmt.training - Epoch   9, Step:    37400, Batch Loss:     1.532246, Batch Acc: 0.542374, Tokens per Sec:    18593, Lr: 0.000300
2024-05-28 13:34:42,842 - INFO - joeynmt.training - Epoch   9, Step:    37500, Batch Loss:     1.611161, Batch Acc: 0.541998, Tokens per Sec:    17946, Lr: 0.000300
2024-05-28 13:34:42,842 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:34:42,842 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:35:01,438 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.10, acc:   0.52, generation: 18.5780[sec], evaluation: 0.0000[sec]
2024-05-28 13:35:01,523 - INFO - joeynmt.helpers - delete models/bpe-subword/35000.ckpt
2024-05-28 13:35:01,528 - INFO - joeynmt.training - Example #0
2024-05-28 13:35:01,528 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:35:01,528 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:35:01,528 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'th@@', 'en,', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', '-@@', 'pos@@', 'iti@@', 've', 'di@@', 'a@@', 'x@@', ',', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'way', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'most', 'ex@@', 'cit@@', 'ing', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'ma@@', 's@@', 'si@@', 've', 'st@@', 'at@@', 'es', 'of', 'ma@@', 's@@', 'si@@', 've', 'st@@', 'at@@', 'es', 'of', '4@@', '8', 'percent', 'of', 'the', 'lar@@', 'ge', 'on@@', 'e,', 'it', 'was', 'tin@@', 'i@@', 'p@@', 'p@@', 'p@@', 'ed', 'by', '4@@', '0', 'percent', 'of', 'the', 'year@@', '.', '</s>']
2024-05-28 13:35:01,528 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:35:01,529 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:35:01,529 - INFO - joeynmt.training - 	Hypothesis: And then, I showed these two dia-positive diax, to demonstrate the way to demonstrate the most exciting of the last three million years of massive states of massive states of 48 percent of the large one, it was tinippped by 40 percent of the year.
2024-05-28 13:35:01,529 - INFO - joeynmt.training - Example #1
2024-05-28 13:35:01,529 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:35:01,529 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:35:01,529 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'ning', 'of', 'the', 'ser@@', 'i@@', 'ous', 'ser@@', 'i@@', 'ous', 'because', 'it', "doesn't", 'look', 'at', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'gu@@', 'y.', '</s>']
2024-05-28 13:35:01,529 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:35:01,529 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:35:01,529 - INFO - joeynmt.training - 	Hypothesis: But this morning of the serious serious because it doesn't look at the gross of the gross of the guy.
2024-05-28 13:35:01,529 - INFO - joeynmt.training - Example #2
2024-05-28 13:35:01,530 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:35:01,530 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:35:01,530 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ch@@', 'o@@', 'ice', 'is', 'from', 'the', 'pol@@', 'ar', 'is', 'in', 'a', 'wa@@', 'y,', 'the', 'hear@@', 't', 'of', 'the', 'cl@@', 'im@@', 'ate', 'system@@', '.', '</s>']
2024-05-28 13:35:01,530 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:35:01,530 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:35:01,530 - INFO - joeynmt.training - 	Hypothesis: The choice is from the polar is in a way, the heart of the climate system.
2024-05-28 13:35:01,530 - INFO - joeynmt.training - Example #3
2024-05-28 13:35:01,530 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:35:01,530 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:35:01,530 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'p@@', 'ect@@', 'ing', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:35:01,531 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:35:01,531 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:35:01,531 - INFO - joeynmt.training - 	Hypothesis: She was expecting and contraction and contract.
2024-05-28 13:35:01,531 - INFO - joeynmt.training - Example #4
2024-05-28 13:35:01,531 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:35:01,531 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:35:01,531 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'U@@', 'r@@', 'h@@', 'y@@', 'th@@', 'm', 'that', 'I', 'will', 'show', 'you', 'that', 'I', 'will', 'show', 'you', 'the', 'f@@', 'ast@@', 'est', 'of', 'what', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:35:01,531 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:35:01,531 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:35:01,532 - INFO - joeynmt.training - 	Hypothesis: The Urhythm that I will show you that I will show you the fastest of what happened in the last 25 years.
2024-05-28 13:35:05,257 - INFO - joeynmt.training - Epoch   9, Step:    37600, Batch Loss:     1.681308, Batch Acc: 0.547673, Tokens per Sec:    17945, Lr: 0.000300
2024-05-28 13:35:08,616 - INFO - joeynmt.training - Epoch   9, Step:    37700, Batch Loss:     1.541404, Batch Acc: 0.545287, Tokens per Sec:    21666, Lr: 0.000300
2024-05-28 13:35:12,324 - INFO - joeynmt.training - Epoch   9, Step:    37800, Batch Loss:     1.505092, Batch Acc: 0.542525, Tokens per Sec:    18960, Lr: 0.000300
2024-05-28 13:35:15,673 - INFO - joeynmt.training - Epoch   9, Step:    37900, Batch Loss:     1.638879, Batch Acc: 0.542681, Tokens per Sec:    21034, Lr: 0.000300
2024-05-28 13:35:18,818 - INFO - joeynmt.training - Epoch   9, Step:    38000, Batch Loss:     1.517306, Batch Acc: 0.547669, Tokens per Sec:    22463, Lr: 0.000300
2024-05-28 13:35:18,819 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:35:18,819 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:35:28,143 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.09, acc:   0.53, generation: 9.3064[sec], evaluation: 0.0000[sec]
2024-05-28 13:35:28,228 - INFO - joeynmt.helpers - delete models/bpe-subword/37000.ckpt
2024-05-28 13:35:28,229 - INFO - joeynmt.training - Example #0
2024-05-28 13:35:28,230 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:35:28,230 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:35:28,230 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 'pos@@', 'iti@@', 've', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'as', 'the', 'most', 'of', 'the', 'pol@@', 'ar', 'that', 'in', 'the', 'most', 'ex@@', 'cit@@', 'ed', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'mar@@', 'ri@@', 'ed', 'by', '4@@', '8', 'percent', 'of', 'the', 'big', '4@@', '8', 'percent', 'of', 'the', 'big', '4@@', '8', 'percent', 'of', 'the', 'big', '4@@', '8', 'percent', 'of', 'the', 'sm@@', 'all', 'st@@', 'at@@', 'es', 'of', '4@@', '0', 'percent', 'of', 'the', '4@@', '0', 'percent', 'of', 'the', 'f@@', 'our@@', '.', '</s>']
2024-05-28 13:35:28,230 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:35:28,230 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:35:28,230 - INFO - joeynmt.training - 	Hypothesis: And the year I showed these two diapositive to demonstrate as the most of the polar that in the most excited of the last three million years of the last three million years of married by 48 percent of the big 48 percent of the big 48 percent of the big 48 percent of the small states of 40 percent of the 40 percent of the four.
2024-05-28 13:35:28,230 - INFO - joeynmt.training - Example #1
2024-05-28 13:35:28,230 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:35:28,230 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:35:28,231 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing@@', 'ly', 'the', 'ser@@', 'i@@', 'ous', 'speci@@', 'al', 'problem@@', 's', 'because', 'it', "doesn't", 'look', 'like', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'gu@@', 'y.', '</s>']
2024-05-28 13:35:28,231 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:35:28,231 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:35:28,231 - INFO - joeynmt.training - 	Hypothesis: But this morningly the serious special problems because it doesn't look like the gross of the guy.
2024-05-28 13:35:28,231 - INFO - joeynmt.training - Example #2
2024-05-28 13:35:28,231 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:35:28,231 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:35:28,231 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['C@@', 'al@@', 'o@@', 'pol@@', 'ar', 'is,', 'in', 'a', 'wa@@', 'y,', 'the', 'hear@@', 't', 'of', 'the', 'cl@@', 'im@@', 'ate', 'system@@', '.', '</s>']
2024-05-28 13:35:28,232 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:35:28,232 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:35:28,232 - INFO - joeynmt.training - 	Hypothesis: Calopolar is, in a way, the heart of the climate system.
2024-05-28 13:35:28,232 - INFO - joeynmt.training - Example #3
2024-05-28 13:35:28,232 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:35:28,232 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:35:28,232 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'was', 'ex@@', 'p@@', 'and@@', 'ing', 'of', 'the', 'w@@', 'in@@', 'do@@', 'w', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:35:28,232 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:35:28,232 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:35:28,232 - INFO - joeynmt.training - 	Hypothesis: She was expanding of the window and contract.
2024-05-28 13:35:28,233 - INFO - joeynmt.training - Example #4
2024-05-28 13:35:28,233 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:35:28,233 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:35:28,233 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'U@@', 'r@@', 'h@@', 'y@@', 'th@@', 'm', 'of', 'the', 's@@', 'li@@', 'de', 'that', 'I', 'will', 'show', 'it', 'a', 'qu@@', 'ic@@', 'k', 'of', 'what', 'happen@@', 'ed', 'on', 'what', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:35:28,233 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:35:28,233 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:35:28,233 - INFO - joeynmt.training - 	Hypothesis: The Urhythm of the slide that I will show it a quick of what happened on what happened in the last 25 years.
2024-05-28 13:35:31,549 - INFO - joeynmt.training - Epoch   9, Step:    38100, Batch Loss:     1.427121, Batch Acc: 0.545327, Tokens per Sec:    21058, Lr: 0.000300
2024-05-28 13:35:34,621 - INFO - joeynmt.training - Epoch   9, Step:    38200, Batch Loss:     1.509731, Batch Acc: 0.544311, Tokens per Sec:    23255, Lr: 0.000300
2024-05-28 13:35:37,930 - INFO - joeynmt.training - Epoch   9, Step:    38300, Batch Loss:     1.603645, Batch Acc: 0.541559, Tokens per Sec:    21583, Lr: 0.000300
2024-05-28 13:35:41,768 - INFO - joeynmt.training - Epoch   9, Step:    38400, Batch Loss:     1.486615, Batch Acc: 0.542115, Tokens per Sec:    18775, Lr: 0.000300
2024-05-28 13:35:45,804 - INFO - joeynmt.training - Epoch   9, Step:    38500, Batch Loss:     1.507474, Batch Acc: 0.543789, Tokens per Sec:    17388, Lr: 0.000300
2024-05-28 13:35:45,804 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 13:35:45,804 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 13:36:06,882 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.05, acc:   0.53, generation: 21.0595[sec], evaluation: 0.0000[sec]
2024-05-28 13:36:06,883 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 13:36:07,039 - INFO - joeynmt.helpers - delete models/bpe-subword/35500.ckpt
2024-05-28 13:36:07,052 - INFO - joeynmt.training - Example #0
2024-05-28 13:36:07,052 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'tre@@', 'cut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'dou@@', 'a', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 've', 'pentru', 'a', 'de@@', 'mon@@', 'str@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'maj@@', 'or@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'mil@@', 'ioane', 'de', 'ani', 'a', 'fost', 'de', 'd@@', 'imen@@', 'si@@', 'unea', 'a', '4@@', '8', 'de', 'st@@', 'ate', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0@@', '%', '.']
2024-05-28 13:36:07,052 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'perc@@', 'ent.']
2024-05-28 13:36:07,052 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'y@@', 'ear', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'uch', 'a', 'pos@@', 'iti@@', 've', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'the', 'pol@@', 'ar', 'that', 'the', 'big', 'pol@@', 'ar', 'as', 'the', 'most', 'of', 'the', 'most', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'last', 'three', 'mil@@', 'lion', 'years', 'of', 'mar@@', 'ri@@', 'ed', 'by', '4@@', '8', 'percent', 'of', 'the', 'lar@@', 'ge', 'of', 'a', 'sm@@', 'all', 'st@@', 'ate', 'with', '4@@', '0', 'percent', 'of', 'the', 'last', '4@@', '0', 'percent', 'of', 'the', 'last', '4@@', '0', 'percent', 'of', 'these', 'two', 'percent', 'of', 'these', 'two', 'percent', 'of', 'these', 'two', 'percent', 'of', 'these', 'two', 'percent', 'of', 'the', 's@@', 'li@@', 'ght@@', 'ly', 'b@@', 'ul@@', 'l@@', ',', '</s>']
2024-05-28 13:36:07,053 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 13:36:07,053 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 13:36:07,053 - INFO - joeynmt.training - 	Hypothesis: And the year I showed these two such a positive to demonstrate the polar that the big polar as the most of the most of the last three million years of the size of the last three million years of married by 48 percent of the large of a small state with 40 percent of the last 40 percent of the last 40 percent of these two percent of these two percent of these two percent of these two percent of the slightly bull,
2024-05-28 13:36:07,053 - INFO - joeynmt.training - Example #1
2024-05-28 13:36:07,053 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'd@@', 'im@@', 'in@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acest@@', 'ei', 'problem@@', 'e', 'speci@@', 'ale', 'de@@', 'oare@@', 'ce', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'im@@', 'ea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 13:36:07,053 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ous@@', 'n@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'n@@', 'ess', 'of', 'the', 'ice.']
2024-05-28 13:36:07,053 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'ning', 'is', 'the', 'ser@@', 'i@@', 'ous', 'ser@@', 'i@@', 'ous', 'speci@@', 'al', 'of', 'this', 'speci@@', 'al', 'prob@@', 'le@@', 'm', 'because', 'it', "doesn't", 'look', 'like', 'the', 'gu@@', 'y.', '</s>']
2024-05-28 13:36:07,053 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 13:36:07,053 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 13:36:07,053 - INFO - joeynmt.training - 	Hypothesis: But this morning is the serious serious special of this special problem because it doesn't look like the guy.
2024-05-28 13:36:07,053 - INFO - joeynmt.training - Example #2
2024-05-28 13:36:07,054 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'est@@', 'e,', 'in@@', 'tr-@@', 'un', 'fel@@', ',', 'in@@', 'im@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'cl@@', 'im@@', 'ati@@', 'c', 'glob@@', 'al.']
2024-05-28 13:36:07,054 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cl@@', 'im@@', 'ate', 'system@@', '.']
2024-05-28 13:36:07,054 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'is', 'in', 'a', 'pol@@', 'ar', 'is', 'in', 'a', 'way', 'that', 'the', 'cl@@', 'im@@', 'ate', 'system@@', '.', '</s>']
2024-05-28 13:36:07,054 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 13:36:07,054 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 13:36:07,054 - INFO - joeynmt.training - 	Hypothesis: The polar is in a polar is in a way that the climate system.
2024-05-28 13:36:07,054 - INFO - joeynmt.training - Example #3
2024-05-28 13:36:07,054 - DEBUG - joeynmt.training - 	Tokenized source:     ['E@@', 'a', 'se', 'ex@@', 'tin@@', 'de', 'iar@@', 'n@@', 'a', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'v@@', 'ar@@', 'a.']
2024-05-28 13:36:07,054 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 13:36:07,054 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'he', 'ex@@', 'p@@', 'ect@@', 's', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 13:36:07,055 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 13:36:07,055 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 13:36:07,055 - INFO - joeynmt.training - 	Hypothesis: She expects and contraction and contraction and contract.
2024-05-28 13:36:07,055 - INFO - joeynmt.training - Example #4
2024-05-28 13:36:07,055 - DEBUG - joeynmt.training - 	Tokenized source:     ['U@@', 'r@@', 'mat@@', 'orul', 'di@@', 'a@@', 'po@@', 'z@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-@@', 'l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 've@@', 'd@@', 'ere', 'rap@@', 'i@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'in@@', 't@@', 'am@@', 'pl@@', 'at', 'in', 'ultim@@', 'ii', '2@@', '5', 'de', 'ani.']
2024-05-28 13:36:07,055 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-28 13:36:07,055 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'uni@@', 'ver@@', 'se', 'that', 'I', 'will', 'show', 'you', 'that', 'I', 'will', 'show', 'you', 'a', 'qu@@', 'ic@@', 'k', 'on', 'what', 'it', 'was', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-28 13:36:07,055 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 13:36:07,056 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 13:36:07,056 - INFO - joeynmt.training - 	Hypothesis: The universe that I will show you that I will show you a quick on what it was happened in the last 25 years.
2024-05-28 13:36:10,823 - INFO - joeynmt.training - Epoch   9, Step:    38600, Batch Loss:     1.651066, Batch Acc: 0.542580, Tokens per Sec:    18785, Lr: 0.000300
2024-05-28 13:36:14,484 - INFO - joeynmt.training - Epoch   9, Step:    38700, Batch Loss:     1.647122, Batch Acc: 0.537814, Tokens per Sec:    18732, Lr: 0.000300
2024-05-28 13:36:18,464 - INFO - joeynmt.training - Epoch   9, Step:    38800, Batch Loss:     1.519562, Batch Acc: 0.542559, Tokens per Sec:    17427, Lr: 0.000300
