2024-05-28 11:59:43,542 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2024-05-28 11:59:43,542 - INFO - joeynmt.helpers -                           cfg.name : transformer_bpe-vocab_config
2024-05-28 11:59:43,542 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2024-05-28 11:59:43,542 - INFO - joeynmt.helpers -                     cfg.data.train : data/sub_train.ro-en
2024-05-28 11:59:43,542 - INFO - joeynmt.helpers -                       cfg.data.dev : data/dev.ro-en
2024-05-28 11:59:43,542 - INFO - joeynmt.helpers -                      cfg.data.test : data/test.ro-en
2024-05-28 11:59:43,542 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2024-05-28 11:59:43,543 - INFO - joeynmt.helpers -                  cfg.data.src.lang : ro
2024-05-28 11:59:43,543 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2024-05-28 11:59:43,543 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2024-05-28 11:59:43,543 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2024-05-28 11:59:43,543 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : data/vocab_clean.bpe
2024-05-28 11:59:43,543 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt
2024-05-28 11:59:43,543 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : data/bpe.codes
2024-05-28 11:59:43,543 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : en
2024-05-28 11:59:43,543 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2024-05-28 11:59:43,543 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2024-05-28 11:59:43,543 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2024-05-28 11:59:43,543 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : data/vocab_clean.bpe
2024-05-28 11:59:43,543 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt
2024-05-28 11:59:43,543 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : data/bpe.codes
2024-05-28 11:59:43,543 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2024-05-28 11:59:43,543 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2024-05-28 11:59:43,543 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2024-05-28 11:59:43,543 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2024-05-28 11:59:43,543 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2024-05-28 11:59:43,543 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2024-05-28 11:59:43,544 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2024-05-28 11:59:43,544 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2024-05-28 11:59:43,544 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2024-05-28 11:59:43,544 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2024-05-28 11:59:43,544 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2024-05-28 11:59:43,544 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2024-05-28 11:59:43,544 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2024-05-28 11:59:43,544 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2024-05-28 11:59:43,544 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2024-05-28 11:59:43,544 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2024-05-28 11:59:43,544 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2024-05-28 11:59:43,544 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2024-05-28 11:59:43,544 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2024-05-28 11:59:43,544 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/bpe-vocab
2024-05-28 11:59:43,544 - INFO - joeynmt.helpers -             cfg.training.overwrite : False
2024-05-28 11:59:43,544 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2024-05-28 11:59:43,544 - INFO - joeynmt.helpers -              cfg.training.use_cuda : True
2024-05-28 11:59:43,544 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2024-05-28 11:59:43,544 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2024-05-28 11:59:43,544 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2024-05-28 11:59:43,544 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2024-05-28 11:59:43,545 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2024-05-28 11:59:43,545 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2024-05-28 11:59:43,545 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2024-05-28 11:59:43,545 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2024-05-28 11:59:43,545 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : True
2024-05-28 11:59:43,545 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2024-05-28 11:59:43,545 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2024-05-28 11:59:43,545 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2024-05-28 11:59:43,545 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2024-05-28 11:59:43,545 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2024-05-28 11:59:43,545 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2024-05-28 11:59:43,545 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2024-05-28 11:59:43,545 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2024-05-28 11:59:43,545 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2024-05-28 11:59:43,545 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2024-05-28 11:59:43,545 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2024-05-28 11:59:43,545 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2024-05-28 11:59:43,545 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2024-05-28 11:59:43,545 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2024-05-28 11:59:43,545 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2024-05-28 11:59:43,546 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2024-05-28 11:59:43,546 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2024-05-28 11:59:43,546 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2024-05-28 11:59:43,546 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2024-05-28 11:59:43,713 - INFO - joeynmt.data - Building tokenizer...
2024-05-28 11:59:43,752 - INFO - joeynmt.tokenizers - ro tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2024-05-28 11:59:43,753 - INFO - joeynmt.tokenizers - en tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2024-05-28 11:59:43,753 - INFO - joeynmt.data - Loading train set...
2024-05-28 11:59:44,261 - INFO - joeynmt.data - Building vocabulary...
2024-05-28 11:59:44,635 - INFO - joeynmt.data - Loading dev set...
2024-05-28 11:59:44,695 - INFO - joeynmt.data - Loading test set...
2024-05-28 11:59:44,877 - INFO - joeynmt.data - Data loaded.
2024-05-28 11:59:44,878 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=100000, src_lang=ro, trg_lang=en, has_trg=True, random_subset=-1)
2024-05-28 11:59:44,878 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=914, src_lang=ro, trg_lang=en, has_trg=True, random_subset=-1)
2024-05-28 11:59:44,878 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1678, src_lang=ro, trg_lang=en, has_trg=True, random_subset=-1)
2024-05-28 11:59:44,878 - INFO - joeynmt.data - First training example:
	[SRC] At@@ unc@@ i, pentru voi vis@@ ul e@@ ...
	[TRG] For you, the dre@@ am here then is that --
2024-05-28 11:59:44,878 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) a (5) the (6) de (7) to (8) of (9) and
2024-05-28 11:59:44,878 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) a (5) the (6) de (7) to (8) of (9) and
2024-05-28 11:59:44,878 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 5000
2024-05-28 11:59:44,878 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 5000
2024-05-28 11:59:44,881 - INFO - joeynmt.model - Building an encoder-decoder model...
2024-05-28 11:59:44,967 - INFO - joeynmt.model - Enc-dec model built.
2024-05-28 11:59:44,971 - INFO - joeynmt.model - Total params: 4179200
2024-05-28 11:59:44,972 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight']
2024-05-28 11:59:44,972 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=5000),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=5000),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2024-05-28 11:59:45,740 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2024-05-28 11:59:45,740 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, verbose=False, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2024-05-28 11:59:45,741 - INFO - joeynmt.training - Train stats:
	device: cuda
	n_gpu: 1
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2024-05-28 11:59:45,741 - INFO - joeynmt.training - EPOCH 1
2024-05-28 11:59:49,677 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     4.355893, Batch Acc: 0.049521, Tokens per Sec:    17369, Lr: 0.000300
2024-05-28 11:59:52,870 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     4.041765, Batch Acc: 0.077759, Tokens per Sec:    21117, Lr: 0.000300
2024-05-28 11:59:55,968 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     4.031817, Batch Acc: 0.091123, Tokens per Sec:    21282, Lr: 0.000300
2024-05-28 11:59:59,053 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     3.755678, Batch Acc: 0.101255, Tokens per Sec:    21954, Lr: 0.000300
2024-05-28 12:00:02,108 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     3.837281, Batch Acc: 0.111932, Tokens per Sec:    22557, Lr: 0.000300
2024-05-28 12:00:02,108 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:00:02,108 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:00:10,862 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.79, ppl:  44.04, acc:   0.12, generation: 8.7132[sec], evaluation: 0.0000[sec]
2024-05-28 12:00:10,862 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:00:10,938 - INFO - joeynmt.training - Example #0
2024-05-28 12:00:10,939 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:00:10,939 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:00:10,939 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'think', 'that', 'we', 'have', 'to', 'be', 'a', 'lot', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the']
2024-05-28 12:00:10,939 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:00:10,939 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:00:10,939 - INFO - joeynmt.training - 	Hypothesis: And I think that we have to be a lot of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the
2024-05-28 12:00:10,939 - INFO - joeynmt.training - Example #1
2024-05-28 12:00:10,939 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:00:10,939 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:00:10,939 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'think', 'you', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'be', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'the', 'first', 'of', 'the', 'first', 'the', 'first', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first']
2024-05-28 12:00:10,940 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:00:10,940 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:00:10,940 - INFO - joeynmt.training - 	Hypothesis: And I think you can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can be the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the the first of the first the first the first of the first of the first of the first of the first of the first
2024-05-28 12:00:10,940 - INFO - joeynmt.training - Example #2
2024-05-28 12:00:10,940 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:00:10,940 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:00:10,940 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'think', 'you', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'be', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'the', 'the', 'first', 'of', 'the', 'first', 'the', 'first', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the']
2024-05-28 12:00:10,941 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:00:10,941 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:00:10,941 - INFO - joeynmt.training - 	Hypothesis: And I think you can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can be the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the the the first of the first the first the first of the first of the first of the first of the first of the
2024-05-28 12:00:10,941 - INFO - joeynmt.training - Example #3
2024-05-28 12:00:10,941 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:00:10,941 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:00:10,941 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'think', 'you', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'can', 'be', 'the', 'first', 'it.', '</s>']
2024-05-28 12:00:10,941 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:00:10,941 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:00:10,941 - INFO - joeynmt.training - 	Hypothesis: And I think you can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can be the first it.
2024-05-28 12:00:10,941 - INFO - joeynmt.training - Example #4
2024-05-28 12:00:10,942 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:00:10,942 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:00:10,942 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'think', 'that', 'we', 'have', 'to', 'be', 'a', 'lot', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the']
2024-05-28 12:00:10,942 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:00:10,942 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:00:10,942 - INFO - joeynmt.training - 	Hypothesis: And I think that we have to be a lot of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the
2024-05-28 12:00:13,957 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     3.732747, Batch Acc: 0.125875, Tokens per Sec:    21873, Lr: 0.000300
2024-05-28 12:00:16,973 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     3.611120, Batch Acc: 0.139417, Tokens per Sec:    22926, Lr: 0.000300
2024-05-28 12:00:19,959 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     3.409786, Batch Acc: 0.150425, Tokens per Sec:    22851, Lr: 0.000300
2024-05-28 12:00:22,947 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     3.368180, Batch Acc: 0.161093, Tokens per Sec:    23032, Lr: 0.000300
2024-05-28 12:00:26,042 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     3.392665, Batch Acc: 0.165319, Tokens per Sec:    22131, Lr: 0.000300
2024-05-28 12:00:26,042 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:00:26,042 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:00:34,628 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.43, ppl:  30.88, acc:   0.17, generation: 8.5538[sec], evaluation: 0.0000[sec]
2024-05-28 12:00:34,629 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:00:34,714 - INFO - joeynmt.training - Example #0
2024-05-28 12:00:34,714 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:00:34,714 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:00:34,714 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world']
2024-05-28 12:00:34,715 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:00:34,715 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:00:34,715 - INFO - joeynmt.training - 	Hypothesis: And the first of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world
2024-05-28 12:00:34,715 - INFO - joeynmt.training - Example #1
2024-05-28 12:00:34,715 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:00:34,715 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:00:34,715 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world']
2024-05-28 12:00:34,715 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:00:34,715 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:00:34,715 - INFO - joeynmt.training - 	Hypothesis: And the first of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world
2024-05-28 12:00:34,716 - INFO - joeynmt.training - Example #2
2024-05-28 12:00:34,716 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:00:34,716 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:00:34,716 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world']
2024-05-28 12:00:34,716 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:00:34,716 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:00:34,716 - INFO - joeynmt.training - 	Hypothesis: And the first of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world
2024-05-28 12:00:34,716 - INFO - joeynmt.training - Example #3
2024-05-28 12:00:34,716 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:00:34,716 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:00:34,716 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'we', 'can', 'be', 'a', 'lot', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world.', '</s>']
2024-05-28 12:00:34,717 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:00:34,717 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:00:34,717 - INFO - joeynmt.training - 	Hypothesis: And we can be a lot of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world.
2024-05-28 12:00:34,717 - INFO - joeynmt.training - Example #4
2024-05-28 12:00:34,717 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:00:34,717 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:00:34,717 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world']
2024-05-28 12:00:34,718 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:00:34,718 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:00:34,718 - INFO - joeynmt.training - 	Hypothesis: And the first of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world
2024-05-28 12:00:37,671 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     3.574160, Batch Acc: 0.168057, Tokens per Sec:    21914, Lr: 0.000300
2024-05-28 12:00:40,622 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     3.384452, Batch Acc: 0.171421, Tokens per Sec:    23224, Lr: 0.000300
2024-05-28 12:00:43,577 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     3.333766, Batch Acc: 0.174702, Tokens per Sec:    23614, Lr: 0.000300
2024-05-28 12:00:46,544 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     3.370889, Batch Acc: 0.174974, Tokens per Sec:    23258, Lr: 0.000300
2024-05-28 12:00:49,491 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     3.211298, Batch Acc: 0.181586, Tokens per Sec:    23337, Lr: 0.000300
2024-05-28 12:00:49,492 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:00:49,492 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:00:58,096 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.26, ppl:  26.08, acc:   0.18, generation: 8.5842[sec], evaluation: 0.0000[sec]
2024-05-28 12:00:58,096 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:00:58,176 - INFO - joeynmt.training - Example #0
2024-05-28 12:00:58,176 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:00:58,176 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:00:58,176 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'a', 'lot', 'of', 'the', 'first', 'thing', 'that', 'I', 'was', 'a', 'little', 'bit', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'way', 'to', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'way', 'to', 'be', 'a', 'little', 'bit', 'of', 'the', 'first', 'of', 'the', 'first', 'thing', 'to', 'be', 'the', 'world', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'way', 'to', 'be', 'a', 'little', 'bit']
2024-05-28 12:00:58,177 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:00:58,177 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:00:58,177 - INFO - joeynmt.training - 	Hypothesis: And I was a lot of the first thing that I was a little bit of the first of the first of the first of the first of the first of the way to the first of the first of the first of the first of the first of the first of the first of the first of the first of the first of the way to be a little bit of the first of the first thing to be the world of the first of the first of the way to be a little bit
2024-05-28 12:00:58,177 - INFO - joeynmt.training - Example #1
2024-05-28 12:00:58,177 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:00:58,177 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:00:58,177 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'a', 'lot', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'world', 'is', 'a', 'little', 'bit', 'of', 'the', 'world.', '</s>']
2024-05-28 12:00:58,178 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:00:58,178 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:00:58,178 - INFO - joeynmt.training - 	Hypothesis: And I was a lot of the first of the first of the first of the world is a little bit of the world.
2024-05-28 12:00:58,178 - INFO - joeynmt.training - Example #2
2024-05-28 12:00:58,178 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:00:58,178 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:00:58,178 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'a', 'lot', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world.', '</s>']
2024-05-28 12:00:58,178 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:00:58,178 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:00:58,178 - INFO - joeynmt.training - 	Hypothesis: And I was a lot of the first of the first of the first of the first of the world of the world of the world.
2024-05-28 12:00:58,179 - INFO - joeynmt.training - Example #3
2024-05-28 12:00:58,179 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:00:58,179 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:00:58,179 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'think', 'that', 'I', 'think', 'that', 'I', 'was', 'a', 'little', 'bit', 'of', 'the', 'world.', '</s>']
2024-05-28 12:00:58,179 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:00:58,179 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:00:58,179 - INFO - joeynmt.training - 	Hypothesis: And I think that I think that I was a little bit of the world.
2024-05-28 12:00:58,179 - INFO - joeynmt.training - Example #4
2024-05-28 12:00:58,179 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:00:58,179 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:00:58,179 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'think', 'that', 'I', 'think', 'that', 'I', 'was', 'a', 'lot', 'of', 'the', 'first', 'thing', 'to', 'be', 'a', 'lot', 'of', 'the', 'way', 'to', 'be', 'a', 'lot', 'of', 'the', 'way', 'to', 'be', 'a', 'little', 'bit', 'of', 'the', 'way', 'to', 'the', 'way', 'to', 'be', 'a', 'lot', 'of', 'the', 'world.', '</s>']
2024-05-28 12:00:58,180 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:00:58,180 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:00:58,180 - INFO - joeynmt.training - 	Hypothesis: And I think that I think that I was a lot of the first thing to be a lot of the way to be a lot of the way to be a little bit of the way to the way to be a lot of the world.
2024-05-28 12:01:01,099 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     3.254767, Batch Acc: 0.182157, Tokens per Sec:    22364, Lr: 0.000300
2024-05-28 12:01:04,039 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     3.164755, Batch Acc: 0.184716, Tokens per Sec:    23783, Lr: 0.000300
2024-05-28 12:01:06,936 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     3.118885, Batch Acc: 0.188509, Tokens per Sec:    22862, Lr: 0.000300
2024-05-28 12:01:09,822 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     3.281272, Batch Acc: 0.191323, Tokens per Sec:    22733, Lr: 0.000300
2024-05-28 12:01:12,749 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     3.181364, Batch Acc: 0.190363, Tokens per Sec:    23600, Lr: 0.000300
2024-05-28 12:01:12,750 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:01:12,750 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:01:19,703 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.17, ppl:  23.74, acc:   0.19, generation: 6.9377[sec], evaluation: 0.0000[sec]
2024-05-28 12:01:19,704 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:01:19,786 - INFO - joeynmt.training - Example #0
2024-05-28 12:01:19,786 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:01:19,786 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:01:19,786 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'thing', 'is', 'that', 'the', 'first', 'thing', 'that', 'I', 'was', 'a', 'lot', 'of', 'the', 'first', 'thing', 'that', 'I', 'was', 'a', 'lot', 'of', 'the', 'first', 'thing', 'that', 'was', 'a', 'lot', 'of', 'the', 'same', 'thing', 'that', 'I', 'was', 'a', 'lot', 'of', 'the', 'first', 'thing', 'that', 'was', 'a', 'lot', 'of', 'the', 'first', 'thing', 'that', 'was', 'a', 'little', 'bit', 'of', 'the', 'same', 'thing', 'that', 'I', 'was', 'a', 'lot', 'of', 'the', 'first', 'thing', 'that', 'I', 'was', 'a', 'little', 'bit', 'of', 'the', 'same', 'thing.', '</s>']
2024-05-28 12:01:19,787 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:01:19,787 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:01:19,787 - INFO - joeynmt.training - 	Hypothesis: And the first thing is that the first thing that I was a lot of the first thing that I was a lot of the first thing that was a lot of the same thing that I was a lot of the first thing that was a lot of the first thing that was a little bit of the same thing that I was a lot of the first thing that I was a little bit of the same thing.
2024-05-28 12:01:19,787 - INFO - joeynmt.training - Example #1
2024-05-28 12:01:19,787 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:01:19,787 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:01:19,787 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'thing', 'is', 'that', 'the', 'first', 'thing', 'is', 'that', 'the', 'same', 'thing', 'is', 'that', 'the', 'same', 'thing', 'that', 'is', 'that', 'the', 'same', 'thing', 'that', 'is', 'that', 'the', 'same', 'thing.', '</s>']
2024-05-28 12:01:19,787 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:01:19,788 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:01:19,788 - INFO - joeynmt.training - 	Hypothesis: And the first thing is that the first thing is that the same thing is that the same thing that is that the same thing that is that the same thing.
2024-05-28 12:01:19,788 - INFO - joeynmt.training - Example #2
2024-05-28 12:01:19,788 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:01:19,788 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:01:19,788 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'thing', 'is', 'that', 'the', 'first', 'thing', 'is', 'that', 'the', 'first', 'thing', 'is', 'that', 'the', 'same', 'thing', 'is', 'that', 'the', 'same', 'thing', 'that', 'is', 'a', 'lot', 'of', 'the', 'same', 'thing.', '</s>']
2024-05-28 12:01:19,788 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:01:19,788 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:01:19,788 - INFO - joeynmt.training - 	Hypothesis: And the first thing is that the first thing is that the first thing is that the same thing is that the same thing that is a lot of the same thing.
2024-05-28 12:01:19,788 - INFO - joeynmt.training - Example #3
2024-05-28 12:01:19,788 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:01:19,789 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:01:19,789 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'a', 'lot', 'of', 'the', 'same', 'thing', 'that', 'I', 'was', 'a', 'lot', 'of', 'the', 'world.', '</s>']
2024-05-28 12:01:19,789 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:01:19,789 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:01:19,789 - INFO - joeynmt.training - 	Hypothesis: And I was a lot of the same thing that I was a lot of the world.
2024-05-28 12:01:19,789 - INFO - joeynmt.training - Example #4
2024-05-28 12:01:19,789 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:01:19,789 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:01:19,789 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'thing', 'is', 'that', 'the', 'first', 'thing', 'that', 'I', 'was', 'a', 'lot', 'of', 'the', 'same', 'thing', 'that', 'I', 'was', 'a', 'lot', 'of', 'the', 'same', 'thing', 'that', 'is', 'that', 'we', 'can', 'see', 'the', 'same', 'thing.', '</s>']
2024-05-28 12:01:19,790 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:01:19,790 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:01:19,790 - INFO - joeynmt.training - 	Hypothesis: And the first thing is that the first thing that I was a lot of the same thing that I was a lot of the same thing that is that we can see the same thing.
2024-05-28 12:01:22,701 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     3.199234, Batch Acc: 0.194911, Tokens per Sec:    22704, Lr: 0.000300
2024-05-28 12:01:25,631 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     3.067204, Batch Acc: 0.196393, Tokens per Sec:    24133, Lr: 0.000300
2024-05-28 12:01:28,548 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     3.120795, Batch Acc: 0.199263, Tokens per Sec:    23816, Lr: 0.000300
2024-05-28 12:01:31,457 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     3.007812, Batch Acc: 0.197602, Tokens per Sec:    24122, Lr: 0.000300
2024-05-28 12:01:34,340 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     3.026983, Batch Acc: 0.201707, Tokens per Sec:    23325, Lr: 0.000300
2024-05-28 12:01:34,340 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:01:34,340 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:01:41,672 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.11, ppl:  22.43, acc:   0.20, generation: 7.3149[sec], evaluation: 0.0000[sec]
2024-05-28 12:01:41,672 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:01:41,903 - INFO - joeynmt.training - Example #0
2024-05-28 12:01:41,903 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:01:41,903 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:01:41,903 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'thing', 'is', 'that', 'the', 'first', 'time', 'I', 'was', 'a', 'few', 'years', 'ago,', 'and', 'I', 'was', 'a', 'few', 'years', 'ago,', 'and', 'I', 'was', 'a', 'few', 'years', 'ago,', 'and', 'I', 'was', 'a', 'few', 'years', 'ago,', 'and', 'I', 'was', 'a', 'few', 'years', 'ago,', 'and', 'I', 'was', 'a', 'little', 'bit', 'of', 'the', 'world', 'of', 'the', 'world', 'in', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'same', 'way', 'of', 'the', 'world', 'in', 'the', 'world', 'in', 'the', 'world', 'of', 'the', 'world', '</s>']
2024-05-28 12:01:41,904 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:01:41,904 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:01:41,904 - INFO - joeynmt.training - 	Hypothesis: And the first thing is that the first time I was a few years ago, and I was a few years ago, and I was a few years ago, and I was a few years ago, and I was a few years ago, and I was a little bit of the world of the world in the world of the world of the world of the world of the world of the world of the same way of the world in the world in the world of the world
2024-05-28 12:01:41,904 - INFO - joeynmt.training - Example #1
2024-05-28 12:01:41,904 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:01:41,904 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:01:41,904 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'way', 'we', 'have', 'to', 'be', 'a', 'lot', 'of', 'the', 'world', 'of', 'the', 'world', 'is', 'a', 'lot', 'of', 'the', 'world', 'of', 'the', 'world.', '</s>']
2024-05-28 12:01:41,904 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:01:41,904 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:01:41,904 - INFO - joeynmt.training - 	Hypothesis: And the way we have to be a lot of the world of the world is a lot of the world of the world.
2024-05-28 12:01:41,904 - INFO - joeynmt.training - Example #2
2024-05-28 12:01:41,905 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:01:41,905 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:01:41,905 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'thing', 'is', 'that', 'the', 'world', 'is', 'a', 'little', 'bit', 'of', 'the', 'world', 'is', 'a', 'little', 'bit', 'of', 'the', 'world.', '</s>']
2024-05-28 12:01:41,905 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:01:41,905 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:01:41,905 - INFO - joeynmt.training - 	Hypothesis: And the first thing is that the world is a little bit of the world is a little bit of the world.
2024-05-28 12:01:41,905 - INFO - joeynmt.training - Example #3
2024-05-28 12:01:41,905 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:01:41,905 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:01:41,905 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'thing', 'is', 'a', 'lot', 'of', 'the', 'world', 'is', 'a', 'very', 'important', 'thing', 'is', 'to', 'be', 'a', 'little', 'bit', 'of', 'it.', '</s>']
2024-05-28 12:01:41,906 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:01:41,906 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:01:41,906 - INFO - joeynmt.training - 	Hypothesis: And the first thing is a lot of the world is a very important thing is to be a little bit of it.
2024-05-28 12:01:41,906 - INFO - joeynmt.training - Example #4
2024-05-28 12:01:41,906 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:01:41,906 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:01:41,906 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'thing', 'is', 'that', 'the', 'world', 'is', 'a', 'few', 'years', 'ago,', 'and', 'the', 'world', 'is', 'a', 'few', 'years', 'ago,', 'and', 'the', 'world', 'is', 'a', 'little', 'bit', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world.', '</s>']
2024-05-28 12:01:41,907 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:01:41,907 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:01:41,907 - INFO - joeynmt.training - 	Hypothesis: And the first thing is that the world is a few years ago, and the world is a few years ago, and the world is a little bit of the world of the world of the world of the world of the world of the world.
2024-05-28 12:01:44,806 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     3.074677, Batch Acc: 0.201722, Tokens per Sec:    21908, Lr: 0.000300
2024-05-28 12:01:47,696 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     2.962031, Batch Acc: 0.204436, Tokens per Sec:    23666, Lr: 0.000300
2024-05-28 12:01:50,586 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     3.030770, Batch Acc: 0.207290, Tokens per Sec:    23564, Lr: 0.000300
2024-05-28 12:01:53,457 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     2.965115, Batch Acc: 0.208786, Tokens per Sec:    24031, Lr: 0.000300
2024-05-28 12:01:56,367 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     3.066072, Batch Acc: 0.210065, Tokens per Sec:    23860, Lr: 0.000300
2024-05-28 12:01:56,367 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:01:56,367 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:02:03,618 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.07, ppl:  21.48, acc:   0.20, generation: 7.2362[sec], evaluation: 0.0000[sec]
2024-05-28 12:02:03,619 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:02:03,700 - INFO - joeynmt.helpers - delete models/bpe-vocab/500.ckpt
2024-05-28 12:02:03,710 - INFO - joeynmt.training - Example #0
2024-05-28 12:02:03,710 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:02:03,710 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:02:03,710 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'of', 'the', 'same', 'thing', 'that', 'was', 'the', 'same', 'time.', '</s>']
2024-05-28 12:02:03,711 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:02:03,711 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:02:03,711 - INFO - joeynmt.training - 	Hypothesis: And the first of the first of the first of the first of the first time of the first time of the first time of the first time of the first time of the first of the first of the first of the first of the first of the first of the first of the first time of the first time of the first time of the first time of the first of the same thing that was the same time.
2024-05-28 12:02:03,711 - INFO - joeynmt.training - Example #1
2024-05-28 12:02:03,711 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:02:03,711 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:02:03,711 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'same', 'thing', 'that', 'we', 'can', 'be', 'a', 'lot', 'of', 'the', 'same', 'thing', 'that', 'is', 'that', 'the', 'same', 'time.', '</s>']
2024-05-28 12:02:03,711 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:02:03,711 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:02:03,712 - INFO - joeynmt.training - 	Hypothesis: And the same thing that we can be a lot of the same thing that is that the same time.
2024-05-28 12:02:03,712 - INFO - joeynmt.training - Example #2
2024-05-28 12:02:03,712 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:02:03,712 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:02:03,712 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'same', 'thing', 'is', 'the', 'same', 'of', 'the', 'same', 'of', 'the', 'same', 'of', 'the', 'same', 'time.', '</s>']
2024-05-28 12:02:03,712 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:02:03,712 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:02:03,712 - INFO - joeynmt.training - 	Hypothesis: And the same thing is the same of the same of the same of the same time.
2024-05-28 12:02:03,712 - INFO - joeynmt.training - Example #3
2024-05-28 12:02:03,712 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:02:03,712 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:02:03,712 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'same', 'thing', 'that', 'is', 'that', 'the', 'same', 'thing', 'that', 'is', 'the', 'same', 'time.', '</s>']
2024-05-28 12:02:03,713 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:02:03,713 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:02:03,713 - INFO - joeynmt.training - 	Hypothesis: And the same thing that is that the same thing that is the same time.
2024-05-28 12:02:03,713 - INFO - joeynmt.training - Example #4
2024-05-28 12:02:03,713 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:02:03,713 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:02:03,713 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'think', 'that', 'we', 'have', 'a', 'lot', 'of', 'the', 'same', 'thing', 'that', 'we', 'have', 'a', 'lot', 'of', 'the', 'same', 'thing', 'that', 'we', 'have', 'a', 'lot', 'of', 'the', 'same', 'thing', 'that', 'is', 'that', 'the', 'same', 'thing', 'that', 'I', 'was', 'a', 'good', 'good', 'good', 'thing.', '</s>']
2024-05-28 12:02:03,714 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:02:03,714 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:02:03,714 - INFO - joeynmt.training - 	Hypothesis: And I think that we have a lot of the same thing that we have a lot of the same thing that we have a lot of the same thing that is that the same thing that I was a good good good thing.
2024-05-28 12:02:06,647 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     3.092355, Batch Acc: 0.211562, Tokens per Sec:    23445, Lr: 0.000300
2024-05-28 12:02:09,536 - INFO - joeynmt.training - Epoch   1, Step:     3200, Batch Loss:     3.041497, Batch Acc: 0.214066, Tokens per Sec:    23640, Lr: 0.000300
2024-05-28 12:02:12,438 - INFO - joeynmt.training - Epoch   1, Step:     3300, Batch Loss:     3.017984, Batch Acc: 0.213443, Tokens per Sec:    23554, Lr: 0.000300
2024-05-28 12:02:15,338 - INFO - joeynmt.training - Epoch   1, Step:     3400, Batch Loss:     3.022077, Batch Acc: 0.214153, Tokens per Sec:    23729, Lr: 0.000300
2024-05-28 12:02:18,269 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:     3.000829, Batch Acc: 0.218868, Tokens per Sec:    24117, Lr: 0.000300
2024-05-28 12:02:18,269 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:02:18,269 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:02:26,213 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.02, ppl:  20.41, acc:   0.21, generation: 7.9272[sec], evaluation: 0.0000[sec]
2024-05-28 12:02:26,213 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:02:27,006 - INFO - joeynmt.helpers - delete models/bpe-vocab/1000.ckpt
2024-05-28 12:02:27,016 - INFO - joeynmt.training - Example #0
2024-05-28 12:02:27,016 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:02:27,016 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:02:27,016 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'time', 'I', 'was', 'a', 'very', 'un@@', 'fortun@@', 'at@@', 'ely,', 'and', 'I', 'was', 'a', 'very', 'un@@', 'un@@', 'fortun@@', 'at@@', 'ely,', 'and', 'I', 'was', 'a', 'very', 'good', 'way', 'to', 'the', 'first', 'time', 'to', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'to', 'the', 'first', 'time', 'to', 'the', 'first']
2024-05-28 12:02:27,017 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:02:27,017 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:02:27,017 - INFO - joeynmt.training - 	Hypothesis: And the first time I was a very unfortunately, and I was a very ununfortunately, and I was a very good way to the first time to the first time of the first time of the first time of the first time of the first time of the first time of the first time of the first time of the first time of the first time of the first time of the first time of the first time of the first time to the first time to the first
2024-05-28 12:02:27,017 - INFO - joeynmt.training - Example #1
2024-05-28 12:02:27,017 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:02:27,017 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:02:27,017 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'other', 'wor@@', 'ds,', 'and', 'we', 'have', 'a', 'lot', 'of', 'the', 'same', 'way', 'to', 'the', 'other', 'other', 'wor@@', 'ds,', 'and', 'the', 'other', 'other', 'wor@@', 'ds,', '</s>']
2024-05-28 12:02:27,017 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:02:27,018 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:02:27,018 - INFO - joeynmt.training - 	Hypothesis: And the other words, and we have a lot of the same way to the other other words, and the other other words,
2024-05-28 12:02:27,018 - INFO - joeynmt.training - Example #2
2024-05-28 12:02:27,018 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:02:27,018 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:02:27,018 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['This', 'is', 'a', 'very', 'good', 'at', 'the', 'same', 'time,', 'and', 'the', 'same', 'time,', 'and', 'the', 'same', 'time,', 'and', 'the', 'other', 'other', 'wor@@', 'ds,', '</s>']
2024-05-28 12:02:27,018 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:02:27,018 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:02:27,018 - INFO - joeynmt.training - 	Hypothesis: This is a very good at the same time, and the same time, and the same time, and the other other words,
2024-05-28 12:02:27,018 - INFO - joeynmt.training - Example #3
2024-05-28 12:02:27,018 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:02:27,019 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:02:27,019 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'time', 'is', 'a', 'little', 'bit', 'of', 'the', 'same', 'time.', '</s>']
2024-05-28 12:02:27,019 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:02:27,019 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:02:27,019 - INFO - joeynmt.training - 	Hypothesis: And the first time is a little bit of the same time.
2024-05-28 12:02:27,019 - INFO - joeynmt.training - Example #4
2024-05-28 12:02:27,019 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:02:27,019 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:02:27,019 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'idea', 'is', 'that', 'the', 'idea', 'of', 'the', 'world', 'is', 'that', 'the', 'first', 'time', 'to', 'the', 'world', 'that', 'is', 'that', 'the', 'same', 'time,', 'and', 'I', 'think', 'about', 'the', 'same', 'time,', 'and', 'I', 'think', 'about', 'the', 'same', 'thing', 'that', 'is', 'that', 'the', 'same', 'time.', '</s>']
2024-05-28 12:02:27,020 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:02:27,020 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:02:27,020 - INFO - joeynmt.training - 	Hypothesis: And the idea is that the idea of the world is that the first time to the world that is that the same time, and I think about the same time, and I think about the same thing that is that the same time.
2024-05-28 12:02:29,897 - INFO - joeynmt.training - Epoch   1, Step:     3600, Batch Loss:     3.030400, Batch Acc: 0.220376, Tokens per Sec:    18346, Lr: 0.000300
2024-05-28 12:02:32,761 - INFO - joeynmt.training - Epoch   1, Step:     3700, Batch Loss:     2.887179, Batch Acc: 0.218662, Tokens per Sec:    23473, Lr: 0.000300
2024-05-28 12:02:35,619 - INFO - joeynmt.training - Epoch   1, Step:     3800, Batch Loss:     2.909399, Batch Acc: 0.220847, Tokens per Sec:    23177, Lr: 0.000300
2024-05-28 12:02:38,506 - INFO - joeynmt.training - Epoch   1, Step:     3900, Batch Loss:     2.969505, Batch Acc: 0.222203, Tokens per Sec:    23623, Lr: 0.000300
2024-05-28 12:02:39,188 - INFO - joeynmt.training - Epoch   1: total training loss 12958.94
2024-05-28 12:02:39,188 - INFO - joeynmt.training - EPOCH 2
2024-05-28 12:02:41,321 - INFO - joeynmt.training - Epoch   2, Step:     4000, Batch Loss:     2.919065, Batch Acc: 0.229285, Tokens per Sec:    24916, Lr: 0.000300
2024-05-28 12:02:41,321 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:02:41,321 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:02:49,829 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.98, ppl:  19.76, acc:   0.22, generation: 8.4893[sec], evaluation: 0.0000[sec]
2024-05-28 12:02:49,829 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:02:49,902 - INFO - joeynmt.helpers - delete models/bpe-vocab/1500.ckpt
2024-05-28 12:02:49,909 - INFO - joeynmt.training - Example #0
2024-05-28 12:02:49,910 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:02:49,910 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:02:49,910 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'time', 'was', 'the', 'first', 'time', 'in', 'the', '19@@', '7@@', '0@@', 's,', 'and', 'the', 'first', 'time', 'was', 'the', 'first', 'time', 'in', 'the', '19@@', '7@@', '0@@', 's,', 'and', 'the', 'first', 'time', 'was', 'the', 'first', 'time', 'in', 'the', '19@@', '7@@', '0@@', 's,', 'and', 'the', 'first', 'time', 'was', 'the', 'first', 'time', 'in', 'the', '19@@', '7@@', '0@@', '0@@', ',000', 'years', 'ago.', '</s>']
2024-05-28 12:02:49,910 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:02:49,910 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:02:49,910 - INFO - joeynmt.training - 	Hypothesis: And the first time was the first time in the 1970s, and the first time was the first time in the 1970s, and the first time was the first time in the 1970s, and the first time was the first time in the 19700,000 years ago.
2024-05-28 12:02:49,910 - INFO - joeynmt.training - Example #1
2024-05-28 12:02:49,911 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:02:49,911 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:02:49,911 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'I', 'think', 'that', 'we', 'have', 'a', 'lot', 'of', 'people', 'who', 'are', 'going', 'to', 'be', 'a', 'little', 'bit', 'of', 'the', 'same', 'time.', '</s>']
2024-05-28 12:02:49,911 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:02:49,911 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:02:49,911 - INFO - joeynmt.training - 	Hypothesis: But I think that we have a lot of people who are going to be a little bit of the same time.
2024-05-28 12:02:49,911 - INFO - joeynmt.training - Example #2
2024-05-28 12:02:49,911 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:02:49,911 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:02:49,911 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'other', 'thing', 'is', 'that', 'the', 'most', 'important', 'thing', 'is', 'that', 'we', 'have', 'a', 'lot', 'of', 'the', 'same', 'time,', 'and', 'the', 'other', 'other', 'than', 'the', 'other', 'other', 'other', 'than', 'the', 'world.', '</s>']
2024-05-28 12:02:49,912 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:02:49,912 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:02:49,912 - INFO - joeynmt.training - 	Hypothesis: The other thing is that the most important thing is that we have a lot of the same time, and the other other than the other other other than the world.
2024-05-28 12:02:49,912 - INFO - joeynmt.training - Example #3
2024-05-28 12:02:49,912 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:02:49,912 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:02:49,912 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'this', 'is', 'a', 'very', 'good', 'way', 'to', 'be', 'a', 'little', 'bit', 'of', 'it.', '</s>']
2024-05-28 12:02:49,912 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:02:49,912 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:02:49,913 - INFO - joeynmt.training - 	Hypothesis: And this is a very good way to be a little bit of it.
2024-05-28 12:02:49,913 - INFO - joeynmt.training - Example #4
2024-05-28 12:02:49,913 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:02:49,913 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:02:49,913 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'thing', 'that', 'I', 'was', 'a', 'little', 'bit', 'of', 'the', 'first', 'time', 'I', 'was', 'a', 'little', 'bit', 'about', 'the', 'first', 'time', 'to', 'be', 'a', 'little', 'bit', 'of', 'the', 'most', 'important', 'thing', 'that', 'I', 'was', 'a', 'little', 'bit', 'about', 'the', 'time.', '</s>']
2024-05-28 12:02:49,913 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:02:49,913 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:02:49,913 - INFO - joeynmt.training - 	Hypothesis: The first thing that I was a little bit of the first time I was a little bit about the first time to be a little bit of the most important thing that I was a little bit about the time.
2024-05-28 12:02:52,660 - INFO - joeynmt.training - Epoch   2, Step:     4100, Batch Loss:     2.965278, Batch Acc: 0.234521, Tokens per Sec:    24158, Lr: 0.000300
2024-05-28 12:02:55,395 - INFO - joeynmt.training - Epoch   2, Step:     4200, Batch Loss:     2.809901, Batch Acc: 0.235487, Tokens per Sec:    24734, Lr: 0.000300
2024-05-28 12:02:58,138 - INFO - joeynmt.training - Epoch   2, Step:     4300, Batch Loss:     2.992354, Batch Acc: 0.239097, Tokens per Sec:    24914, Lr: 0.000300
2024-05-28 12:03:00,884 - INFO - joeynmt.training - Epoch   2, Step:     4400, Batch Loss:     2.845337, Batch Acc: 0.239604, Tokens per Sec:    24587, Lr: 0.000300
2024-05-28 12:03:03,640 - INFO - joeynmt.training - Epoch   2, Step:     4500, Batch Loss:     2.791173, Batch Acc: 0.238588, Tokens per Sec:    24672, Lr: 0.000300
2024-05-28 12:03:03,641 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:03:03,641 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:03:11,781 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.93, ppl:  18.67, acc:   0.24, generation: 8.1212[sec], evaluation: 0.0000[sec]
2024-05-28 12:03:11,781 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:03:11,855 - INFO - joeynmt.helpers - delete models/bpe-vocab/2000.ckpt
2024-05-28 12:03:11,864 - INFO - joeynmt.training - Example #0
2024-05-28 12:03:11,865 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:03:11,865 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:03:11,865 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'time', 'I', 'was', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'was', 'the', 'first', 'time', 'of', 'the', '19@@', 'th', 'centur@@', 'y,', 'and', 'the', 'first', 'time', 'was', 'a', 'little', 'bit', 'of', 'the', '19@@', 'th', 'centur@@', 'y,', 'and', 'the', 'first', 'time', 'was', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'U.S.', '</s>']
2024-05-28 12:03:11,865 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:03:11,865 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:03:11,865 - INFO - joeynmt.training - 	Hypothesis: The first time I was the first time of the first time of the first time of the first time of the first time was the first time of the 19th century, and the first time was a little bit of the 19th century, and the first time was the first time of the first time of the first time of the first time of the first time of the U.S.
2024-05-28 12:03:11,865 - INFO - joeynmt.training - Example #1
2024-05-28 12:03:11,866 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:03:11,866 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:03:11,866 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'the', 'first', 'thing', 'that', 'is', 'that', 'we', 'have', 'to', 'be', 'a', 'lot', 'of', 'the', 'same', 'way', 'to', 'be', 'a', 'very', 'simple', 'way', 'to', 'be', 'a', 'lot', 'of', 'the', 'world.', '</s>']
2024-05-28 12:03:11,866 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:03:11,866 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:03:11,866 - INFO - joeynmt.training - 	Hypothesis: But the first thing that is that we have to be a lot of the same way to be a very simple way to be a lot of the world.
2024-05-28 12:03:11,866 - INFO - joeynmt.training - Example #2
2024-05-28 12:03:11,866 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:03:11,866 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:03:11,866 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'second', 'is', 'the', 'most', 'important', 'thing', 'that', 'is', 'that', 'the', 'most', 'important', 'thing', 'that', 'is', 'that', 'the', 'most', 'important', 'thing', 'that', 'is', 'that', 'the', 'most', 'important', 'thing', 'that', 'is', 'that', 'the', 'same', 'thing', 'that', 'is', 'that', 'the', 'same', 'thing.', '</s>']
2024-05-28 12:03:11,867 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:03:11,867 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:03:11,867 - INFO - joeynmt.training - 	Hypothesis: The second is the most important thing that is that the most important thing that is that the most important thing that is that the most important thing that is that the same thing that is that the same thing.
2024-05-28 12:03:11,867 - INFO - joeynmt.training - Example #3
2024-05-28 12:03:11,867 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:03:11,867 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:03:11,867 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'time', 'we', 'have', 'to', 'be', 'able', 'to', 'be', 'able', 'to', 'be', 'the', 'same', 'thing.', '</s>']
2024-05-28 12:03:11,867 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:03:11,867 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:03:11,868 - INFO - joeynmt.training - 	Hypothesis: And the first time we have to be able to be able to be the same thing.
2024-05-28 12:03:11,868 - INFO - joeynmt.training - Example #4
2024-05-28 12:03:11,868 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:03:11,868 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:03:11,868 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'thing', 'that', 'is', 'that', 'the', 'first', 'thing', 'that', 'I', 'think', 'that', 'I', 'think', 'that', 'is', 'that', 'I', 'was', 'a', 'little', 'bit', 'of', 'the', 'most', 'important', 'thing', 'that', 'is', 'that', 'I', 'was', 'a', 'very', 'difficult', 'to', 'be', 'the', 'same', 'thing.', '</s>']
2024-05-28 12:03:11,868 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:03:11,868 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:03:11,868 - INFO - joeynmt.training - 	Hypothesis: The first thing that is that the first thing that I think that I think that is that I was a little bit of the most important thing that is that I was a very difficult to be the same thing.
2024-05-28 12:03:14,617 - INFO - joeynmt.training - Epoch   2, Step:     4600, Batch Loss:     2.842334, Batch Acc: 0.247627, Tokens per Sec:    24524, Lr: 0.000300
2024-05-28 12:03:17,376 - INFO - joeynmt.training - Epoch   2, Step:     4700, Batch Loss:     2.749938, Batch Acc: 0.245731, Tokens per Sec:    24727, Lr: 0.000300
2024-05-28 12:03:20,115 - INFO - joeynmt.training - Epoch   2, Step:     4800, Batch Loss:     2.809286, Batch Acc: 0.249493, Tokens per Sec:    24681, Lr: 0.000300
2024-05-28 12:03:22,858 - INFO - joeynmt.training - Epoch   2, Step:     4900, Batch Loss:     2.951772, Batch Acc: 0.243957, Tokens per Sec:    24542, Lr: 0.000300
2024-05-28 12:03:25,610 - INFO - joeynmt.training - Epoch   2, Step:     5000, Batch Loss:     2.847586, Batch Acc: 0.251226, Tokens per Sec:    25282, Lr: 0.000300
2024-05-28 12:03:25,610 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:03:25,611 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:03:34,162 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.88, ppl:  17.87, acc:   0.24, generation: 8.5327[sec], evaluation: 0.0000[sec]
2024-05-28 12:03:34,162 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:03:34,237 - INFO - joeynmt.helpers - delete models/bpe-vocab/2500.ckpt
2024-05-28 12:03:34,244 - INFO - joeynmt.training - Example #0
2024-05-28 12:03:34,244 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:03:34,245 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:03:34,245 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'we', 'were', 'in', 'the', 'first', 'time', 'in', 'the', 'last', 'time', 'that', 'we', 'have', 'been', 'in', 'the', 'United', 'Stat@@', 'es,', 'and', 'the', 'first', 'time', 'in', 'the', 'last', 'year', 'of', 'the', 'last', 'year', '--', 'in', 'the', 'last', 'year', 'year', 'after', 'a', 'year', 'year', 'in', 'the', 'last', 'year', 'of', 'the', 'last', 'year', 'of', 'the', 'last', 'year', 'year', 'after', '1@@', '5@@', '.', '</s>']
2024-05-28 12:03:34,245 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:03:34,245 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:03:34,245 - INFO - joeynmt.training - 	Hypothesis: And we were in the first time in the last time that we have been in the United States, and the first time in the last year of the last year -- in the last year year after a year year in the last year of the last year of the last year year after 15.
2024-05-28 12:03:34,245 - INFO - joeynmt.training - Example #1
2024-05-28 12:03:34,245 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:03:34,245 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:03:34,245 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'a', 'lot', 'of', 'the', 'things', 'that', 'are', 'the', 'most', 'important', 'thing', 'is', 'that', 'the', 'first', 'time', 'of', 'the', 'most', 'important', 'thing', 'is', 'that', 'the', 'most', 'important', 'thing', 'is', 'that', 'the', 'world.', '</s>']
2024-05-28 12:03:34,246 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:03:34,246 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:03:34,246 - INFO - joeynmt.training - 	Hypothesis: But this is a lot of the things that are the most important thing is that the first time of the most important thing is that the most important thing is that the world.
2024-05-28 12:03:34,246 - INFO - joeynmt.training - Example #2
2024-05-28 12:03:34,246 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:03:34,246 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:03:34,246 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'thing', 'is', 'that', 'the', 'first', 'thing', 'is', 'that', 'the', 'most', 'important', 'thing', 'is', 'that', 'the', 'most', 'important', 'thing', 'is', 'to', 'be', 'the', 'most', 'important', 'of', 'the', 'world.', '</s>']
2024-05-28 12:03:34,246 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:03:34,247 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:03:34,247 - INFO - joeynmt.training - 	Hypothesis: The first thing is that the first thing is that the most important thing is that the most important thing is to be the most important of the world.
2024-05-28 12:03:34,247 - INFO - joeynmt.training - Example #3
2024-05-28 12:03:34,247 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:03:34,247 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:03:34,247 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'he', 'was', 'the', 'same', 'time', 'to', 'be', 'able', 'to', 'be', 'able', 'to', 'be', 'the', 'same', 'thing.', '</s>']
2024-05-28 12:03:34,247 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:03:34,247 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:03:34,247 - INFO - joeynmt.training - 	Hypothesis: And he was the same time to be able to be able to be the same thing.
2024-05-28 12:03:34,247 - INFO - joeynmt.training - Example #4
2024-05-28 12:03:34,248 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:03:34,248 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:03:34,248 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'thing', 'is', 'that', 'the', 'first', 'time', 'to', 'do', 'you', 'know,', 'I', "don't", 'know', 'that', 'the', 'first', 'thing', 'is', 'that', 'we', 'have', 'been', 'in', 'the', 'last', 'year', 'to', 'the', 'last', 'year', 'to', 'the', 'last', 'year', 'year', 'to', 'the', 'last', 'two', 'years.', '</s>']
2024-05-28 12:03:34,248 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:03:34,248 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:03:34,248 - INFO - joeynmt.training - 	Hypothesis: The first thing is that the first time to do you know, I don't know that the first thing is that we have been in the last year to the last year to the last year year to the last two years.
2024-05-28 12:03:36,988 - INFO - joeynmt.training - Epoch   2, Step:     5100, Batch Loss:     2.912818, Batch Acc: 0.250949, Tokens per Sec:    23760, Lr: 0.000300
2024-05-28 12:03:39,752 - INFO - joeynmt.training - Epoch   2, Step:     5200, Batch Loss:     2.608967, Batch Acc: 0.255583, Tokens per Sec:    25251, Lr: 0.000300
2024-05-28 12:03:42,510 - INFO - joeynmt.training - Epoch   2, Step:     5300, Batch Loss:     2.723642, Batch Acc: 0.259266, Tokens per Sec:    25233, Lr: 0.000300
2024-05-28 12:03:45,262 - INFO - joeynmt.training - Epoch   2, Step:     5400, Batch Loss:     2.992032, Batch Acc: 0.260358, Tokens per Sec:    25219, Lr: 0.000300
2024-05-28 12:03:48,026 - INFO - joeynmt.training - Epoch   2, Step:     5500, Batch Loss:     2.846160, Batch Acc: 0.263374, Tokens per Sec:    25779, Lr: 0.000300
2024-05-28 12:03:48,026 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:03:48,026 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:03:54,230 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.84, ppl:  17.20, acc:   0.25, generation: 6.1895[sec], evaluation: 0.0000[sec]
2024-05-28 12:03:54,231 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:03:54,309 - INFO - joeynmt.helpers - delete models/bpe-vocab/3000.ckpt
2024-05-28 12:03:54,310 - INFO - joeynmt.training - Example #0
2024-05-28 12:03:54,310 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:03:54,310 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:03:54,310 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'the', '19@@', '6@@', '0@@', 's,', 'we', 'were', 'in', 'the', 'last', 'few', 'years', 'ago,', 'the', 'first', 'time', 'in', 'the', 'United', 'States', 'of', 'the', 'United', 'States', 'of', 'the', 'last', 'few', 'years', 'ago,', 'the', 'last', '10', 'years,', 'and', 'the', 'last', '10', 'years,', 'and', 'the', 'last', '10', 'years.', '</s>']
2024-05-28 12:03:54,311 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:03:54,311 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:03:54,311 - INFO - joeynmt.training - 	Hypothesis: In the 1960s, we were in the last few years ago, the first time in the United States of the United States of the last few years ago, the last 10 years, and the last 10 years, and the last 10 years.
2024-05-28 12:03:54,311 - INFO - joeynmt.training - Example #1
2024-05-28 12:03:54,311 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:03:54,311 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:03:54,311 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'the', 'first', 'thing', 'that', 'is', 'that', 'the', 'first', 'thing', 'that', 'is', 'that', 'we', "don't", 'have', 'a', 'little', 'bit', 'of', 'the', 'world.', '</s>']
2024-05-28 12:03:54,312 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:03:54,312 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:03:54,312 - INFO - joeynmt.training - 	Hypothesis: But the first thing that is that the first thing that is that we don't have a little bit of the world.
2024-05-28 12:03:54,312 - INFO - joeynmt.training - Example #2
2024-05-28 12:03:54,312 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:03:54,312 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:03:54,312 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'other', 'thing', 'is', 'that', 'the', 'first', 'one', 'of', 'the', 'most', 'important', 'thing', 'that', 'is', 'that', 'the', 'world', 'is', 'the', 'world.', '</s>']
2024-05-28 12:03:54,312 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:03:54,312 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:03:54,312 - INFO - joeynmt.training - 	Hypothesis: The other thing is that the first one of the most important thing that is that the world is the world.
2024-05-28 12:03:54,312 - INFO - joeynmt.training - Example #3
2024-05-28 12:03:54,313 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:03:54,313 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:03:54,313 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['He', 'was', 'the', 'same', 'and', 'they', 'are', 'the', 'same', 'thing.', '</s>']
2024-05-28 12:03:54,313 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:03:54,313 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:03:54,313 - INFO - joeynmt.training - 	Hypothesis: He was the same and they are the same thing.
2024-05-28 12:03:54,313 - INFO - joeynmt.training - Example #4
2024-05-28 12:03:54,313 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:03:54,313 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:03:54,313 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'one', 'of', 'the', 'first', 'thing', 'I', 'want', 'to', 'do', 'is', 'that', 'the', 'first', 'thing', 'that', 'we', 'have', 'to', 'be', 'the', 'last', '10', 'years', 'ago,', 'the', 'last', '10', 'years', 'ago.', '</s>']
2024-05-28 12:03:54,314 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:03:54,314 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:03:54,314 - INFO - joeynmt.training - 	Hypothesis: The first one of the first thing I want to do is that the first thing that we have to be the last 10 years ago, the last 10 years ago.
2024-05-28 12:03:57,062 - INFO - joeynmt.training - Epoch   2, Step:     5600, Batch Loss:     2.768550, Batch Acc: 0.263827, Tokens per Sec:    24556, Lr: 0.000300
2024-05-28 12:03:59,812 - INFO - joeynmt.training - Epoch   2, Step:     5700, Batch Loss:     2.929438, Batch Acc: 0.266764, Tokens per Sec:    25349, Lr: 0.000300
2024-05-28 12:04:02,569 - INFO - joeynmt.training - Epoch   2, Step:     5800, Batch Loss:     2.774242, Batch Acc: 0.264910, Tokens per Sec:    25424, Lr: 0.000300
2024-05-28 12:04:05,293 - INFO - joeynmt.training - Epoch   2, Step:     5900, Batch Loss:     2.760989, Batch Acc: 0.270071, Tokens per Sec:    24047, Lr: 0.000300
2024-05-28 12:04:08,048 - INFO - joeynmt.training - Epoch   2, Step:     6000, Batch Loss:     2.752879, Batch Acc: 0.272043, Tokens per Sec:    25408, Lr: 0.000300
2024-05-28 12:04:08,048 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:04:08,048 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:04:15,118 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.81, ppl:  16.55, acc:   0.26, generation: 7.0524[sec], evaluation: 0.0000[sec]
2024-05-28 12:04:15,118 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:04:15,192 - INFO - joeynmt.helpers - delete models/bpe-vocab/3500.ckpt
2024-05-28 12:04:15,193 - INFO - joeynmt.training - Example #0
2024-05-28 12:04:15,193 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:04:15,193 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:04:15,193 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'we', 'have', 'been', 'working', 'on', 'the', 'first', 'of', 'the', 'first', 'time', 'that', 'the', 'most', 'of', 'the', 'people', 'that', 'are', 'the', 're@@', 'mark@@', 'able', 'of', 'the', 'most', 'of', 'the', 'most', 'of', 'the', 'first', 'time', 'in', 'the', 'first', 'of', 'the', 'first', 'time', 'in', 'the', 'last', 'year', 'in', 'the', 'first', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'of', 'the', 'first', 'time', 'of', 'the', 'first', 'time.', '</s>']
2024-05-28 12:04:15,193 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:04:15,194 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:04:15,194 - INFO - joeynmt.training - 	Hypothesis: And we have been working on the first of the first time that the most of the people that are the remarkable of the most of the most of the first time in the first of the first time in the last year in the first of the first time of the first time of the first time of the first time of the first time of the first of the first time of the first time.
2024-05-28 12:04:15,194 - INFO - joeynmt.training - Example #1
2024-05-28 12:04:15,194 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:04:15,194 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:04:15,194 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'same', 'way', 'of', 'the', 'most', 'important', 'thing', 'that', 'is', 'that', 'the', 'most', 'of', 'the', 'most', 'of', 'the', 'other', 'wor@@', 'ds,', 'but', 'it', 'is', 'not', 'the', 're@@', 'mark@@', 'ab@@', 'ly', 'of', 'the', 's@@', 'ou@@', 'th.', '</s>']
2024-05-28 12:04:15,194 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:04:15,194 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:04:15,194 - INFO - joeynmt.training - 	Hypothesis: But this is the same way of the most important thing that is that the most of the most of the other words, but it is not the remarkably of the south.
2024-05-28 12:04:15,194 - INFO - joeynmt.training - Example #2
2024-05-28 12:04:15,195 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:04:15,195 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:04:15,195 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'r@@', 'ange', 'of', 'the', 'r@@', 'ange', 'of', 'a', 'new', 'way', 'of', 'the', 'most', 'of', 'the', 'other', 'side', 'of', 'the', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world.', '</s>']
2024-05-28 12:04:15,195 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:04:15,195 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:04:15,195 - INFO - joeynmt.training - 	Hypothesis: The range of the range of a new way of the most of the other side of the the world of the world of the world of the world.
2024-05-28 12:04:15,195 - INFO - joeynmt.training - Example #3
2024-05-28 12:04:15,195 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:04:15,195 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:04:15,195 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'the', 'same', 'and', 'the', 'f@@', 'ing@@', 'ers', 'and', 'the', 's@@', 'ea', 'of', 'the', 's@@', 'hap@@', 'e.', '</s>']
2024-05-28 12:04:15,196 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:04:15,196 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:04:15,196 - INFO - joeynmt.training - 	Hypothesis: It was the same and the fingers and the sea of the shape.
2024-05-28 12:04:15,196 - INFO - joeynmt.training - Example #4
2024-05-28 12:04:15,196 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:04:15,196 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:04:15,196 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'thing', 'I', 'can', 'tell', 'you', 'that', 'you', 'can', 'see', 'if', 'you', "don't", 'have', 'a', 'little', 'bit', 'about', 'the', 'first', 'time', 'to', 'do', 'that', 'in', 'the', 'first', 'time', 'in', 'the', 'world', 'in', 'the', 'world', 'in', 'the', 'world', 'in', 'the', 'first', 'time', 'in', 'the', 'world', 'in', 'the', 'world', 'in', 'the', 'first', 'time', 'of', 'the', 'first', 'time.', '</s>']
2024-05-28 12:04:15,196 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:04:15,197 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:04:15,197 - INFO - joeynmt.training - 	Hypothesis: The first thing I can tell you that you can see if you don't have a little bit about the first time to do that in the first time in the world in the world in the world in the first time in the world in the world in the first time of the first time.
2024-05-28 12:04:17,946 - INFO - joeynmt.training - Epoch   2, Step:     6100, Batch Loss:     2.888703, Batch Acc: 0.269735, Tokens per Sec:    23857, Lr: 0.000300
2024-05-28 12:04:20,702 - INFO - joeynmt.training - Epoch   2, Step:     6200, Batch Loss:     2.747784, Batch Acc: 0.270920, Tokens per Sec:    25238, Lr: 0.000300
2024-05-28 12:04:23,444 - INFO - joeynmt.training - Epoch   2, Step:     6300, Batch Loss:     2.634450, Batch Acc: 0.274692, Tokens per Sec:    24744, Lr: 0.000300
2024-05-28 12:04:26,192 - INFO - joeynmt.training - Epoch   2, Step:     6400, Batch Loss:     2.825396, Batch Acc: 0.272962, Tokens per Sec:    24840, Lr: 0.000300
2024-05-28 12:04:28,961 - INFO - joeynmt.training - Epoch   2, Step:     6500, Batch Loss:     2.507555, Batch Acc: 0.275435, Tokens per Sec:    25547, Lr: 0.000300
2024-05-28 12:04:28,961 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:04:28,961 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:04:36,828 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.76, ppl:  15.85, acc:   0.27, generation: 7.8517[sec], evaluation: 0.0000[sec]
2024-05-28 12:04:36,829 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:04:36,913 - INFO - joeynmt.helpers - delete models/bpe-vocab/4000.ckpt
2024-05-28 12:04:36,922 - INFO - joeynmt.training - Example #0
2024-05-28 12:04:36,923 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:04:36,923 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:04:36,923 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'one', 'of', 'the', 'two', 'years', 'of', 'the', 'first', 'time', 'that', 'I', 'was', 'going', 'to', 'be', 'a', 'little', 'bit', 'of', 'the', 'first', 'time', 'in', 'the', 'last', 'few', 'years', 'ago.', '</s>']
2024-05-28 12:04:36,923 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:04:36,923 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:04:36,923 - INFO - joeynmt.training - 	Hypothesis: The first one of the two years of the first time that I was going to be a little bit of the first time in the last few years ago.
2024-05-28 12:04:36,923 - INFO - joeynmt.training - Example #1
2024-05-28 12:04:36,923 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:04:36,923 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:04:36,923 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'was', 'the', 's@@', 'un', 'of', 'the', 'most', 'of', 'the', 'things', 'that', 'you', 'have', 'no', 'idea', 'that', 'you', "don't", 'have', 'a', 'lot', 'of', 'the', 's@@', 'hap@@', 'e.', '</s>']
2024-05-28 12:04:36,924 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:04:36,924 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:04:36,924 - INFO - joeynmt.training - 	Hypothesis: But this was the sun of the most of the things that you have no idea that you don't have a lot of the shape.
2024-05-28 12:04:36,924 - INFO - joeynmt.training - Example #2
2024-05-28 12:04:36,924 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:04:36,924 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:04:36,924 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'second', 'is', 'the', 'most', 'of', 'the', 'first', 'time', 'of', 'the', 'world', 'is', 'a', 'new', 'world', 'of', 'the', 'world.', '</s>']
2024-05-28 12:04:36,925 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:04:36,925 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:04:36,925 - INFO - joeynmt.training - 	Hypothesis: The second is the most of the first time of the world is a new world of the world.
2024-05-28 12:04:36,925 - INFO - joeynmt.training - Example #3
2024-05-28 12:04:36,925 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:04:36,925 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:04:36,925 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['He', 'was', 'the', 'first', 'time', 'and', 'he', 'was', 'the', 's@@', 'mo@@', 'k@@', 'e.', '</s>']
2024-05-28 12:04:36,925 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:04:36,925 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:04:36,925 - INFO - joeynmt.training - 	Hypothesis: He was the first time and he was the smoke.
2024-05-28 12:04:36,925 - INFO - joeynmt.training - Example #4
2024-05-28 12:04:36,926 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:04:36,926 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:04:36,926 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'thing', 'that', 'you', 'have', 'to', 'be', 'able', 'to', 'be', 'a', 'little', 'bit', 'of', 'the', 'first', 'thing', 'that', 'I', 'was', 'going', 'to', 'be', 'the', 'last', '10', 'years', 'ago.', '</s>']
2024-05-28 12:04:36,926 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:04:36,926 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:04:36,926 - INFO - joeynmt.training - 	Hypothesis: The first thing that you have to be able to be a little bit of the first thing that I was going to be the last 10 years ago.
2024-05-28 12:04:39,683 - INFO - joeynmt.training - Epoch   2, Step:     6600, Batch Loss:     2.736154, Batch Acc: 0.276299, Tokens per Sec:    23620, Lr: 0.000300
2024-05-28 12:04:42,433 - INFO - joeynmt.training - Epoch   2, Step:     6700, Batch Loss:     2.822397, Batch Acc: 0.274157, Tokens per Sec:    25088, Lr: 0.000300
2024-05-28 12:04:45,190 - INFO - joeynmt.training - Epoch   2, Step:     6800, Batch Loss:     2.716495, Batch Acc: 0.281422, Tokens per Sec:    24792, Lr: 0.000300
2024-05-28 12:04:47,942 - INFO - joeynmt.training - Epoch   2, Step:     6900, Batch Loss:     2.575410, Batch Acc: 0.285511, Tokens per Sec:    24729, Lr: 0.000300
2024-05-28 12:04:50,695 - INFO - joeynmt.training - Epoch   2, Step:     7000, Batch Loss:     2.572292, Batch Acc: 0.286823, Tokens per Sec:    25320, Lr: 0.000300
2024-05-28 12:04:50,695 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:04:50,695 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:04:59,001 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.73, ppl:  15.41, acc:   0.28, generation: 8.2884[sec], evaluation: 0.0000[sec]
2024-05-28 12:04:59,002 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:04:59,087 - INFO - joeynmt.helpers - delete models/bpe-vocab/4500.ckpt
2024-05-28 12:04:59,097 - INFO - joeynmt.training - Example #0
2024-05-28 12:04:59,097 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:04:59,097 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:04:59,097 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'was', 'the', 'first', 'of', 'the', 'two', 'of', 'the', 'most', 'important', 'thing', 'that', 'the', 'most', 'important', 'thing', 'to', 'the', 'most', 'important', 'thing', 'to', 'the', 'most', 'important', 'thing', 'to', 'the', 'most', 'important', 'thing', 'to', 'the', 'first', 'one', 'of', 'the', 'first', 'one', 'of', 'the', 'two', 'million', 'years', 'ago.', '</s>']
2024-05-28 12:04:59,097 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:04:59,097 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:04:59,097 - INFO - joeynmt.training - 	Hypothesis: The first was the first of the two of the most important thing that the most important thing to the most important thing to the most important thing to the most important thing to the first one of the first one of the two million years ago.
2024-05-28 12:04:59,097 - INFO - joeynmt.training - Example #1
2024-05-28 12:04:59,098 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:04:59,098 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:04:59,098 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'was', 'the', 'most', 'important', 'thing', 'that', 'the', 'most', 'important', 'thing', 'that', 'is', 'not', 'only', 'the', 'de@@', 'si@@', 're', 'that', 'is', 'not', 'the', 'de@@', 'si@@', 're', 'of', 'the', 'w@@', 'il@@', 'd@@', 'ly', 'of', 'the', 'w@@', 'il@@', 'd.', '</s>']
2024-05-28 12:04:59,098 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:04:59,098 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:04:59,098 - INFO - joeynmt.training - 	Hypothesis: But this was the most important thing that the most important thing that is not only the desire that is not the desire of the wildly of the wild.
2024-05-28 12:04:59,098 - INFO - joeynmt.training - Example #2
2024-05-28 12:04:59,098 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:04:59,098 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:04:59,098 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'most', 'important', 'thing', 'is', 'the', 'most', 'important', 'thing', 'to', 'the', 'most', 'important', 'thing', 'to', 'the', 'world', 'in', 'the', 'world.', '</s>']
2024-05-28 12:04:59,099 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:04:59,099 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:04:59,099 - INFO - joeynmt.training - 	Hypothesis: The most important thing is the most important thing to the most important thing to the world in the world.
2024-05-28 12:04:59,099 - INFO - joeynmt.training - Example #3
2024-05-28 12:04:59,099 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:04:59,099 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:04:59,099 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['He', 'had', 'the', 'same', 'way', 'to', 'be', 'the', 'de@@', 'pres@@', 'si@@', 'on.', '</s>']
2024-05-28 12:04:59,100 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:04:59,100 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:04:59,100 - INFO - joeynmt.training - 	Hypothesis: He had the same way to be the depression.
2024-05-28 12:04:59,100 - INFO - joeynmt.training - Example #4
2024-05-28 12:04:59,100 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:04:59,100 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:04:59,100 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'one', 'of', 'the', 'de@@', 'si@@', 're', 'that', 'I', 'will', 'be', 'a', 'very', 'important', 'thing', 'to', 'do', 'to', 'the', 'same', 'thing', 'that', 'the', 'first', 'thing', 'that', 'was', 'the', 'first', 'thing', 'that', 'was', 'the', 'first', 'thing', 'that', 'we', 'have', 'to', 'do', 'about', 'the', 'last', '10', 'years.', '</s>']
2024-05-28 12:04:59,100 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:04:59,100 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:04:59,100 - INFO - joeynmt.training - 	Hypothesis: The first one of the desire that I will be a very important thing to do to the same thing that the first thing that was the first thing that was the first thing that we have to do about the last 10 years.
2024-05-28 12:05:01,835 - INFO - joeynmt.training - Epoch   2, Step:     7100, Batch Loss:     2.634753, Batch Acc: 0.289687, Tokens per Sec:    23266, Lr: 0.000300
2024-05-28 12:05:04,590 - INFO - joeynmt.training - Epoch   2, Step:     7200, Batch Loss:     2.763247, Batch Acc: 0.286627, Tokens per Sec:    25402, Lr: 0.000300
2024-05-28 12:05:07,349 - INFO - joeynmt.training - Epoch   2, Step:     7300, Batch Loss:     2.711898, Batch Acc: 0.288710, Tokens per Sec:    25114, Lr: 0.000300
2024-05-28 12:05:10,113 - INFO - joeynmt.training - Epoch   2, Step:     7400, Batch Loss:     2.407177, Batch Acc: 0.296336, Tokens per Sec:    25116, Lr: 0.000300
2024-05-28 12:05:12,856 - INFO - joeynmt.training - Epoch   2, Step:     7500, Batch Loss:     2.676622, Batch Acc: 0.289571, Tokens per Sec:    24717, Lr: 0.000300
2024-05-28 12:05:12,856 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:05:12,856 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:05:20,987 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.70, ppl:  14.90, acc:   0.28, generation: 8.1131[sec], evaluation: 0.0000[sec]
2024-05-28 12:05:20,988 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:05:21,081 - INFO - joeynmt.helpers - delete models/bpe-vocab/5000.ckpt
2024-05-28 12:05:21,084 - INFO - joeynmt.training - Example #0
2024-05-28 12:05:21,084 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:05:21,084 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:05:21,084 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'the', 'first', 'of', 'the', 'two', 'of', 'the', 'most', 'of', 'the', 'most', 'important', 'thing', 'that', 'the', 're@@', 'mark@@', 'able', 'of', 'the', 'most', 'of', 'the', 'most', 'of', 'the', 'most', 'of', 'the', 'most', 'of', 'the', 'most', 'of', 'the', 'most', 'important', 'thing', 'about', 'two', 'million', 'dollars', 'per', 'per', 'year.', '</s>']
2024-05-28 12:05:21,085 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:05:21,085 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:05:21,085 - INFO - joeynmt.training - 	Hypothesis: And I was the first of the two of the most of the most important thing that the remarkable of the most of the most of the most of the most of the most of the most important thing about two million dollars per per year.
2024-05-28 12:05:21,085 - INFO - joeynmt.training - Example #1
2024-05-28 12:05:21,085 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:05:21,085 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:05:21,085 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'f@@', 'un', 'is', 'the', 'most', 'important', 'thing', 'that', 'is', 'that', 'the', 'most', 'important', 'thing', 'that', 'is', 'not', 'the', 'de@@', 'pres@@', 'si@@', 'on.', '</s>']
2024-05-28 12:05:21,086 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:05:21,086 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:05:21,086 - INFO - joeynmt.training - 	Hypothesis: But this is the fun is the most important thing that is that the most important thing that is not the depression.
2024-05-28 12:05:21,086 - INFO - joeynmt.training - Example #2
2024-05-28 12:05:21,086 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:05:21,086 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:05:21,086 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'r@@', 'ange', 'of', 'the', 'brain', 'is', 'a', 'very', 'important', 'thing', 'that', 'is', 'that', 'the', 'most', 'important', 'thing', 'is', 'the', 'most', 'important', 'world.', '</s>']
2024-05-28 12:05:21,086 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:05:21,086 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:05:21,086 - INFO - joeynmt.training - 	Hypothesis: The range of the brain is a very important thing that is that the most important thing is the most important world.
2024-05-28 12:05:21,086 - INFO - joeynmt.training - Example #3
2024-05-28 12:05:21,087 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:05:21,087 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:05:21,087 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['He', 'had', 'the', 'same', 'way', 'and', 'the', 'de@@', 'pres@@', 'si@@', 'on.', '</s>']
2024-05-28 12:05:21,087 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:05:21,087 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:05:21,087 - INFO - joeynmt.training - 	Hypothesis: He had the same way and the depression.
2024-05-28 12:05:21,087 - INFO - joeynmt.training - Example #4
2024-05-28 12:05:21,087 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:05:21,087 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:05:21,087 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'thing', 'that', 'the', 'f@@', 'un', 'that', 'I', 'will', 'be', 'able', 'to', 'be', 'a', 'very', 'good', 'way', 'that', 'I', 'have', 'to', 'do', 'with', 'the', 'same', 'thing', 'that', 'in', 'the', 'last', '20', 'years.', '</s>']
2024-05-28 12:05:21,088 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:05:21,088 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:05:21,088 - INFO - joeynmt.training - 	Hypothesis: The first thing that the fun that I will be able to be a very good way that I have to do with the same thing that in the last 20 years.
2024-05-28 12:05:23,842 - INFO - joeynmt.training - Epoch   2, Step:     7600, Batch Loss:     2.855119, Batch Acc: 0.291250, Tokens per Sec:    23464, Lr: 0.000300
2024-05-28 12:05:26,602 - INFO - joeynmt.training - Epoch   2, Step:     7700, Batch Loss:     2.583165, Batch Acc: 0.296655, Tokens per Sec:    25035, Lr: 0.000300
2024-05-28 12:05:29,338 - INFO - joeynmt.training - Epoch   2, Step:     7800, Batch Loss:     2.617570, Batch Acc: 0.296997, Tokens per Sec:    24571, Lr: 0.000300
2024-05-28 12:05:30,330 - INFO - joeynmt.training - Epoch   2: total training loss 10855.34
2024-05-28 12:05:30,334 - INFO - joeynmt.training - EPOCH 3
2024-05-28 12:05:32,104 - INFO - joeynmt.training - Epoch   3, Step:     7900, Batch Loss:     2.464183, Batch Acc: 0.307745, Tokens per Sec:    24111, Lr: 0.000300
2024-05-28 12:05:34,848 - INFO - joeynmt.training - Epoch   3, Step:     8000, Batch Loss:     2.544980, Batch Acc: 0.308955, Tokens per Sec:    24524, Lr: 0.000300
2024-05-28 12:05:34,852 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:05:34,855 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:05:43,423 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.67, ppl:  14.49, acc:   0.30, generation: 8.5480[sec], evaluation: 0.0000[sec]
2024-05-28 12:05:43,427 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:05:43,517 - INFO - joeynmt.helpers - delete models/bpe-vocab/5500.ckpt
2024-05-28 12:05:43,525 - INFO - joeynmt.training - Example #0
2024-05-28 12:05:43,529 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:05:43,529 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:05:43,529 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'the', 'last', 'few', 'years', 'of', 'the', 'most', 'important', 'thing', 'to', 'do', 'is', 'that', 'in', 'the', 'f@@', 'ish', 'of', 'the', 'r@@', 'ole', 'of', 'the', 'last', 'few', 'years,', 'which', 'is', 'the', 'last', '10', 'years,', 'which', 'was', 'a', 'few', 'years', 'ol@@', 'd,', 'which', 'was', 'a', 'few', 'years', 'ol@@', 'd,', 'the', 'last', '10', 'years.', '</s>']
2024-05-28 12:05:43,530 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:05:43,545 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:05:43,548 - INFO - joeynmt.training - 	Hypothesis: And I was the last few years of the most important thing to do is that in the fish of the role of the last few years, which is the last 10 years, which was a few years old, which was a few years old, the last 10 years.
2024-05-28 12:05:43,552 - INFO - joeynmt.training - Example #1
2024-05-28 12:05:43,555 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:05:43,555 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:05:43,555 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'most', 'important', 'thing', 'that', 'is', 'that', 'that', 'it', "doesn't", 'have', 'no', 'longer', 'the', 're@@', 'mark@@', 'able', 'of', 'the', 'de@@', 'b@@', 'ate', 'of', 'the', 'de@@', 'b@@', 'ate', 'of', 'the', 'de@@', 'b@@', 'er.', '</s>']
2024-05-28 12:05:43,556 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:05:43,559 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:05:43,562 - INFO - joeynmt.training - 	Hypothesis: But this is the most important thing that is that that it doesn't have no longer the remarkable of the debate of the debate of the deber.
2024-05-28 12:05:43,565 - INFO - joeynmt.training - Example #2
2024-05-28 12:05:43,568 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:05:43,568 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:05:43,568 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'other', 'in@@', 'iti@@', 'ation', 'is', 'a', 'lot', 'of', 'the', 'most', 'important', 'thing', 'to', 'do', 'with', 'the', 'system@@', '.', '</s>']
2024-05-28 12:05:43,569 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:05:43,571 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:05:43,574 - INFO - joeynmt.training - 	Hypothesis: The other initiation is a lot of the most important thing to do with the system.
2024-05-28 12:05:43,577 - INFO - joeynmt.training - Example #3
2024-05-28 12:05:43,605 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:05:43,605 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:05:43,605 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['He', 'was', 'the', 'most', 'of', 'the', 'de@@', 'ep', 'and', 'the', 'way', 'of', 'the', 'de@@', 'ep', '</s>']
2024-05-28 12:05:43,606 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:05:43,609 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:05:43,612 - INFO - joeynmt.training - 	Hypothesis: He was the most of the deep and the way of the deep
2024-05-28 12:05:43,615 - INFO - joeynmt.training - Example #4
2024-05-28 12:05:43,618 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:05:43,618 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:05:43,618 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'one', 'of', 'the', 'way', 'that', 'I', 'want', 'to', 'do', 'a', 'lot', 'of', 'a', 'very', 'small', 'amount', 'of', 'time', 'to', 'do', 'this', 'in', 'the', 'last', '10', 'years.', '</s>']
2024-05-28 12:05:43,619 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:05:43,622 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:05:43,624 - INFO - joeynmt.training - 	Hypothesis: The first one of the way that I want to do a lot of a very small amount of time to do this in the last 10 years.
2024-05-28 12:05:46,382 - INFO - joeynmt.training - Epoch   3, Step:     8100, Batch Loss:     2.673365, Batch Acc: 0.306551, Tokens per Sec:    22897, Lr: 0.000300
2024-05-28 12:05:49,128 - INFO - joeynmt.training - Epoch   3, Step:     8200, Batch Loss:     2.646038, Batch Acc: 0.307477, Tokens per Sec:    24523, Lr: 0.000300
2024-05-28 12:05:51,875 - INFO - joeynmt.training - Epoch   3, Step:     8300, Batch Loss:     2.418568, Batch Acc: 0.306253, Tokens per Sec:    25056, Lr: 0.000300
2024-05-28 12:05:54,660 - INFO - joeynmt.training - Epoch   3, Step:     8400, Batch Loss:     2.403134, Batch Acc: 0.314397, Tokens per Sec:    25190, Lr: 0.000300
2024-05-28 12:05:57,417 - INFO - joeynmt.training - Epoch   3, Step:     8500, Batch Loss:     2.491643, Batch Acc: 0.313940, Tokens per Sec:    24884, Lr: 0.000300
2024-05-28 12:05:57,422 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:05:57,425 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:06:05,600 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.64, ppl:  14.05, acc:   0.30, generation: 8.1543[sec], evaluation: 0.0000[sec]
2024-05-28 12:06:05,604 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:06:05,695 - INFO - joeynmt.helpers - delete models/bpe-vocab/6000.ckpt
2024-05-28 12:06:05,744 - INFO - joeynmt.training - Example #0
2024-05-28 12:06:05,749 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:06:05,749 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:06:05,749 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'one', 'I', 'was', 'the', 'two', 'of', 'these', 'two', 'years', 'of', 'the', 'most', 'of', 'the', 's@@', 'am@@', 'p', 'of', 'the', 'ma@@', 'p', 'of', 'the', 'first', 'of', 'the', 'last', 'two', 'years', 'of', 'the', 'last', 'two', 'years', 'of', 'the', 'last', 'two', 'years', 'of', 'the', 'last', 'two', 'years', 'of', 'a', 'half', 'of', 'the', 'last', 'two', 'years', 'of', 'a', 'million', 'dollars', 'of', 'a', 'year', 'in', 'the', 'last', 'two', 'years.', '</s>']
2024-05-28 12:06:05,749 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:06:05,752 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:06:05,756 - INFO - joeynmt.training - 	Hypothesis: The first one I was the two of these two years of the most of the samp of the map of the first of the last two years of the last two years of the last two years of the last two years of a half of the last two years of a million dollars of a year in the last two years.
2024-05-28 12:06:05,759 - INFO - joeynmt.training - Example #1
2024-05-28 12:06:05,763 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:06:05,763 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:06:05,763 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 's@@', 'hap@@', 'es', 'of', 'this', 'is', 'the', 'most', 'important', 'thing', 'that', 'it', "doesn't", 'have', 'the', 'same', 'co@@', 'ver', 'of', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:06:05,763 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:06:05,780 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:06:05,783 - INFO - joeynmt.training - 	Hypothesis: But this is the shapes of this is the most important thing that it doesn't have the same cover of the same.
2024-05-28 12:06:05,800 - INFO - joeynmt.training - Example #2
2024-05-28 12:06:05,803 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:06:05,803 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:06:05,803 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'S@@', 'ci@@', 'ence', 'is', 'a', 'a', 'little', 'bit', 'of', 'a', 'little', 'b@@', 'ase', 'of', 'the', 'system', 'of', 'the', 'system@@', '.', '</s>']
2024-05-28 12:06:05,804 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:06:05,807 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:06:05,810 - INFO - joeynmt.training - 	Hypothesis: The Science is a a little bit of a little base of the system of the system.
2024-05-28 12:06:05,835 - INFO - joeynmt.training - Example #3
2024-05-28 12:06:05,844 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:06:05,844 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:06:05,844 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['He', 'has', 'the', 's@@', 'am@@', 'e,', 'and', 'the', 're@@', 'sist@@', 's', 'and', 'the', 's@@', 'et.', '</s>']
2024-05-28 12:06:05,845 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:06:05,848 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:06:05,852 - INFO - joeynmt.training - 	Hypothesis: He has the same, and the resists and the set.
2024-05-28 12:06:05,854 - INFO - joeynmt.training - Example #4
2024-05-28 12:06:05,858 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:06:05,858 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:06:05,858 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'thing', 'that', 'I', 'want', 'to', 'do', 'is', 'to', 'be', 'a', 'very', 'simple', 'that', 'I', 'would', 'be', 'a', 'little', 'bit', 'of', 'the', 'last', 'two', 'years', 'of', 'the', 'last', '10', 'years', 'of', 'the', 'last', '10', 'years.', '</s>']
2024-05-28 12:06:05,858 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:06:05,861 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:06:05,864 - INFO - joeynmt.training - 	Hypothesis: The next thing that I want to do is to be a very simple that I would be a little bit of the last two years of the last 10 years of the last 10 years.
2024-05-28 12:06:08,659 - INFO - joeynmt.training - Epoch   3, Step:     8600, Batch Loss:     2.506848, Batch Acc: 0.315205, Tokens per Sec:    22921, Lr: 0.000300
2024-05-28 12:06:11,383 - INFO - joeynmt.training - Epoch   3, Step:     8700, Batch Loss:     2.504234, Batch Acc: 0.309760, Tokens per Sec:    23445, Lr: 0.000300
2024-05-28 12:06:14,131 - INFO - joeynmt.training - Epoch   3, Step:     8800, Batch Loss:     2.778426, Batch Acc: 0.313643, Tokens per Sec:    24453, Lr: 0.000300
2024-05-28 12:06:16,893 - INFO - joeynmt.training - Epoch   3, Step:     8900, Batch Loss:     2.507596, Batch Acc: 0.318281, Tokens per Sec:    25262, Lr: 0.000300
2024-05-28 12:06:19,667 - INFO - joeynmt.training - Epoch   3, Step:     9000, Batch Loss:     2.399571, Batch Acc: 0.323614, Tokens per Sec:    25568, Lr: 0.000300
2024-05-28 12:06:19,671 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:06:19,674 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:06:27,577 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.62, ppl:  13.67, acc:   0.31, generation: 7.8571[sec], evaluation: 0.0000[sec]
2024-05-28 12:06:27,582 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:06:27,664 - INFO - joeynmt.helpers - delete models/bpe-vocab/6500.ckpt
2024-05-28 12:06:27,677 - INFO - joeynmt.training - Example #0
2024-05-28 12:06:27,680 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:06:27,681 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:06:27,681 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'thing', 'I', 'was', 'the', 'two', 'of', 'the', 'two', 'of', 'the', 'most', 'important', 'thing', 'to', 'the', 'f@@', 'os@@', 'si@@', 'l', 'of', 'the', 'de@@', 'ath', 'of', 'the', 'most', 'important', 'thing', 'that', 'was', 'about', 'the', 'last', 'year', 'of', 'the', 'last', '10', 'years,', 'in', 'the', 'last', 'dec@@', 'a@@', 'de', 'of', 'the', 'last', 'year.', '</s>']
2024-05-28 12:06:27,681 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:06:27,684 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:06:27,688 - INFO - joeynmt.training - 	Hypothesis: The first thing I was the two of the two of the most important thing to the fossil of the death of the most important thing that was about the last year of the last 10 years, in the last decade of the last year.
2024-05-28 12:06:27,691 - INFO - joeynmt.training - Example #1
2024-05-28 12:06:27,694 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:06:27,694 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:06:27,694 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'great', 'ide@@', 'al', 'of', 'the', 'most', 'important', 'thing', 'that', 'is', 'not', 'the', 'most', 'important', 'thing', 'of', 'the', 'f@@', 'os@@', 'si@@', 'l', 'of', 'the', 'n@@', 'an@@', 'om@@', 'or@@', 'ro@@', 'om@@', 's.', '</s>']
2024-05-28 12:06:27,695 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:06:27,698 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:06:27,709 - INFO - joeynmt.training - 	Hypothesis: But this is the great ideal of the most important thing that is not the most important thing of the fossil of the nanomorrooms.
2024-05-28 12:06:27,712 - INFO - joeynmt.training - Example #2
2024-05-28 12:06:27,716 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:06:27,716 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:06:27,716 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'r@@', 'ange', 'of', 'the', 'f@@', 'os@@', 'si@@', 'l', 'of', 'a', 'very', 'simple', 'system@@', ',', 'which', 'is', 'the', 'system@@', '.', '</s>']
2024-05-28 12:06:27,716 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:06:27,719 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:06:27,742 - INFO - joeynmt.training - 	Hypothesis: The range of the fossil of a very simple system, which is the system.
2024-05-28 12:06:27,745 - INFO - joeynmt.training - Example #3
2024-05-28 12:06:27,748 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:06:27,748 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:06:27,748 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['He', 'got', 'the', 'way', 'to', 'the', 'de@@', 'ath', 'of', 'the', 'de@@', 'ath', 'of', 'the', 'w@@', 'all.', '</s>']
2024-05-28 12:06:27,749 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:06:27,752 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:06:27,756 - INFO - joeynmt.training - 	Hypothesis: He got the way to the death of the death of the wall.
2024-05-28 12:06:27,759 - INFO - joeynmt.training - Example #4
2024-05-28 12:06:27,762 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:06:27,762 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:06:27,762 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'thing', 'about', 'the', 'great', 'thing', 'that', 'you', 'would', 'have', 'to', 'be', 'a', 'very', 'simple', 'way', 'to', 'do', 'what', 'happened', 'to', 'the', 'next', 'thing', 'about', 'the', 'last', 'year.', '</s>']
2024-05-28 12:06:27,763 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:06:27,766 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:06:27,769 - INFO - joeynmt.training - 	Hypothesis: The next thing about the great thing that you would have to be a very simple way to do what happened to the next thing about the last year.
2024-05-28 12:06:30,563 - INFO - joeynmt.training - Epoch   3, Step:     9100, Batch Loss:     2.519057, Batch Acc: 0.320809, Tokens per Sec:    23327, Lr: 0.000300
2024-05-28 12:06:33,309 - INFO - joeynmt.training - Epoch   3, Step:     9200, Batch Loss:     2.562467, Batch Acc: 0.318656, Tokens per Sec:    24046, Lr: 0.000300
2024-05-28 12:06:36,102 - INFO - joeynmt.training - Epoch   3, Step:     9300, Batch Loss:     2.492409, Batch Acc: 0.320882, Tokens per Sec:    24847, Lr: 0.000300
2024-05-28 12:06:38,871 - INFO - joeynmt.training - Epoch   3, Step:     9400, Batch Loss:     2.375785, Batch Acc: 0.320351, Tokens per Sec:    24637, Lr: 0.000300
2024-05-28 12:06:41,634 - INFO - joeynmt.training - Epoch   3, Step:     9500, Batch Loss:     2.516649, Batch Acc: 0.325955, Tokens per Sec:    24438, Lr: 0.000300
2024-05-28 12:06:41,638 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:06:41,641 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:06:49,120 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.59, ppl:  13.34, acc:   0.32, generation: 7.4585[sec], evaluation: 0.0000[sec]
2024-05-28 12:06:49,124 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:06:49,222 - INFO - joeynmt.helpers - delete models/bpe-vocab/7000.ckpt
2024-05-28 12:06:49,237 - INFO - joeynmt.training - Example #0
2024-05-28 12:06:49,256 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:06:49,256 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:06:49,257 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'year', 'I', 'was', 'the', 'two', 'of', 'the', 'two', 'of', 'the', 'most', 'important', 'thing', 'that', 'is', 'that', 'the', 'r@@', 'ole', 'of', 'the', 'f@@', 'ing@@', 'er@@', 'r@@', 'or', 'of', 'the', 'most', 'of', 'the', 'most', 'most', 'people', 'in', 'the', 'last', 'two', 'years.', '</s>']
2024-05-28 12:06:49,257 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:06:49,260 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:06:49,264 - INFO - joeynmt.training - 	Hypothesis: The first year I was the two of the two of the most important thing that is that the role of the fingerror of the most of the most most people in the last two years.
2024-05-28 12:06:49,276 - INFO - joeynmt.training - Example #1
2024-05-28 12:06:49,280 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:06:49,280 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:06:49,280 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'most', 'important', 'of', 'the', 'most', 'important', 'problem', 'because', 'the', 'most', 'important', 'thing', 'that', 'it', "doesn't", 'have', 'the', 'r@@', 'ole', 'of', 'the', 'ro@@', 'om.', '</s>']
2024-05-28 12:06:49,280 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:06:49,283 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:06:49,286 - INFO - joeynmt.training - 	Hypothesis: But this is the most important of the most important problem because the most important thing that it doesn't have the role of the room.
2024-05-28 12:06:49,290 - INFO - joeynmt.training - Example #2
2024-05-28 12:06:49,293 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:06:49,293 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:06:49,293 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'P@@', 'an@@', 'ci@@', 'ent', 'is', 'a', 're@@', 'mark@@', 'able', 'of', 'a', 'system', 'that', 'has', 'been', 'the', 'evolu@@', 'tion', 'of', 'the', 'system@@', '.', '</s>']
2024-05-28 12:06:49,293 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:06:49,318 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:06:49,321 - INFO - joeynmt.training - 	Hypothesis: The Pancient is a remarkable of a system that has been the evolution of the system.
2024-05-28 12:06:49,324 - INFO - joeynmt.training - Example #3
2024-05-28 12:06:49,328 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:06:49,328 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:06:49,328 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['He', 'was', 'the', 'way', 'to', 'the', 're@@', 'mark@@', 'able', 'and', 'the', 're@@', 'mark@@', 'able', '</s>']
2024-05-28 12:06:49,328 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:06:49,331 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:06:49,335 - INFO - joeynmt.training - 	Hypothesis: He was the way to the remarkable and the remarkable
2024-05-28 12:06:49,338 - INFO - joeynmt.training - Example #4
2024-05-28 12:06:49,341 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:06:49,341 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:06:49,341 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'thing', 'is', 'that', 'the', 'best', 'thing', 'that', 'I', 'will', 'do', 'is', 'a', 'good', 'way', 'to', 'be', 'a', 'good', 'way', 'that', 'it', 'was', 'the', 'last', '10', 'years.', '</s>']
2024-05-28 12:06:49,341 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:06:49,344 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:06:49,347 - INFO - joeynmt.training - 	Hypothesis: The next thing is that the best thing that I will do is a good way to be a good way that it was the last 10 years.
2024-05-28 12:06:52,099 - INFO - joeynmt.training - Epoch   3, Step:     9600, Batch Loss:     2.574261, Batch Acc: 0.323743, Tokens per Sec:    22975, Lr: 0.000300
2024-05-28 12:06:54,861 - INFO - joeynmt.training - Epoch   3, Step:     9700, Batch Loss:     2.544872, Batch Acc: 0.326109, Tokens per Sec:    24692, Lr: 0.000300
2024-05-28 12:06:57,639 - INFO - joeynmt.training - Epoch   3, Step:     9800, Batch Loss:     2.594092, Batch Acc: 0.323146, Tokens per Sec:    24513, Lr: 0.000300
2024-05-28 12:07:00,486 - INFO - joeynmt.training - Epoch   3, Step:     9900, Batch Loss:     2.510349, Batch Acc: 0.335178, Tokens per Sec:    24801, Lr: 0.000300
2024-05-28 12:07:03,353 - INFO - joeynmt.training - Epoch   3, Step:    10000, Batch Loss:     2.498091, Batch Acc: 0.330762, Tokens per Sec:    24412, Lr: 0.000300
2024-05-28 12:07:03,357 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:07:03,360 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:07:10,794 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.56, ppl:  12.93, acc:   0.32, generation: 7.3806[sec], evaluation: 0.0000[sec]
2024-05-28 12:07:10,798 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:07:10,896 - INFO - joeynmt.helpers - delete models/bpe-vocab/7500.ckpt
2024-05-28 12:07:10,901 - INFO - joeynmt.training - Example #0
2024-05-28 12:07:10,905 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:07:10,906 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:07:10,906 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'was', 'the', 'two', 'of', 'these', 'two', '--', 'these', 'two', 're@@', 'port@@', 's', 'that', 'the', 'ma@@', 'in', 'the', 'middle', 'of', 'the', 'in@@', 'iti@@', 'al', 'of', 'the', 'last', 'two', 'wee@@', 'ks', 'of', 'the', 'last', 'two', 'years.', '</s>']
2024-05-28 12:07:10,906 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:07:10,910 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:07:10,919 - INFO - joeynmt.training - 	Hypothesis: And the first was the two of these two -- these two reports that the main the middle of the initial of the last two weeks of the last two years.
2024-05-28 12:07:10,922 - INFO - joeynmt.training - Example #1
2024-05-28 12:07:10,925 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:07:10,925 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:07:10,925 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'co@@', 'de', 'of', 'the', 'most', 'important', 'thing', 'is', 'not', 'because', 'of', 'the', 'most', 'important', 'thing', 'of', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:07:10,925 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:07:10,928 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:07:10,932 - INFO - joeynmt.training - 	Hypothesis: But this is the code of the most important thing is not because of the most important thing of the same.
2024-05-28 12:07:10,934 - INFO - joeynmt.training - Example #2
2024-05-28 12:07:10,937 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:07:10,937 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:07:10,938 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is', 'the', 'in@@', 'iti@@', 've,', 'which', 'is', 'the', 'co@@', 'de', 'of', 'the', 'system@@', '.', '</s>']
2024-05-28 12:07:10,938 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:07:10,941 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:07:10,960 - INFO - joeynmt.training - 	Hypothesis: The police is the initive, which is the code of the system.
2024-05-28 12:07:10,963 - INFO - joeynmt.training - Example #3
2024-05-28 12:07:10,967 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:07:10,967 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:07:10,967 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['He', 'has', 'been', 're@@', 'lea@@', 'se', 'and', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:07:10,968 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:07:10,973 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:07:10,976 - INFO - joeynmt.training - 	Hypothesis: He has been release and the same.
2024-05-28 12:07:10,979 - INFO - joeynmt.training - Example #4
2024-05-28 12:07:10,981 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:07:10,981 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:07:10,981 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'thing', 'I', 'would', 'like', 'to', 'tell', 'you', 'that', 'I', 'would', 'be', 'a', 'little', 'bit', 'about', 'what', 'I', 'would', 'be', 'able', 'to', 'do', 'about', 'the', 'last', 'two', 'years.', '</s>']
2024-05-28 12:07:10,982 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:07:10,984 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:07:10,987 - INFO - joeynmt.training - 	Hypothesis: The next thing I would like to tell you that I would be a little bit about what I would be able to do about the last two years.
2024-05-28 12:07:13,792 - INFO - joeynmt.training - Epoch   3, Step:    10100, Batch Loss:     2.561788, Batch Acc: 0.327909, Tokens per Sec:    23169, Lr: 0.000300
2024-05-28 12:07:16,573 - INFO - joeynmt.training - Epoch   3, Step:    10200, Batch Loss:     2.545707, Batch Acc: 0.331665, Tokens per Sec:    25241, Lr: 0.000300
2024-05-28 12:07:19,340 - INFO - joeynmt.training - Epoch   3, Step:    10300, Batch Loss:     2.423316, Batch Acc: 0.336382, Tokens per Sec:    24852, Lr: 0.000300
2024-05-28 12:07:22,119 - INFO - joeynmt.training - Epoch   3, Step:    10400, Batch Loss:     2.463297, Batch Acc: 0.332700, Tokens per Sec:    25219, Lr: 0.000300
2024-05-28 12:07:24,895 - INFO - joeynmt.training - Epoch   3, Step:    10500, Batch Loss:     2.336189, Batch Acc: 0.337083, Tokens per Sec:    25020, Lr: 0.000300
2024-05-28 12:07:24,899 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:07:24,902 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:07:32,795 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.53, ppl:  12.57, acc:   0.33, generation: 7.8735[sec], evaluation: 0.0000[sec]
2024-05-28 12:07:32,799 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:07:32,896 - INFO - joeynmt.helpers - delete models/bpe-vocab/8000.ckpt
2024-05-28 12:07:32,903 - INFO - joeynmt.training - Example #0
2024-05-28 12:07:32,907 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:07:32,907 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:07:32,907 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'the', 'last', 'year,', 'we', 'were', 'the', 'two', 'of', 'these', 'two', 'years', 'of', 'the', 'last', 'few', 'years', 'ago,', 'which', 'is', 'the', 'most', 'of', 'the', 'most', 'of', 'the', 'first', 'time', 'of', 'the', 'last', 'two', 'million', 'of', 'the', 'last', 'two', 'million', 'years', 'ago.', '</s>']
2024-05-28 12:07:32,908 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:07:32,911 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:07:32,914 - INFO - joeynmt.training - 	Hypothesis: In the last year, we were the two of these two years of the last few years ago, which is the most of the most of the first time of the last two million of the last two million years ago.
2024-05-28 12:07:32,917 - INFO - joeynmt.training - Example #1
2024-05-28 12:07:32,920 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:07:32,920 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:07:32,920 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'end', 'of', 'the', 'same', 'problem@@', ',', 'because', 'of', 'this', 'is', 'not', 'the', 'same', 'as', 'a', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:07:32,921 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:07:32,924 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:07:32,927 - INFO - joeynmt.training - 	Hypothesis: But this is the end of the same problem, because of this is not the same as a same.
2024-05-28 12:07:32,930 - INFO - joeynmt.training - Example #2
2024-05-28 12:07:32,969 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:07:32,969 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:07:32,969 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'of', 'the', 'pol@@', 'lu@@', 'tion', 'of', 'the', 'most', 'of', 'the', 'system@@', ',', 'which', 'is', 'the', 'global', 'system@@', '.', '</s>']
2024-05-28 12:07:32,969 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:07:32,973 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:07:32,976 - INFO - joeynmt.training - 	Hypothesis: The police of the pollution of the most of the system, which is the global system.
2024-05-28 12:07:32,979 - INFO - joeynmt.training - Example #3
2024-05-28 12:07:32,982 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:07:32,982 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:07:32,982 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'he', 'has', 'the', 'way', 'to', 'get', 'the', 'w@@', 'all', 'of', 'the', 'time.', '</s>']
2024-05-28 12:07:32,982 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:07:32,985 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:07:32,988 - INFO - joeynmt.training - 	Hypothesis: And he has the way to get the wall of the time.
2024-05-28 12:07:32,991 - INFO - joeynmt.training - Example #4
2024-05-28 12:07:32,994 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:07:32,994 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:07:32,994 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'thing', 'I', 'will', 'be', 'the', 's@@', 'am@@', 'e,', 'I', 'will', 'be', 'a', 'little', 'bit', 'of', 'what', 'I', 'was', 'going', 'to', 'be', 'the', 'last', '20', 'years.', '</s>']
2024-05-28 12:07:32,994 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:07:32,997 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:07:33,000 - INFO - joeynmt.training - 	Hypothesis: The first thing I will be the same, I will be a little bit of what I was going to be the last 20 years.
2024-05-28 12:07:35,763 - INFO - joeynmt.training - Epoch   3, Step:    10600, Batch Loss:     2.457349, Batch Acc: 0.339853, Tokens per Sec:    23083, Lr: 0.000300
2024-05-28 12:07:38,550 - INFO - joeynmt.training - Epoch   3, Step:    10700, Batch Loss:     2.525334, Batch Acc: 0.337575, Tokens per Sec:    25018, Lr: 0.000300
2024-05-28 12:07:41,308 - INFO - joeynmt.training - Epoch   3, Step:    10800, Batch Loss:     2.563781, Batch Acc: 0.339975, Tokens per Sec:    24674, Lr: 0.000300
2024-05-28 12:07:44,080 - INFO - joeynmt.training - Epoch   3, Step:    10900, Batch Loss:     2.633437, Batch Acc: 0.336119, Tokens per Sec:    24640, Lr: 0.000300
2024-05-28 12:07:46,832 - INFO - joeynmt.training - Epoch   3, Step:    11000, Batch Loss:     2.478510, Batch Acc: 0.343171, Tokens per Sec:    23989, Lr: 0.000300
2024-05-28 12:07:46,858 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:07:46,861 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:07:55,050 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.51, ppl:  12.36, acc:   0.34, generation: 8.1685[sec], evaluation: 0.0000[sec]
2024-05-28 12:07:55,054 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:07:55,157 - INFO - joeynmt.helpers - delete models/bpe-vocab/8500.ckpt
2024-05-28 12:07:55,163 - INFO - joeynmt.training - Example #0
2024-05-28 12:07:55,166 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:07:55,166 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:07:55,166 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'one', 'of', 'these', 'two', 're@@', 'feren@@', 'ce', 'of', 'these', 'two', 're@@', 'feren@@', 'ce', 'to', 'the', 'same', 'way', 'that', 'the', 'P@@', 'ol@@', 'it@@', 'an', 'of', 'the', 'last', 'two', 'million', 'years', 'of', 'the', 'last', 'two', 'million', 'years', 'ago,', 'was', 'the', 'only', 'two', 'million', 'years', 'ol@@', 'd,', 'the', '2@@', '2@@', '2@@', '5@@', '.', '</s>']
2024-05-28 12:07:55,167 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:07:55,169 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:07:55,173 - INFO - joeynmt.training - 	Hypothesis: The first one of these two reference of these two reference to the same way that the Politan of the last two million years of the last two million years ago, was the only two million years old, the 2225.
2024-05-28 12:07:55,176 - INFO - joeynmt.training - Example #1
2024-05-28 12:07:55,179 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:07:55,179 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:07:55,179 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'New', 'York', 'C@@', 'ity', 'of', 'this', 'issu@@', 'e', 'because', 'the', 'same', 'kind', 'of', 'a', 'very', 'str@@', 'ange', 'of', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:07:55,180 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:07:55,183 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:07:55,186 - INFO - joeynmt.training - 	Hypothesis: But this is the New York City of this issue because the same kind of a very strange of the same.
2024-05-28 12:07:55,189 - INFO - joeynmt.training - Example #2
2024-05-28 12:07:55,227 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:07:55,227 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:07:55,227 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'P@@', 'ol@@', 'an@@', 'cy', 'is', 'the', 'one', 'of', 'the', 'most', 'important', 'thing', 'that', 'the', 'system', 'that', 'the', 'system', 'of', 'the', 'system', 'of', 'the', 'system', 'of', 'the', 'global', 'system', 'of', 'the', 'global', 'system@@', '.', '</s>']
2024-05-28 12:07:55,228 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:07:55,234 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:07:55,237 - INFO - joeynmt.training - 	Hypothesis: The Polancy is the one of the most important thing that the system that the system of the system of the system of the global system of the global system.
2024-05-28 12:07:55,240 - INFO - joeynmt.training - Example #3
2024-05-28 12:07:55,243 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:07:55,243 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:07:55,243 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'has', 'been', 'a', 'lot', 'of', 'time', 'and', 'the', 'in@@', 'come', 'and', 'the', 's@@', 'ea', 'of', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:07:55,244 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:07:55,247 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:07:55,250 - INFO - joeynmt.training - 	Hypothesis: It has been a lot of time and the income and the sea of the same.
2024-05-28 12:07:55,252 - INFO - joeynmt.training - Example #4
2024-05-28 12:07:55,271 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:07:55,271 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:07:55,271 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'thing', 'I', 'am', 'of', 'the', 'con@@', 'feren@@', 'ce', 'of', 'the', 'kind', 'of', 'a', 'very', 'good', 'thing', 'to', 'do', 'about', 'what', 'happened', 'to', 'the', 'last', 'two', 'years', 'ago.', '</s>']
2024-05-28 12:07:55,272 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:07:55,275 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:07:55,278 - INFO - joeynmt.training - 	Hypothesis: The next thing I am of the conference of the kind of a very good thing to do about what happened to the last two years ago.
2024-05-28 12:07:58,069 - INFO - joeynmt.training - Epoch   3, Step:    11100, Batch Loss:     2.443607, Batch Acc: 0.343711, Tokens per Sec:    23082, Lr: 0.000300
2024-05-28 12:08:00,825 - INFO - joeynmt.training - Epoch   3, Step:    11200, Batch Loss:     2.326020, Batch Acc: 0.346631, Tokens per Sec:    24900, Lr: 0.000300
2024-05-28 12:08:03,585 - INFO - joeynmt.training - Epoch   3, Step:    11300, Batch Loss:     2.584311, Batch Acc: 0.345330, Tokens per Sec:    24389, Lr: 0.000300
2024-05-28 12:08:06,368 - INFO - joeynmt.training - Epoch   3, Step:    11400, Batch Loss:     2.428375, Batch Acc: 0.347253, Tokens per Sec:    25549, Lr: 0.000300
2024-05-28 12:08:09,131 - INFO - joeynmt.training - Epoch   3, Step:    11500, Batch Loss:     2.396028, Batch Acc: 0.348970, Tokens per Sec:    24658, Lr: 0.000300
2024-05-28 12:08:09,152 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:08:09,155 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:08:16,470 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.49, ppl:  12.09, acc:   0.34, generation: 7.2964[sec], evaluation: 0.0000[sec]
2024-05-28 12:08:16,475 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:08:16,559 - INFO - joeynmt.helpers - delete models/bpe-vocab/9000.ckpt
2024-05-28 12:08:16,570 - INFO - joeynmt.training - Example #0
2024-05-28 12:08:16,574 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:08:16,574 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:08:16,574 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'third', 'I', 'was', 'the', 'two', 'of', 'these', 'two', 're@@', 'ach@@', 'es', 'to', 'the', 'two', 'of', 'the', 'third', 'of', 'the', 'most', 'popul@@', 'ar', 'of', 'the', 'last', 'centur@@', 'y', 'of', 'the', 'last', 'two', 'million', 'years', 'of', 'the', 'last', 'two', 'million', 'years', 'ago,', 'the', 'last', '1@@', '50', 'million', 'years', 'ago,', '</s>']
2024-05-28 12:08:16,574 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:08:16,577 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:08:16,580 - INFO - joeynmt.training - 	Hypothesis: The third I was the two of these two reaches to the two of the third of the most popular of the last century of the last two million years of the last two million years ago, the last 150 million years ago,
2024-05-28 12:08:16,583 - INFO - joeynmt.training - Example #1
2024-05-28 12:08:16,586 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:08:16,586 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:08:16,586 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'mor@@', 'n@@', 'ing.', 'But', 'the', 'problem', 'of', 'this', 'issu@@', 'e', 'because', 'of', 'the', 'most', 'important', 'thing', 'for', 'the', 'p@@', 'est@@', '.', '</s>']
2024-05-28 12:08:16,587 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:08:16,590 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:08:16,595 - INFO - joeynmt.training - 	Hypothesis: But this is the morning. But the problem of this issue because of the most important thing for the pest.
2024-05-28 12:08:16,598 - INFO - joeynmt.training - Example #2
2024-05-28 12:08:16,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:08:16,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:08:16,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is', 'the', 'pol@@', 'ice', 'of', 'the', 'heart', 'of', 'the', 'future', 'of', 'the', 'global', 'system@@', '.', '</s>']
2024-05-28 12:08:16,601 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:08:16,635 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:08:16,639 - INFO - joeynmt.training - 	Hypothesis: The police is the police of the heart of the future of the global system.
2024-05-28 12:08:16,642 - INFO - joeynmt.training - Example #3
2024-05-28 12:08:16,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:08:16,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:08:16,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'is', 'the', 'time', 'and', 'he', 'was', 'the', 'in@@', 'struc@@', 'tion', 'and', 'he', 'was', 'the', 'w@@', 'il@@', 'd.', '</s>']
2024-05-28 12:08:16,645 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:08:16,649 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:08:16,652 - INFO - joeynmt.training - 	Hypothesis: She is the time and he was the instruction and he was the wild.
2024-05-28 12:08:16,655 - INFO - joeynmt.training - Example #4
2024-05-28 12:08:16,663 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:08:16,663 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:08:16,663 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'one', 'of', 'the', 're@@', 'feren@@', 'ce', 'that', 'I', 'will', 'show', 'you', 'a', 'little', 'bit', 'of', 'what', 'I', 'would', 'be', 'a', 'third', 'of', 'the', 'last', 'centur@@', 'y.', '</s>']
2024-05-28 12:08:16,664 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:08:16,675 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:08:16,684 - INFO - joeynmt.training - 	Hypothesis: The next one of the reference that I will show you a little bit of what I would be a third of the last century.
2024-05-28 12:08:19,433 - INFO - joeynmt.training - Epoch   3, Step:    11600, Batch Loss:     2.348878, Batch Acc: 0.352035, Tokens per Sec:    22875, Lr: 0.000300
2024-05-28 12:08:22,193 - INFO - joeynmt.training - Epoch   3, Step:    11700, Batch Loss:     2.412926, Batch Acc: 0.349532, Tokens per Sec:    25287, Lr: 0.000300
2024-05-28 12:08:23,576 - INFO - joeynmt.training - Epoch   3: total training loss 9847.19
2024-05-28 12:08:23,580 - INFO - joeynmt.training - EPOCH 4
2024-05-28 12:08:24,997 - INFO - joeynmt.training - Epoch   4, Step:    11800, Batch Loss:     2.287337, Batch Acc: 0.368598, Tokens per Sec:    25020, Lr: 0.000300
2024-05-28 12:08:27,778 - INFO - joeynmt.training - Epoch   4, Step:    11900, Batch Loss:     2.424428, Batch Acc: 0.368627, Tokens per Sec:    25040, Lr: 0.000300
2024-05-28 12:08:30,531 - INFO - joeynmt.training - Epoch   4, Step:    12000, Batch Loss:     2.325821, Batch Acc: 0.367152, Tokens per Sec:    24957, Lr: 0.000300
2024-05-28 12:08:30,545 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:08:30,548 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:08:38,555 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.45, ppl:  11.64, acc:   0.35, generation: 7.9856[sec], evaluation: 0.0000[sec]
2024-05-28 12:08:38,559 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:08:38,646 - INFO - joeynmt.helpers - delete models/bpe-vocab/9500.ckpt
2024-05-28 12:08:38,658 - INFO - joeynmt.training - Example #0
2024-05-28 12:08:38,680 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:08:38,680 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:08:38,680 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'year', 'I', 'went', 'to', 'these', 'two', 're@@', 'port', 'to', 'the', 'two', 'of', 'the', 'ma@@', 'in', 'the', 'ra@@', 'in@@', 'fo@@', 'rest', 'that', 'the', 'pol@@', 'l@@', 'en', 'in', 'the', 'last', 'few', 'months', 'of', 'the', 'last', 'few', 'months', 'of', 'the', 'last', 'dec@@', 'ade@@', 's', 'of', 'the', 'last', 'two', 'million', 'years', 'of', 'the', 'year', 'of', 'the', 'two', 'percent', 'of', 'the', 'two', 'percent', 'of', 'the', 'two', 'percent', 'of', 'the', 'two', 'percent', 'of', 'the', 'ear@@', 'th@@', 'qu@@', 'ak@@', 'e.', '</s>']
2024-05-28 12:08:38,680 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:08:38,683 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:08:38,687 - INFO - joeynmt.training - 	Hypothesis: The first year I went to these two report to the two of the main the rainforest that the pollen in the last few months of the last few months of the last decades of the last two million years of the year of the two percent of the two percent of the two percent of the two percent of the earthquake.
2024-05-28 12:08:38,690 - INFO - joeynmt.training - Example #1
2024-05-28 12:08:38,694 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:08:38,694 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:08:38,694 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'al', '--', 'the', 'most', 'important', 'issu@@', 'es', 'that', 'the', 'problems', 'is', 'not', 'the', 'most', 'important', 'thing', 'that', 'the', 'gen@@', 'om@@', 'e.', '</s>']
2024-05-28 12:08:38,694 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:08:38,698 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:08:38,725 - INFO - joeynmt.training - 	Hypothesis: But this moral -- the most important issues that the problems is not the most important thing that the genome.
2024-05-28 12:08:38,728 - INFO - joeynmt.training - Example #2
2024-05-28 12:08:38,731 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:08:38,731 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:08:38,732 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'l@@', 'en', 'is', 'the', 'pol@@', 'ic@@', 'y', 'of', 'the', 'left', 'of', 'the', 'system@@', 's', 'of', 'the', 'system@@', '.', '</s>']
2024-05-28 12:08:38,732 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:08:38,735 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:08:38,738 - INFO - joeynmt.training - 	Hypothesis: The pollen is the policy of the left of the systems of the system.
2024-05-28 12:08:38,741 - INFO - joeynmt.training - Example #3
2024-05-28 12:08:38,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:08:38,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:08:38,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'the', 'time', 'of', 'the', 'en@@', 'd,', 'and', 'the', 'en@@', 'd,', '</s>']
2024-05-28 12:08:38,744 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:08:38,747 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:08:38,749 - INFO - joeynmt.training - 	Hypothesis: It was the time of the end, and the end,
2024-05-28 12:08:38,752 - INFO - joeynmt.training - Example #4
2024-05-28 12:08:38,755 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:08:38,755 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:08:38,755 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'next', 'few', 'minu@@', 'tes', 'that', 'I', 'will', 'be', 'a', 'very', 'good', 'way', 'to', 'be', 'a', 'very', 'good', 'way', 'to', 'what', 'happened', 'to', 'happen', 'to', 'the', 'last', '20', 'years.', '</s>']
2024-05-28 12:08:38,756 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:08:38,758 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:08:38,761 - INFO - joeynmt.training - 	Hypothesis: The next next few minutes that I will be a very good way to be a very good way to what happened to happen to the last 20 years.
2024-05-28 12:08:41,536 - INFO - joeynmt.training - Epoch   4, Step:    12100, Batch Loss:     2.513371, Batch Acc: 0.367703, Tokens per Sec:    23271, Lr: 0.000300
2024-05-28 12:08:44,301 - INFO - joeynmt.training - Epoch   4, Step:    12200, Batch Loss:     2.521480, Batch Acc: 0.369076, Tokens per Sec:    25063, Lr: 0.000300
2024-05-28 12:08:47,079 - INFO - joeynmt.training - Epoch   4, Step:    12300, Batch Loss:     2.440504, Batch Acc: 0.364561, Tokens per Sec:    25053, Lr: 0.000300
2024-05-28 12:08:49,830 - INFO - joeynmt.training - Epoch   4, Step:    12400, Batch Loss:     2.339618, Batch Acc: 0.370388, Tokens per Sec:    24645, Lr: 0.000300
2024-05-28 12:08:52,610 - INFO - joeynmt.training - Epoch   4, Step:    12500, Batch Loss:     2.498427, Batch Acc: 0.370361, Tokens per Sec:    25226, Lr: 0.000300
2024-05-28 12:08:52,614 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:08:52,618 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:09:00,629 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.44, ppl:  11.43, acc:   0.36, generation: 7.9915[sec], evaluation: 0.0000[sec]
2024-05-28 12:09:00,633 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:09:00,733 - INFO - joeynmt.helpers - delete models/bpe-vocab/10000.ckpt
2024-05-28 12:09:00,738 - INFO - joeynmt.training - Example #0
2024-05-28 12:09:00,742 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:09:00,742 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:09:00,742 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'one', 'of', 'these', 'two', 'two', 'of', 'these', 'two', 'minu@@', 'tes', 'to', 'be', 'the', 'same', 'as', 'a', 'young', 'man', 'who', 'was', 'the', 'most', 'of', 'the', 'most', 'of', 'the', 'most', 'of', 'the', 'most', 'of', 'the', 'last', 'two', 'million', 'years', 'ago,', 'the', 'most', 'of', 'the', 'year', 'of', 'the', 'year', 'of', 'the', 'top', 'of', 'the', 'two', 'million', 'years', 'of', 'a', 'little', 'bit', 'of', 'a', 'small', 'million', 'dollars', 'a', 'little', 'bit', 'of', 'a', 'little', 'bit', 'of', 'a', 'small', 'than', '4@@', '0@@', '-@@', 'dol@@', 'l@@', 'ar', 'year', 'than', 'the', 'small', 'than', 'the', 'dol@@', 'l@@', 'ar', 'than', 'the', 'little', 'more', 'than']
2024-05-28 12:09:00,742 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:09:00,746 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:09:00,749 - INFO - joeynmt.training - 	Hypothesis: The first one of these two two of these two minutes to be the same as a young man who was the most of the most of the most of the most of the last two million years ago, the most of the year of the year of the top of the two million years of a little bit of a small million dollars a little bit of a little bit of a small than 40-dollar year than the small than the dollar than the little more than
2024-05-28 12:09:00,776 - INFO - joeynmt.training - Example #1
2024-05-28 12:09:00,780 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:09:00,780 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:09:00,780 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'ning', 'the', 'mor@@', 'al', 'of', 'this', 'is', 'the', 'very', 'important', 'thing', 'because', 'of', 'the', 'met@@', 'ap@@', 'h@@', 'or.', '</s>']
2024-05-28 12:09:00,780 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:09:00,784 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:09:00,788 - INFO - joeynmt.training - 	Hypothesis: But this morning the moral of this is the very important thing because of the metaphor.
2024-05-28 12:09:00,791 - INFO - joeynmt.training - Example #2
2024-05-28 12:09:00,794 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:09:00,794 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:09:00,794 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'of', 'the', 'pol@@', 'ice', 'is', 'a', 'lot', 'of', 'the', 'human', 'gen@@', 'ome', 'is', 'the', 'global', 'system@@', '.', '</s>']
2024-05-28 12:09:00,795 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:09:00,803 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:09:00,806 - INFO - joeynmt.training - 	Hypothesis: The police of the police is a lot of the human genome is the global system.
2024-05-28 12:09:00,810 - INFO - joeynmt.training - Example #3
2024-05-28 12:09:00,813 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:09:00,813 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:09:00,813 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'the', 'en@@', 'ter', 'of', 'the', 'de@@', 'b@@', 'ate', 'and', 'the', 'de@@', 'ta@@', 'il.', '</s>']
2024-05-28 12:09:00,813 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:09:00,816 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:09:00,819 - INFO - joeynmt.training - 	Hypothesis: It was the enter of the debate and the detail.
2024-05-28 12:09:00,822 - INFO - joeynmt.training - Example #4
2024-05-28 12:09:00,825 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:09:00,825 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:09:00,825 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'thing', 'I', 'will', 'tell', 'you', 'that', 'I', 'will', 'be', 'a', 'little', 'bit', 'more', 'than', 'what', 'happened', 'to', 'be', 'a', 'bit', 'of', 'the', 'last', '20', 'years.', '</s>']
2024-05-28 12:09:00,825 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:09:00,828 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:09:00,831 - INFO - joeynmt.training - 	Hypothesis: The next thing I will tell you that I will be a little bit more than what happened to be a bit of the last 20 years.
2024-05-28 12:09:03,582 - INFO - joeynmt.training - Epoch   4, Step:    12600, Batch Loss:     2.552560, Batch Acc: 0.365880, Tokens per Sec:    23000, Lr: 0.000300
2024-05-28 12:09:06,329 - INFO - joeynmt.training - Epoch   4, Step:    12700, Batch Loss:     2.323658, Batch Acc: 0.373084, Tokens per Sec:    24805, Lr: 0.000300
2024-05-28 12:09:09,108 - INFO - joeynmt.training - Epoch   4, Step:    12800, Batch Loss:     2.449709, Batch Acc: 0.372988, Tokens per Sec:    24969, Lr: 0.000300
2024-05-28 12:09:11,889 - INFO - joeynmt.training - Epoch   4, Step:    12900, Batch Loss:     2.478278, Batch Acc: 0.373054, Tokens per Sec:    25491, Lr: 0.000300
2024-05-28 12:09:14,637 - INFO - joeynmt.training - Epoch   4, Step:    13000, Batch Loss:     2.364524, Batch Acc: 0.375684, Tokens per Sec:    24172, Lr: 0.000300
2024-05-28 12:09:14,641 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:09:14,644 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:09:22,579 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.41, ppl:  11.09, acc:   0.36, generation: 7.9123[sec], evaluation: 0.0000[sec]
2024-05-28 12:09:22,582 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:09:22,673 - INFO - joeynmt.helpers - delete models/bpe-vocab/10500.ckpt
2024-05-28 12:09:22,681 - INFO - joeynmt.training - Example #0
2024-05-28 12:09:22,684 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:09:22,684 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:09:22,685 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'we', 'have', 'been', 'on', 'these', 'two', 'secon@@', 'ds', 'to', 'show', 'these', 'two', 'wee@@', 'ks', 'that', 'the', 'most', 'of', 'the', 'most', 'popul@@', 'ar', 'that', 'the', 'most', 'of', 'the', 'most', 'popul@@', 'ar', 'was', 'the', 'last', 'three', 'million', 'years', 'ol@@', 'd,', 'was', 'a', 'little', 'bit', 'of', 'a', 'little', '2@@', '-@@', 'year-@@', 'old', 'gir@@', 'l', 'has', 'a', 'little', 'bit', 'of', '4@@', '2', 'million', 'years', 'ol@@', 'd,', '</s>']
2024-05-28 12:09:22,685 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:09:22,688 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:09:22,691 - INFO - joeynmt.training - 	Hypothesis: The year we have been on these two seconds to show these two weeks that the most of the most popular that the most of the most popular was the last three million years old, was a little bit of a little 2-year-old girl has a little bit of 42 million years old,
2024-05-28 12:09:22,712 - INFO - joeynmt.training - Example #1
2024-05-28 12:09:22,716 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:09:22,716 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:09:22,716 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing.', 'It', 'is', 'the', 'last', 'issu@@', 'e', 'because', 'of', 'the', 'most', 'important', 'issu@@', 'es', 'of', 'the', 'met@@', 'ap@@', 'h@@', 'or', 'of', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:09:22,716 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:09:22,719 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:09:22,722 - INFO - joeynmt.training - 	Hypothesis: But this morning. It is the last issue because of the most important issues of the metaphor of the same.
2024-05-28 12:09:22,725 - INFO - joeynmt.training - Example #2
2024-05-28 12:09:22,728 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:09:22,728 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:09:22,728 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is', 'in', 'a', 'way,', 'in', 'a', 'family', 'that', 'the', 'world', 'is', 'the', 'global', 'system@@', ',', 'which', 'is', 'the', 'global', 'system@@', '.', '</s>']
2024-05-28 12:09:22,728 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:09:22,732 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:09:22,735 - INFO - joeynmt.training - 	Hypothesis: The police is in a way, in a family that the world is the global system, which is the global system.
2024-05-28 12:09:22,738 - INFO - joeynmt.training - Example #3
2024-05-28 12:09:22,742 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:09:22,742 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:09:22,742 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'has', 'been', 'the', 'ex@@', 'pen@@', 'sive', 'and', 'the', 'de@@', 'ta@@', 'il.', '</s>']
2024-05-28 12:09:22,743 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:09:22,746 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:09:22,749 - INFO - joeynmt.training - 	Hypothesis: It has been the expensive and the detail.
2024-05-28 12:09:22,751 - INFO - joeynmt.training - Example #4
2024-05-28 12:09:22,755 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:09:22,755 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:09:22,755 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'few', 'days', 'of', 'the', 'pictu@@', 'res', 'that', 'I', 'would', 'have', 'a', 'little', 'bit', 'of', 'what', 'was', 'going', 'to', 'be', 'a', 'third', 'of', 'the', 'last', '20', 'years.', '</s>']
2024-05-28 12:09:22,755 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:09:22,759 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:09:22,762 - INFO - joeynmt.training - 	Hypothesis: The next few days of the pictures that I would have a little bit of what was going to be a third of the last 20 years.
2024-05-28 12:09:25,503 - INFO - joeynmt.training - Epoch   4, Step:    13100, Batch Loss:     2.364185, Batch Acc: 0.375216, Tokens per Sec:    23733, Lr: 0.000300
2024-05-28 12:09:28,239 - INFO - joeynmt.training - Epoch   4, Step:    13200, Batch Loss:     2.332831, Batch Acc: 0.369533, Tokens per Sec:    24042, Lr: 0.000300
2024-05-28 12:09:30,978 - INFO - joeynmt.training - Epoch   4, Step:    13300, Batch Loss:     2.289748, Batch Acc: 0.383271, Tokens per Sec:    24516, Lr: 0.000300
2024-05-28 12:09:33,711 - INFO - joeynmt.training - Epoch   4, Step:    13400, Batch Loss:     2.382129, Batch Acc: 0.379958, Tokens per Sec:    24769, Lr: 0.000300
2024-05-28 12:09:36,449 - INFO - joeynmt.training - Epoch   4, Step:    13500, Batch Loss:     2.220812, Batch Acc: 0.379743, Tokens per Sec:    24612, Lr: 0.000300
2024-05-28 12:09:36,453 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:09:36,456 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:09:44,456 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.38, ppl:  10.75, acc:   0.37, generation: 7.9817[sec], evaluation: 0.0000[sec]
2024-05-28 12:09:44,460 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:09:44,551 - INFO - joeynmt.helpers - delete models/bpe-vocab/11000.ckpt
2024-05-28 12:09:44,578 - INFO - joeynmt.training - Example #0
2024-05-28 12:09:44,582 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:09:44,582 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:09:44,582 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'was', 'the', 'last', 'two', 'of', 'the', 'second', 'to', 'show', 'that', 'the', 'third', 'of', 'the', 'same', 're@@', 'qui@@', 'red', 'the', 'r@@', 'ich', 'of', 'the', 'city', 'that', 'the', 'last', 'three', 'million', 'years', 'ago,', 'the', 'last', 'year', 'was', 'a', 'year', 'of', 'the', 'last', '4@@', '5', 'million', 'years', 'ol@@', 'd,', 'and', 'the', 'last', '4@@', '0@@', ',000', 'fe@@', 'et', 'of', 'the', 'age', 'of', 'the', 'age', 'of', '4@@', '0@@', ',000', 'fe@@', 'et.', '</s>']
2024-05-28 12:09:44,582 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:09:44,585 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:09:44,588 - INFO - joeynmt.training - 	Hypothesis: The year I was the last two of the second to show that the third of the same required the rich of the city that the last three million years ago, the last year was a year of the last 45 million years old, and the last 40,000 feet of the age of the age of 40,000 feet.
2024-05-28 12:09:44,620 - INFO - joeynmt.training - Example #1
2024-05-28 12:09:44,623 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:09:44,623 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:09:44,623 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'al', 'mor@@', 'al', 'issu@@', 'e', 'for', 'this', 'problem', 'because', 'of', 'the', 'problems', 'that', 'are', 'not', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:09:44,623 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:09:44,626 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:09:44,629 - INFO - joeynmt.training - 	Hypothesis: But this moral moral issue for this problem because of the problems that are not the size of the size of the size of the same.
2024-05-28 12:09:44,631 - INFO - joeynmt.training - Example #2
2024-05-28 12:09:44,634 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:09:44,634 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:09:44,634 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is', 'a', 'pol@@', 'ice', 'that', 'the', 'future', 'of', 'the', 'global', 'system@@', ',', 'which', 'is', 'the', 'global', 'system@@', '.', '</s>']
2024-05-28 12:09:44,635 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:09:44,637 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:09:44,640 - INFO - joeynmt.training - 	Hypothesis: The police is a police that the future of the global system, which is the global system.
2024-05-28 12:09:44,642 - INFO - joeynmt.training - Example #3
2024-05-28 12:09:44,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:09:44,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:09:44,646 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'has', 'been', 'the', 'en@@', 'd,', 'and', 'the', 'en@@', 'd,', 'and', 'the', 's@@', 'ea', 'of', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:09:44,646 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:09:44,649 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:09:44,652 - INFO - joeynmt.training - 	Hypothesis: It has been the end, and the end, and the sea of the same.
2024-05-28 12:09:44,654 - INFO - joeynmt.training - Example #4
2024-05-28 12:09:44,657 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:09:44,657 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:09:44,657 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'day', 'I', 'would', 'like', 'to', 'be', 'a', 'very', 'difficult', 'to', 'be', 'a', 'very', 'difficult', 'to', 'be', 'a', 'third', 'of', 'the', 'last', '50', 'years.', '</s>']
2024-05-28 12:09:44,658 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:09:44,660 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:09:44,663 - INFO - joeynmt.training - 	Hypothesis: The next day I would like to be a very difficult to be a very difficult to be a third of the last 50 years.
2024-05-28 12:09:47,427 - INFO - joeynmt.training - Epoch   4, Step:    13600, Batch Loss:     2.407664, Batch Acc: 0.383497, Tokens per Sec:    23736, Lr: 0.000300
2024-05-28 12:09:50,200 - INFO - joeynmt.training - Epoch   4, Step:    13700, Batch Loss:     2.138411, Batch Acc: 0.387398, Tokens per Sec:    24489, Lr: 0.000300
2024-05-28 12:09:52,991 - INFO - joeynmt.training - Epoch   4, Step:    13800, Batch Loss:     2.365757, Batch Acc: 0.386299, Tokens per Sec:    26046, Lr: 0.000300
2024-05-28 12:09:55,719 - INFO - joeynmt.training - Epoch   4, Step:    13900, Batch Loss:     2.246371, Batch Acc: 0.382772, Tokens per Sec:    24668, Lr: 0.000300
2024-05-28 12:09:58,481 - INFO - joeynmt.training - Epoch   4, Step:    14000, Batch Loss:     2.342826, Batch Acc: 0.385715, Tokens per Sec:    25238, Lr: 0.000300
2024-05-28 12:09:58,485 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:09:58,488 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:10:05,903 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.34, ppl:  10.38, acc:   0.38, generation: 7.3932[sec], evaluation: 0.0000[sec]
2024-05-28 12:10:05,907 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:10:05,999 - INFO - joeynmt.helpers - delete models/bpe-vocab/11500.ckpt
2024-05-28 12:10:06,013 - INFO - joeynmt.training - Example #0
2024-05-28 12:10:06,016 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:10:06,016 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:10:06,016 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'last', 'year,', 'we', 'were', 'the', 'second', 'second', 'to', 'these', 'two', 'to', 'show', 'that', 'the', 'tre@@', 'at', 'the', 'same', 'level', 'of', 'pol@@', 'ice', 'that', 'in', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'ago,', 'the', 'most', 'of', 'the', 'last', '4@@', '0@@', ',000', 'years', 'of', 'the', 'tre@@', 'at@@', 'ment', 'of', 'the', 'tre@@', 'at@@', 'ment', 'of', 'the', 'tre@@', 'at@@', 'ment', 'of', 'the', 'tre@@', 'at@@', 'ment', 'of', 'the', 'tre@@', 'at@@', 'ment', 'of', 'the', 'tre@@', 'at@@', 'ment', 'of', 'the', 'last', 'dec@@', 'a@@', 'de.', '</s>']
2024-05-28 12:10:06,017 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:10:06,020 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:10:06,049 - INFO - joeynmt.training - 	Hypothesis: The last year, we were the second second to these two to show that the treat the same level of police that in the last three million years of the last three million years ago, the most of the last 40,000 years of the treatment of the treatment of the treatment of the treatment of the treatment of the treatment of the last decade.
2024-05-28 12:10:06,052 - INFO - joeynmt.training - Example #1
2024-05-28 12:10:06,055 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:10:06,055 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:10:06,055 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'al', 'mor@@', 'al', 'is', 'the', 'very', 'speci@@', 'fic', 'issu@@', 'e', 'because', 'of', 'the', 'met@@', 'al', 'issu@@', 'e', 'because', 'of', 'the', 'met@@', 'ap@@', 'h@@', 'or.', '</s>']
2024-05-28 12:10:06,056 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:10:06,060 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:10:06,063 - INFO - joeynmt.training - 	Hypothesis: But this moral moral is the very specific issue because of the metal issue because of the metaphor.
2024-05-28 12:10:06,067 - INFO - joeynmt.training - Example #2
2024-05-28 12:10:06,069 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:10:06,069 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:10:06,069 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is', 'a', 'pol@@', 'ice', 'of', 'the', 'human', 'human', 'nature', 'of', 'the', 'global', 'system@@', ',', 'which', 'is', 'the', 'global', 'global', 'system@@', '.', '</s>']
2024-05-28 12:10:06,070 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:10:06,073 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:10:06,076 - INFO - joeynmt.training - 	Hypothesis: The police is a police of the human human nature of the global system, which is the global global system.
2024-05-28 12:10:06,080 - INFO - joeynmt.training - Example #3
2024-05-28 12:10:06,083 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:10:06,083 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:10:06,083 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'is', 'the', 'en@@', 'd,', 'and', 'the', 're@@', 'qui@@', 'res', 'of', 'the', 's@@', 'ou@@', 'ther@@', 'n', 'of', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:10:06,084 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:10:06,087 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:10:06,090 - INFO - joeynmt.training - 	Hypothesis: It is the end, and the requires of the southern of the same.
2024-05-28 12:10:06,093 - INFO - joeynmt.training - Example #4
2024-05-28 12:10:06,097 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:10:06,097 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:10:06,097 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'picture', 'of', 'the', 'con@@', 'feren@@', 'ce', 'that', 'you', 'would', 'be', 'a', 'very', 'difficult', 'to', 'be', 'a', 'very', 'much', 'of', 'what', 'happened', 'to', 'do', 'is', 'in', 'the', 'last', '50', 'years.', '</s>']
2024-05-28 12:10:06,097 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:10:06,100 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:10:06,103 - INFO - joeynmt.training - 	Hypothesis: The next picture of the conference that you would be a very difficult to be a very much of what happened to do is in the last 50 years.
2024-05-28 12:10:08,873 - INFO - joeynmt.training - Epoch   4, Step:    14100, Batch Loss:     2.124949, Batch Acc: 0.389226, Tokens per Sec:    22714, Lr: 0.000300
2024-05-28 12:10:11,605 - INFO - joeynmt.training - Epoch   4, Step:    14200, Batch Loss:     2.275231, Batch Acc: 0.390213, Tokens per Sec:    24248, Lr: 0.000300
2024-05-28 12:10:14,427 - INFO - joeynmt.training - Epoch   4, Step:    14300, Batch Loss:     2.230371, Batch Acc: 0.390186, Tokens per Sec:    25273, Lr: 0.000300
2024-05-28 12:10:17,157 - INFO - joeynmt.training - Epoch   4, Step:    14400, Batch Loss:     2.264196, Batch Acc: 0.389781, Tokens per Sec:    24262, Lr: 0.000300
2024-05-28 12:10:19,926 - INFO - joeynmt.training - Epoch   4, Step:    14500, Batch Loss:     2.608599, Batch Acc: 0.392370, Tokens per Sec:    25296, Lr: 0.000300
2024-05-28 12:10:19,930 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:10:19,933 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:10:27,830 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.32, ppl:  10.18, acc:   0.38, generation: 7.8767[sec], evaluation: 0.0000[sec]
2024-05-28 12:10:27,835 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:10:27,920 - INFO - joeynmt.helpers - delete models/bpe-vocab/12000.ckpt
2024-05-28 12:10:27,930 - INFO - joeynmt.training - Example #0
2024-05-28 12:10:27,934 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:10:27,934 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:10:27,934 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'were', 'the', 'second', 'of', 'these', 'two', 'to', 'show', 'that', 'the', 'third', 'of', 'the', 'same', 'as', 'the', 'most', 'of', 'the', 'most', 'of', 'the', 'most', 'most', 'of', 'the', 'most', 'most', 'most', 'of', 'the', 'most', 'of', 'the', 'most', 'important', 'thing', 'was', 'about', '4@@', '5', 'million', 'years', 'ago', 'was', 'a', 'small', 'number', 'of', 'years', 'of', 'the', 'size', 'of', '4@@', '5', 'million', 'of', 'the', 'size', 'of', '4@@', '0@@', 's.', '</s>']
2024-05-28 12:10:27,934 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:10:27,937 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:10:27,940 - INFO - joeynmt.training - 	Hypothesis: And the year we were the second of these two to show that the third of the same as the most of the most of the most most of the most most most of the most of the most important thing was about 45 million years ago was a small number of years of the size of 45 million of the size of 40s.
2024-05-28 12:10:27,966 - INFO - joeynmt.training - Example #1
2024-05-28 12:10:27,971 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:10:27,971 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:10:27,971 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'al', 'is', 'the', 'most', 'important', 'issu@@', 'es', 'of', 'this', 'issu@@', 'e', 'because', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'the', 'size', 'of', 'this', 'issu@@', 'e.', '</s>']
2024-05-28 12:10:27,971 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:10:27,979 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:10:27,982 - INFO - joeynmt.training - 	Hypothesis: But this moral is the most important issues of this issue because the size of the size of the size of the size of the size of the size of the size of the size of the size of the size of the the size of this issue.
2024-05-28 12:10:27,986 - INFO - joeynmt.training - Example #2
2024-05-28 12:10:27,989 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:10:27,989 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:10:27,989 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'of', 'pol@@', 'ice', 'is', 'a', 'way', 'that', 'the', 'global', 'world', 'is', 'the', 'global', 'war@@', 'm@@', 'ing.', '</s>']
2024-05-28 12:10:27,989 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:10:27,992 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:10:27,996 - INFO - joeynmt.training - 	Hypothesis: The police of police is a way that the global world is the global warming.
2024-05-28 12:10:27,999 - INFO - joeynmt.training - Example #3
2024-05-28 12:10:28,002 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:10:28,002 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:10:28,002 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'has', 'been', 'able', 'to', 'be', 'able', 'to', 're@@', 'vis@@', 'ion', 'the', 'de@@', 'ad@@', '.', '</s>']
2024-05-28 12:10:28,003 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:10:28,006 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:10:28,010 - INFO - joeynmt.training - 	Hypothesis: It has been able to be able to revision the dead.
2024-05-28 12:10:28,013 - INFO - joeynmt.training - Example #4
2024-05-28 12:10:28,016 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:10:28,016 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:10:28,016 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'one', 'of', 'the', 'next', 'few', 'of', 'them', 'will', 'be', 'a', 'little', 'bit', 'of', 'what', 'it', 'was', 'going', 'to', 'happen', 'to', 'the', 'last', '50', 'years.', '</s>']
2024-05-28 12:10:28,016 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:10:28,019 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:10:28,023 - INFO - joeynmt.training - 	Hypothesis: The next one of the next few of them will be a little bit of what it was going to happen to the last 50 years.
2024-05-28 12:10:30,802 - INFO - joeynmt.training - Epoch   4, Step:    14600, Batch Loss:     2.068274, Batch Acc: 0.395327, Tokens per Sec:    23857, Lr: 0.000300
2024-05-28 12:10:33,556 - INFO - joeynmt.training - Epoch   4, Step:    14700, Batch Loss:     2.533562, Batch Acc: 0.400143, Tokens per Sec:    25055, Lr: 0.000300
2024-05-28 12:10:36,323 - INFO - joeynmt.training - Epoch   4, Step:    14800, Batch Loss:     2.494819, Batch Acc: 0.397861, Tokens per Sec:    25118, Lr: 0.000300
2024-05-28 12:10:39,070 - INFO - joeynmt.training - Epoch   4, Step:    14900, Batch Loss:     2.406432, Batch Acc: 0.398785, Tokens per Sec:    25069, Lr: 0.000300
2024-05-28 12:10:41,805 - INFO - joeynmt.training - Epoch   4, Step:    15000, Batch Loss:     2.166861, Batch Acc: 0.401511, Tokens per Sec:    24430, Lr: 0.000300
2024-05-28 12:10:41,809 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:10:41,812 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:10:49,712 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.30, ppl:  10.01, acc:   0.39, generation: 7.8790[sec], evaluation: 0.0000[sec]
2024-05-28 12:10:49,715 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:10:49,802 - INFO - joeynmt.helpers - delete models/bpe-vocab/12500.ckpt
2024-05-28 12:10:49,808 - INFO - joeynmt.training - Example #0
2024-05-28 12:10:49,812 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:10:49,812 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:10:49,812 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'we', 'have', 'these', 'two', 're@@', 'por@@', 'ted', 're@@', 'por@@', 'ted', 'these', 'two', 're@@', 'por@@', 'ted', 're@@', 'ag@@', 'ing', 'pol@@', 'ic@@', 'y', 'in', 'the', 'last', 'few', 'million', 'years', 'ago,', 'the', 'last', 'few', 'million', 'years', 'ago,', 'the', 'last', '4@@', '5', 'million', 'years', 'ago,', 'the', 'larg@@', 'est', 'r@@', 'ang@@', 'e,', 'a', 'little', 'bit', 'of', 'a', 'small', 'number', 'of', 'years', 'ago.', '</s>']
2024-05-28 12:10:49,813 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:10:49,815 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:10:49,837 - INFO - joeynmt.training - 	Hypothesis: The year we have these two reported reported these two reported reaging policy in the last few million years ago, the last few million years ago, the last 45 million years ago, the largest range, a little bit of a small number of years ago.
2024-05-28 12:10:49,840 - INFO - joeynmt.training - Example #1
2024-05-28 12:10:49,844 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:10:49,844 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:10:49,844 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'tal@@', 'ity', 'of', 'the', 'species', 'of', 'this', 'issu@@', 'e', 'because', 'the', 'most', 'important', 'issu@@', 'es', 'because', 'they', "don't", 'have', 'the', 'r@@', 'itu@@', 'de.', '</s>']
2024-05-28 12:10:49,844 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:10:49,847 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:10:49,850 - INFO - joeynmt.training - 	Hypothesis: But this mortality of the species of this issue because the most important issues because they don't have the ritude.
2024-05-28 12:10:49,853 - INFO - joeynmt.training - Example #2
2024-05-28 12:10:49,856 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:10:49,856 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:10:49,856 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'of', 'pol@@', 'ice', 'is', 'in', 'a', 'way', 'that', 'the', 'future', 'of', 'the', 'climate', 'system@@', ',', '</s>']
2024-05-28 12:10:49,857 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:10:49,860 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:10:49,863 - INFO - joeynmt.training - 	Hypothesis: The police of police is in a way that the future of the climate system,
2024-05-28 12:10:49,865 - INFO - joeynmt.training - Example #3
2024-05-28 12:10:49,868 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:10:49,868 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:10:49,869 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'is', 'also', 'the', 'ex@@', 'pen@@', 'sive', 'and', 'the', 'ex@@', 'pen@@', 'sive', 'and', 'the', 'ex@@', 'pen@@', 'sive', 'one.', '</s>']
2024-05-28 12:10:49,869 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:10:49,872 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:10:49,876 - INFO - joeynmt.training - 	Hypothesis: She is also the expensive and the expensive and the expensive one.
2024-05-28 12:10:49,879 - INFO - joeynmt.training - Example #4
2024-05-28 12:10:49,882 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:10:49,882 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:10:49,882 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'few', 'years', 'of', 'the', 'pos@@', 'itive', 'thing', 'that', 'I', 'will', 'be', 'a', 'very', 'small', 'amount', 'of', 'time', 'to', 'be', 'a', 'little', 'bit', 'of', 'what', 'happened', 'in', 'the', 'last', '1@@', '5@@', '-@@', 'year-@@', 'old', 'da@@', 'u@@', 'gh@@', 'ter', 'in', 'the', 'last', '1@@', '5@@', '.', '</s>']
2024-05-28 12:10:49,883 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:10:49,886 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:10:49,889 - INFO - joeynmt.training - 	Hypothesis: The next few years of the positive thing that I will be a very small amount of time to be a little bit of what happened in the last 15-year-old daughter in the last 15.
2024-05-28 12:10:52,676 - INFO - joeynmt.training - Epoch   4, Step:    15100, Batch Loss:     2.208596, Batch Acc: 0.393789, Tokens per Sec:    23003, Lr: 0.000300
2024-05-28 12:10:55,428 - INFO - joeynmt.training - Epoch   4, Step:    15200, Batch Loss:     2.302962, Batch Acc: 0.404332, Tokens per Sec:    24989, Lr: 0.000300
2024-05-28 12:10:58,193 - INFO - joeynmt.training - Epoch   4, Step:    15300, Batch Loss:     2.270380, Batch Acc: 0.402010, Tokens per Sec:    24820, Lr: 0.000300
2024-05-28 12:11:00,973 - INFO - joeynmt.training - Epoch   4, Step:    15400, Batch Loss:     2.287388, Batch Acc: 0.412922, Tokens per Sec:    24807, Lr: 0.000300
2024-05-28 12:11:03,746 - INFO - joeynmt.training - Epoch   4, Step:    15500, Batch Loss:     1.979103, Batch Acc: 0.405585, Tokens per Sec:    25361, Lr: 0.000300
2024-05-28 12:11:03,763 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:11:03,782 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:11:11,024 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.27, ppl:   9.67, acc:   0.39, generation: 7.2217[sec], evaluation: 0.0000[sec]
2024-05-28 12:11:11,028 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:11:11,116 - INFO - joeynmt.helpers - delete models/bpe-vocab/13000.ckpt
2024-05-28 12:11:11,122 - INFO - joeynmt.training - Example #0
2024-05-28 12:11:11,125 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:11:11,126 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:11:11,126 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'last', 'year,', 'I', 'had', 'this', 'two', 'di@@', 'am@@', 'e@@', 'ter', 'to', 'show', 'that', 'the', 'second', 'to', 'show', 'that', 'the', 'c@@', 'ause', 'of', 'the', 'c@@', 'le@@', 'ver', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'two', 'million', 'years', 'of', 'the', 'p@@', 'age', 'of', 'the', 'small', 'cr@@', 'os@@', 's', 'of', 'the', 'small', 'cr@@', 'u@@', 'de', 'of', '4@@', '00', 'percent', 'of', 'the', 'little', 'b@@', 'it.', '</s>']
2024-05-28 12:11:11,126 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:11:11,129 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:11:11,132 - INFO - joeynmt.training - 	Hypothesis: The last year, I had this two diameter to show that the second to show that the cause of the clever of the last three million years of the last three million years of the last two million years of the page of the small cross of the small crude of 400 percent of the little bit.
2024-05-28 12:11:11,135 - INFO - joeynmt.training - Example #1
2024-05-28 12:11:11,139 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:11:11,139 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:11:11,139 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'al', 'mor@@', 'al', 'is', 'the', 'relation@@', 'ship', 'of', 'this', 'issu@@', 'e', 'because', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'p@@', 'y@@', 'ram@@', 'i@@', 'd.', '</s>']
2024-05-28 12:11:11,139 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:11:11,142 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:11:11,146 - INFO - joeynmt.training - 	Hypothesis: But this moral moral is the relationship of this issue because of the size of the size of the size of the size of the size of the size of the pyramid.
2024-05-28 12:11:11,148 - INFO - joeynmt.training - Example #2
2024-05-28 12:11:11,152 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:11:11,152 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:11:11,152 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is', 'the', 'pol@@', 'ice', 'of', 'the', 'future', 'that', 'the', 'global', 'system@@', 's', 'that', 'the', 'global', 'system@@', 's', 'of', 'global', 'system@@', '.', '</s>']
2024-05-28 12:11:11,152 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:11:11,155 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:11:11,158 - INFO - joeynmt.training - 	Hypothesis: The police is the police of the future that the global systems that the global systems of global system.
2024-05-28 12:11:11,161 - INFO - joeynmt.training - Example #3
2024-05-28 12:11:11,164 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:11:11,164 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:11:11,164 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'was', 'ex@@', 'ten@@', 'd', 'to', 'the', 's@@', 'am@@', 'ple', 'of', 'the', 'fo@@', 'ot@@', 'prin@@', 't.', '</s>']
2024-05-28 12:11:11,164 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:11:11,168 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:11:11,171 - INFO - joeynmt.training - 	Hypothesis: She was extend to the sample of the footprint.
2024-05-28 12:11:11,174 - INFO - joeynmt.training - Example #4
2024-05-28 12:11:11,177 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:11:11,177 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:11:11,177 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'few', 'years', 'of', 'the', 'pos@@', 'itive', 'I', 'will', 'show', 'you', 'the', 'point', 'of', 'what', "I'm", 'going', 'to', 'happen', 'in', 'the', 'last', '25', 'years', 'ago.', '</s>']
2024-05-28 12:11:11,177 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:11:11,207 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:11:11,211 - INFO - joeynmt.training - 	Hypothesis: The next few years of the positive I will show you the point of what I'm going to happen in the last 25 years ago.
2024-05-28 12:11:14,003 - INFO - joeynmt.training - Epoch   4, Step:    15600, Batch Loss:     2.312148, Batch Acc: 0.408987, Tokens per Sec:    22933, Lr: 0.000300
2024-05-28 12:11:15,763 - INFO - joeynmt.training - Epoch   4: total training loss 8968.52
2024-05-28 12:11:15,767 - INFO - joeynmt.training - EPOCH 5
2024-05-28 12:11:16,828 - INFO - joeynmt.training - Epoch   5, Step:    15700, Batch Loss:     2.060571, Batch Acc: 0.426467, Tokens per Sec:    24425, Lr: 0.000300
2024-05-28 12:11:19,587 - INFO - joeynmt.training - Epoch   5, Step:    15800, Batch Loss:     2.104176, Batch Acc: 0.429212, Tokens per Sec:    24778, Lr: 0.000300
2024-05-28 12:11:22,322 - INFO - joeynmt.training - Epoch   5, Step:    15900, Batch Loss:     2.274542, Batch Acc: 0.423274, Tokens per Sec:    24961, Lr: 0.000300
2024-05-28 12:11:25,055 - INFO - joeynmt.training - Epoch   5, Step:    16000, Batch Loss:     2.344947, Batch Acc: 0.426494, Tokens per Sec:    24895, Lr: 0.000300
2024-05-28 12:11:25,059 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:11:25,063 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:11:32,241 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.24, ppl:   9.43, acc:   0.40, generation: 7.1568[sec], evaluation: 0.0000[sec]
2024-05-28 12:11:32,265 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:11:32,357 - INFO - joeynmt.helpers - delete models/bpe-vocab/13500.ckpt
2024-05-28 12:11:32,373 - INFO - joeynmt.training - Example #0
2024-05-28 12:11:32,377 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:11:32,377 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:11:32,377 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'of', 'these', 'two', 're@@', 'ach@@', 'ed', 'the', 'second', 're@@', 'feren@@', 'ce', 'to', 'the', 'third', 'of', 'the', 'c@@', 'ause', 'of', 'the', 'c@@', 'le@@', 'ver', 'of', 'the', 'last', 'two', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'was', 'the', 'last', '1@@', '.@@', '8', 'years', 'of', 'the', 'size', 'of', '4@@', '4', 'to', '4@@', '.', '</s>']
2024-05-28 12:11:32,377 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:11:32,380 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:11:32,383 - INFO - joeynmt.training - 	Hypothesis: The year of these two reached the second reference to the third of the cause of the clever of the last two million years of the last three million years was the last 1.8 years of the size of 44 to 4.
2024-05-28 12:11:32,386 - INFO - joeynmt.training - Example #1
2024-05-28 12:11:32,388 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:11:32,388 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:11:32,388 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'al', 'mor@@', 'al', 'of', 'this', 'problem', 'because', 'of', 'this', 'speci@@', 'fic', 'issu@@', 'e', 'because', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:11:32,389 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:11:32,391 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:11:32,394 - INFO - joeynmt.training - 	Hypothesis: But this moral moral of this problem because of this specific issue because the size of the size of the size of the size of the size of the size of the same.
2024-05-28 12:11:32,397 - INFO - joeynmt.training - Example #2
2024-05-28 12:11:32,419 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:11:32,419 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:11:32,419 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'of', 'pol@@', 'ice', 'is', 'a', 'global', 'war@@', 'm@@', 'ing', 'the', 'global', 'system', 'that', 'the', 'global', 'system@@', '.', '</s>']
2024-05-28 12:11:32,420 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:11:32,423 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:11:32,426 - INFO - joeynmt.training - 	Hypothesis: The police of police is a global warming the global system that the global system.
2024-05-28 12:11:32,429 - INFO - joeynmt.training - Example #3
2024-05-28 12:11:32,433 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:11:32,433 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:11:32,433 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'is', 're@@', 'plac@@', 'ed', 'by', 'the', 'way,', 'and', 'the', 'contr@@', 'ac@@', 'tion', 'of', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:11:32,433 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:11:32,437 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:11:32,440 - INFO - joeynmt.training - 	Hypothesis: She is replaced by the way, and the contraction of the same.
2024-05-28 12:11:32,468 - INFO - joeynmt.training - Example #4
2024-05-28 12:11:32,471 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:11:32,471 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:11:32,471 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'year', 'of', 'the', 'picture', 'that', 'I', 'will', 'be', 'a', 'little', 'bit', 'of', 'what', 'it', 'is', 'a', 'little', 'bit', 'of', 'what', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:11:32,471 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:11:32,474 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:11:32,478 - INFO - joeynmt.training - 	Hypothesis: The next year of the picture that I will be a little bit of what it is a little bit of what happened in the last 25 years.
2024-05-28 12:11:35,229 - INFO - joeynmt.training - Epoch   5, Step:    16100, Batch Loss:     2.113258, Batch Acc: 0.427560, Tokens per Sec:    22922, Lr: 0.000300
2024-05-28 12:11:37,997 - INFO - joeynmt.training - Epoch   5, Step:    16200, Batch Loss:     1.945990, Batch Acc: 0.429816, Tokens per Sec:    25100, Lr: 0.000300
2024-05-28 12:11:40,787 - INFO - joeynmt.training - Epoch   5, Step:    16300, Batch Loss:     2.114850, Batch Acc: 0.429644, Tokens per Sec:    25010, Lr: 0.000300
2024-05-28 12:11:43,532 - INFO - joeynmt.training - Epoch   5, Step:    16400, Batch Loss:     2.075386, Batch Acc: 0.428838, Tokens per Sec:    24646, Lr: 0.000300
2024-05-28 12:11:46,296 - INFO - joeynmt.training - Epoch   5, Step:    16500, Batch Loss:     2.115394, Batch Acc: 0.428852, Tokens per Sec:    25056, Lr: 0.000300
2024-05-28 12:11:46,300 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:11:46,303 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:11:52,919 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.22, ppl:   9.22, acc:   0.41, generation: 6.5973[sec], evaluation: 0.0000[sec]
2024-05-28 12:11:52,926 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:11:53,022 - INFO - joeynmt.helpers - delete models/bpe-vocab/14000.ckpt
2024-05-28 12:11:53,088 - INFO - joeynmt.training - Example #0
2024-05-28 12:11:53,104 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:11:53,104 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:11:53,104 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'was', 'able', 'these', 'two', 'di@@', 'am@@', 'e@@', 'ter', 'to', 'show', 'that', 'the', 'second', 're@@', 'ag@@', 'er', 'of', 'the', 'cr@@', 'is@@', 'is', 'that', 'the', 'maj@@', 'or', '40', 'million', 'years', 'ago,', 'the', 'most', 'important', 'thing', 'was', 'about', '4@@', '8', 'million', 'years', 'ol@@', 'd,', 'was', 'the', 'size', 'of', '4@@', '8', 'percent', 'of', 'the', 'size', 'of', '4@@', '0@@', 's.', '</s>']
2024-05-28 12:11:53,105 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:11:53,108 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:11:53,111 - INFO - joeynmt.training - 	Hypothesis: The year I was able these two diameter to show that the second reager of the crisis that the major 40 million years ago, the most important thing was about 48 million years old, was the size of 48 percent of the size of 40s.
2024-05-28 12:11:53,114 - INFO - joeynmt.training - Example #1
2024-05-28 12:11:53,118 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:11:53,118 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:11:53,118 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'al', 'mor@@', 'al', 'issu@@', 'es', 'because', 'of', 'this', 'speci@@', 'fic', 'issu@@', 'e', 'because', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'this', 'mor@@', 'al', 'mor@@', 'al', 'mor@@', 'al', 'mor@@', 'al', 'mor@@', 'al', 'mor@@', 'al', 'mor@@', 'al', 'in', 'but', 'this', 'mor@@', 'al', 'mor@@', 'al', 'mor@@', 'al', 'mor@@', 'al', 'mor@@', 'al', '</s>']
2024-05-28 12:11:53,118 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:11:53,121 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:11:53,125 - INFO - joeynmt.training - 	Hypothesis: But this moral moral issues because of this specific issue because of the size of the size of the size of the size of the size of the size of the size of the size of the size of the size of the size of the size of this moral moral moral moral moral moral moral in but this moral moral moral moral moral
2024-05-28 12:11:53,128 - INFO - joeynmt.training - Example #2
2024-05-28 12:11:53,131 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:11:53,131 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:11:53,131 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'other', 'pol@@', 'ice', 'is', 'a', 'way', 'that', 'the', 'future', 'of', 'the', 'global', 'world', 'that', 'is', 'the', 'global', 'system@@', '.', '</s>']
2024-05-28 12:11:53,131 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:11:53,135 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:11:53,138 - INFO - joeynmt.training - 	Hypothesis: The other police is a way that the future of the global world that is the global system.
2024-05-28 12:11:53,143 - INFO - joeynmt.training - Example #3
2024-05-28 12:11:53,145 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:11:53,145 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:11:53,145 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'is', 'also', 'the', 'ex@@', 'ten@@', 'si@@', 'on,', 'and', 'the', 'de@@', 'si@@', 're', 'of', 'the', 'way.', '</s>']
2024-05-28 12:11:53,146 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:11:53,178 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:11:53,181 - INFO - joeynmt.training - 	Hypothesis: She is also the extension, and the desire of the way.
2024-05-28 12:11:53,185 - INFO - joeynmt.training - Example #4
2024-05-28 12:11:53,188 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:11:53,188 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:11:53,188 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'pos@@', 'itive', 'pos@@', 'itive', 'that', 'I', 'will', 'be', 'a', 'very', 'quick@@', 'ly', 're@@', 'qui@@', 'red', 'to', 'what', 'happen@@', 's.', '</s>']
2024-05-28 12:11:53,188 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:11:53,192 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:11:53,195 - INFO - joeynmt.training - 	Hypothesis: The next positive positive that I will be a very quickly required to what happens.
2024-05-28 12:11:55,935 - INFO - joeynmt.training - Epoch   5, Step:    16600, Batch Loss:     2.064906, Batch Acc: 0.426107, Tokens per Sec:    22603, Lr: 0.000300
2024-05-28 12:11:58,675 - INFO - joeynmt.training - Epoch   5, Step:    16700, Batch Loss:     1.980461, Batch Acc: 0.426667, Tokens per Sec:    24815, Lr: 0.000300
2024-05-28 12:12:01,403 - INFO - joeynmt.training - Epoch   5, Step:    16800, Batch Loss:     2.199394, Batch Acc: 0.431554, Tokens per Sec:    24641, Lr: 0.000300
2024-05-28 12:12:04,162 - INFO - joeynmt.training - Epoch   5, Step:    16900, Batch Loss:     2.280553, Batch Acc: 0.424863, Tokens per Sec:    25001, Lr: 0.000300
2024-05-28 12:12:06,904 - INFO - joeynmt.training - Epoch   5, Step:    17000, Batch Loss:     2.095969, Batch Acc: 0.431574, Tokens per Sec:    25003, Lr: 0.000300
2024-05-28 12:12:06,908 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:12:06,912 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:12:13,750 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.20, ppl:   9.06, acc:   0.41, generation: 6.8182[sec], evaluation: 0.0000[sec]
2024-05-28 12:12:13,753 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:12:13,845 - INFO - joeynmt.helpers - delete models/bpe-vocab/14500.ckpt
2024-05-28 12:12:13,896 - INFO - joeynmt.training - Example #0
2024-05-28 12:12:13,948 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:12:13,948 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:12:13,948 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'we', 'have', 'this', 'one', 'of', 'the', 'two', 'di@@', 'am@@', 'e@@', 'ter', 'to', 'demonstr@@', 'ate', 'that', 'the', 'r@@', 'ole', 'of', 'the', 'pol@@', 'ice', 'that', 'the', 'most', 'of', 'the', 'last', 'few', 'million', 'years', 'ago,', 'the', 'most', 'of', 'the', 'last', '4@@', '8', 'million', 'years', 'ago,', 'he', 'was', 'a', 'number', 'of', 'women', 'in', 'the', 'number', 'of', 'cancer', 'in', 'the', 'number', 'of', 'cancer', 'in', 'a', 'little', 'bit', 'of', '4@@', '0@@', '-@@', 'dol@@', 'l@@', 'ar', 'year', 'with', '4@@', '0@@', 's.', '</s>']
2024-05-28 12:12:13,948 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:12:13,951 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:12:13,954 - INFO - joeynmt.training - 	Hypothesis: The year we have this one of the two diameter to demonstrate that the role of the police that the most of the last few million years ago, the most of the last 48 million years ago, he was a number of women in the number of cancer in the number of cancer in a little bit of 40-dollar year with 40s.
2024-05-28 12:12:13,957 - INFO - joeynmt.training - Example #1
2024-05-28 12:12:13,960 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:12:13,960 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:12:13,960 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'al', 'mor@@', 'al', 'in', 'the', 'mor@@', 'al', 'issu@@', 'e', 'because', 'the', 'r@@', 'ole', 'of', 'the', 'size', 'of', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:12:13,960 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:12:13,963 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:12:13,966 - INFO - joeynmt.training - 	Hypothesis: But this moral moral in the moral issue because the role of the size of the same.
2024-05-28 12:12:13,969 - INFO - joeynmt.training - Example #2
2024-05-28 12:12:13,972 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:12:13,972 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:12:13,972 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is', 'the', 'pol@@', 'ice', 'is', 'a', 'way', 'that', 'the', 'global', 'world', 'that', 'is', 'the', 'global', 'system', 'of', 'global', 'system@@', '.', '</s>']
2024-05-28 12:12:13,972 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:12:13,975 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:12:13,978 - INFO - joeynmt.training - 	Hypothesis: The police is the police is a way that the global world that is the global system of global system.
2024-05-28 12:12:13,981 - INFO - joeynmt.training - Example #3
2024-05-28 12:12:14,015 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:12:14,015 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:12:14,015 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['He', 'was', 'ex@@', 'pen@@', 'sive', 'and', 'the', 'de@@', 'b@@', 'ate', 'and', 'the', 'de@@', 'b@@', 'er.', '</s>']
2024-05-28 12:12:14,016 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:12:14,019 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:12:14,022 - INFO - joeynmt.training - 	Hypothesis: He was expensive and the debate and the deber.
2024-05-28 12:12:14,025 - INFO - joeynmt.training - Example #4
2024-05-28 12:12:14,028 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:12:14,029 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:12:14,029 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'few', 'years', 'of', 'the', 'pos@@', 'itive', 'that', 'I', 'will', 'be', 'a', 'lot', 'of', 'time', 'to', 'be', 'a', 'little', 'bit', 'of', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:12:14,029 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:12:14,032 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:12:14,034 - INFO - joeynmt.training - 	Hypothesis: The next few years of the positive that I will be a lot of time to be a little bit of the last 25 years.
2024-05-28 12:12:16,777 - INFO - joeynmt.training - Epoch   5, Step:    17100, Batch Loss:     2.061716, Batch Acc: 0.430672, Tokens per Sec:    22605, Lr: 0.000300
2024-05-28 12:12:19,524 - INFO - joeynmt.training - Epoch   5, Step:    17200, Batch Loss:     1.966650, Batch Acc: 0.430272, Tokens per Sec:    25247, Lr: 0.000300
2024-05-28 12:12:22,283 - INFO - joeynmt.training - Epoch   5, Step:    17300, Batch Loss:     2.306792, Batch Acc: 0.432779, Tokens per Sec:    25263, Lr: 0.000300
2024-05-28 12:12:25,029 - INFO - joeynmt.training - Epoch   5, Step:    17400, Batch Loss:     2.065154, Batch Acc: 0.431956, Tokens per Sec:    24878, Lr: 0.000300
2024-05-28 12:12:27,782 - INFO - joeynmt.training - Epoch   5, Step:    17500, Batch Loss:     2.177329, Batch Acc: 0.431946, Tokens per Sec:    24795, Lr: 0.000300
2024-05-28 12:12:27,791 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:12:27,794 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:12:35,217 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.18, ppl:   8.87, acc:   0.42, generation: 7.4037[sec], evaluation: 0.0000[sec]
2024-05-28 12:12:35,221 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:12:35,360 - INFO - joeynmt.helpers - delete models/bpe-vocab/15000.ckpt
2024-05-28 12:12:35,393 - INFO - joeynmt.training - Example #0
2024-05-28 12:12:35,402 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:12:35,402 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:12:35,402 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'got', 'these', 'two', 'di@@', 'vi@@', 'ded', 'to', 'demonstr@@', 'ate', 'that', 'the', 'second', 'to', 'show', 'that', 'the', 'most', 'of', 'the', 'most', 'of', 'the', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'ago,', 'the', 'last', 'two', 'million', 'years', 'of', 'the', 'larg@@', 'est', 'r@@', 'ate', 'of', '4@@', '0@@', '-@@', 'dol@@', 'l@@', 'ar', 'sp@@', 'in', 'the', '2@@', '1@@', '.', '</s>']
2024-05-28 12:12:35,402 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:12:35,405 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:12:35,407 - INFO - joeynmt.training - 	Hypothesis: And the year we got these two divided to demonstrate that the second to show that the most of the most of the most of the last three million years of the last three million years ago, the last two million years of the largest rate of 40-dollar spin the 21.
2024-05-28 12:12:35,411 - INFO - joeynmt.training - Example #1
2024-05-28 12:12:35,414 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:12:35,414 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:12:35,414 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'al', 'the@@', 'ory', 'of', 'this', 'species', 'because', 'the', 'most', 'speci@@', 'fic', 'issu@@', 'es', 'because', 'the', 'r@@', 'ole', 'of', 'the', 'most', 'of', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:12:35,414 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:12:35,417 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:12:35,420 - INFO - joeynmt.training - 	Hypothesis: But this moral theory of this species because the most specific issues because the role of the most of the same.
2024-05-28 12:12:35,423 - INFO - joeynmt.training - Example #2
2024-05-28 12:12:35,426 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:12:35,426 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:12:35,426 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'pol@@', 'ice', 'is', 'a', 'way', 'of', 'the', 'global', 'global', 'world', 'system@@', '.', '</s>']
2024-05-28 12:12:35,427 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:12:35,430 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:12:35,433 - INFO - joeynmt.training - 	Hypothesis: The police police is a way of the global global world system.
2024-05-28 12:12:35,436 - INFO - joeynmt.training - Example #3
2024-05-28 12:12:35,439 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:12:35,439 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:12:35,439 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'was', 'the', 'ex@@', 'pen@@', 'sive', 'and', 'the', 'contr@@', 'ac@@', 'tion', 'of', 'the', 's@@', 'ou@@', 'th', 'of', 'the', 's@@', 'ou@@', 'th', 'of', 'the', 's@@', 'ou@@', 'th', 'of', 'the', 's@@', 'ou@@', 'th', 'of', 'the', 's@@', 'ou@@', 'th', 'of', 'the', 's@@', 'ou@@', 'th', 'of', 'the', 's@@', 'ou@@', 'th', 'of', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:12:35,440 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:12:35,470 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:12:35,473 - INFO - joeynmt.training - 	Hypothesis: She was the expensive and the contraction of the south of the south of the south of the south of the south of the south of the south of the same.
2024-05-28 12:12:35,476 - INFO - joeynmt.training - Example #4
2024-05-28 12:12:35,479 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:12:35,479 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:12:35,479 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'picture', 'of', 'the', 'next', 'picture', 'that', "I'm", 'going', 'to', 'be', 'a', 'lot', 'of', 'about', 'what', 'happen@@', 'ed,', 'at', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:12:35,480 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:12:35,482 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:12:35,485 - INFO - joeynmt.training - 	Hypothesis: The next picture of the next picture that I'm going to be a lot of about what happened, at the last 25 years.
2024-05-28 12:12:38,238 - INFO - joeynmt.training - Epoch   5, Step:    17600, Batch Loss:     2.171264, Batch Acc: 0.433657, Tokens per Sec:    22451, Lr: 0.000300
2024-05-28 12:12:41,003 - INFO - joeynmt.training - Epoch   5, Step:    17700, Batch Loss:     2.118479, Batch Acc: 0.431762, Tokens per Sec:    25578, Lr: 0.000300
2024-05-28 12:12:43,763 - INFO - joeynmt.training - Epoch   5, Step:    17800, Batch Loss:     2.215133, Batch Acc: 0.437158, Tokens per Sec:    24898, Lr: 0.000300
2024-05-28 12:12:46,526 - INFO - joeynmt.training - Epoch   5, Step:    17900, Batch Loss:     1.953433, Batch Acc: 0.435097, Tokens per Sec:    25525, Lr: 0.000300
2024-05-28 12:12:49,290 - INFO - joeynmt.training - Epoch   5, Step:    18000, Batch Loss:     2.172495, Batch Acc: 0.438654, Tokens per Sec:    25445, Lr: 0.000300
2024-05-28 12:12:49,294 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:12:49,297 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:12:56,000 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.16, ppl:   8.67, acc:   0.43, generation: 6.6836[sec], evaluation: 0.0000[sec]
2024-05-28 12:12:56,011 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:12:56,111 - INFO - joeynmt.helpers - delete models/bpe-vocab/15500.ckpt
2024-05-28 12:12:56,116 - INFO - joeynmt.training - Example #0
2024-05-28 12:12:56,121 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:12:56,121 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:12:56,121 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'last', 'year,', 'I', 'showed', 'these', 'two', 'di@@', 'vi@@', 'ded', 're@@', 'cei@@', 'ved', 'to', 'show', 'that', 'pol@@', 'ice', 'pol@@', 'ice', 'that', 'was', 'in', 'the', 'last', 'three', 'million', 'years', 'ago,', 'the', 'last', 'three', 'million', 'years', 'ago,', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'size', 'of', '4@@', '8', 'million', 'compani@@', 'es', 'in', 'the', 'number', 'of', 'different', 'compani@@', 'es', 'in', 'a', 'few', 'hundre@@', 'd', 'percent', 'of', 'the', 'size', 'of', '4@@', '0@@', 's.', '</s>']
2024-05-28 12:12:56,121 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:12:56,124 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:12:56,128 - INFO - joeynmt.training - 	Hypothesis: And the last year, I showed these two divided received to show that police police that was in the last three million years ago, the last three million years ago, the last three million years of the size of 48 million companies in the number of different companies in a few hundred percent of the size of 40s.
2024-05-28 12:12:56,131 - INFO - joeynmt.training - Example #1
2024-05-28 12:12:56,136 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:12:56,136 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:12:56,136 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'al', 'mor@@', 'al', 'in', 'this', 'speci@@', 'fic', 'issu@@', 'e', 'because', 'it', "doesn't", 'look', 'at', 'the', 'bot@@', 'tom', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:12:56,137 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:12:56,140 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:12:56,143 - INFO - joeynmt.training - 	Hypothesis: But this moral moral in this specific issue because it doesn't look at the bottom of the size of the size of the size of the size of the size of the same.
2024-05-28 12:12:56,147 - INFO - joeynmt.training - Example #2
2024-05-28 12:12:56,152 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:12:56,152 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:12:56,152 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is', 'in', 'the', 'pol@@', 'ice', 'is', 'a', 'global', 'war@@', 'm@@', 'ing', 'system@@', '.', '</s>']
2024-05-28 12:12:56,152 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:12:56,159 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:12:56,161 - INFO - joeynmt.training - 	Hypothesis: The police is in the police is a global warming system.
2024-05-28 12:12:56,164 - INFO - joeynmt.training - Example #3
2024-05-28 12:12:56,168 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:12:56,168 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:12:56,168 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'was', 'ex@@', 'ten@@', 'd', 'and', 'the', 'contr@@', 'ac@@', 'tion', 'and', 'the', 'contr@@', 'ac@@', 'tion', 'of', 'it.', '</s>']
2024-05-28 12:12:56,168 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:12:56,172 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:12:56,231 - INFO - joeynmt.training - 	Hypothesis: She was extend and the contraction and the contraction of it.
2024-05-28 12:12:56,234 - INFO - joeynmt.training - Example #4
2024-05-28 12:12:56,280 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:12:56,280 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:12:56,280 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'thing', 'that', 'I', 'will', 'show', 'you', 'the', 'next', 'to', 'what', 'was', 'going', 'to', 'happen', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:12:56,281 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:12:56,284 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:12:56,287 - INFO - joeynmt.training - 	Hypothesis: The next thing that I will show you the next to what was going to happen in the last 25 years.
2024-05-28 12:12:59,045 - INFO - joeynmt.training - Epoch   5, Step:    18100, Batch Loss:     2.072132, Batch Acc: 0.438978, Tokens per Sec:    22829, Lr: 0.000300
2024-05-28 12:13:01,809 - INFO - joeynmt.training - Epoch   5, Step:    18200, Batch Loss:     2.143767, Batch Acc: 0.437445, Tokens per Sec:    24887, Lr: 0.000300
2024-05-28 12:13:04,553 - INFO - joeynmt.training - Epoch   5, Step:    18300, Batch Loss:     1.980989, Batch Acc: 0.443417, Tokens per Sec:    24515, Lr: 0.000300
2024-05-28 12:13:07,310 - INFO - joeynmt.training - Epoch   5, Step:    18400, Batch Loss:     1.993164, Batch Acc: 0.446426, Tokens per Sec:    25317, Lr: 0.000300
2024-05-28 12:13:10,074 - INFO - joeynmt.training - Epoch   5, Step:    18500, Batch Loss:     2.006869, Batch Acc: 0.438634, Tokens per Sec:    25175, Lr: 0.000300
2024-05-28 12:13:10,079 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:13:10,082 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:13:17,520 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.14, ppl:   8.51, acc:   0.43, generation: 7.4191[sec], evaluation: 0.0000[sec]
2024-05-28 12:13:17,538 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:13:17,629 - INFO - joeynmt.helpers - delete models/bpe-vocab/16000.ckpt
2024-05-28 12:13:17,634 - INFO - joeynmt.training - Example #0
2024-05-28 12:13:17,637 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:13:17,637 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:13:17,637 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'we', 'got', 'these', 'two', 'di@@', 'am@@', 'e@@', 'te@@', 's,', 'to', 'pro@@', 've', 'to', 'the', 'cr@@', 'y@@', 'p@@', 'ical', 'pol@@', 'ice', 'that', 'in', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'ago,', 'the', 'last', 'three', 'million', 'years', 'ago,', 'he', 'was', 'a', 'little', 'bit', 'of', '4@@', '00', 'million', 'years', 'of', 'the', 'size', 'of', '4@@', '00', 'million', 'years', 'of', 'a', 'little', 'bit', 'of', '4@@', '00', 'percent', 'of', 'the', 'size', 'of', 'the', 'year.', '</s>']
2024-05-28 12:13:17,638 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:13:17,641 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:13:17,643 - INFO - joeynmt.training - 	Hypothesis: The year we got these two diametes, to prove to the crypical police that in the last three million years of the last three million years ago, the last three million years ago, he was a little bit of 400 million years of the size of 400 million years of a little bit of 400 percent of the size of the year.
2024-05-28 12:13:17,646 - INFO - joeynmt.training - Example #1
2024-05-28 12:13:17,649 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:13:17,649 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:13:17,649 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'al', 'mor@@', 'al', 'mor@@', 'ality', 'because', 'of', 'this', 'speci@@', 'fic', 'issu@@', 'e', 'because', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'mi@@', 'r@@', 'r@@', 'r@@', 'r@@', 'at@@', 's.', '</s>']
2024-05-28 12:13:17,649 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:13:17,652 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:13:17,654 - INFO - joeynmt.training - 	Hypothesis: But this moral moral morality because of this specific issue because the size of the size of the size of the size of the size of the size of the size of the size of the size of the size of the mirrrrats.
2024-05-28 12:13:17,657 - INFO - joeynmt.training - Example #2
2024-05-28 12:13:17,660 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:13:17,660 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:13:17,660 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'pol@@', 'ice', 'is', 'in', 'a', 'way', 'that', 'the', 'global', 'system', 'that', 'is', 'the', 'global', 'system@@', '.', '</s>']
2024-05-28 12:13:17,660 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:13:17,663 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:13:17,665 - INFO - joeynmt.training - 	Hypothesis: The police police is in a way that the global system that is the global system.
2024-05-28 12:13:17,668 - INFO - joeynmt.training - Example #3
2024-05-28 12:13:17,670 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:13:17,670 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:13:17,670 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['He', 'is', 'ex@@', 'ten@@', 'd', 'to', 'the', 'r@@', 'ange', 'and', 'the', 'contr@@', 'ac@@', 'tion', 'of', 'the', 'countr@@', 'y.', '</s>']
2024-05-28 12:13:17,671 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:13:17,673 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:13:17,694 - INFO - joeynmt.training - 	Hypothesis: He is extend to the range and the contraction of the country.
2024-05-28 12:13:17,697 - INFO - joeynmt.training - Example #4
2024-05-28 12:13:17,700 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:13:17,700 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:13:17,700 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'thing', 'that', 'is', 'going', 'to', 'be', 'a', 'little', 'bit', 'of', 'going', 'to', 'be', 'a', 'very', 'quick@@', 'ly', 're@@', 'mo@@', 'te', 'to', 'the', 'last', '25', 'years', 'ago.', '</s>']
2024-05-28 12:13:17,701 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:13:17,703 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:13:17,706 - INFO - joeynmt.training - 	Hypothesis: The next thing that is going to be a little bit of going to be a very quickly remote to the last 25 years ago.
2024-05-28 12:13:20,465 - INFO - joeynmt.training - Epoch   5, Step:    18600, Batch Loss:     1.956422, Batch Acc: 0.440466, Tokens per Sec:    23855, Lr: 0.000300
2024-05-28 12:13:23,214 - INFO - joeynmt.training - Epoch   5, Step:    18700, Batch Loss:     2.182422, Batch Acc: 0.440978, Tokens per Sec:    24832, Lr: 0.000300
2024-05-28 12:13:25,957 - INFO - joeynmt.training - Epoch   5, Step:    18800, Batch Loss:     2.155628, Batch Acc: 0.438185, Tokens per Sec:    24956, Lr: 0.000300
2024-05-28 12:13:28,705 - INFO - joeynmt.training - Epoch   5, Step:    18900, Batch Loss:     2.026430, Batch Acc: 0.443904, Tokens per Sec:    24858, Lr: 0.000300
2024-05-28 12:13:31,455 - INFO - joeynmt.training - Epoch   5, Step:    19000, Batch Loss:     2.061104, Batch Acc: 0.448116, Tokens per Sec:    25288, Lr: 0.000300
2024-05-28 12:13:31,459 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:13:31,463 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:13:38,293 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.12, ppl:   8.30, acc:   0.44, generation: 6.7990[sec], evaluation: 0.0000[sec]
2024-05-28 12:13:38,312 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:13:38,413 - INFO - joeynmt.helpers - delete models/bpe-vocab/16500.ckpt
2024-05-28 12:13:38,427 - INFO - joeynmt.training - Example #0
2024-05-28 12:13:38,431 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:13:38,431 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:13:38,431 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'have', 'ar@@', 'ri@@', 'ved', 'these', 'two', 'di@@', 'am@@', 'e@@', 'ter', 'to', 'pro@@', 've', 'that', 'the', 'big', 'is@@', 'land', 'of', 'the', 'last', 'three', 'million', 'years', 'ago,', 'the', 'most', 'of', 'the', 'last', '4@@', '8', 'million', 'years', 'ago', 'was', 'the', 'size', 'of', '4@@', '8', 'percent', 'of', 'the', 'mon@@', 'th', 'of', '4@@', '00', 'percent', 'of', 'the', 'mon@@', '.', '</s>']
2024-05-28 12:13:38,432 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:13:38,435 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:13:38,439 - INFO - joeynmt.training - 	Hypothesis: And the year we have arrived these two diameter to prove that the big island of the last three million years ago, the most of the last 48 million years ago was the size of 48 percent of the month of 400 percent of the mon.
2024-05-28 12:13:38,442 - INFO - joeynmt.training - Example #1
2024-05-28 12:13:38,445 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:13:38,445 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:13:38,445 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'this', 'is', 'the', 'seri@@', 'ous', 'issu@@', 'e', 'because', 'it', "doesn't", 'have', 'the', 'r@@', 'ange', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'mi@@', 'd-@@', 'to@@', '-@@', 'the@@', '-@@', 'the@@', 'at@@', 'er.', '</s>']
2024-05-28 12:13:38,446 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:13:38,449 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:13:38,452 - INFO - joeynmt.training - 	Hypothesis: But this morning, this is the serious issue because it doesn't have the range of the size of the size of the size of the size of the size of the size of the size of the size of the mid-to-the-theater.
2024-05-28 12:13:38,455 - INFO - joeynmt.training - Example #2
2024-05-28 12:13:38,458 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:13:38,458 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:13:38,458 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'pol@@', 'ice', 'is', 'in', 'a', 'way', 'of', 'the', 'global', 'system', 'that', 'is', 'the', 'global', 'system@@', '.', '</s>']
2024-05-28 12:13:38,459 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:13:38,461 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:13:38,464 - INFO - joeynmt.training - 	Hypothesis: The police police is in a way of the global system that is the global system.
2024-05-28 12:13:38,467 - INFO - joeynmt.training - Example #3
2024-05-28 12:13:38,471 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:13:38,471 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:13:38,471 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'was', 'exp@@', 'ected', 'by', 'the', 'way,', 'and', 'the', 'contr@@', 'ac@@', 'tion', 'of', 'the', 'countr@@', 'y.', '</s>']
2024-05-28 12:13:38,471 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:13:38,504 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:13:38,507 - INFO - joeynmt.training - 	Hypothesis: She was expected by the way, and the contraction of the country.
2024-05-28 12:13:38,511 - INFO - joeynmt.training - Example #4
2024-05-28 12:13:38,514 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:13:38,514 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:13:38,514 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'mon@@', 'th', 'of', 'the', 'next', 'pos@@', 'itive', 'that', 'you', 'will', 'be', 'a', 'very', 'quick@@', 'ly', 'quick@@', 'ly', 'will', 'be', 'a', 'little', 'bit', 'of', 'what', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:13:38,514 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:13:38,517 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:13:38,521 - INFO - joeynmt.training - 	Hypothesis: The next month of the next positive that you will be a very quickly quickly will be a little bit of what happened in the last 25 years.
2024-05-28 12:13:41,273 - INFO - joeynmt.training - Epoch   5, Step:    19100, Batch Loss:     2.029278, Batch Acc: 0.446668, Tokens per Sec:    23270, Lr: 0.000300
2024-05-28 12:13:44,027 - INFO - joeynmt.training - Epoch   5, Step:    19200, Batch Loss:     1.897748, Batch Acc: 0.441296, Tokens per Sec:    24836, Lr: 0.000300
2024-05-28 12:13:46,770 - INFO - joeynmt.training - Epoch   5, Step:    19300, Batch Loss:     1.991268, Batch Acc: 0.443802, Tokens per Sec:    25055, Lr: 0.000300
2024-05-28 12:13:49,540 - INFO - joeynmt.training - Epoch   5, Step:    19400, Batch Loss:     2.024761, Batch Acc: 0.447932, Tokens per Sec:    24881, Lr: 0.000300
2024-05-28 12:13:52,307 - INFO - joeynmt.training - Epoch   5, Step:    19500, Batch Loss:     1.951092, Batch Acc: 0.449138, Tokens per Sec:    25182, Lr: 0.000300
2024-05-28 12:13:52,311 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:13:52,314 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:13:58,574 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.10, ppl:   8.19, acc:   0.44, generation: 6.2431[sec], evaluation: 0.0000[sec]
2024-05-28 12:13:58,596 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:13:58,685 - INFO - joeynmt.helpers - delete models/bpe-vocab/17000.ckpt
2024-05-28 12:13:58,696 - INFO - joeynmt.training - Example #0
2024-05-28 12:13:58,700 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:13:58,700 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:13:58,700 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'showed', 'these', 'two', 'di@@', 'as@@', 's@@', 'ets', 'to', 'demonstr@@', 'ate', 'that', 'was', 'like', 'the', 'second', 'to', 'the', 'city', 'that', 'in', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'was', 'the', 'size', 'of', 'the', 'last', '4@@', '8@@', '0@@', '-@@', 'year', 'year', 'year', 'year', 'by', '4@@', '.', '</s>']
2024-05-28 12:13:58,701 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:13:58,704 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:13:58,707 - INFO - joeynmt.training - 	Hypothesis: And the year we showed these two diassets to demonstrate that was like the second to the city that in the last three million years of the last three million years was the size of the last 480-year year year year by 4.
2024-05-28 12:13:58,710 - INFO - joeynmt.training - Example #1
2024-05-28 12:13:58,729 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:13:58,729 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:13:58,729 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'al', 'mor@@', 'al', 'is', 'seri@@', 'ous', 'about', 'this', 'speci@@', 'fic', 'issu@@', 'e', 'because', 'it', "doesn't", 'look', 'at', 'the', 'stre@@', 'ets', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'si@@', 'de.', '</s>']
2024-05-28 12:13:58,729 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:13:58,732 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:13:58,735 - INFO - joeynmt.training - 	Hypothesis: But this moral moral is serious about this specific issue because it doesn't look at the streets of the size of the size of the size of the size of the size of the size of the side.
2024-05-28 12:13:58,739 - INFO - joeynmt.training - Example #2
2024-05-28 12:13:58,742 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:13:58,742 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:13:58,742 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'pol@@', 'ice', 'is', 'a', 'way', 'that', 'the', 'global', 'war@@', 'm@@', 'ing', 'system@@', ',', 'in', 'a', 'global', 'system@@', '.', '</s>']
2024-05-28 12:13:58,742 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:13:58,745 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:13:58,748 - INFO - joeynmt.training - 	Hypothesis: The police police is a way that the global warming system, in a global system.
2024-05-28 12:13:58,750 - INFO - joeynmt.training - Example #3
2024-05-28 12:13:58,753 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:13:58,754 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:13:58,754 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ded', 'up', 'and', 'they', 'are', 'de@@', 'ep', 'and', 'the', 'cl@@', 'a@@', 'im@@', 'ing', 'of', 'the', 'wat@@', 'er.', '</s>']
2024-05-28 12:13:58,754 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:13:58,757 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:13:58,777 - INFO - joeynmt.training - 	Hypothesis: It expanded up and they are deep and the claiming of the water.
2024-05-28 12:13:58,781 - INFO - joeynmt.training - Example #4
2024-05-28 12:13:58,784 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:13:58,784 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:13:58,784 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'pos@@', 'itive', 'pos@@', 'iti@@', 'ons', 'that', 'I', 'will', 'be', 'a', 'quick@@', 'ly', 'quick@@', 'ly', 'will', 'be', 'a', 'little', 'bit', 'like', 'what', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:13:58,785 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:13:58,788 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:13:58,792 - INFO - joeynmt.training - 	Hypothesis: The next positive positions that I will be a quickly quickly will be a little bit like what happened in the last 25 years.
2024-05-28 12:14:00,658 - INFO - joeynmt.training - Epoch   5: total training loss 8190.49
2024-05-28 12:14:00,662 - INFO - joeynmt.training - EPOCH 6
2024-05-28 12:14:01,550 - INFO - joeynmt.training - Epoch   6, Step:    19600, Batch Loss:     1.857172, Batch Acc: 0.472022, Tokens per Sec:    24216, Lr: 0.000300
2024-05-28 12:14:04,311 - INFO - joeynmt.training - Epoch   6, Step:    19700, Batch Loss:     1.976525, Batch Acc: 0.468204, Tokens per Sec:    25558, Lr: 0.000300
2024-05-28 12:14:07,052 - INFO - joeynmt.training - Epoch   6, Step:    19800, Batch Loss:     2.013440, Batch Acc: 0.471004, Tokens per Sec:    24834, Lr: 0.000300
2024-05-28 12:14:09,799 - INFO - joeynmt.training - Epoch   6, Step:    19900, Batch Loss:     1.890027, Batch Acc: 0.466558, Tokens per Sec:    25023, Lr: 0.000300
2024-05-28 12:14:12,566 - INFO - joeynmt.training - Epoch   6, Step:    20000, Batch Loss:     2.062779, Batch Acc: 0.469829, Tokens per Sec:    25128, Lr: 0.000300
2024-05-28 12:14:12,570 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:14:12,573 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:14:19,066 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.08, ppl:   8.04, acc:   0.45, generation: 6.4743[sec], evaluation: 0.0000[sec]
2024-05-28 12:14:19,070 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:14:19,160 - INFO - joeynmt.helpers - delete models/bpe-vocab/17500.ckpt
2024-05-28 12:14:19,173 - INFO - joeynmt.training - Example #0
2024-05-28 12:14:19,177 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:14:19,177 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:14:19,177 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'ar@@', 'ri@@', 'ved', 'these', 'two', 'di@@', 'vi@@', 'de', 'to', 'demonstr@@', 'ate', 'that', 'the', 'pol@@', 'ar', 'pol@@', 'ar', 'pol@@', 'ar', 'pol@@', 'ar', 'pol@@', 'ar', 'that', 'ma@@', 'in', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'few', 'million', 'years', 'ago,', 'was', 'a', 'little', 'bit', 'of', '4@@', '8', 'years', 'ol@@', 'd.', '</s>']
2024-05-28 12:14:19,178 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:14:19,181 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:14:19,184 - INFO - joeynmt.training - 	Hypothesis: And the year we arrived these two divide to demonstrate that the polar polar polar polar polar that main the last three million years of the last few million years ago, was a little bit of 48 years old.
2024-05-28 12:14:19,187 - INFO - joeynmt.training - Example #1
2024-05-28 12:14:19,190 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:14:19,191 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:14:19,191 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'a', 'seri@@', 'ous', 'seri@@', 'ous', 'issu@@', 'e', 'because', 'the', 'fact', 'that', 'it', "doesn't", 'look', 'like', 'the', 's@@', 'oul', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'time.', '</s>']
2024-05-28 12:14:19,191 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:14:19,195 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:14:19,197 - INFO - joeynmt.training - 	Hypothesis: But this is a serious serious issue because the fact that it doesn't look like the soul of the size of the size of the size of the size of the size of the size of the size of the size of the time.
2024-05-28 12:14:19,201 - INFO - joeynmt.training - Example #2
2024-05-28 12:14:19,204 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:14:19,204 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:14:19,204 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'pol@@', 'ice', 'is', 'in', 'a', 'way', 'that', 'the', 'global', 'system', 'that', 'has', 'the', 'climate', 'system@@', '.', '</s>']
2024-05-28 12:14:19,205 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:14:19,208 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:14:19,211 - INFO - joeynmt.training - 	Hypothesis: The police police is in a way that the global system that has the climate system.
2024-05-28 12:14:19,214 - INFO - joeynmt.training - Example #3
2024-05-28 12:14:19,217 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:14:19,217 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:14:19,217 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'is', 'exp@@', 'ected', 'by', 'the', 'way,', 'and', 'the', 'contr@@', 'ac@@', 'tion', 'of', 'the', 'fo@@', 'ot@@', 'prin@@', 't.', '</s>']
2024-05-28 12:14:19,218 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:14:19,235 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:14:19,238 - INFO - joeynmt.training - 	Hypothesis: She is expected by the way, and the contraction of the footprint.
2024-05-28 12:14:19,242 - INFO - joeynmt.training - Example #4
2024-05-28 12:14:19,245 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:14:19,245 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:14:19,245 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'pos@@', 'itive', 'thing', 'that', 'I', 'will', 'be', 'a', 'quick@@', 'ly', 'going', 'to', 'be', 'a', 'little', 'bit', 'of', 'what', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:14:19,245 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:14:19,248 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:14:19,251 - INFO - joeynmt.training - 	Hypothesis: The next positive thing that I will be a quickly going to be a little bit of what happened in the last 25 years.
2024-05-28 12:14:22,004 - INFO - joeynmt.training - Epoch   6, Step:    20100, Batch Loss:     2.065572, Batch Acc: 0.472286, Tokens per Sec:    23354, Lr: 0.000300
2024-05-28 12:14:24,751 - INFO - joeynmt.training - Epoch   6, Step:    20200, Batch Loss:     1.838368, Batch Acc: 0.464367, Tokens per Sec:    24857, Lr: 0.000300
2024-05-28 12:14:27,533 - INFO - joeynmt.training - Epoch   6, Step:    20300, Batch Loss:     1.950851, Batch Acc: 0.465735, Tokens per Sec:    24728, Lr: 0.000300
2024-05-28 12:14:30,278 - INFO - joeynmt.training - Epoch   6, Step:    20400, Batch Loss:     1.962427, Batch Acc: 0.469222, Tokens per Sec:    24952, Lr: 0.000300
2024-05-28 12:14:33,034 - INFO - joeynmt.training - Epoch   6, Step:    20500, Batch Loss:     1.997799, Batch Acc: 0.464582, Tokens per Sec:    25062, Lr: 0.000300
2024-05-28 12:14:33,038 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:14:33,041 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:14:39,894 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.09, ppl:   8.05, acc:   0.44, generation: 6.8350[sec], evaluation: 0.0000[sec]
2024-05-28 12:14:39,979 - INFO - joeynmt.helpers - delete models/bpe-vocab/18000.ckpt
2024-05-28 12:14:40,003 - INFO - joeynmt.training - Example #0
2024-05-28 12:14:40,007 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:14:40,007 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:14:40,007 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'last', 'year', 'we', 'have', 'been', 'able', 'to', 'demonstr@@', 'ate', 'these', 'two', 'di@@', 'vi@@', 'de', 'to', 'demonstr@@', 'ate', 'that', 'the', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'was', 'the', 'size', 'of', 'the', 'last', '4@@', '8', 'percent', 'of', 'the', 'last', '4@@', '8', 'percent', 'of', 'the', 'last', '4@@', 'th', 'of', 'percent', 'of', 'the', 'last', '4@@', '.', '</s>']
2024-05-28 12:14:40,008 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:14:40,011 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:14:40,014 - INFO - joeynmt.training - 	Hypothesis: And the last year we have been able to demonstrate these two divide to demonstrate that the most of the last three million years of the last three million years was the size of the last 48 percent of the last 48 percent of the last 4th of percent of the last 4.
2024-05-28 12:14:40,017 - INFO - joeynmt.training - Example #1
2024-05-28 12:14:40,020 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:14:40,020 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:14:40,021 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'al', 'mor@@', 'al', 'real@@', 'ity', 'of', 'this', 'speci@@', 'fic', 'issu@@', 'e', 'because', 'the', 'f@@', 'os@@', 'si@@', 'l', 'of', 'the', 'f@@', 'os@@', 'si@@', 'l', 'of', 'the', 'f@@', 'os@@', 'si@@', 'l', 'of', 'the', 'f@@', 'os@@', 'si@@', 'l', 'of', 'the', 'f@@', 'os@@', 'si@@', 'l', 'of', 'this', 'speci@@', 'es.', '</s>']
2024-05-28 12:14:40,021 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:14:40,024 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:14:40,027 - INFO - joeynmt.training - 	Hypothesis: But this moral moral reality of this specific issue because the fossil of the fossil of the fossil of the fossil of the fossil of this species.
2024-05-28 12:14:40,030 - INFO - joeynmt.training - Example #2
2024-05-28 12:14:40,033 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:14:40,033 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:14:40,033 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'pol@@', 'ice', 'is', 'in', 'a', 'way', 'that', 'the', 'global', 'system', 'that', 'we', 'have', 'the', 'climate', 'system@@', '.', '</s>']
2024-05-28 12:14:40,033 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:14:40,036 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:14:40,040 - INFO - joeynmt.training - 	Hypothesis: The police police is in a way that the global system that we have the climate system.
2024-05-28 12:14:40,042 - INFO - joeynmt.training - Example #3
2024-05-28 12:14:40,045 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:14:40,045 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:14:40,045 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'goes', 'on', 'and', 'the', 'bot@@', 'tom', 'and', 'the', 'f@@', 'light', 'and', 'the', 'f@@', 'low@@', '.', '</s>']
2024-05-28 12:14:40,046 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:14:40,061 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:14:40,064 - INFO - joeynmt.training - 	Hypothesis: It goes on and the bottom and the flight and the flow.
2024-05-28 12:14:40,067 - INFO - joeynmt.training - Example #4
2024-05-28 12:14:40,070 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:14:40,070 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:14:40,070 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'pos@@', 'itive', 'pos@@', 'itive', 'that', 'I', 'will', 'be', 'a', 'very', 'quick@@', 'ly', 'going', 'to', 'be', 'a', 'very', 'quick@@', 'ly', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:14:40,070 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:14:40,074 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:14:40,077 - INFO - joeynmt.training - 	Hypothesis: The next positive positive that I will be a very quickly going to be a very quickly in the last 25 years.
2024-05-28 12:14:42,847 - INFO - joeynmt.training - Epoch   6, Step:    20600, Batch Loss:     2.126750, Batch Acc: 0.473620, Tokens per Sec:    24303, Lr: 0.000300
2024-05-28 12:14:45,628 - INFO - joeynmt.training - Epoch   6, Step:    20700, Batch Loss:     1.954100, Batch Acc: 0.466056, Tokens per Sec:    25992, Lr: 0.000300
2024-05-28 12:14:48,381 - INFO - joeynmt.training - Epoch   6, Step:    20800, Batch Loss:     1.900924, Batch Acc: 0.467615, Tokens per Sec:    25208, Lr: 0.000300
2024-05-28 12:14:51,113 - INFO - joeynmt.training - Epoch   6, Step:    20900, Batch Loss:     1.983522, Batch Acc: 0.463867, Tokens per Sec:    24774, Lr: 0.000300
2024-05-28 12:14:53,852 - INFO - joeynmt.training - Epoch   6, Step:    21000, Batch Loss:     1.970722, Batch Acc: 0.471815, Tokens per Sec:    25372, Lr: 0.000300
2024-05-28 12:14:53,856 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:14:53,860 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:15:00,172 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.06, ppl:   7.88, acc:   0.45, generation: 6.2955[sec], evaluation: 0.0000[sec]
2024-05-28 12:15:00,188 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:15:00,277 - INFO - joeynmt.helpers - delete models/bpe-vocab/18500.ckpt
2024-05-28 12:15:00,283 - INFO - joeynmt.training - Example #0
2024-05-28 12:15:00,288 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:15:00,289 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:15:00,289 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'showed', 'these', 'two', 'di@@', 'vi@@', 'ded', 'pictu@@', 'res', 'to', 'demonstr@@', 'ate', 'that', 'in', 'the', 'cr@@', 'y@@', 'p@@', 'ti@@', 'a', 'in', 'the', 'last', 'three', 'to', 'the', 'last', 'three', 'to', 'the', 'last', 'three', 'to', 'the', 'last', '4@@', '8', 'million', 'years', 'ago.', '</s>']
2024-05-28 12:15:00,289 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:15:00,293 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:15:00,296 - INFO - joeynmt.training - 	Hypothesis: And the year we showed these two divided pictures to demonstrate that in the cryptia in the last three to the last three to the last three to the last 48 million years ago.
2024-05-28 12:15:00,299 - INFO - joeynmt.training - Example #1
2024-05-28 12:15:00,302 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:15:00,302 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:15:00,303 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'ning', 'of', 'this', 'speci@@', 'fic', 'issu@@', 'e', 'because', 'of', 'the', 'f@@', 'os@@', 'si@@', 'l', 'of', 'the', 'f@@', 'ish@@', '.', '</s>']
2024-05-28 12:15:00,303 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:15:00,306 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:15:00,309 - INFO - joeynmt.training - 	Hypothesis: But this morning of this specific issue because of the fossil of the fish.
2024-05-28 12:15:00,322 - INFO - joeynmt.training - Example #2
2024-05-28 12:15:00,325 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:15:00,325 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:15:00,325 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is', 'in', 'a', 'way', 'that', 'the', 'heart', 'of', 'the', 'global', 'system', 'that', 'was', 'global', 'system@@', '.', '</s>']
2024-05-28 12:15:00,326 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:15:00,329 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:15:00,332 - INFO - joeynmt.training - 	Hypothesis: The police is in a way that the heart of the global system that was global system.
2024-05-28 12:15:00,335 - INFO - joeynmt.training - Example #3
2024-05-28 12:15:00,338 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:15:00,338 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:15:00,338 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'is', 'exp@@', 'ected', 'to', 'the', 'l@@', 'ack', 'of', 'the', 'countr@@', 'y.', '</s>']
2024-05-28 12:15:00,339 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:15:00,342 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:15:00,345 - INFO - joeynmt.training - 	Hypothesis: She is expected to the lack of the country.
2024-05-28 12:15:00,373 - INFO - joeynmt.training - Example #4
2024-05-28 12:15:00,376 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:15:00,376 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:15:00,376 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'that', "I'm", 'going', 'to', 'show', 'you', 'a', 'very', 'quick@@', 'ly', 'will', 'be', 'a', 'very', 'quick@@', 'ly', 'going', 'to', 'be', 'a', 'little', 'bit', 'of', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:15:00,376 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:15:00,379 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:15:00,383 - INFO - joeynmt.training - 	Hypothesis: The next slide that I'm going to show you a very quickly will be a very quickly going to be a little bit of the last 25 years.
2024-05-28 12:15:03,163 - INFO - joeynmt.training - Epoch   6, Step:    21100, Batch Loss:     1.770610, Batch Acc: 0.471750, Tokens per Sec:    23235, Lr: 0.000300
2024-05-28 12:15:05,884 - INFO - joeynmt.training - Epoch   6, Step:    21200, Batch Loss:     1.975674, Batch Acc: 0.464739, Tokens per Sec:    24281, Lr: 0.000300
2024-05-28 12:15:08,620 - INFO - joeynmt.training - Epoch   6, Step:    21300, Batch Loss:     1.933029, Batch Acc: 0.469154, Tokens per Sec:    24656, Lr: 0.000300
2024-05-28 12:15:11,373 - INFO - joeynmt.training - Epoch   6, Step:    21400, Batch Loss:     1.945950, Batch Acc: 0.469792, Tokens per Sec:    25947, Lr: 0.000300
2024-05-28 12:15:14,103 - INFO - joeynmt.training - Epoch   6, Step:    21500, Batch Loss:     1.806327, Batch Acc: 0.468386, Tokens per Sec:    24899, Lr: 0.000300
2024-05-28 12:15:14,108 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:15:14,111 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:15:20,746 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.04, ppl:   7.72, acc:   0.45, generation: 6.6167[sec], evaluation: 0.0000[sec]
2024-05-28 12:15:20,755 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:15:20,842 - INFO - joeynmt.helpers - delete models/bpe-vocab/19000.ckpt
2024-05-28 12:15:20,855 - INFO - joeynmt.training - Example #0
2024-05-28 12:15:20,858 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:15:20,858 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:15:20,858 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'got', 'these', 'two', 'di@@', 'vi@@', 'ded', 'photo@@', 'graph@@', 's', 'to', 'show', 'that', 'the', 'r@@', 'ole', 'of', 'the', 'last', 'three', 'to', 'the', 'last', 'three', 'million', 'years', 'that', 'in', 'the', 'last', 'three', 'million', 'years', 'ago', 'was', 'the', 'size', 'of', '4@@', '8', 'million', 'years', 'ago', 'was', 'a', 'little', 'bit', 'of', '4@@', '8', 'percent', 'of', 'the', 'size', 'of', '4@@', '0@@', 's', 'of', 'the', 'mon@@', 'th', 'of', '4@@', 'th', 'centur@@', 'y.', '</s>']
2024-05-28 12:15:20,859 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:15:20,862 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:15:20,865 - INFO - joeynmt.training - 	Hypothesis: The year I got these two divided photographs to show that the role of the last three to the last three million years that in the last three million years ago was the size of 48 million years ago was a little bit of 48 percent of the size of 40s of the month of 4th century.
2024-05-28 12:15:20,868 - INFO - joeynmt.training - Example #1
2024-05-28 12:15:20,871 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:15:20,871 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:15:20,871 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'seri@@', 'ous', 'seri@@', 'ous', 'about', 'this', 'speci@@', 'fic', 'issu@@', 'e', 'because', 'the', 'size', 'of', 'this', 'speci@@', 'fic', 'issu@@', 'e.', '</s>']
2024-05-28 12:15:20,872 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:15:20,875 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:15:20,878 - INFO - joeynmt.training - 	Hypothesis: But this is serious serious about this specific issue because the size of this specific issue.
2024-05-28 12:15:20,881 - INFO - joeynmt.training - Example #2
2024-05-28 12:15:20,884 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:15:20,884 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:15:20,884 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is', 'in', 'a', 'way', 'that', 'the', 'global', 'war@@', 'm@@', 'ing', 'system@@', ',', 'the', 'global', 'system@@', '.', '</s>']
2024-05-28 12:15:20,885 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:15:20,888 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:15:20,891 - INFO - joeynmt.training - 	Hypothesis: The police is in a way that the global warming system, the global system.
2024-05-28 12:15:20,893 - INFO - joeynmt.training - Example #3
2024-05-28 12:15:20,896 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:15:20,896 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:15:20,896 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'is', 'exp@@', 'ect@@', 'ing', 'and', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 'tion', 'of', 'the', 'b@@', 'read@@', '.', '</s>']
2024-05-28 12:15:20,897 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:15:20,900 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:15:20,927 - INFO - joeynmt.training - 	Hypothesis: She is expecting and contraction and contraction of the bread.
2024-05-28 12:15:20,930 - INFO - joeynmt.training - Example #4
2024-05-28 12:15:20,934 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:15:20,934 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:15:20,934 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'pos@@', 'itive', 'pos@@', 'itive', 'that', 'you', 'will', 'show', 'you', 'a', 'very', 'quick@@', 'ly', 'f@@', 'ast', 'to', 'what', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:15:20,934 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:15:20,937 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:15:20,941 - INFO - joeynmt.training - 	Hypothesis: The next positive positive that you will show you a very quickly fast to what happened in the last 25 years.
2024-05-28 12:15:23,691 - INFO - joeynmt.training - Epoch   6, Step:    21600, Batch Loss:     1.930653, Batch Acc: 0.476706, Tokens per Sec:    23961, Lr: 0.000300
2024-05-28 12:15:26,438 - INFO - joeynmt.training - Epoch   6, Step:    21700, Batch Loss:     2.049997, Batch Acc: 0.464440, Tokens per Sec:    24607, Lr: 0.000300
2024-05-28 12:15:29,148 - INFO - joeynmt.training - Epoch   6, Step:    21800, Batch Loss:     2.062055, Batch Acc: 0.475872, Tokens per Sec:    24451, Lr: 0.000300
2024-05-28 12:15:31,875 - INFO - joeynmt.training - Epoch   6, Step:    21900, Batch Loss:     1.811291, Batch Acc: 0.464231, Tokens per Sec:    25127, Lr: 0.000300
2024-05-28 12:15:34,606 - INFO - joeynmt.training - Epoch   6, Step:    22000, Batch Loss:     1.969779, Batch Acc: 0.467146, Tokens per Sec:    25148, Lr: 0.000300
2024-05-28 12:15:34,610 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:15:34,613 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:15:41,642 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.04, ppl:   7.71, acc:   0.46, generation: 7.0111[sec], evaluation: 0.0000[sec]
2024-05-28 12:15:41,661 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:15:41,768 - INFO - joeynmt.helpers - delete models/bpe-vocab/19500.ckpt
2024-05-28 12:15:41,781 - INFO - joeynmt.training - Example #0
2024-05-28 12:15:41,785 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:15:41,785 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:15:41,785 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'we', 'ar@@', 'gu@@', 'ed', 'these', 'two', 'di@@', 'am@@', 'e@@', 'ter', 'to', 'demonstr@@', 'ate', 'that', 'the', 'r@@', 'ole', 'of', 'the', 'cr@@', 'y@@', 'p@@', 'tion', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'countries', 'that', 'was', 'a', 'little', 'bit', '4@@', '0@@', '-@@', 'year', 'of', 'the', 'time', 'of', '4@@', '00', 'percent', 'of', 'the', 'size', 'of', 'the', '20@@', '.', '</s>']
2024-05-28 12:15:41,785 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:15:41,788 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:15:41,790 - INFO - joeynmt.training - 	Hypothesis: The year we argued these two diameter to demonstrate that the role of the cryption of the last three million years of the last three million years of the last three million years of the last three million countries that was a little bit 40-year of the time of 400 percent of the size of the 20.
2024-05-28 12:15:41,793 - INFO - joeynmt.training - Example #1
2024-05-28 12:15:41,796 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:15:41,796 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:15:41,796 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'al', 'mor@@', 'al', 'of', 'this', 'speci@@', 'fic', 'issu@@', 'e', 'because', 'the', 'size', 'of', 'the', 'bl@@', 'ue', 'of', 'the', 'bl@@', 'ue', 'of', 'the', 'bl@@', 'ue', 'of', 'the', 'bl@@', 'ue', 'of', 'the', 'bl@@', 'ue', 'of', 'the', 'bl@@', 'ue', 'of', 'the', 'f@@', 'os@@', 'si@@', 'l', 'in', 'the', 'mor@@', 'al', 'mor@@', 'al', 'issu@@', 'e.', '</s>']
2024-05-28 12:15:41,796 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:15:41,799 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:15:41,801 - INFO - joeynmt.training - 	Hypothesis: But this moral moral of this specific issue because the size of the blue of the blue of the blue of the blue of the blue of the blue of the fossil in the moral moral issue.
2024-05-28 12:15:41,804 - INFO - joeynmt.training - Example #2
2024-05-28 12:15:41,807 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:15:41,807 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:15:41,807 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is', 'in', 'a', 'way', 'that', 'the', 'future', 'of', 'the', 'climate', 'of', 'the', 'climate', 'system@@', '.', '</s>']
2024-05-28 12:15:41,807 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:15:41,810 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:15:41,813 - INFO - joeynmt.training - 	Hypothesis: The police is in a way that the future of the climate of the climate system.
2024-05-28 12:15:41,815 - INFO - joeynmt.training - Example #3
2024-05-28 12:15:41,818 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:15:41,818 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:15:41,818 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'was', 'exp@@', 'ected', 'and', 'the', 'contr@@', 'ac@@', 'tion', 'and', 'the', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 12:15:41,819 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:15:41,821 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:15:41,824 - INFO - joeynmt.training - 	Hypothesis: She was expected and the contraction and the contract.
2024-05-28 12:15:41,859 - INFO - joeynmt.training - Example #4
2024-05-28 12:15:41,862 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:15:41,862 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:15:41,862 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'pos@@', 'itive', 'thing', 'that', 'I', 'will', 'show', 'you', 'a', 'lot', 'of', 'what', 'is', 'going', 'to', 'be', 'a', 'little', 'bit', 'of', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:15:41,862 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:15:41,865 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:15:41,869 - INFO - joeynmt.training - 	Hypothesis: The next positive thing that I will show you a lot of what is going to be a little bit of the last 25 years.
2024-05-28 12:15:44,624 - INFO - joeynmt.training - Epoch   6, Step:    22100, Batch Loss:     2.060129, Batch Acc: 0.467199, Tokens per Sec:    23746, Lr: 0.000300
2024-05-28 12:15:47,387 - INFO - joeynmt.training - Epoch   6, Step:    22200, Batch Loss:     1.770403, Batch Acc: 0.472915, Tokens per Sec:    25606, Lr: 0.000300
2024-05-28 12:15:50,116 - INFO - joeynmt.training - Epoch   6, Step:    22300, Batch Loss:     1.913375, Batch Acc: 0.470350, Tokens per Sec:    25025, Lr: 0.000300
2024-05-28 12:15:52,852 - INFO - joeynmt.training - Epoch   6, Step:    22400, Batch Loss:     1.888412, Batch Acc: 0.470022, Tokens per Sec:    25360, Lr: 0.000300
2024-05-28 12:15:55,588 - INFO - joeynmt.training - Epoch   6, Step:    22500, Batch Loss:     1.864347, Batch Acc: 0.471675, Tokens per Sec:    24790, Lr: 0.000300
2024-05-28 12:15:55,592 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:15:55,595 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:16:02,638 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.02, ppl:   7.56, acc:   0.46, generation: 7.0242[sec], evaluation: 0.0000[sec]
2024-05-28 12:16:02,642 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:16:02,733 - INFO - joeynmt.helpers - delete models/bpe-vocab/20500.ckpt
2024-05-28 12:16:02,759 - INFO - joeynmt.training - Example #0
2024-05-28 12:16:02,762 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:16:02,762 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:16:02,762 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'last', 'two', 'di@@', 'es', 'we', 'ar@@', 'ri@@', 'ved', 'to', 'pro@@', 've', 'that', 'the', 'pol@@', 'ice', 'pol@@', 'ice', 'pol@@', 'ice', 'that', 'in', 'the', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'few', 'million', 'years', 'of', 'the', 'big', 'big', 'size', 'of', 'the', 'big', 'big', 'big', 'size', 'of', 'the', 'big', 'w@@', 'ast@@', 'e.', '</s>']
2024-05-28 12:16:02,763 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:16:02,765 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:16:02,769 - INFO - joeynmt.training - 	Hypothesis: And the last two dies we arrived to prove that the police police police that in the most of the last three million years of the last three million years of the last few million years of the big big size of the big big big size of the big waste.
2024-05-28 12:16:02,772 - INFO - joeynmt.training - Example #1
2024-05-28 12:16:02,775 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:16:02,775 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:16:02,775 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'al', 'mor@@', 'al', 'mor@@', 'al', 'issu@@', 'es', 'because', 'it', "doesn't", 'look', 'at', 'the', 'size', 'of', 'the', 'f@@', 'an@@', 'cy', 'of', 'the', 'f@@', 'an@@', 'cy', 'of', 'the', 'f@@', 'os@@', 'si@@', 'l', 'of', 'the', 'f@@', 'os@@', 'si@@', 'l', 'of', 'the', 'mor@@', 'n@@', 'ing.', '</s>']
2024-05-28 12:16:02,776 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:16:02,779 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:16:02,782 - INFO - joeynmt.training - 	Hypothesis: But this moral moral moral issues because it doesn't look at the size of the fancy of the fancy of the fossil of the fossil of the morning.
2024-05-28 12:16:02,785 - INFO - joeynmt.training - Example #2
2024-05-28 12:16:02,789 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:16:02,789 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:16:02,789 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is', 'in', 'a', 'way', 'that', 'the', 'future', 'of', 'climate', 'that', 'has', 'been', 'a', 'global', 'system', 'of', 'climate', 'chang@@', 'e.', '</s>']
2024-05-28 12:16:02,789 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:16:02,793 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:16:02,795 - INFO - joeynmt.training - 	Hypothesis: The police is in a way that the future of climate that has been a global system of climate change.
2024-05-28 12:16:02,798 - INFO - joeynmt.training - Example #3
2024-05-28 12:16:02,801 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:16:02,801 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:16:02,801 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'exp@@', 'ected', 'the', 'w@@', 'ast@@', 'e,', 'and', 'the', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 12:16:02,802 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:16:02,804 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:16:02,807 - INFO - joeynmt.training - 	Hypothesis: She expected the waste, and the contract.
2024-05-28 12:16:02,810 - INFO - joeynmt.training - Example #4
2024-05-28 12:16:02,824 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:16:02,824 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:16:02,825 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'thing', 'that', 'I', 'will', 'be', 'able', 'to', 'show', 'up', 'to', 'what', 'was', 'going', 'to', 'be', 'a', 'very', 'quick@@', 'ly', 'about', 'the', 'last', '25', 'years', 'ago.', '</s>']
2024-05-28 12:16:02,825 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:16:02,828 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:16:02,831 - INFO - joeynmt.training - 	Hypothesis: The next thing that I will be able to show up to what was going to be a very quickly about the last 25 years ago.
2024-05-28 12:16:05,615 - INFO - joeynmt.training - Epoch   6, Step:    22600, Batch Loss:     2.094234, Batch Acc: 0.476831, Tokens per Sec:    23091, Lr: 0.000300
2024-05-28 12:16:08,365 - INFO - joeynmt.training - Epoch   6, Step:    22700, Batch Loss:     1.833349, Batch Acc: 0.476150, Tokens per Sec:    24602, Lr: 0.000300
2024-05-28 12:16:11,162 - INFO - joeynmt.training - Epoch   6, Step:    22800, Batch Loss:     1.991348, Batch Acc: 0.473085, Tokens per Sec:    25164, Lr: 0.000300
2024-05-28 12:16:13,936 - INFO - joeynmt.training - Epoch   6, Step:    22900, Batch Loss:     1.900418, Batch Acc: 0.476248, Tokens per Sec:    25256, Lr: 0.000300
2024-05-28 12:16:16,751 - INFO - joeynmt.training - Epoch   6, Step:    23000, Batch Loss:     1.966078, Batch Acc: 0.468627, Tokens per Sec:    25162, Lr: 0.000300
2024-05-28 12:16:16,755 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:16:16,759 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:16:23,095 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.02, ppl:   7.51, acc:   0.46, generation: 6.3179[sec], evaluation: 0.0000[sec]
2024-05-28 12:16:23,100 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:16:23,210 - INFO - joeynmt.helpers - delete models/bpe-vocab/20000.ckpt
2024-05-28 12:16:23,216 - INFO - joeynmt.training - Example #0
2024-05-28 12:16:23,252 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:16:23,252 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:16:23,252 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'last', 'year,', 'we', 'ar@@', 'gu@@', 'ed', 'these', 'two', 'di@@', 'am@@', 'on@@', 'e@@', 'y,', 'to', 'demonstr@@', 'ate', 'that', 'the', 'r@@', 'ange', 'of', 'the', 'last', 'three', 'million', 'years', 'was', 'the', 'last', 'three', 'million', 'years', 'ago', 'was', 'the', 'last', '4@@', '8', 'million', 'years', 'ago', 'was', 'a', 'little', 'bit', 'of', '4@@', '8', 'million', 'stat@@', 'us', 'in', 'the', 'last', '4@@', '0@@', '-@@', 'percent', 'of', 'the', 'year.', '</s>']
2024-05-28 12:16:23,252 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:16:23,256 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:16:23,259 - INFO - joeynmt.training - 	Hypothesis: And the last year, we argued these two diamoney, to demonstrate that the range of the last three million years was the last three million years ago was the last 48 million years ago was a little bit of 48 million status in the last 40-percent of the year.
2024-05-28 12:16:23,263 - INFO - joeynmt.training - Example #1
2024-05-28 12:16:23,266 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:16:23,266 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:16:23,266 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'al', 'mor@@', 'al', 'mor@@', 'ality', 'because', 'it', "doesn't", 'look', 'at', 'this', 'speci@@', 'fic', 'issu@@', 'e', 'because', 'the', 'f@@', 'os@@', 'si@@', 'l', 'of', 'the', 'f@@', 'low@@', 'er', 'of', 'the', 'f@@', 'os@@', 'si@@', 'l', 'of', 'the', 'f@@', 'os@@', 'si@@', 'l', 'of', 'the', 'f@@', 'low@@', '.', '</s>']
2024-05-28 12:16:23,266 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:16:23,270 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:16:23,273 - INFO - joeynmt.training - 	Hypothesis: But this moral moral morality because it doesn't look at this specific issue because the fossil of the flower of the fossil of the fossil of the flow.
2024-05-28 12:16:23,276 - INFO - joeynmt.training - Example #2
2024-05-28 12:16:23,280 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:16:23,280 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:16:23,280 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is', 'in', 'a', 'way,', 'in', 'a', 'way,', 'the', 'heart', 'of', 'the', 'global', 'system', 'that', 'we', 'have', 'the', 'global', 'system', 'of', 'climate', 'chang@@', 'e.', '</s>']
2024-05-28 12:16:23,280 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:16:23,283 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:16:23,286 - INFO - joeynmt.training - 	Hypothesis: The police is in a way, in a way, the heart of the global system that we have the global system of climate change.
2024-05-28 12:16:23,289 - INFO - joeynmt.training - Example #3
2024-05-28 12:16:23,292 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:16:23,293 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:16:23,293 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'ex@@', 'ten@@', 'ded', 'to', 'the', 'ex@@', 'ten@@', 'd', 'to', 'the', 'contr@@', 'ac@@', 'y.', '</s>']
2024-05-28 12:16:23,293 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:16:23,296 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:16:23,298 - INFO - joeynmt.training - 	Hypothesis: She extended to the extend to the contracy.
2024-05-28 12:16:23,301 - INFO - joeynmt.training - Example #4
2024-05-28 12:16:23,304 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:16:23,304 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:16:23,304 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'next', 'pos@@', 'itive', 'mo@@', 'un@@', 'ta@@', 'ins', 'will', 'be', 'a', 'r@@', 'ange', 'of', 'what', 'happened', 'to', 'the', 'next', '25', 'years.', '</s>']
2024-05-28 12:16:23,304 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:16:23,307 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:16:23,355 - INFO - joeynmt.training - 	Hypothesis: The next next positive mountains will be a range of what happened to the next 25 years.
2024-05-28 12:16:26,129 - INFO - joeynmt.training - Epoch   6, Step:    23100, Batch Loss:     1.912387, Batch Acc: 0.469305, Tokens per Sec:    22485, Lr: 0.000300
2024-05-28 12:16:28,912 - INFO - joeynmt.training - Epoch   6, Step:    23200, Batch Loss:     2.012910, Batch Acc: 0.471758, Tokens per Sec:    24583, Lr: 0.000300
2024-05-28 12:16:31,670 - INFO - joeynmt.training - Epoch   6, Step:    23300, Batch Loss:     1.808122, Batch Acc: 0.470621, Tokens per Sec:    24357, Lr: 0.000300
2024-05-28 12:16:34,446 - INFO - joeynmt.training - Epoch   6, Step:    23400, Batch Loss:     1.945795, Batch Acc: 0.466886, Tokens per Sec:    24847, Lr: 0.000300
2024-05-28 12:16:36,384 - INFO - joeynmt.training - Epoch   6: total training loss 7634.22
2024-05-28 12:16:36,388 - INFO - joeynmt.training - EPOCH 7
2024-05-28 12:16:37,251 - INFO - joeynmt.training - Epoch   7, Step:    23500, Batch Loss:     1.987504, Batch Acc: 0.495362, Tokens per Sec:    24729, Lr: 0.000300
2024-05-28 12:16:37,256 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:16:37,258 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:16:43,943 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.01, ppl:   7.47, acc:   0.46, generation: 6.6636[sec], evaluation: 0.0000[sec]
2024-05-28 12:16:43,947 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:16:44,036 - INFO - joeynmt.helpers - delete models/bpe-vocab/21000.ckpt
2024-05-28 12:16:44,049 - INFO - joeynmt.training - Example #0
2024-05-28 12:16:44,052 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:16:44,052 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:16:44,053 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'ar@@', 'ri@@', 'ved', 'these', 'two', 'di@@', 'am@@', 'e@@', 'ter', 'pos@@', 'itive', 'to', 'demonstr@@', 'ate', 'that', 'the', 'entire', 'pol@@', 'ice', 'that', 'in', 'the', 'ma@@', 'in', 'which', 'the', 'ma@@', 'in', 'the', 'last', 'three', 'million', 'years', 'ago', 'was', 'the', 'size', 'of', 'the', 'last', '3@@', '0@@', '-@@', 'year', 'n@@', 'ine', 'years', 'ago', 'was', 'a', 'small', 'amount', 'of', 'big', '4@@', '0@@', '-@@', 'percent', 'of', 'the', 'mar@@', 'i@@', 'th@@', 's', 'of', 'the', 'second', 'di@@', 'am@@', 'ong', '40', 'percent', 'of', 'the', 'entire', 'di@@', 'am@@', 'p@@', 's.', '</s>']
2024-05-28 12:16:44,053 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:16:44,056 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:16:44,059 - INFO - joeynmt.training - 	Hypothesis: And the year we arrived these two diameter positive to demonstrate that the entire police that in the main which the main the last three million years ago was the size of the last 30-year nine years ago was a small amount of big 40-percent of the mariths of the second diamong 40 percent of the entire diamps.
2024-05-28 12:16:44,062 - INFO - joeynmt.training - Example #1
2024-05-28 12:16:44,065 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:16:44,065 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:16:44,066 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'seri@@', 'ous', 'problem', 'because', 'this', 'speci@@', 'fic', 'issu@@', 'e', 'because', 'it', "doesn't", 'look', 'at', 'the', 'size', 'of', 'this', 'particular', 'way.', '</s>']
2024-05-28 12:16:44,066 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:16:44,069 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:16:44,072 - INFO - joeynmt.training - 	Hypothesis: But this is the serious problem because this specific issue because it doesn't look at the size of this particular way.
2024-05-28 12:16:44,075 - INFO - joeynmt.training - Example #2
2024-05-28 12:16:44,079 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:16:44,079 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:16:44,079 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is,', 'in', 'a', 'way', 'that', 'the', 'heart', 'system@@', ',', 'the', 'global', 'system@@', ',', 'the', 'global', 'system@@', '.', '</s>']
2024-05-28 12:16:44,079 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:16:44,082 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:16:44,085 - INFO - joeynmt.training - 	Hypothesis: The police is, in a way that the heart system, the global system, the global system.
2024-05-28 12:16:44,137 - INFO - joeynmt.training - Example #3
2024-05-28 12:16:44,140 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:16:44,140 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:16:44,140 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'ex@@', 'ten@@', 'ded', 'to', 'the', 'contr@@', 'ac@@', 'tion', 'and', 'contr@@', 'ac@@', 'y.', '</s>']
2024-05-28 12:16:44,141 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:16:44,144 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:16:44,147 - INFO - joeynmt.training - 	Hypothesis: She extended to the contraction and contracy.
2024-05-28 12:16:44,150 - INFO - joeynmt.training - Example #4
2024-05-28 12:16:44,153 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:16:44,153 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:16:44,153 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'next', 'thing', 'I', 'will', 'show', 'you', 'the', 'next', 'will', 'be', 'a', 'quick@@', 'ly', 'f@@', 'ast', 'at', 'what', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:16:44,154 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:16:44,211 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:16:44,253 - INFO - joeynmt.training - 	Hypothesis: The next next thing I will show you the next will be a quickly fast at what happened in the last 25 years.
2024-05-28 12:16:47,005 - INFO - joeynmt.training - Epoch   7, Step:    23600, Batch Loss:     1.793176, Batch Acc: 0.495038, Tokens per Sec:    22272, Lr: 0.000300
2024-05-28 12:16:49,765 - INFO - joeynmt.training - Epoch   7, Step:    23700, Batch Loss:     1.857937, Batch Acc: 0.499434, Tokens per Sec:    25174, Lr: 0.000300
2024-05-28 12:16:52,535 - INFO - joeynmt.training - Epoch   7, Step:    23800, Batch Loss:     1.927296, Batch Acc: 0.499029, Tokens per Sec:    24880, Lr: 0.000300
2024-05-28 12:16:55,267 - INFO - joeynmt.training - Epoch   7, Step:    23900, Batch Loss:     1.888079, Batch Acc: 0.492122, Tokens per Sec:    24460, Lr: 0.000300
2024-05-28 12:16:58,053 - INFO - joeynmt.training - Epoch   7, Step:    24000, Batch Loss:     1.714497, Batch Acc: 0.496625, Tokens per Sec:    25765, Lr: 0.000300
2024-05-28 12:16:58,057 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:16:58,060 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:17:04,861 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.00, ppl:   7.39, acc:   0.46, generation: 6.7828[sec], evaluation: 0.0000[sec]
2024-05-28 12:17:04,865 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:17:04,958 - INFO - joeynmt.helpers - delete models/bpe-vocab/21500.ckpt
2024-05-28 12:17:04,963 - INFO - joeynmt.training - Example #0
2024-05-28 12:17:04,966 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:17:04,966 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:17:04,966 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'showed', 'these', 'two', 'di@@', 'am@@', 'p@@', 'ped', 'to', 'demonstr@@', 'ate', 'as', 'a', 'pol@@', 'ar', 'that', 'was', 'a', 'pol@@', 'ar', 'that', 'was', 'the', 'ma@@', 'in', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'number', 'of', 'mar@@', 'vel@@', 'ed', '4@@', '8', 'percent', 'of', 'the', 'ma@@', 'gic', 'of', 'the', 'mag@@', 'n@@', 'itu@@', 'de', '4@@', '0,', 'percent', 'of', 'the', 'size', 'of', 'the', 'two', 'percent', 'of', 'the', 'size', 'of', 'the', 'second', 'di@@', 'd.', '</s>']
2024-05-28 12:17:04,967 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:17:04,989 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:17:04,992 - INFO - joeynmt.training - 	Hypothesis: And the year we showed these two diampped to demonstrate as a polar that was a polar that was the main the last three million years of the last three million years of the number of marveled 48 percent of the magic of the magnitude 40, percent of the size of the two percent of the size of the second did.
2024-05-28 12:17:05,012 - INFO - joeynmt.training - Example #1
2024-05-28 12:17:05,016 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:17:05,016 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:17:05,016 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'the', 'seri@@', 'ous', 'issu@@', 'e', 'because', 'it', "doesn't", 'look', 'at', 'the', 'size', 'of', 'this', 'speci@@', 'fic', 'issu@@', 'e.', '</s>']
2024-05-28 12:17:05,016 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:17:05,020 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:17:05,023 - INFO - joeynmt.training - 	Hypothesis: But this morning, the serious issue because it doesn't look at the size of this specific issue.
2024-05-28 12:17:05,025 - INFO - joeynmt.training - Example #2
2024-05-28 12:17:05,028 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:17:05,028 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:17:05,028 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is', 'a', 'way', 'of', 'the', 'pol@@', 'ice', 'that', 'the', 'global', 'system', 'of', 'climate', 'system@@', '.', '</s>']
2024-05-28 12:17:05,029 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:17:05,032 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:17:05,034 - INFO - joeynmt.training - 	Hypothesis: The police is a way of the police that the global system of climate system.
2024-05-28 12:17:05,037 - INFO - joeynmt.training - Example #3
2024-05-28 12:17:05,040 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:17:05,040 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:17:05,040 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'ex@@', 'ten@@', 'ded', 'to', 'the', 'bot@@', 'tom', 'and', 'the', 'f@@', 'ear', 'and', 'the', 'f@@', 'ear', 'of', 'the', 'wat@@', 'er.', '</s>']
2024-05-28 12:17:05,040 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:17:05,043 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:17:05,046 - INFO - joeynmt.training - 	Hypothesis: She extended to the bottom and the fear and the fear of the water.
2024-05-28 12:17:05,048 - INFO - joeynmt.training - Example #4
2024-05-28 12:17:05,051 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:17:05,051 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:17:05,051 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'thing', 'I', 'would', 'like', 'to', 'show', 'you', 'a', 'quick@@', 'ly', 'will', 'be', 'a', 'f@@', 'ear', 'on', 'what', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:17:05,051 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:17:05,071 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:17:05,074 - INFO - joeynmt.training - 	Hypothesis: The next thing I would like to show you a quickly will be a fear on what happened in the last 25 years.
2024-05-28 12:17:07,840 - INFO - joeynmt.training - Epoch   7, Step:    24100, Batch Loss:     1.800158, Batch Acc: 0.497090, Tokens per Sec:    23342, Lr: 0.000300
2024-05-28 12:17:10,637 - INFO - joeynmt.training - Epoch   7, Step:    24200, Batch Loss:     1.859068, Batch Acc: 0.494682, Tokens per Sec:    25042, Lr: 0.000300
2024-05-28 12:17:13,384 - INFO - joeynmt.training - Epoch   7, Step:    24300, Batch Loss:     1.792226, Batch Acc: 0.491266, Tokens per Sec:    24119, Lr: 0.000300
2024-05-28 12:17:16,128 - INFO - joeynmt.training - Epoch   7, Step:    24400, Batch Loss:     1.849736, Batch Acc: 0.485206, Tokens per Sec:    24351, Lr: 0.000300
2024-05-28 12:17:18,869 - INFO - joeynmt.training - Epoch   7, Step:    24500, Batch Loss:     2.043051, Batch Acc: 0.490060, Tokens per Sec:    24762, Lr: 0.000300
2024-05-28 12:17:18,873 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:17:18,876 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:17:25,289 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.00, ppl:   7.36, acc:   0.47, generation: 6.3942[sec], evaluation: 0.0000[sec]
2024-05-28 12:17:25,292 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:17:25,385 - INFO - joeynmt.helpers - delete models/bpe-vocab/22000.ckpt
2024-05-28 12:17:25,398 - INFO - joeynmt.training - Example #0
2024-05-28 12:17:25,402 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:17:25,402 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:17:25,402 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'ar@@', 'gu@@', 'ed', 'these', 'two', 'di@@', 'et', 'of', 'the', 'second', 'sli@@', 'de', 'to', 'demonstr@@', 'ate', 'that', 'the', 'pol@@', 'ar', 'pol@@', 'ar', 'that', 'was', 'the', 'last', 'three', 'million', 'years', 'ago,', 'the', 'last', '3@@', '0@@', '-@@', 'year', 'stat@@', 'us', 'was', 'a', 'little', 'bit', 'of', '4@@', '8', 'percent', 'of', 'the', 'size', 'of', '4@@', '-@@', 'percent', 'of', 'the', 'size', 'of', '4@@', '0,', 'percent', 'of', 'the', 'size', 'of', '4@@', '0,', 'percent', 'of', 'the', 'size', 'of', 'the', 'two', 'percent', 'of', 'the', 'year.', '</s>']
2024-05-28 12:17:25,403 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:17:25,405 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:17:25,408 - INFO - joeynmt.training - 	Hypothesis: And the year we argued these two diet of the second slide to demonstrate that the polar polar that was the last three million years ago, the last 30-year status was a little bit of 48 percent of the size of 4-percent of the size of 40, percent of the size of 40, percent of the size of the two percent of the year.
2024-05-28 12:17:25,411 - INFO - joeynmt.training - Example #1
2024-05-28 12:17:25,414 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:17:25,414 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:17:25,414 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'ning', 'is', 'seri@@', 'ous', 'seri@@', 'ous', 'because', 'it', "doesn't", 'show', 'because', 'it', "doesn't", 'show', 'the', 'size', 'of', 'this', 'speci@@', 'es.', '</s>']
2024-05-28 12:17:25,414 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:17:25,417 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:17:25,420 - INFO - joeynmt.training - 	Hypothesis: But this morning is serious serious because it doesn't show because it doesn't show the size of this species.
2024-05-28 12:17:25,422 - INFO - joeynmt.training - Example #2
2024-05-28 12:17:25,425 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:17:25,425 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:17:25,425 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'is', 'in', 'a', 'way', 'of', 'the', 'pol@@', 'ar', 'system@@', ',', 'which', 'is', 'the', 'climate', 'climate', 'system@@', '.', '</s>']
2024-05-28 12:17:25,425 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:17:25,428 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:17:25,431 - INFO - joeynmt.training - 	Hypothesis: The polar is in a way of the polar system, which is the climate climate system.
2024-05-28 12:17:25,434 - INFO - joeynmt.training - Example #3
2024-05-28 12:17:25,436 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:17:25,436 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:17:25,436 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'ex@@', 'ten@@', 'ded', 'to', 'the', 'f@@', 'all', 'and', 'contr@@', 'ac@@', 'y.', '</s>']
2024-05-28 12:17:25,437 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:17:25,456 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:17:25,459 - INFO - joeynmt.training - 	Hypothesis: She extended to the fall and contracy.
2024-05-28 12:17:25,462 - INFO - joeynmt.training - Example #4
2024-05-28 12:17:25,483 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:17:25,483 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:17:25,484 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'thing', 'I', 'will', 'show', 'you', 'the', 'next', 'thing', 'that', 'I', 'would', 'show', 'you', 'the', 'way', 'to', 'what', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:17:25,484 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:17:25,487 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:17:25,489 - INFO - joeynmt.training - 	Hypothesis: The next thing I will show you the next thing that I would show you the way to what happened in the last 25 years.
2024-05-28 12:17:28,225 - INFO - joeynmt.training - Epoch   7, Step:    24600, Batch Loss:     1.973894, Batch Acc: 0.490355, Tokens per Sec:    23524, Lr: 0.000300
2024-05-28 12:17:30,960 - INFO - joeynmt.training - Epoch   7, Step:    24700, Batch Loss:     1.938365, Batch Acc: 0.495755, Tokens per Sec:    25365, Lr: 0.000300
2024-05-28 12:17:33,682 - INFO - joeynmt.training - Epoch   7, Step:    24800, Batch Loss:     1.693906, Batch Acc: 0.490856, Tokens per Sec:    24805, Lr: 0.000300
2024-05-28 12:17:36,430 - INFO - joeynmt.training - Epoch   7, Step:    24900, Batch Loss:     1.947715, Batch Acc: 0.490577, Tokens per Sec:    25309, Lr: 0.000300
2024-05-28 12:17:39,166 - INFO - joeynmt.training - Epoch   7, Step:    25000, Batch Loss:     2.032537, Batch Acc: 0.484386, Tokens per Sec:    24916, Lr: 0.000300
2024-05-28 12:17:39,170 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:17:39,173 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:17:44,995 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.99, ppl:   7.30, acc:   0.47, generation: 5.8040[sec], evaluation: 0.0000[sec]
2024-05-28 12:17:45,000 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:17:45,086 - INFO - joeynmt.helpers - delete models/bpe-vocab/22500.ckpt
2024-05-28 12:17:45,097 - INFO - joeynmt.training - Example #0
2024-05-28 12:17:45,101 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:17:45,101 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:17:45,101 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'ar@@', 'ri@@', 'ed', 'these', 'two', 'pos@@', 'itive', 'pos@@', 'itive', 'to', 'demonstr@@', 'ate', 'that', 'the', 'pol@@', 'ice', 'in', 'the', 'last', 'three', 'million', 'years', 'that', 'was', 'the', 'last', 'three', 'million', 'years', 'ago', 'was', 'the', 'last', 'two', 'years', 'ago', 'was', 'the', 'size', 'of', 'the', '2@@', '2@@', '2@@', '-@@', 'year', 'stat@@', 'us', 'of', 'the', 'mar@@', 'ine', 'of', 'the', 'mar@@', 'ine', 'of', '4@@', 'th', 'of', 'the', 'mar@@', 'ine', 'of', '4@@', 'th', 'of', 'the', '2@@', '2@@', '2@@', '-@@', 'percent', 'of', 'the', 'year.', '</s>']
2024-05-28 12:17:45,101 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:17:45,105 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:17:45,108 - INFO - joeynmt.training - 	Hypothesis: And the year we arried these two positive positive to demonstrate that the police in the last three million years that was the last three million years ago was the last two years ago was the size of the 222-year status of the marine of the marine of 4th of the marine of 4th of the 222-percent of the year.
2024-05-28 12:17:45,111 - INFO - joeynmt.training - Example #1
2024-05-28 12:17:45,115 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:17:45,115 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:17:45,115 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'ning', 'of', 'the', 'seri@@', 'ous', 'issu@@', 'e', 'because', 'it', "doesn't", 'look', 'like', 'the', 'size', 'of', 'this', 'speci@@', 'fic', 'r@@', 'ou@@', 'te@@', 's.', '</s>']
2024-05-28 12:17:45,115 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:17:45,118 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:17:45,121 - INFO - joeynmt.training - 	Hypothesis: But this morning of the serious issue because it doesn't look like the size of this specific routes.
2024-05-28 12:17:45,124 - INFO - joeynmt.training - Example #2
2024-05-28 12:17:45,127 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:17:45,127 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:17:45,127 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is', 'in', 'a', 'way,', 'the', 'heart', 'of', 'the', 'climate', 'system@@', ',', 'which', 'the', 'global', 'system@@', '.', '</s>']
2024-05-28 12:17:45,128 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:17:45,131 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:17:45,133 - INFO - joeynmt.training - 	Hypothesis: The police is in a way, the heart of the climate system, which the global system.
2024-05-28 12:17:45,137 - INFO - joeynmt.training - Example #3
2024-05-28 12:17:45,139 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:17:45,139 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:17:45,139 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'was', 'ex@@', 'ten@@', 'ded', 'by', 'the', 'way,', 'and', 'the', 'contr@@', 'ac@@', 'tion', 'of', 'the', 'wat@@', 'er.', '</s>']
2024-05-28 12:17:45,139 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:17:45,143 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:17:45,145 - INFO - joeynmt.training - 	Hypothesis: She was extended by the way, and the contraction of the water.
2024-05-28 12:17:45,148 - INFO - joeynmt.training - Example #4
2024-05-28 12:17:45,211 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:17:45,211 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:17:45,211 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'mo@@', 'vi@@', 'e,', "I'm", 'going', 'to', 'show', 'you', 'a', 'very', 'quick@@', 'ly', 'will', 'be', 'a', 'quick@@', 'ly', 'close', 'to', 'what', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:17:45,211 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:17:45,215 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:17:45,218 - INFO - joeynmt.training - 	Hypothesis: The next movie, I'm going to show you a very quickly will be a quickly close to what happened in the last 25 years.
2024-05-28 12:17:47,957 - INFO - joeynmt.training - Epoch   7, Step:    25100, Batch Loss:     1.783225, Batch Acc: 0.490336, Tokens per Sec:    23408, Lr: 0.000300
2024-05-28 12:17:50,709 - INFO - joeynmt.training - Epoch   7, Step:    25200, Batch Loss:     1.645007, Batch Acc: 0.489799, Tokens per Sec:    25725, Lr: 0.000300
2024-05-28 12:17:53,454 - INFO - joeynmt.training - Epoch   7, Step:    25300, Batch Loss:     1.917332, Batch Acc: 0.493780, Tokens per Sec:    25287, Lr: 0.000300
2024-05-28 12:17:56,181 - INFO - joeynmt.training - Epoch   7, Step:    25400, Batch Loss:     1.759700, Batch Acc: 0.487785, Tokens per Sec:    24788, Lr: 0.000300
2024-05-28 12:17:58,914 - INFO - joeynmt.training - Epoch   7, Step:    25500, Batch Loss:     1.926779, Batch Acc: 0.496840, Tokens per Sec:    25170, Lr: 0.000300
2024-05-28 12:17:58,918 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:17:58,920 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:18:05,878 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.97, ppl:   7.14, acc:   0.47, generation: 6.9393[sec], evaluation: 0.0000[sec]
2024-05-28 12:18:05,882 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:18:05,967 - INFO - joeynmt.helpers - delete models/bpe-vocab/23000.ckpt
2024-05-28 12:18:05,979 - INFO - joeynmt.training - Example #0
2024-05-28 12:18:05,982 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:18:05,982 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:18:05,982 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'ar@@', 'ri@@', 'ed', 'these', 'two', 'di@@', 'sor@@', 'der@@', 's', 'to', 'demonstr@@', 'ate', 'that', 'the', 'political', 'cr@@', 'os@@', 's', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'was', 'the', 'size', 'of', 'the', 'last', 'few', 'million', 'years', 'of', 'the', 'last', 'few', 'years.', '</s>']
2024-05-28 12:18:05,983 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:18:05,986 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:18:05,989 - INFO - joeynmt.training - 	Hypothesis: And the year we arried these two disorders to demonstrate that the political cross of the last three million years of the last three million years was the size of the last few million years of the last few years.
2024-05-28 12:18:05,992 - INFO - joeynmt.training - Example #1
2024-05-28 12:18:05,995 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:18:05,995 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:18:05,995 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'al', 'mor@@', 'al', 'problem', 'because', 'of', 'this', 'speci@@', 'fic', 'issu@@', 'es', 'because', 'it', "doesn't", 'take', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'this', 'mor@@', 'al', 'issu@@', 'e', 'of', 'the', 'mor@@', 'al', 'issu@@', 'e', 'of', 'this', 'speci@@', 'fic', 'mor@@', 'al', 'issu@@', 'e', 'of', 'this', 'speci@@', 'fic', 'issu@@', 'e', 'of', 'the', 'speci@@', 'fic', 'issu@@', 'e', 'because', 'of', 'this', 'speci@@', 'fic', 'issu@@', 'es', 'because', 'it', "doesn't", 'really', 'look', 'at', 'this', 'speci@@', 'fic', 'issu@@', 'es', 'because', 'the']
2024-05-28 12:18:05,995 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:18:05,998 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:18:06,001 - INFO - joeynmt.training - 	Hypothesis: But this moral moral problem because of this specific issues because it doesn't take the size of the size of the size of the size of the size of the size of the size of the size of the size of this moral issue of the moral issue of this specific moral issue of this specific issue of the specific issue because of this specific issues because it doesn't really look at this specific issues because the
2024-05-28 12:18:06,004 - INFO - joeynmt.training - Example #2
2024-05-28 12:18:06,007 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:18:06,007 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:18:06,007 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is', 'in', 'a', 'way', 'that', 'the', 'global', 'system', 'that', 'has', 'been', 'cr@@', 'os@@', 's', 'of', 'global', 'system@@', '.', '</s>']
2024-05-28 12:18:06,008 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:18:06,020 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:18:06,023 - INFO - joeynmt.training - 	Hypothesis: The police is in a way that the global system that has been cross of global system.
2024-05-28 12:18:06,026 - INFO - joeynmt.training - Example #3
2024-05-28 12:18:06,029 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:18:06,029 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:18:06,029 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'ex@@', 'ten@@', 'ded', 'to', 'the', 'bot@@', 't@@', 'om,', 'and', 'the', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 12:18:06,030 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:18:06,033 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:18:06,035 - INFO - joeynmt.training - 	Hypothesis: She extended to the bottom, and the contract.
2024-05-28 12:18:06,039 - INFO - joeynmt.training - Example #4
2024-05-28 12:18:06,060 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:18:06,060 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:18:06,060 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'thing', 'I', 'will', 'show', 'you', 'the', 'next', 'thing', 'that', 'is', 'going', 'to', 'be', 'a', 'very', 'quick@@', 'ly', 'will', 'be', 'a', 'very', 'quick@@', 'ly', 'ab@@', 'o@@', 've', 'of', 'the', 'next', '25', 'years.', '</s>']
2024-05-28 12:18:06,060 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:18:06,121 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:18:06,125 - INFO - joeynmt.training - 	Hypothesis: The next thing I will show you the next thing that is going to be a very quickly will be a very quickly above of the next 25 years.
2024-05-28 12:18:08,854 - INFO - joeynmt.training - Epoch   7, Step:    25600, Batch Loss:     1.809478, Batch Acc: 0.491767, Tokens per Sec:    22455, Lr: 0.000300
2024-05-28 12:18:11,580 - INFO - joeynmt.training - Epoch   7, Step:    25700, Batch Loss:     1.884516, Batch Acc: 0.488464, Tokens per Sec:    24610, Lr: 0.000300
2024-05-28 12:18:14,323 - INFO - joeynmt.training - Epoch   7, Step:    25800, Batch Loss:     1.945860, Batch Acc: 0.493510, Tokens per Sec:    25880, Lr: 0.000300
2024-05-28 12:18:17,039 - INFO - joeynmt.training - Epoch   7, Step:    25900, Batch Loss:     2.048608, Batch Acc: 0.491422, Tokens per Sec:    24696, Lr: 0.000300
2024-05-28 12:18:19,806 - INFO - joeynmt.training - Epoch   7, Step:    26000, Batch Loss:     1.899242, Batch Acc: 0.488138, Tokens per Sec:    24032, Lr: 0.000300
2024-05-28 12:18:19,813 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:18:19,816 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:18:26,418 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.96, ppl:   7.12, acc:   0.47, generation: 6.5839[sec], evaluation: 0.0000[sec]
2024-05-28 12:18:26,450 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:18:26,542 - INFO - joeynmt.helpers - delete models/bpe-vocab/23500.ckpt
2024-05-28 12:18:26,554 - INFO - joeynmt.training - Example #0
2024-05-28 12:18:26,557 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:18:26,557 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:18:26,557 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'started', 'to', 'show', 'these', 'two', 'di@@', 'es@@', 'e@@', 'try', 'to', 'show', 'that', 'the', 'pol@@', 'ar', 't@@', 'ar', 'pol@@', 'ar', 'that', 'the', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'ago,', 'the', 'last', 'three', 'million', 'years', 'ago,', 'he', 'was', 'a', 'little', 'bit', 'of', 'the', 'age', 'of', '4@@', '0@@', '-@@', 'percent', 'of', 'the', 'mar@@', 'ri@@', 'age', 'of', '4@@', '0@@', '-@@', 'percent', 'of', 'the', 'top', 'of', 'the', 'second', 'di@@', 'e.', '</s>']
2024-05-28 12:18:26,558 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:18:26,561 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:18:26,565 - INFO - joeynmt.training - 	Hypothesis: The year I started to show these two diesetry to show that the polar tar polar that the most of the last three million years of the last three million years ago, the last three million years ago, he was a little bit of the age of 40-percent of the marriage of 40-percent of the top of the second die.
2024-05-28 12:18:26,568 - INFO - joeynmt.training - Example #1
2024-05-28 12:18:26,571 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:18:26,571 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:18:26,571 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'speci@@', 'fic', 'issu@@', 'e', 'because', 'it', "doesn't", 'show', 'the', 'size', 'of', 'the', 'gu@@', 'y.', '</s>']
2024-05-28 12:18:26,571 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:18:26,574 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:18:26,578 - INFO - joeynmt.training - 	Hypothesis: But this morning, the seriousness of this specific issue because it doesn't show the size of the guy.
2024-05-28 12:18:26,580 - INFO - joeynmt.training - Example #2
2024-05-28 12:18:26,583 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:18:26,583 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:18:26,583 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'of', 'the', 'pol@@', 'ice', 'is,', 'in', 'a', 'global', 'war@@', 'm@@', 'ed', 'global', 'system@@', '.', '</s>']
2024-05-28 12:18:26,584 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:18:26,587 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:18:26,590 - INFO - joeynmt.training - 	Hypothesis: The police of the police is, in a global warmed global system.
2024-05-28 12:18:26,593 - INFO - joeynmt.training - Example #3
2024-05-28 12:18:26,596 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:18:26,596 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:18:26,597 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'exp@@', 'ect@@', 'ations', 'and', 'the', 'contr@@', 'ac@@', 'tion', 'of', 'the', 'bot@@', 'tom', 'line', 'of', 'the', 'fo@@', 'od.', '</s>']
2024-05-28 12:18:26,597 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:18:26,602 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:18:26,605 - INFO - joeynmt.training - 	Hypothesis: She expectations and the contraction of the bottom line of the food.
2024-05-28 12:18:26,667 - INFO - joeynmt.training - Example #4
2024-05-28 12:18:26,670 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:18:26,670 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:18:26,670 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'step', 'that', 'you', 'look', 'at', 'the', 'spe@@', 'ec@@', 'h', 'will', 'show', 'you', 'the', 'right', 'thing', 'on', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:18:26,670 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:18:26,674 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:18:26,676 - INFO - joeynmt.training - 	Hypothesis: The next step that you look at the speech will show you the right thing on the last 25 years.
2024-05-28 12:18:29,429 - INFO - joeynmt.training - Epoch   7, Step:    26100, Batch Loss:     1.666313, Batch Acc: 0.494793, Tokens per Sec:    23502, Lr: 0.000300
2024-05-28 12:18:32,170 - INFO - joeynmt.training - Epoch   7, Step:    26200, Batch Loss:     1.902619, Batch Acc: 0.487831, Tokens per Sec:    24956, Lr: 0.000300
2024-05-28 12:18:34,913 - INFO - joeynmt.training - Epoch   7, Step:    26300, Batch Loss:     1.923164, Batch Acc: 0.488953, Tokens per Sec:    24809, Lr: 0.000300
2024-05-28 12:18:37,678 - INFO - joeynmt.training - Epoch   7, Step:    26400, Batch Loss:     1.922511, Batch Acc: 0.493753, Tokens per Sec:    25271, Lr: 0.000300
2024-05-28 12:18:40,441 - INFO - joeynmt.training - Epoch   7, Step:    26500, Batch Loss:     1.881402, Batch Acc: 0.494713, Tokens per Sec:    24901, Lr: 0.000300
2024-05-28 12:18:40,445 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:18:40,448 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:18:48,135 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.96, ppl:   7.09, acc:   0.47, generation: 7.6665[sec], evaluation: 0.0000[sec]
2024-05-28 12:18:48,152 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:18:48,419 - INFO - joeynmt.helpers - delete models/bpe-vocab/24000.ckpt
2024-05-28 12:18:48,432 - INFO - joeynmt.training - Example #0
2024-05-28 12:18:48,436 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:18:48,436 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:18:48,436 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'showed', 'these', 'two', 'di@@', 'as@@', 'sig@@', 'n@@', 'ment', 'to', 'demonstr@@', 'ate', 'that', 'the', 'in@@', 'tre@@', 'e', 'of', 'the', 'country', 'that', 'was', 'the', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'few', 'hundre@@', 'd', 'million', 'years', 'of', 'mar@@', 'ri@@', 'age', 'in', '4@@', '8', 'percent', 'of', 'the', 'mar@@', 'ri@@', 'age', 'of', '4@@', '00', 'percent', 'of', 'the', 'size', 'of', '4@@', '00', 'percent', 'of', 'it.', '</s>']
2024-05-28 12:18:48,437 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:18:48,440 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:18:48,444 - INFO - joeynmt.training - 	Hypothesis: And the year we showed these two diassignment to demonstrate that the intree of the country that was the most of the last three million years of the last three million years of the last few hundred million years of marriage in 48 percent of the marriage of 400 percent of the size of 400 percent of it.
2024-05-28 12:18:48,447 - INFO - joeynmt.training - Example #1
2024-05-28 12:18:48,449 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:18:48,449 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:18:48,449 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'the', 'seri@@', 'ous', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'size', 'of', 'this', 'speci@@', 'fic', 'issu@@', 'e.', '</s>']
2024-05-28 12:18:48,449 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:18:48,453 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:18:48,456 - INFO - joeynmt.training - 	Hypothesis: But this morning, the serious problem because it doesn't show the size of this specific issue.
2024-05-28 12:18:48,459 - INFO - joeynmt.training - Example #2
2024-05-28 12:18:48,462 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:18:48,462 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:18:48,462 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is', 'in', 'a', 'way', 'that', 'the', 'heart', 'of', 'the', 'climate', 'that', 'we', 'b@@', 'ear', 'the', 'climate', 'system@@', '.', '</s>']
2024-05-28 12:18:48,463 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:18:48,465 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:18:48,468 - INFO - joeynmt.training - 	Hypothesis: The police is in a way that the heart of the climate that we bear the climate system.
2024-05-28 12:18:48,471 - INFO - joeynmt.training - Example #3
2024-05-28 12:18:48,474 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:18:48,474 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:18:48,474 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'was', 'ex@@', 'ten@@', 'ded', 'to', 'the', 'ex@@', 'ten@@', 'sion', 'and', 'the', 'contr@@', 'ac@@', 'tion', 'of', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:18:48,474 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:18:48,477 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:18:48,480 - INFO - joeynmt.training - 	Hypothesis: She was extended to the extension and the contraction of the same.
2024-05-28 12:18:48,495 - INFO - joeynmt.training - Example #4
2024-05-28 12:18:48,499 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:18:48,499 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:18:48,499 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'that', "I'm", 'going', 'to', 'show', 'you', 'going', 'to', 'show', 'up', 'about', 'what', 'happened', 'to', 'the', 'next', '25', 'years.', '</s>']
2024-05-28 12:18:48,499 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:18:48,502 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:18:48,505 - INFO - joeynmt.training - 	Hypothesis: The next slide that I'm going to show you going to show up about what happened to the next 25 years.
2024-05-28 12:18:51,235 - INFO - joeynmt.training - Epoch   7, Step:    26600, Batch Loss:     1.972314, Batch Acc: 0.489611, Tokens per Sec:    21403, Lr: 0.000300
2024-05-28 12:18:53,992 - INFO - joeynmt.training - Epoch   7, Step:    26700, Batch Loss:     1.882817, Batch Acc: 0.497960, Tokens per Sec:    25371, Lr: 0.000300
2024-05-28 12:18:56,736 - INFO - joeynmt.training - Epoch   7, Step:    26800, Batch Loss:     1.817642, Batch Acc: 0.495391, Tokens per Sec:    25579, Lr: 0.000300
2024-05-28 12:18:59,463 - INFO - joeynmt.training - Epoch   7, Step:    26900, Batch Loss:     1.789594, Batch Acc: 0.491857, Tokens per Sec:    24736, Lr: 0.000300
2024-05-28 12:19:02,200 - INFO - joeynmt.training - Epoch   7, Step:    27000, Batch Loss:     1.709250, Batch Acc: 0.490530, Tokens per Sec:    25137, Lr: 0.000300
2024-05-28 12:19:02,204 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:19:02,207 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:19:09,265 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.95, ppl:   7.04, acc:   0.48, generation: 7.0391[sec], evaluation: 0.0000[sec]
2024-05-28 12:19:09,268 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:19:09,401 - INFO - joeynmt.helpers - delete models/bpe-vocab/24500.ckpt
2024-05-28 12:19:09,417 - INFO - joeynmt.training - Example #0
2024-05-28 12:19:09,421 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:19:09,421 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:19:09,421 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'showed', 'these', 'two', 'di@@', 'ap@@', 'h@@', 'ors', 'to', 'demonstr@@', 'ate', 'that', 'the', 'pol@@', 'ar', 'pol@@', 'ar', 'that', 'in', 'the', 'last', 'three', 'to', 'the', 'last', 'three', 'to', 'the', 'last', 'three', 'to', 'the', 'last', 'three', 'to', 'the', 'size', 'of', 'the', '2@@', '1@@', 'st', 'centur@@', 'y', 'of', 'the', 'mon@@', 'th', 'of', 'the', '2@@', '1@@', 'st', 'centur@@', 'y', 'of', 'it.', '</s>']
2024-05-28 12:19:09,422 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:19:09,424 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:19:09,427 - INFO - joeynmt.training - 	Hypothesis: And the year we showed these two diaphors to demonstrate that the polar polar that in the last three to the last three to the last three to the last three to the size of the 21st century of the month of the 21st century of it.
2024-05-28 12:19:09,431 - INFO - joeynmt.training - Example #1
2024-05-28 12:19:09,434 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:19:09,434 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:19:09,434 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ity', 'is', 'seri@@', 'ous', 'because', 'this', 'particular', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'size', 'of', 'the', 'bl@@', 'os@@', 'e.', '</s>']
2024-05-28 12:19:09,434 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:19:09,437 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:19:09,441 - INFO - joeynmt.training - 	Hypothesis: But this mornity is serious because this particular particular problem because it doesn't show the size of the blose.
2024-05-28 12:19:09,444 - INFO - joeynmt.training - Example #2
2024-05-28 12:19:09,447 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:19:09,447 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:19:09,447 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'pol@@', 'ar', 'is', 'in', 'a', 'way', 'that', 'the', 'global', 'global', 'system', 'that', 'global', 'climate', 'cr@@', 'is@@', 'is.', '</s>']
2024-05-28 12:19:09,447 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:19:09,450 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:19:09,453 - INFO - joeynmt.training - 	Hypothesis: The polar polar is in a way that the global global system that global climate crisis.
2024-05-28 12:19:09,457 - INFO - joeynmt.training - Example #3
2024-05-28 12:19:09,460 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:19:09,460 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:19:09,460 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'goes', 'on', 'and', 'she', 'is', 'exp@@', 'and@@', 'ing', 'and', 'contr@@', 'ac@@', 'y.', '</s>']
2024-05-28 12:19:09,460 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:19:09,463 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:19:09,466 - INFO - joeynmt.training - 	Hypothesis: She goes on and she is expanding and contracy.
2024-05-28 12:19:09,469 - INFO - joeynmt.training - Example #4
2024-05-28 12:19:09,506 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:19:09,506 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:19:09,506 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'pos@@', 'itive', 'data', 'that', 'I', 'will', 'show', 'you', 'will', 'show', 'up', 'to', 'what', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:19:09,506 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:19:09,510 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:19:09,514 - INFO - joeynmt.training - 	Hypothesis: The next positive data that I will show you will show up to what happened in the last 25 years.
2024-05-28 12:19:12,251 - INFO - joeynmt.training - Epoch   7, Step:    27100, Batch Loss:     1.763271, Batch Acc: 0.489244, Tokens per Sec:    22331, Lr: 0.000300
2024-05-28 12:19:14,995 - INFO - joeynmt.training - Epoch   7, Step:    27200, Batch Loss:     1.951349, Batch Acc: 0.491619, Tokens per Sec:    25392, Lr: 0.000300
2024-05-28 12:19:17,753 - INFO - joeynmt.training - Epoch   7, Step:    27300, Batch Loss:     2.019817, Batch Acc: 0.496329, Tokens per Sec:    25611, Lr: 0.000300
2024-05-28 12:19:20,138 - INFO - joeynmt.training - Epoch   7: total training loss 7296.51
2024-05-28 12:19:20,142 - INFO - joeynmt.training - EPOCH 8
2024-05-28 12:19:20,504 - INFO - joeynmt.training - Epoch   8, Step:    27400, Batch Loss:     1.854023, Batch Acc: 0.520645, Tokens per Sec:    24020, Lr: 0.000300
2024-05-28 12:19:23,273 - INFO - joeynmt.training - Epoch   8, Step:    27500, Batch Loss:     1.682693, Batch Acc: 0.520568, Tokens per Sec:    25301, Lr: 0.000300
2024-05-28 12:19:23,277 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:19:23,281 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:19:29,631 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.94, ppl:   6.93, acc:   0.48, generation: 6.3311[sec], evaluation: 0.0000[sec]
2024-05-28 12:19:29,692 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:19:29,792 - INFO - joeynmt.helpers - delete models/bpe-vocab/25000.ckpt
2024-05-28 12:19:29,804 - INFO - joeynmt.training - Example #0
2024-05-28 12:19:29,808 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:19:29,808 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:19:29,809 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'showed', 'these', 'two', 'di@@', 'a@@', 'wa@@', 'y@@', 'e', 'to', 'demonstr@@', 'ate', 'that', 'the', 'pol@@', 'ar', 'pol@@', 'ar', 'to', 'demonstr@@', 'ate', 'that', 'in', 'the', 'last', 'three', 'million', 'years', 'was', 'the', 'size', 'of', 'the', 'last', '3@@', '0@@', '-@@', 'state', 'state', 'level@@', ',', 'has', 'been', 'fl@@', 'ying', 'with', '4@@', '8', 'percent', 'of', 'the', 'mon@@', 'th.', '</s>']
2024-05-28 12:19:29,809 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:19:29,813 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:19:29,816 - INFO - joeynmt.training - 	Hypothesis: And the year we showed these two diawaye to demonstrate that the polar polar to demonstrate that in the last three million years was the size of the last 30-state state level, has been flying with 48 percent of the month.
2024-05-28 12:19:29,819 - INFO - joeynmt.training - Example #1
2024-05-28 12:19:29,822 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:19:29,822 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:19:29,822 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'the', 'seri@@', 'ous', 'issu@@', 'e', 'because', "it's", 'not', 'the', 'end', 'because', 'it', "doesn't", 'look', 'like', 'the', 'black', 'black', 'h@@', 'et@@', 'ts.', '</s>']
2024-05-28 12:19:29,822 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:19:29,825 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:19:29,827 - INFO - joeynmt.training - 	Hypothesis: But this morning, the serious issue because it's not the end because it doesn't look like the black black hetts.
2024-05-28 12:19:29,830 - INFO - joeynmt.training - Example #2
2024-05-28 12:19:29,835 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:19:29,835 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:19:29,835 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'pol@@', 'ar', 'is', 'in', 'a', 'way,', 'the', 'global', 'system', 'that', 'the', 'global', 'system', 'that', 'we', 'have', 'global', 'climate', 'system@@', '.', '</s>']
2024-05-28 12:19:29,835 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:19:29,838 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:19:29,840 - INFO - joeynmt.training - 	Hypothesis: The polar polar is in a way, the global system that the global system that we have global climate system.
2024-05-28 12:19:29,844 - INFO - joeynmt.training - Example #3
2024-05-28 12:19:29,846 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:19:29,846 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:19:29,846 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'goes', 'on', 'and', 'they', 'are', 'ex@@', 'ten@@', 'ded', 'to', 'the', 's@@', 'ou@@', 'th.', '</s>']
2024-05-28 12:19:29,847 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:19:29,849 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:19:29,853 - INFO - joeynmt.training - 	Hypothesis: It goes on and they are extended to the south.
2024-05-28 12:19:29,928 - INFO - joeynmt.training - Example #4
2024-05-28 12:19:29,932 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:19:29,932 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:19:29,932 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'that', "I'm", 'going', 'to', 'show', 'you', 'will', 'show', 'up', 'to', 'what', 'happened', 'to', 'be', 'a', 'little', 'bit', 'of', 'what', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:19:29,932 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:19:29,936 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:19:29,940 - INFO - joeynmt.training - 	Hypothesis: The next slide that I'm going to show you will show up to what happened to be a little bit of what happened in the last 25 years.
2024-05-28 12:19:32,686 - INFO - joeynmt.training - Epoch   8, Step:    27600, Batch Loss:     1.700455, Batch Acc: 0.517998, Tokens per Sec:    23070, Lr: 0.000300
2024-05-28 12:19:35,413 - INFO - joeynmt.training - Epoch   8, Step:    27700, Batch Loss:     1.745289, Batch Acc: 0.513249, Tokens per Sec:    25147, Lr: 0.000300
2024-05-28 12:19:38,146 - INFO - joeynmt.training - Epoch   8, Step:    27800, Batch Loss:     1.890646, Batch Acc: 0.518911, Tokens per Sec:    25222, Lr: 0.000300
2024-05-28 12:19:40,883 - INFO - joeynmt.training - Epoch   8, Step:    27900, Batch Loss:     1.962605, Batch Acc: 0.513510, Tokens per Sec:    24890, Lr: 0.000300
2024-05-28 12:19:43,628 - INFO - joeynmt.training - Epoch   8, Step:    28000, Batch Loss:     1.699677, Batch Acc: 0.511315, Tokens per Sec:    24961, Lr: 0.000300
2024-05-28 12:19:43,632 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:19:43,636 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:19:50,177 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.89, acc:   0.48, generation: 6.5228[sec], evaluation: 0.0000[sec]
2024-05-28 12:19:50,235 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:19:50,330 - INFO - joeynmt.helpers - delete models/bpe-vocab/25500.ckpt
2024-05-28 12:19:50,344 - INFO - joeynmt.training - Example #0
2024-05-28 12:19:50,348 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:19:50,349 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:19:50,349 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'showed', 'these', 'two', 'di@@', 'sor@@', 'der@@', 's', 'to', 'pro@@', 've', 'that', 'the', 'pol@@', 'ar', 'pol@@', 'ar', 'pol@@', 'ar', 'that', 'was', 'the', 'pol@@', 'y@@', 'y@@', 'm@@', 'er', 'that', 'was', 'the', 'size', 'of', 'the', 'last', 'three', 'million', 'stat@@', 'es', 'were', 'sm@@', 'ell@@', 'ed', 'by', '4@@', '8', 'stat@@', 'es', 'of', 'mar@@', 'ine', 'mar@@', 'ine', 'ma@@', 'y@@', 'be,', 'was', 'tin@@', 'y', 'by', '4@@', '0,', 'percent', 'of', 'the', 'big', 'di@@', 'r@@', 'ty', 'of', 'a', 'little', 'di@@', 'd.', '</s>']
2024-05-28 12:19:50,349 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:19:50,352 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:19:50,356 - INFO - joeynmt.training - 	Hypothesis: And the year we showed these two disorders to prove that the polar polar polar that was the polyymer that was the size of the last three million states were smelled by 48 states of marine marine maybe, was tiny by 40, percent of the big dirty of a little did.
2024-05-28 12:19:50,358 - INFO - joeynmt.training - Example #1
2024-05-28 12:19:50,362 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:19:50,362 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:19:50,362 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'this', 'is', 'seri@@', 'ous', 'because', 'it', "doesn't", 'look', 'like', 'the', 'black', 'hol@@', 'e.', '</s>']
2024-05-28 12:19:50,362 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:19:50,365 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:19:50,368 - INFO - joeynmt.training - 	Hypothesis: But this morning, this is serious because it doesn't look like the black hole.
2024-05-28 12:19:50,371 - INFO - joeynmt.training - Example #2
2024-05-28 12:19:50,374 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:19:50,375 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:19:50,375 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is', 'in', 'a', 'way', 'that', 'the', 'heart', 'of', 'the', 'climate', 'system@@', '.', '</s>']
2024-05-28 12:19:50,375 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:19:50,378 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:19:50,381 - INFO - joeynmt.training - 	Hypothesis: The police is in a way that the heart of the climate system.
2024-05-28 12:19:50,384 - INFO - joeynmt.training - Example #3
2024-05-28 12:19:50,387 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:19:50,387 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:19:50,387 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'ex@@', 'ten@@', 's', 'the', 'f@@', 'all@@', 's', 'and', 'contr@@', 'ac@@', 'y.', '</s>']
2024-05-28 12:19:50,388 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:19:50,391 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:19:50,462 - INFO - joeynmt.training - 	Hypothesis: She extens the falls and contracy.
2024-05-28 12:19:50,466 - INFO - joeynmt.training - Example #4
2024-05-28 12:19:50,470 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:19:50,470 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:19:50,470 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'that', "I'm", 'going', 'to', 'show', 'you', 'is', 'a', 'big', 'big', 'going', 'on', 'on', 'what', 'happened', 'to', 'do', 'about', 'about', '25', 'years', 'ol@@', 'd.', '</s>']
2024-05-28 12:19:50,470 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:19:50,473 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:19:50,477 - INFO - joeynmt.training - 	Hypothesis: The next slide that I'm going to show you is a big big going on on what happened to do about about 25 years old.
2024-05-28 12:19:53,231 - INFO - joeynmt.training - Epoch   8, Step:    28100, Batch Loss:     1.673052, Batch Acc: 0.514570, Tokens per Sec:    22614, Lr: 0.000300
2024-05-28 12:19:55,984 - INFO - joeynmt.training - Epoch   8, Step:    28200, Batch Loss:     1.760067, Batch Acc: 0.508467, Tokens per Sec:    25563, Lr: 0.000300
2024-05-28 12:19:58,726 - INFO - joeynmt.training - Epoch   8, Step:    28300, Batch Loss:     1.687036, Batch Acc: 0.511612, Tokens per Sec:    24594, Lr: 0.000300
2024-05-28 12:20:01,562 - INFO - joeynmt.training - Epoch   8, Step:    28400, Batch Loss:     1.667875, Batch Acc: 0.512935, Tokens per Sec:    25944, Lr: 0.000300
2024-05-28 12:20:04,296 - INFO - joeynmt.training - Epoch   8, Step:    28500, Batch Loss:     1.827873, Batch Acc: 0.511522, Tokens per Sec:    25150, Lr: 0.000300
2024-05-28 12:20:04,300 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:20:04,304 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:20:10,968 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.88, acc:   0.48, generation: 6.6458[sec], evaluation: 0.0000[sec]
2024-05-28 12:20:11,038 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:20:11,130 - INFO - joeynmt.helpers - delete models/bpe-vocab/26000.ckpt
2024-05-28 12:20:11,187 - INFO - joeynmt.training - Example #0
2024-05-28 12:20:11,190 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:20:11,190 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:20:11,191 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'just', 'sho@@', 'wn', 'these', 'two', 'di@@', 'am@@', 'on@@', 'e@@', ';', 'we', 'were', 'able', 'to', 'show', 'that', 'the', 'pol@@', 'ar', 'pol@@', 'ar', 'that', 'was', 'the', 'city', 'of', 'the', 'last', 'three', 'million', 'years', 'was', 'the', 'size', 'of', 'the', 'big', 's@@', 'ea', 'of', 'mar@@', 'ine', 'mar@@', 'ine', 'in', 'the', 'mar@@', 'ine', 'r@@', 'ate', 'with', '40', 'percent', 'of', 'the', 'mar@@', 'ine', 'percent', 'of', 'the', 'year.', '</s>']
2024-05-28 12:20:11,191 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:20:11,194 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:20:11,197 - INFO - joeynmt.training - 	Hypothesis: And I was just shown these two diamone; we were able to show that the polar polar that was the city of the last three million years was the size of the big sea of marine marine in the marine rate with 40 percent of the marine percent of the year.
2024-05-28 12:20:11,200 - INFO - joeynmt.training - Example #1
2024-05-28 12:20:11,204 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:20:11,204 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:20:11,204 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'the', 'seri@@', 'ous', 'issu@@', 'e', 'because', 'it', "doesn't", 'look', 'at', 'the', 'black', 'hol@@', 'e.', '</s>']
2024-05-28 12:20:11,204 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:20:11,207 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:20:11,211 - INFO - joeynmt.training - 	Hypothesis: But this morning, the serious issue because it doesn't look at the black hole.
2024-05-28 12:20:11,214 - INFO - joeynmt.training - Example #2
2024-05-28 12:20:11,217 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:20:11,217 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:20:11,217 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is', 'a', 'pol@@', 'ice', 'that', 'the', 'climate', 'system@@', ',', 'which', 'the', 'global', 'system', 'of', 'system@@', '.', '</s>']
2024-05-28 12:20:11,218 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:20:11,222 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:20:11,225 - INFO - joeynmt.training - 	Hypothesis: The police is a police that the climate system, which the global system of system.
2024-05-28 12:20:11,230 - INFO - joeynmt.training - Example #3
2024-05-28 12:20:11,233 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:20:11,233 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:20:11,233 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'is', 'ex@@', 'ten@@', 'ded', 'to', 'the', 'bot@@', 'tom', 'and', 'the', 'f@@', 'low@@', '.', '</s>']
2024-05-28 12:20:11,233 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:20:11,236 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:20:11,240 - INFO - joeynmt.training - 	Hypothesis: She is extended to the bottom and the flow.
2024-05-28 12:20:11,287 - INFO - joeynmt.training - Example #4
2024-05-28 12:20:11,290 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:20:11,290 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:20:11,290 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'thing', 'I', 'will', 'show', 'you', 'the', 'life', 'that', 'will', 'be', 'a', 'very', 'quick@@', 'ly', 'ab@@', 'ly', 'ab@@', 'o@@', 've', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:20:11,291 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:20:11,294 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:20:11,297 - INFO - joeynmt.training - 	Hypothesis: The next thing I will show you the life that will be a very quickly ably above in the last 25 years.
2024-05-28 12:20:14,070 - INFO - joeynmt.training - Epoch   8, Step:    28600, Batch Loss:     1.941639, Batch Acc: 0.508142, Tokens per Sec:    22601, Lr: 0.000300
2024-05-28 12:20:16,797 - INFO - joeynmt.training - Epoch   8, Step:    28700, Batch Loss:     1.721315, Batch Acc: 0.507375, Tokens per Sec:    25068, Lr: 0.000300
2024-05-28 12:20:19,568 - INFO - joeynmt.training - Epoch   8, Step:    28800, Batch Loss:     1.646176, Batch Acc: 0.510332, Tokens per Sec:    24943, Lr: 0.000300
2024-05-28 12:20:22,315 - INFO - joeynmt.training - Epoch   8, Step:    28900, Batch Loss:     1.945685, Batch Acc: 0.502805, Tokens per Sec:    24697, Lr: 0.000300
2024-05-28 12:20:25,064 - INFO - joeynmt.training - Epoch   8, Step:    29000, Batch Loss:     2.231979, Batch Acc: 0.501810, Tokens per Sec:    25163, Lr: 0.000300
2024-05-28 12:20:25,069 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:20:25,072 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:20:32,346 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.89, acc:   0.48, generation: 7.2539[sec], evaluation: 0.0000[sec]
2024-05-28 12:20:32,453 - INFO - joeynmt.helpers - delete models/bpe-vocab/26500.ckpt
2024-05-28 12:20:32,466 - INFO - joeynmt.training - Example #0
2024-05-28 12:20:32,469 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:20:32,469 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:20:32,469 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'showed', 'these', 'two', 'di@@', 'ap@@', 's', 'to', 'demonstr@@', 'ate', 'that', 'the', 'entire', 'pol@@', 'ar', 'to', 'demonstr@@', 'ate', 'that', 'the', 'city', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'size', 'of', 'the', 'mar@@', 'ine', 'of', 'the', 'mar@@', 'ch', 'of', 'the', 'mar@@', 'ch', 'of', 'the', 'mar@@', 'ch', 'of', 'the', 'mar@@', 'ch', 'of', 'the', 'two', 'percent', 'of', 'the', 'mar@@', 'ch', 'of', 'the', 'second', 'big', 'was', 'in', 'a', 'little', 'bit', 'of', 'a', 'little', 'di@@', 'r@@', 'ty', 'percent', 'of', 'the', 'whole', 'di@@', 'e', 'of', 'the']
2024-05-28 12:20:32,470 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:20:32,473 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:20:32,476 - INFO - joeynmt.training - 	Hypothesis: And the year we showed these two diaps to demonstrate that the entire polar to demonstrate that the city of the last three million years of the last three million years of the last three million years of the size of the marine of the march of the march of the march of the march of the two percent of the march of the second big was in a little bit of a little dirty percent of the whole die of the
2024-05-28 12:20:32,481 - INFO - joeynmt.training - Example #1
2024-05-28 12:20:32,484 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:20:32,484 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:20:32,484 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'al', 'mor@@', 'tal@@', 'ity', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'look', 'at', 'the', 'black', 'of', 'the', 'bl@@', 'ue', 'of', 'the', 'bl@@', 'ue', 'of', 'the', 'bl@@', 'ue', 'of', 'the', 'bl@@', 'ack@@', 's.', '</s>']
2024-05-28 12:20:32,485 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:20:32,488 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:20:32,491 - INFO - joeynmt.training - 	Hypothesis: But this moral mortality of this particular problem because it doesn't look at the black of the blue of the blue of the blue of the blacks.
2024-05-28 12:20:32,494 - INFO - joeynmt.training - Example #2
2024-05-28 12:20:32,497 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:20:32,497 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:20:32,497 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'of', 'the', 'pol@@', 'ar', 'is,', 'in', 'a', 'way', 'that', 'the', 'global', 'climate', 'system@@', ',', '</s>']
2024-05-28 12:20:32,498 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:20:32,501 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:20:32,504 - INFO - joeynmt.training - 	Hypothesis: The polar of the polar is, in a way that the global climate system,
2024-05-28 12:20:32,507 - INFO - joeynmt.training - Example #3
2024-05-28 12:20:32,510 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:20:32,510 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:20:32,510 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'was', 'ex@@', 'ten@@', 'ded', 'to', 'the', 'bot@@', 'tom', 'and', 'the', 'sc@@', 'ale.', '</s>']
2024-05-28 12:20:32,511 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:20:32,515 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:20:32,518 - INFO - joeynmt.training - 	Hypothesis: She was extended to the bottom and the scale.
2024-05-28 12:20:32,552 - INFO - joeynmt.training - Example #4
2024-05-28 12:20:32,555 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:20:32,555 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:20:32,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'next', 'sli@@', 'de', 'I', 'will', 'show', 'you', 'will', 'be', 'a', 'very', 'quick@@', 'ly', 'going', 'to', 'be', 'a', 'very', 'quick@@', 'ly', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:20:32,556 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:20:32,560 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:20:32,563 - INFO - joeynmt.training - 	Hypothesis: The next next slide I will show you will be a very quickly going to be a very quickly in the last 25 years.
2024-05-28 12:20:35,349 - INFO - joeynmt.training - Epoch   8, Step:    29100, Batch Loss:     1.994547, Batch Acc: 0.509365, Tokens per Sec:    22912, Lr: 0.000300
2024-05-28 12:20:38,109 - INFO - joeynmt.training - Epoch   8, Step:    29200, Batch Loss:     1.801933, Batch Acc: 0.509321, Tokens per Sec:    24525, Lr: 0.000300
2024-05-28 12:20:40,852 - INFO - joeynmt.training - Epoch   8, Step:    29300, Batch Loss:     1.764265, Batch Acc: 0.508698, Tokens per Sec:    25250, Lr: 0.000300
2024-05-28 12:20:43,622 - INFO - joeynmt.training - Epoch   8, Step:    29400, Batch Loss:     1.758841, Batch Acc: 0.504005, Tokens per Sec:    24923, Lr: 0.000300
2024-05-28 12:20:46,390 - INFO - joeynmt.training - Epoch   8, Step:    29500, Batch Loss:     1.791773, Batch Acc: 0.507185, Tokens per Sec:    24870, Lr: 0.000300
2024-05-28 12:20:46,395 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:20:46,398 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:20:53,746 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.79, acc:   0.49, generation: 7.3288[sec], evaluation: 0.0000[sec]
2024-05-28 12:20:53,800 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:20:53,890 - INFO - joeynmt.helpers - delete models/bpe-vocab/27000.ckpt
2024-05-28 12:20:53,903 - INFO - joeynmt.training - Example #0
2024-05-28 12:20:53,907 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:20:53,907 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:20:53,907 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'showed', 'these', 'two', 'di@@', 'es@@', 'the@@', 'tic', 'thre@@', 'at@@', 's', 'to', 'demonstr@@', 'ate', 'that', 'the', 'pol@@', 'ice', 'that', 'in', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'mar@@', 'ine', 'years', 'of', 'the', 'mar@@', 'ine', 'of', 'the', 'mar@@', 'ine', 'percent', 'of', 'the', 'mar@@', 'ine', 'percent', 'of', 'the', 'mar@@', 'ine', 'percent', 'of', 'the', 'size', 'of', 'the', 'mar@@', 'ine', 'that', 'was', 'a', 'little', 'di@@', 'd.', '</s>']
2024-05-28 12:20:53,908 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:20:53,911 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:20:53,914 - INFO - joeynmt.training - 	Hypothesis: The year I showed these two diesthetic threats to demonstrate that the police that in the last three million years of the last three million years of the last three million years of the marine years of the marine of the marine percent of the marine percent of the marine percent of the size of the marine that was a little did.
2024-05-28 12:20:53,917 - INFO - joeynmt.training - Example #1
2024-05-28 12:20:53,921 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:20:53,921 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:20:53,921 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'al', 'mor@@', 'n@@', 'ity', 'of', 'this', 'speci@@', 'fic@@', 'ally', 'because', 'it', "doesn't", 'look', 'at', 'the', 'black', 'gu@@', 'i@@', 'de', 'of', 'the', 'gu@@', 'il@@', 'ty', 'of', 'the', 'gu@@', 'y.', '</s>']
2024-05-28 12:20:53,921 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:20:53,924 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:20:53,927 - INFO - joeynmt.training - 	Hypothesis: But this moral mornity of this specifically because it doesn't look at the black guide of the guilty of the guy.
2024-05-28 12:20:53,931 - INFO - joeynmt.training - Example #2
2024-05-28 12:20:53,935 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:20:53,935 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:20:53,935 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'pol@@', 'ar', 'is', 'in', 'a', 'way', 'that', 'the', 'global', 'system', 'that', 'is', 'the', 'global', 'system@@', '.', '</s>']
2024-05-28 12:20:53,935 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:20:53,938 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:20:53,941 - INFO - joeynmt.training - 	Hypothesis: The polar polar is in a way that the global system that is the global system.
2024-05-28 12:20:53,944 - INFO - joeynmt.training - Example #3
2024-05-28 12:20:53,947 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:20:53,947 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:20:53,947 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'ex@@', 'ten@@', 'ded', 'to', 'the', 'top', 'and', 'the', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 12:20:53,948 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:20:53,951 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:20:53,988 - INFO - joeynmt.training - 	Hypothesis: It was extended to the top and the contract.
2024-05-28 12:20:53,991 - INFO - joeynmt.training - Example #4
2024-05-28 12:20:53,995 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:20:53,995 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:20:53,995 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'that', "I'm", 'going', 'to', 'show', 'you', 'will', 'show', 'you', 'will', 'have', 'a', 'quick@@', 'ly', 'on', 'what', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:20:53,995 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:20:53,998 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:20:54,027 - INFO - joeynmt.training - 	Hypothesis: The next slide that I'm going to show you will show you will have a quickly on what happened in the last 25 years.
2024-05-28 12:20:56,793 - INFO - joeynmt.training - Epoch   8, Step:    29600, Batch Loss:     1.775690, Batch Acc: 0.511153, Tokens per Sec:    22339, Lr: 0.000300
2024-05-28 12:20:59,548 - INFO - joeynmt.training - Epoch   8, Step:    29700, Batch Loss:     1.764900, Batch Acc: 0.504691, Tokens per Sec:    24985, Lr: 0.000300
2024-05-28 12:21:02,317 - INFO - joeynmt.training - Epoch   8, Step:    29800, Batch Loss:     1.674849, Batch Acc: 0.511009, Tokens per Sec:    24626, Lr: 0.000300
2024-05-28 12:21:05,070 - INFO - joeynmt.training - Epoch   8, Step:    29900, Batch Loss:     1.838304, Batch Acc: 0.511363, Tokens per Sec:    24705, Lr: 0.000300
2024-05-28 12:21:07,877 - INFO - joeynmt.training - Epoch   8, Step:    30000, Batch Loss:     1.817198, Batch Acc: 0.509996, Tokens per Sec:    24958, Lr: 0.000300
2024-05-28 12:21:07,881 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:21:07,884 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:21:14,518 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.79, acc:   0.48, generation: 6.6164[sec], evaluation: 0.0000[sec]
2024-05-28 12:21:14,540 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:21:14,623 - INFO - joeynmt.helpers - delete models/bpe-vocab/27500.ckpt
2024-05-28 12:21:14,636 - INFO - joeynmt.training - Example #0
2024-05-28 12:21:14,640 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:21:14,640 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:21:14,640 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'we', 'were', 'sho@@', 'wn', 'these', 'two', 'di@@', 'am@@', 'on@@', 'e@@', ';', 'to', 'the', 'third', 'of', 'the', 'pol@@', 'ar', 'that', 'the', 'ma@@', 'in', 'pol@@', 'ar', 'that', 'the', 'ma@@', 'in', 'of', 'the', 'last', 'three', 'million', 'years', 'was', 'the', 'size', 'of', 'the', 'ma@@', 'in', 'was', 'a', 'small', 'size', 'of', 'the', 'mar@@', 'ch', 'of', 'the', 'mar@@', 'ch', 'of', 'the', 'mar@@', 'ch', 'of', 'the', 'mar@@', 'ch', 'of', 'the', 'mar@@', 'ch', 'of', 'the', 'ma@@', 'y@@', 'or', 'in', 'the', 'ma@@', 'p.', '</s>']
2024-05-28 12:21:14,640 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:21:14,644 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:21:14,647 - INFO - joeynmt.training - 	Hypothesis: The year we were shown these two diamone; to the third of the polar that the main polar that the main of the last three million years was the size of the main was a small size of the march of the march of the march of the march of the march of the mayor in the map.
2024-05-28 12:21:14,651 - INFO - joeynmt.training - Example #1
2024-05-28 12:21:14,654 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:21:14,654 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:21:14,655 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ity', 'is', 'the', 'seri@@', 'ous', 'problem', 'because', 'it', "doesn't", 'look', 'at', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'f@@', 'os@@', 'si@@', 'l', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'c@@', 'os@@', 'mic', 'mi@@', 'd@@', 'g@@', 'es', 'of', 'this', 'mor@@', 'n@@', 'ity', 'of', 'the', 'mor@@', 'n@@', 'ity', 'of', 'this', 'mor@@', 'n@@', 'ity', 'of', 'this', 'mor@@', 'n@@', 'ity', 'of', 'the', 'problem', 'of', 'this', 'speci@@', 'fic', 'issu@@', 'e', 'of', 'the', 'speci@@', 'fic', 'issu@@', 'e', 'because', 'it', "doesn't", 'look', 'at', 'the', 'speci@@', 'fic', 'issu@@', 'e', 'because', 'it', "doesn't", 'look', 'at', 'the', 'r@@']
2024-05-28 12:21:14,655 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:21:14,658 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:21:14,661 - INFO - joeynmt.training - 	Hypothesis: But this mornity is the serious problem because it doesn't look at the size of the size of the fossil of the size of the size of the size of the cosmic midges of this mornity of the mornity of this mornity of this mornity of the problem of this specific issue of the specific issue because it doesn't look at the specific issue because it doesn't look at the r
2024-05-28 12:21:14,665 - INFO - joeynmt.training - Example #2
2024-05-28 12:21:14,668 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:21:14,668 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:21:14,668 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'pol@@', 'ar', 'is', 'in', 'a', 'way,', 'the', 'heart', 'of', 'the', 'climate', 'of', 'the', 'climate', 'system@@', '.', '</s>']
2024-05-28 12:21:14,669 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:21:14,672 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:21:14,675 - INFO - joeynmt.training - 	Hypothesis: The polar polar is in a way, the heart of the climate of the climate system.
2024-05-28 12:21:14,678 - INFO - joeynmt.training - Example #3
2024-05-28 12:21:14,681 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:21:14,681 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:21:14,681 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'is', 'ex@@', 'ten@@', 'd', 'to', 'the', 'f@@', 'all', 'of', 'the', 'f@@', 'low@@', '.', '</s>']
2024-05-28 12:21:14,682 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:21:14,684 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:21:14,687 - INFO - joeynmt.training - 	Hypothesis: She is extend to the fall of the flow.
2024-05-28 12:21:14,714 - INFO - joeynmt.training - Example #4
2024-05-28 12:21:14,717 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:21:14,717 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:21:14,717 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'thing', 'that', 'I', 'will', 'show', 'you', 'a', 'little', 'bit', 'of', 'a', 'sli@@', 'de', 'will', 'be', 'a', 'little', 'bit', 'of', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:21:14,718 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:21:14,766 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:21:14,769 - INFO - joeynmt.training - 	Hypothesis: The next thing that I will show you a little bit of a slide will be a little bit of the last 25 years.
2024-05-28 12:21:17,528 - INFO - joeynmt.training - Epoch   8, Step:    30100, Batch Loss:     1.625497, Batch Acc: 0.503878, Tokens per Sec:    23041, Lr: 0.000300
2024-05-28 12:21:20,296 - INFO - joeynmt.training - Epoch   8, Step:    30200, Batch Loss:     1.920691, Batch Acc: 0.514832, Tokens per Sec:    25555, Lr: 0.000300
2024-05-28 12:21:23,064 - INFO - joeynmt.training - Epoch   8, Step:    30300, Batch Loss:     1.966616, Batch Acc: 0.505081, Tokens per Sec:    24432, Lr: 0.000300
2024-05-28 12:21:25,809 - INFO - joeynmt.training - Epoch   8, Step:    30400, Batch Loss:     1.713631, Batch Acc: 0.508340, Tokens per Sec:    24719, Lr: 0.000300
2024-05-28 12:21:28,562 - INFO - joeynmt.training - Epoch   8, Step:    30500, Batch Loss:     1.880682, Batch Acc: 0.503795, Tokens per Sec:    24932, Lr: 0.000300
2024-05-28 12:21:28,566 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:21:28,569 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:21:35,823 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.71, acc:   0.48, generation: 7.2345[sec], evaluation: 0.0000[sec]
2024-05-28 12:21:35,833 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:21:35,936 - INFO - joeynmt.helpers - delete models/bpe-vocab/29000.ckpt
2024-05-28 12:21:35,941 - INFO - joeynmt.training - Example #0
2024-05-28 12:21:35,944 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:21:35,944 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:21:35,944 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'were', 'sho@@', 'wn', 'these', 'two', 'di@@', 'ap@@', 's', 'to', 'demonstr@@', 'ate', 'that', 'the', 'pol@@', 'ar', 'pol@@', 'ar', 'in', 'the', 'city', 'that', 'was', 'the', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'size', 'of', 'the', '4@@', '8', 'was', 'the', 'size', 'of', 'a', 'little', 'b@@', 'it.', '</s>']
2024-05-28 12:21:35,945 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:21:35,948 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:21:35,951 - INFO - joeynmt.training - 	Hypothesis: And the year we were shown these two diaps to demonstrate that the polar polar in the city that was the most of the last three million years of the last three million years of the size of the 48 was the size of a little bit.
2024-05-28 12:21:35,956 - INFO - joeynmt.training - Example #1
2024-05-28 12:21:35,960 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:21:35,960 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:21:35,960 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ity', 'is', 'seri@@', 'al', 'seri@@', 'ous', 'because', 'it', "doesn't", 'look', 'at', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 's@@', 'am@@', 'e.', '</s>']
2024-05-28 12:21:35,960 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:21:35,963 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:21:35,967 - INFO - joeynmt.training - 	Hypothesis: But this mornity is serial serious because it doesn't look at the size of the size of the same.
2024-05-28 12:21:35,970 - INFO - joeynmt.training - Example #2
2024-05-28 12:21:35,973 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:21:35,973 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:21:35,973 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'pol@@', 'ar', 'is', 'in', 'a', 'way,', 'the', 'heart', 'of', 'the', 'climate', 'cr@@', 'is@@', 'is', 'the', 'global', 'system@@', '.', '</s>']
2024-05-28 12:21:35,973 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:21:35,976 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:21:35,979 - INFO - joeynmt.training - 	Hypothesis: The polar polar is in a way, the heart of the climate crisis the global system.
2024-05-28 12:21:35,982 - INFO - joeynmt.training - Example #3
2024-05-28 12:21:35,985 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:21:35,985 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:21:35,985 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'goes', 'up', 'and', 'they', 'are', 'exp@@', 'and@@', 'ing', 'and', 'contr@@', 'ac@@', 'y.', '</s>']
2024-05-28 12:21:35,986 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:21:35,989 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:21:36,015 - INFO - joeynmt.training - 	Hypothesis: It goes up and they are expanding and contracy.
2024-05-28 12:21:36,018 - INFO - joeynmt.training - Example #4
2024-05-28 12:21:36,021 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:21:36,021 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:21:36,021 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'thing', 'that', 'I', 'will', 'show', 'you', 'the', 'cur@@', 'e', 'that', 'will', 'be', 'a', 'very', 'quick@@', 'ly', 're@@', 'mo@@', 'te', 'on', 'what', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:21:36,022 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:21:36,024 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:21:36,027 - INFO - joeynmt.training - 	Hypothesis: The next thing that I will show you the cure that will be a very quickly remote on what happened in the last 25 years.
2024-05-28 12:21:38,759 - INFO - joeynmt.training - Epoch   8, Step:    30600, Batch Loss:     1.797881, Batch Acc: 0.507257, Tokens per Sec:    23051, Lr: 0.000300
2024-05-28 12:21:41,484 - INFO - joeynmt.training - Epoch   8, Step:    30700, Batch Loss:     1.764767, Batch Acc: 0.504287, Tokens per Sec:    24739, Lr: 0.000300
2024-05-28 12:21:44,238 - INFO - joeynmt.training - Epoch   8, Step:    30800, Batch Loss:     1.820047, Batch Acc: 0.509858, Tokens per Sec:    24958, Lr: 0.000300
2024-05-28 12:21:47,024 - INFO - joeynmt.training - Epoch   8, Step:    30900, Batch Loss:     1.840181, Batch Acc: 0.503354, Tokens per Sec:    24711, Lr: 0.000300
2024-05-28 12:21:49,810 - INFO - joeynmt.training - Epoch   8, Step:    31000, Batch Loss:     1.816114, Batch Acc: 0.507263, Tokens per Sec:    24658, Lr: 0.000300
2024-05-28 12:21:49,814 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:21:49,818 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:21:56,346 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.66, acc:   0.49, generation: 6.5089[sec], evaluation: 0.0000[sec]
2024-05-28 12:21:56,369 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:21:56,464 - INFO - joeynmt.helpers - delete models/bpe-vocab/28000.ckpt
2024-05-28 12:21:56,468 - INFO - joeynmt.training - Example #0
2024-05-28 12:21:56,471 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:21:56,471 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:21:56,471 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'looked', 'at', 'these', 'two', 'di@@', 'et', 'pos@@', 'iti@@', 'ons', 'to', 'demonstr@@', 'ate', 'that', 'the', 'big', 'pol@@', 'ar', 'pol@@', 'ar', 'pol@@', 'ar', 'that', 'in', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'big', 'amount', 'of', 'big', 'se@@', 'ven@@', ',', 'which', 'was', 'the', 'little', 'amount', 'of', 'f@@', 'low@@', 'er', 'than', '40', 'percent', 'of', 'the', 'Ear@@', 'th.', '</s>']
2024-05-28 12:21:56,472 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:21:56,475 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:21:56,478 - INFO - joeynmt.training - 	Hypothesis: And the year we looked at these two diet positions to demonstrate that the big polar polar polar that in the last three million years of the last three million years of the last three million years of the big amount of big seven, which was the little amount of flower than 40 percent of the Earth.
2024-05-28 12:21:56,481 - INFO - joeynmt.training - Example #1
2024-05-28 12:21:56,484 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:21:56,484 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:21:56,484 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'this', 'is', 'seri@@', 'ous', 'problem', 'because', 'it', "doesn't", 'look', 'at', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'b@@', 'os@@', 's', 'of', 'the', 'b@@', 'os@@', 's', 'of', 'the', 'countr@@', 'y.', '</s>']
2024-05-28 12:21:56,485 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:21:56,488 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:21:56,490 - INFO - joeynmt.training - 	Hypothesis: But this morning, this is serious problem because it doesn't look at the size of the size of the size of the boss of the boss of the country.
2024-05-28 12:21:56,493 - INFO - joeynmt.training - Example #2
2024-05-28 12:21:56,496 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:21:56,496 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:21:56,496 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'is', 'in', 'a', 'way', 'that', 'the', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.', '</s>']
2024-05-28 12:21:56,496 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:21:56,499 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:21:56,502 - INFO - joeynmt.training - 	Hypothesis: The polar is in a way that the heart of the global climate system.
2024-05-28 12:21:56,505 - INFO - joeynmt.training - Example #3
2024-05-28 12:21:56,508 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:21:56,508 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:21:56,508 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'was', 'exp@@', 'and@@', 'ing', 'the', 'f@@', 'ing@@', 'er', 'and', 'the', 'f@@', 'low@@', 'er', 'f@@', 'ing@@', 'er', 'f@@', 'ing@@', 'ers.', '</s>']
2024-05-28 12:21:56,508 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:21:56,511 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:21:56,513 - INFO - joeynmt.training - 	Hypothesis: She was expanding the finger and the flower finger fingers.
2024-05-28 12:21:56,535 - INFO - joeynmt.training - Example #4
2024-05-28 12:21:56,538 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:21:56,538 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:21:56,538 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'next', 'step', 'that', 'I', 'will', 'show', 'you', 'will', 'show', 'you', 'a', 'lot', 'of', 'what', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:21:56,539 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:21:56,542 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:21:56,544 - INFO - joeynmt.training - 	Hypothesis: The next next step that I will show you will show you a lot of what happened in the last 25 years.
2024-05-28 12:21:59,354 - INFO - joeynmt.training - Epoch   8, Step:    31100, Batch Loss:     1.700104, Batch Acc: 0.508754, Tokens per Sec:    23936, Lr: 0.000300
2024-05-28 12:22:02,112 - INFO - joeynmt.training - Epoch   8, Step:    31200, Batch Loss:     1.829488, Batch Acc: 0.505265, Tokens per Sec:    24902, Lr: 0.000300
2024-05-28 12:22:04,726 - INFO - joeynmt.training - Epoch   8: total training loss 7001.02
2024-05-28 12:22:04,730 - INFO - joeynmt.training - EPOCH 9
2024-05-28 12:22:04,926 - INFO - joeynmt.training - Epoch   9, Step:    31300, Batch Loss:     1.577599, Batch Acc: 0.549939, Tokens per Sec:    21224, Lr: 0.000300
2024-05-28 12:22:07,660 - INFO - joeynmt.training - Epoch   9, Step:    31400, Batch Loss:     1.669299, Batch Acc: 0.530118, Tokens per Sec:    24993, Lr: 0.000300
2024-05-28 12:22:10,394 - INFO - joeynmt.training - Epoch   9, Step:    31500, Batch Loss:     1.629481, Batch Acc: 0.527027, Tokens per Sec:    24881, Lr: 0.000300
2024-05-28 12:22:10,398 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:22:10,401 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:22:17,523 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.67, acc:   0.49, generation: 7.1023[sec], evaluation: 0.0000[sec]
2024-05-28 12:22:17,646 - INFO - joeynmt.helpers - delete models/bpe-vocab/28500.ckpt
2024-05-28 12:22:17,686 - INFO - joeynmt.training - Example #0
2024-05-28 12:22:17,689 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:22:17,689 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:22:17,690 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'were', 'thro@@', 'wn', 'these', 'two', 'di@@', 'a@@', 'ys', 'to', 'demonstr@@', 'ate', 'that', 'the', 'pol@@', 'ar', 'pol@@', 'ar', 'that', 'was', 'the', 'pol@@', 'ar', 'in', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'a', 'small', 'size', 'of', 'the', 'last', 'three', 'to', 'the', 'size', 'of', '4@@', '8', 'percent', 'of', 'the', 'size', 'of', 'the', 'mag@@', 'n@@', 'itu@@', 'de,', 'it', 'was', 'a', 'little', 'bit', 'of', '40', 'percent', 'of', 'the', 'time.', '</s>']
2024-05-28 12:22:17,690 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:22:17,693 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:22:17,696 - INFO - joeynmt.training - 	Hypothesis: And the year we were thrown these two diays to demonstrate that the polar polar that was the polar in the last three million years has been a small size of the last three to the size of 48 percent of the size of the magnitude, it was a little bit of 40 percent of the time.
2024-05-28 12:22:17,700 - INFO - joeynmt.training - Example #1
2024-05-28 12:22:17,704 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:22:17,704 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:22:17,704 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'this', 'particular', 'particular', 'particular', 'particular', 'particular', 'problem', 'because', 'it', "doesn't", 'look', 'at', 'the', 'black', 'issu@@', 'e.', '</s>']
2024-05-28 12:22:17,704 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:22:17,708 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:22:17,711 - INFO - joeynmt.training - 	Hypothesis: But this morning, this particular particular particular particular particular problem because it doesn't look at the black issue.
2024-05-28 12:22:17,715 - INFO - joeynmt.training - Example #2
2024-05-28 12:22:17,717 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:22:17,717 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:22:17,717 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'of', 'the', 'pol@@', 'ar', 'is,', 'in', 'a', 'way,', 'the', 'heart', 'of', 'the', 'climate', 'of', 'the', 'climate', 'of', 'the', 'climate', 'of', 'the', 'climate', 'of', 'the', 'clim@@', 'ate.', '</s>']
2024-05-28 12:22:17,718 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:22:17,721 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:22:17,724 - INFO - joeynmt.training - 	Hypothesis: The polar of the polar is, in a way, the heart of the climate of the climate of the climate of the climate of the climate.
2024-05-28 12:22:17,727 - INFO - joeynmt.training - Example #3
2024-05-28 12:22:17,731 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:22:17,731 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:22:17,731 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'goes', 'over@@', ',', 'and', 'they', 'are', 'exp@@', 'and@@', 'ing', 'and', 'the', 'f@@', 'ear', 'and', 'the', 'f@@', 'ear', 'and', 'the', 'f@@', 'ear', 'of', 'the', 'f@@', 'ear', 'and', 'it', 'was', 'exp@@', 'and@@', 'ing', 'the', 'f@@', 'ear', 'and', 'it', 'was', 'exp@@', 'and@@', 'ing', 'and', "it's", 'exp@@', 'and@@', 'ing', 'and', 'the', 'f@@', 'ear', 'and', 'the', 'f@@', 'ear', 'and', 'the', 'f@@', 'ear', 'and', 'the', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 12:22:17,732 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:22:17,735 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:22:17,739 - INFO - joeynmt.training - 	Hypothesis: It goes over, and they are expanding and the fear and the fear and the fear of the fear and it was expanding the fear and it was expanding and it's expanding and the fear and the fear and the fear and the contract.
2024-05-28 12:22:17,742 - INFO - joeynmt.training - Example #4
2024-05-28 12:22:17,765 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:22:17,765 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:22:17,765 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'that', "I'm", 'going', 'to', 'show', 'you', 'will', 'show', 'up', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:22:17,765 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:22:17,769 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:22:17,772 - INFO - joeynmt.training - 	Hypothesis: The next slide that I'm going to show you will show up the last 25 years.
2024-05-28 12:22:20,535 - INFO - joeynmt.training - Epoch   9, Step:    31600, Batch Loss:     1.697850, Batch Acc: 0.533702, Tokens per Sec:    23706, Lr: 0.000300
2024-05-28 12:22:23,272 - INFO - joeynmt.training - Epoch   9, Step:    31700, Batch Loss:     1.629792, Batch Acc: 0.526910, Tokens per Sec:    24932, Lr: 0.000300
2024-05-28 12:22:26,029 - INFO - joeynmt.training - Epoch   9, Step:    31800, Batch Loss:     1.691773, Batch Acc: 0.528258, Tokens per Sec:    24614, Lr: 0.000300
2024-05-28 12:22:28,781 - INFO - joeynmt.training - Epoch   9, Step:    31900, Batch Loss:     1.770607, Batch Acc: 0.524406, Tokens per Sec:    25383, Lr: 0.000300
2024-05-28 12:22:31,521 - INFO - joeynmt.training - Epoch   9, Step:    32000, Batch Loss:     1.835359, Batch Acc: 0.525699, Tokens per Sec:    25633, Lr: 0.000300
2024-05-28 12:22:31,545 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:22:31,549 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:22:38,223 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.67, acc:   0.49, generation: 6.6566[sec], evaluation: 0.0000[sec]
2024-05-28 12:22:38,317 - INFO - joeynmt.helpers - delete models/bpe-vocab/29500.ckpt
2024-05-28 12:22:38,330 - INFO - joeynmt.training - Example #0
2024-05-28 12:22:38,334 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:22:38,334 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:22:38,334 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year,', 'we', 'showed', 'these', 'two', 'di@@', 'am@@', 'on@@', 'ds', 'to', 'pro@@', 've', 'that', 'pol@@', 'ar', 'pol@@', 'ar', 'pol@@', 'ar', 'pol@@', 'ar', 'pol@@', 'ar', 'pol@@', 'ar', 'that', 'was', 'the', 'ma@@', 'in', 'the', 'last', 'three', 'to', 'the', 'last', 'three', 'to', 'the', 'size', 'of', 'the', '2@@', '1@@', 'st', '4@@', '8', 'percent', 'of', 'the', 'mar@@', 'ine', 'of', 'the', 'mar@@', 'ine', 'percent', 'of', 'the', 'time.', '</s>']
2024-05-28 12:22:38,334 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:22:38,337 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:22:38,341 - INFO - joeynmt.training - 	Hypothesis: And the year, we showed these two diamonds to prove that polar polar polar polar polar polar that was the main the last three to the last three to the size of the 21st 48 percent of the marine of the marine percent of the time.
2024-05-28 12:22:38,344 - INFO - joeynmt.training - Example #1
2024-05-28 12:22:38,347 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:22:38,347 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:22:38,347 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'look', 'at', 'the', 'size', 'of', 'the', 'gu@@', 'y.', '</s>']
2024-05-28 12:22:38,348 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:22:38,351 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:22:38,355 - INFO - joeynmt.training - 	Hypothesis: But this morning, the seriousness of this particular problem because it doesn't look at the size of the guy.
2024-05-28 12:22:38,358 - INFO - joeynmt.training - Example #2
2024-05-28 12:22:38,361 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:22:38,361 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:22:38,361 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'pol@@', 'ar', 'is', 'in', 'a', 'way,', 'the', 'heart', 'of', 'the', 'climate', 'of', 'the', 'climate', 'system@@', '.', '</s>']
2024-05-28 12:22:38,362 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:22:38,365 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:22:38,368 - INFO - joeynmt.training - 	Hypothesis: The polar polar is in a way, the heart of the climate of the climate system.
2024-05-28 12:22:38,371 - INFO - joeynmt.training - Example #3
2024-05-28 12:22:38,374 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:22:38,374 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:22:38,374 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'goes', 'back', 'and', 'over', 'and', 'over', 'the', 'f@@', 'ear', 'and', 'the', 'f@@', 'ear', 'of', 'the', 'f@@', 'ear', 'and', 'the', 'f@@', 'ear', 'of', 'the', 'f@@', 'all@@', 's', 'of', 'the', 'f@@', 'all@@', 's', 'of', 'w@@', 'oo@@', 'den', 'and', 'it', 'was', 'ex@@', 'ten@@', 'ded', 'to', 'the', 'f@@', 'all', 'of', 'the', 'w@@', 'oo@@', 'den', 'and', 'the', 'f@@', 'ac@@', 't.', '</s>']
2024-05-28 12:22:38,374 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:22:38,378 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:22:38,381 - INFO - joeynmt.training - 	Hypothesis: It goes back and over and over the fear and the fear of the fear and the fear of the falls of the falls of wooden and it was extended to the fall of the wooden and the fact.
2024-05-28 12:22:38,384 - INFO - joeynmt.training - Example #4
2024-05-28 12:22:38,403 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:22:38,403 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:22:38,403 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'that', 'I', 'will', 'show', 'you', 'a', 'lot', 'of', 'being', 'a', 'quick@@', 'ly', 'quick@@', 'ly', 'going', 'to', 'be', 'a', 'little', 'bit', 'of', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:22:38,403 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:22:38,407 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:22:38,410 - INFO - joeynmt.training - 	Hypothesis: The next slide that I will show you a lot of being a quickly quickly going to be a little bit of the last 25 years.
2024-05-28 12:22:41,145 - INFO - joeynmt.training - Epoch   9, Step:    32100, Batch Loss:     1.835818, Batch Acc: 0.520619, Tokens per Sec:    23667, Lr: 0.000300
2024-05-28 12:22:43,889 - INFO - joeynmt.training - Epoch   9, Step:    32200, Batch Loss:     1.670079, Batch Acc: 0.524114, Tokens per Sec:    25489, Lr: 0.000300
2024-05-28 12:22:46,635 - INFO - joeynmt.training - Epoch   9, Step:    32300, Batch Loss:     1.973717, Batch Acc: 0.520554, Tokens per Sec:    24894, Lr: 0.000300
2024-05-28 12:22:49,337 - INFO - joeynmt.training - Epoch   9, Step:    32400, Batch Loss:     1.630393, Batch Acc: 0.527743, Tokens per Sec:    24130, Lr: 0.000300
2024-05-28 12:22:52,095 - INFO - joeynmt.training - Epoch   9, Step:    32500, Batch Loss:     1.763588, Batch Acc: 0.524517, Tokens per Sec:    25569, Lr: 0.000300
2024-05-28 12:22:52,099 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:22:52,103 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:22:59,004 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.63, acc:   0.49, generation: 6.8827[sec], evaluation: 0.0000[sec]
2024-05-28 12:22:59,008 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:22:59,101 - INFO - joeynmt.helpers - delete models/bpe-vocab/30000.ckpt
2024-05-28 12:22:59,113 - INFO - joeynmt.training - Example #0
2024-05-28 12:22:59,118 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:22:59,118 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:22:59,118 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'showed', 'these', 'two', 'di@@', 'ap@@', 's', 'to', 'demonstr@@', 'ate', 'that', 'the', 'second', 'di@@', 'et', 'to', 'demonstr@@', 'ate', 'that', 'the', 'big', 'pol@@', 'ice', 'that', 'was', 'the', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'was', 'the', 'size', 'of', 'the', '4@@', '8', 'countries', 'was', 'a', 'little', 'size', 'of', 'the', 'mar@@', 'ch', 'of', '4@@', '8', 'percent', 'of', 'it.', '</s>']
2024-05-28 12:22:59,118 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:22:59,121 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:22:59,124 - INFO - joeynmt.training - 	Hypothesis: And the year we showed these two diaps to demonstrate that the second diet to demonstrate that the big police that was the most of the last three million years was the size of the 48 countries was a little size of the march of 48 percent of it.
2024-05-28 12:22:59,127 - INFO - joeynmt.training - Example #1
2024-05-28 12:22:59,130 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:22:59,130 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:22:59,130 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'the', 'seri@@', 'ous', 'problem', 'because', 'it', "doesn't", 'look', 'at', 'the', 'same', 'time.', '</s>']
2024-05-28 12:22:59,130 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:22:59,133 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:22:59,136 - INFO - joeynmt.training - 	Hypothesis: But this morning, the serious problem because it doesn't look at the same time.
2024-05-28 12:22:59,139 - INFO - joeynmt.training - Example #2
2024-05-28 12:22:59,142 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:22:59,142 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:22:59,142 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is', 'in', 'a', 'way,', 'the', 'heart', 'of', 'the', 'global', 'war@@', 'm@@', 'ing', 'system@@', '.', '</s>']
2024-05-28 12:22:59,142 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:22:59,145 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:22:59,147 - INFO - joeynmt.training - 	Hypothesis: The police is in a way, the heart of the global warming system.
2024-05-28 12:22:59,150 - INFO - joeynmt.training - Example #3
2024-05-28 12:22:59,153 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:22:59,153 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:22:59,153 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'was', 'ex@@', 'ten@@', 'ded', 'to', 'the', 'f@@', 'all@@', 's', 'and', 'the', 'f@@', 'ear', 'of', 'the', 'f@@', 'ar.', '</s>']
2024-05-28 12:22:59,154 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:22:59,156 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:22:59,159 - INFO - joeynmt.training - 	Hypothesis: She was extended to the falls and the fear of the far.
2024-05-28 12:22:59,162 - INFO - joeynmt.training - Example #4
2024-05-28 12:22:59,192 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:22:59,192 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:22:59,193 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'I', 'will', 'show', 'you', 'the', 'next', 'thing', 'is', 'going', 'to', 'be', 'a', 'lot', 'of', 'quick@@', 'ly', 'going', 'to', 'be', 'a', 'lot', 'of', 'years.', '</s>']
2024-05-28 12:22:59,193 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:22:59,196 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:22:59,199 - INFO - joeynmt.training - 	Hypothesis: The next slide I will show you the next thing is going to be a lot of quickly going to be a lot of years.
2024-05-28 12:23:01,937 - INFO - joeynmt.training - Epoch   9, Step:    32600, Batch Loss:     1.831466, Batch Acc: 0.521964, Tokens per Sec:    23244, Lr: 0.000300
2024-05-28 12:23:04,662 - INFO - joeynmt.training - Epoch   9, Step:    32700, Batch Loss:     1.615791, Batch Acc: 0.525490, Tokens per Sec:    24578, Lr: 0.000300
2024-05-28 12:23:07,419 - INFO - joeynmt.training - Epoch   9, Step:    32800, Batch Loss:     1.496934, Batch Acc: 0.524908, Tokens per Sec:    25076, Lr: 0.000300
2024-05-28 12:23:10,179 - INFO - joeynmt.training - Epoch   9, Step:    32900, Batch Loss:     1.685236, Batch Acc: 0.522541, Tokens per Sec:    25242, Lr: 0.000300
2024-05-28 12:23:12,938 - INFO - joeynmt.training - Epoch   9, Step:    33000, Batch Loss:     1.956321, Batch Acc: 0.517608, Tokens per Sec:    25394, Lr: 0.000300
2024-05-28 12:23:12,943 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:23:12,949 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:23:19,730 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.60, acc:   0.49, generation: 6.7625[sec], evaluation: 0.0000[sec]
2024-05-28 12:23:19,734 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:23:19,851 - INFO - joeynmt.helpers - delete models/bpe-vocab/30500.ckpt
2024-05-28 12:23:19,882 - INFO - joeynmt.training - Example #0
2024-05-28 12:23:19,886 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:23:19,886 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:23:19,886 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'last', 'year,', 'we', 'sho@@', 'wn', 'these', 'two', 'di@@', 'am@@', 'on@@', 'e@@', 'er', 'di@@', 'et', 'to', 'demonstr@@', 'ate', 'that', 'the', 'ma@@', 'in', 'the', 'pol@@', 'ar', 'pol@@', 'ar', 'that', 'was', 'the', 'ma@@', 'in', 'the', 'last', 'three', 'million', 'years', 'was', 'the', 'size', 'of', 'the', 'mar@@', 'ch', 'of', 'the', 'mar@@', 'ch', 'of', 'the', 'mar@@', 'ch', 'of', '4@@', '0', 'percent', 'of', 'it.', '</s>']
2024-05-28 12:23:19,886 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:23:19,890 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:23:19,894 - INFO - joeynmt.training - 	Hypothesis: And the last year, we shown these two diamoneer diet to demonstrate that the main the polar polar that was the main the last three million years was the size of the march of the march of the march of 40 percent of it.
2024-05-28 12:23:19,897 - INFO - joeynmt.training - Example #1
2024-05-28 12:23:19,900 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:23:19,901 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:23:19,901 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'ning', 'is', 'seri@@', 'ous', 'seri@@', 'al', 'seri@@', 'ous', 'because', 'it', "doesn't", 'look', 'like', 'the', 'fre@@', 'e', 'of', 'the', 'black', 'hol@@', 'es.', '</s>']
2024-05-28 12:23:19,901 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:23:19,904 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:23:19,908 - INFO - joeynmt.training - 	Hypothesis: But this morning is serious serial serious because it doesn't look like the free of the black holes.
2024-05-28 12:23:19,910 - INFO - joeynmt.training - Example #2
2024-05-28 12:23:19,914 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:23:19,914 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:23:19,914 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'pol@@', 'ar', 'is,', 'in', 'a', 'way,', 'the', 'heart', 'of', 'global', 'system@@', '.', '</s>']
2024-05-28 12:23:19,914 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:23:19,917 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:23:19,921 - INFO - joeynmt.training - 	Hypothesis: The polar polar is, in a way, the heart of global system.
2024-05-28 12:23:19,924 - INFO - joeynmt.training - Example #3
2024-05-28 12:23:19,927 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:23:19,927 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:23:19,927 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'goes', 'off', 'and', 'f@@', 'ar,', 'and', 'contr@@', 'ac@@', 'ts', 'and', 'contr@@', 'ac@@', 'ts', 'the', 'f@@', 'low@@', '.', '</s>']
2024-05-28 12:23:19,927 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:23:19,930 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:23:19,933 - INFO - joeynmt.training - 	Hypothesis: It goes off and far, and contracts and contracts the flow.
2024-05-28 12:23:19,935 - INFO - joeynmt.training - Example #4
2024-05-28 12:23:19,937 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:23:19,937 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:23:19,937 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'that', 'I', 'will', 'show', 'you', 'is', 'going', 'to', 'show', 'it', 'is', 'going', 'to', 'be', 'a', 'quick@@', 'ly', 'sli@@', 'ght@@', 'ly', 'on', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:23:19,938 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:23:19,957 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:23:19,960 - INFO - joeynmt.training - 	Hypothesis: The next slide that I will show you is going to show it is going to be a quickly slightly on the last 25 years.
2024-05-28 12:23:22,715 - INFO - joeynmt.training - Epoch   9, Step:    33100, Batch Loss:     1.706733, Batch Acc: 0.519553, Tokens per Sec:    23040, Lr: 0.000300
2024-05-28 12:23:25,453 - INFO - joeynmt.training - Epoch   9, Step:    33200, Batch Loss:     1.933046, Batch Acc: 0.520389, Tokens per Sec:    25030, Lr: 0.000300
2024-05-28 12:23:28,176 - INFO - joeynmt.training - Epoch   9, Step:    33300, Batch Loss:     1.859609, Batch Acc: 0.521142, Tokens per Sec:    25015, Lr: 0.000300
2024-05-28 12:23:30,895 - INFO - joeynmt.training - Epoch   9, Step:    33400, Batch Loss:     1.548119, Batch Acc: 0.521207, Tokens per Sec:    24371, Lr: 0.000300
2024-05-28 12:23:33,620 - INFO - joeynmt.training - Epoch   9, Step:    33500, Batch Loss:     1.661404, Batch Acc: 0.520813, Tokens per Sec:    24880, Lr: 0.000300
2024-05-28 12:23:33,623 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:23:33,627 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:23:40,216 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.60, acc:   0.49, generation: 6.5695[sec], evaluation: 0.0000[sec]
2024-05-28 12:23:40,220 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:23:40,307 - INFO - joeynmt.helpers - delete models/bpe-vocab/32000.ckpt
2024-05-28 12:23:40,313 - INFO - joeynmt.training - Example #0
2024-05-28 12:23:40,317 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:23:40,317 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:23:40,317 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'showed', 'these', 'two', 'di@@', 'a@@', 'ded', 'degre@@', 'es', 'to', 'demonstr@@', 'ate', 'that', 'the', 'pol@@', 'ice', 'that', 'the', 'most', 'of', 'the', 'pol@@', 'ice', 'that', 'the', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'was', 'the', 'size', 'of', 'the', 'size', 'of', 'the', 'mar@@', 'ine', 'of', '4@@', '8', 'percent', 'of', 'the', 'mar@@', 'ine', 'of', '4@@', '0@@', '-@@', 'percent', 'of', 'the', 'mar@@', 'ine', 'r@@', 'ate', 'with', '4@@', '0', 'percent', 'of', 'the', 'year.', '</s>']
2024-05-28 12:23:40,317 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:23:40,321 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:23:40,324 - INFO - joeynmt.training - 	Hypothesis: And the year we showed these two diaded degrees to demonstrate that the police that the most of the police that the most of the last three million years was the size of the size of the marine of 48 percent of the marine of 40-percent of the marine rate with 40 percent of the year.
2024-05-28 12:23:40,327 - INFO - joeynmt.training - Example #1
2024-05-28 12:23:40,331 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:23:40,331 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:23:40,331 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'al', 'mor@@', 'al', 'issu@@', 'es', 'because', 'it', "doesn't", 'look', 'because', 'it', "doesn't", 'look', 'at', 'the', 'black', 'h@@', 'et@@', 's.', '</s>']
2024-05-28 12:23:40,331 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:23:40,334 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:23:40,336 - INFO - joeynmt.training - 	Hypothesis: But this moral moral issues because it doesn't look because it doesn't look at the black hets.
2024-05-28 12:23:40,339 - INFO - joeynmt.training - Example #2
2024-05-28 12:23:40,342 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:23:40,342 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:23:40,342 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is', 'in', 'a', 'way,', 'in', 'a', 'way,', 'the', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.', '</s>']
2024-05-28 12:23:40,343 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:23:40,346 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:23:40,348 - INFO - joeynmt.training - 	Hypothesis: The police is in a way, in a way, the heart of the global climate system.
2024-05-28 12:23:40,351 - INFO - joeynmt.training - Example #3
2024-05-28 12:23:40,354 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:23:40,354 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:23:40,355 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'goes', 'down', 'and', 'it', 'goes', 'down', 'and', 'it', 'is', 'contr@@', 'ac@@', 'ts', 'and', 'it', 'is', 'contr@@', 'ac@@', 'ts', 'and', 'it', 'is', 'the', 'ac@@', 'ts', 'of', 'the', 's@@', 'am@@', 'e,', 'and', 'it', 'goes', 'down', 'and', 'it', 'goes', 'down', 'and', 'it', 'goes', 'down', 'and', 'it', 'goes', 'down', 'and', 'it', 'goes', 'down', 'and', 'it', 'is', 'ex@@', 't@@', 'ent', 'and', 'it', 'is', 'the', 'ac@@', 't.', '</s>']
2024-05-28 12:23:40,355 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:23:40,358 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:23:40,360 - INFO - joeynmt.training - 	Hypothesis: It goes down and it goes down and it is contracts and it is contracts and it is the acts of the same, and it goes down and it goes down and it goes down and it goes down and it goes down and it is extent and it is the act.
2024-05-28 12:23:40,363 - INFO - joeynmt.training - Example #4
2024-05-28 12:23:40,423 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:23:40,423 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:23:40,423 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'that', 'I', 'will', 'show', 'you', 'a', 'very', 'quick@@', 'ly', 'going', 'to', 'be', 'a', 'quick@@', 'ly', 'on', 'what', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:23:40,423 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:23:40,427 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:23:40,430 - INFO - joeynmt.training - 	Hypothesis: The next slide that I will show you a very quickly going to be a quickly on what happened in the last 25 years.
2024-05-28 12:23:43,179 - INFO - joeynmt.training - Epoch   9, Step:    33600, Batch Loss:     1.882511, Batch Acc: 0.519409, Tokens per Sec:    23487, Lr: 0.000300
2024-05-28 12:23:45,921 - INFO - joeynmt.training - Epoch   9, Step:    33700, Batch Loss:     1.543885, Batch Acc: 0.517926, Tokens per Sec:    25136, Lr: 0.000300
2024-05-28 12:23:48,635 - INFO - joeynmt.training - Epoch   9, Step:    33800, Batch Loss:     1.866281, Batch Acc: 0.520832, Tokens per Sec:    24230, Lr: 0.000300
2024-05-28 12:23:51,368 - INFO - joeynmt.training - Epoch   9, Step:    33900, Batch Loss:     1.646373, Batch Acc: 0.519455, Tokens per Sec:    24845, Lr: 0.000300
2024-05-28 12:23:54,139 - INFO - joeynmt.training - Epoch   9, Step:    34000, Batch Loss:     1.690657, Batch Acc: 0.515897, Tokens per Sec:    24544, Lr: 0.000300
2024-05-28 12:23:54,144 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:23:54,147 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:24:01,480 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.57, acc:   0.49, generation: 7.3137[sec], evaluation: 0.0000[sec]
2024-05-28 12:24:01,484 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:24:01,653 - INFO - joeynmt.helpers - delete models/bpe-vocab/31500.ckpt
2024-05-28 12:24:01,657 - INFO - joeynmt.training - Example #0
2024-05-28 12:24:01,661 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:24:01,661 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:24:01,661 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'showed', 'these', 'two', 'di@@', 'a@@', 'wa@@', 'y@@', 'ed', 'to', 'demonstr@@', 'ate', 'that', 'the', 'pol@@', 'ice', 'to', 'show', 'that', 'pol@@', 'ice', 'that', 'in', 'the', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'was', 'the', 'size', 'of', 'the', 'size', 'of', '4@@', '8', 'percent', 'of', 'the', 'size', 'of', 'the', 'mar@@', 'ch', 'of', 'the', 'mar@@', 'ch', 'of', 'the', 'mar@@', 'ch', 'of', 'the', 'mar@@', 'ch', 'of', 'the', 'two', 'percent', 'of', 'the', 'year.', '</s>']
2024-05-28 12:24:01,662 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:24:01,665 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:24:01,669 - INFO - joeynmt.training - 	Hypothesis: And the year we showed these two diawayed to demonstrate that the police to show that police that in the most of the last three million years was the size of the size of 48 percent of the size of the march of the march of the march of the march of the two percent of the year.
2024-05-28 12:24:01,672 - INFO - joeynmt.training - Example #1
2024-05-28 12:24:01,675 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:24:01,675 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:24:01,675 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ity', 'is', 'seri@@', 'ous', 'seri@@', 'ous', 'because', 'it', "doesn't", 'show', 'the', 'black', 'hol@@', 'e.', '</s>']
2024-05-28 12:24:01,676 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:24:01,679 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:24:01,682 - INFO - joeynmt.training - 	Hypothesis: But this mornity is serious serious because it doesn't show the black hole.
2024-05-28 12:24:01,685 - INFO - joeynmt.training - Example #2
2024-05-28 12:24:01,688 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:24:01,688 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:24:01,689 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is', 'a', 'way', 'of', 'the', 'heart', 'of', 'the', 'climate', 'that', 'is', 'the', 'global', 'system@@', ',', 'which', 'is', 'the', 'global', 'system@@', '.', '</s>']
2024-05-28 12:24:01,689 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:24:01,692 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:24:01,695 - INFO - joeynmt.training - 	Hypothesis: The police is a way of the heart of the climate that is the global system, which is the global system.
2024-05-28 12:24:01,698 - INFO - joeynmt.training - Example #3
2024-05-28 12:24:01,701 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:24:01,701 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:24:01,701 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'goes', 'on', 'and', 'the', 'ex@@', 'ten@@', 'sion', 'and', 'the', 'contr@@', 'ac@@', 'ting', 'the', 'se@@', 'ven@@', '.', '</s>']
2024-05-28 12:24:01,702 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:24:01,705 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:24:01,708 - INFO - joeynmt.training - 	Hypothesis: It goes on and the extension and the contracting the seven.
2024-05-28 12:24:01,714 - INFO - joeynmt.training - Example #4
2024-05-28 12:24:01,746 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:24:01,746 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:24:01,746 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'that', "I'm", 'going', 'to', 'show', 'you', 'a', 'quick@@', 'ly', 'will', 'show', 'you', 'a', 'quick@@', 'ly', 'about', 'what', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:24:01,746 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:24:01,750 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:24:01,753 - INFO - joeynmt.training - 	Hypothesis: The next slide that I'm going to show you a quickly will show you a quickly about what happened in the last 25 years.
2024-05-28 12:24:04,529 - INFO - joeynmt.training - Epoch   9, Step:    34100, Batch Loss:     1.712154, Batch Acc: 0.519655, Tokens per Sec:    22651, Lr: 0.000300
2024-05-28 12:24:07,303 - INFO - joeynmt.training - Epoch   9, Step:    34200, Batch Loss:     1.696287, Batch Acc: 0.519420, Tokens per Sec:    25106, Lr: 0.000300
2024-05-28 12:24:10,053 - INFO - joeynmt.training - Epoch   9, Step:    34300, Batch Loss:     1.748344, Batch Acc: 0.527591, Tokens per Sec:    25248, Lr: 0.000300
2024-05-28 12:24:12,800 - INFO - joeynmt.training - Epoch   9, Step:    34400, Batch Loss:     1.759949, Batch Acc: 0.521947, Tokens per Sec:    25042, Lr: 0.000300
2024-05-28 12:24:15,537 - INFO - joeynmt.training - Epoch   9, Step:    34500, Batch Loss:     1.796363, Batch Acc: 0.518141, Tokens per Sec:    24663, Lr: 0.000300
2024-05-28 12:24:15,541 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:24:15,544 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:24:22,174 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.87, ppl:   6.50, acc:   0.50, generation: 6.5900[sec], evaluation: 0.0000[sec]
2024-05-28 12:24:22,178 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:24:22,268 - INFO - joeynmt.helpers - delete models/bpe-vocab/31000.ckpt
2024-05-28 12:24:22,284 - INFO - joeynmt.training - Example #0
2024-05-28 12:24:22,287 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:24:22,287 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:24:22,287 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'last', 'year,', 'we', 'showed', 'these', 'two', 'two', 'di@@', 'am@@', 'on@@', 'd@@', 'ance', 'to', 'demonstr@@', 'ate', 'that', 'pol@@', 'ar', 'pol@@', 'ar', 'that', 'was', 'the', 'pol@@', 'ice', 'that', 'the', 'ma@@', 'in', 'was', 'the', 'size', 'of', 'the', 'last', 'three', 'million', 'years', 'ago', 'was', 'a', 'little', 'size', 'of', 'a', 'small', 'mar@@', 'ch', 'of', 'the', 'mar@@', 'ine', 'of', '4@@', '0@@', '-@@', 'percent', 'of', 'it.', '</s>']
2024-05-28 12:24:22,288 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:24:22,291 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:24:22,294 - INFO - joeynmt.training - 	Hypothesis: And last year, we showed these two two diamondance to demonstrate that polar polar that was the police that the main was the size of the last three million years ago was a little size of a small march of the marine of 40-percent of it.
2024-05-28 12:24:22,297 - INFO - joeynmt.training - Example #1
2024-05-28 12:24:22,301 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:24:22,301 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:24:22,301 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'mor@@', 'n@@', 'ing,', 'because', 'of', 'this', 'speci@@', 'fic', 'issu@@', 'e', 'because', 'it', "doesn't", 'show', 'the', 'gr@@', 'os@@', 's.', '</s>']
2024-05-28 12:24:22,301 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:24:22,305 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:24:22,307 - INFO - joeynmt.training - 	Hypothesis: But this mormorning, because of this specific issue because it doesn't show the gross.
2024-05-28 12:24:22,310 - INFO - joeynmt.training - Example #2
2024-05-28 12:24:22,314 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:24:22,314 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:24:22,314 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ice', 'is', 'in', 'a', 'way', 'of', 'the', 'body', 'that', 'the', 'heart', 'of', 'the', 'climate', 'system@@', ',', 'the', 'global', 'system@@', '.', '</s>']
2024-05-28 12:24:22,314 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:24:22,317 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:24:22,320 - INFO - joeynmt.training - 	Hypothesis: The police is in a way of the body that the heart of the climate system, the global system.
2024-05-28 12:24:22,323 - INFO - joeynmt.training - Example #3
2024-05-28 12:24:22,325 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:24:22,326 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:24:22,326 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'ex@@', 'ten@@', 'ded', 'to', 'the', 'top', 'and', 'the', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 12:24:22,326 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:24:22,329 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:24:22,332 - INFO - joeynmt.training - 	Hypothesis: It was extended to the top and the contract.
2024-05-28 12:24:22,336 - INFO - joeynmt.training - Example #4
2024-05-28 12:24:22,362 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:24:22,362 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:24:22,362 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'that', 'I', 'will', 'show', 'you', 'is', 'going', 'to', 'be', 'a', 'quick@@', 'ly', 'quick@@', 'ly', 'on', 'what', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:24:22,362 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:24:22,366 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:24:22,369 - INFO - joeynmt.training - 	Hypothesis: The next slide that I will show you is going to be a quickly quickly on what happened in the last 25 years.
2024-05-28 12:24:25,097 - INFO - joeynmt.training - Epoch   9, Step:    34600, Batch Loss:     1.632714, Batch Acc: 0.515613, Tokens per Sec:    23256, Lr: 0.000300
2024-05-28 12:24:27,853 - INFO - joeynmt.training - Epoch   9, Step:    34700, Batch Loss:     1.844001, Batch Acc: 0.521211, Tokens per Sec:    24996, Lr: 0.000300
2024-05-28 12:24:30,627 - INFO - joeynmt.training - Epoch   9, Step:    34800, Batch Loss:     1.790260, Batch Acc: 0.518615, Tokens per Sec:    25037, Lr: 0.000300
2024-05-28 12:24:33,389 - INFO - joeynmt.training - Epoch   9, Step:    34900, Batch Loss:     1.734373, Batch Acc: 0.514718, Tokens per Sec:    25335, Lr: 0.000300
2024-05-28 12:24:36,229 - INFO - joeynmt.training - Epoch   9, Step:    35000, Batch Loss:     1.730302, Batch Acc: 0.522397, Tokens per Sec:    24182, Lr: 0.000300
2024-05-28 12:24:36,262 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:24:36,266 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:24:42,458 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.86, ppl:   6.43, acc:   0.50, generation: 6.1743[sec], evaluation: 0.0000[sec]
2024-05-28 12:24:42,462 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:24:42,544 - INFO - joeynmt.helpers - delete models/bpe-vocab/32500.ckpt
2024-05-28 12:24:42,556 - INFO - joeynmt.training - Example #0
2024-05-28 12:24:42,560 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:24:42,560 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:24:42,560 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'showed', 'these', 'two', 'di@@', 'et@@', 'ers', 'to', 'show', 'that', 'two', 'di@@', 'et', 'to', 'demonstr@@', 'ate', 'that', 'pol@@', 'ar', 'pol@@', 'ar', 'that', 'the', 'big', 'pol@@', 'ar', 'that', 'the', 'mo@@', 'on', 'the', 'last', 'three', 'million', 'years', 'was', 'the', 'size', 'of', 'the', 'big', 'si@@', 'on,', '</s>']
2024-05-28 12:24:42,561 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:24:42,564 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:24:42,566 - INFO - joeynmt.training - 	Hypothesis: And the year we showed these two dieters to show that two diet to demonstrate that polar polar that the big polar that the moon the last three million years was the size of the big sion,
2024-05-28 12:24:42,569 - INFO - joeynmt.training - Example #1
2024-05-28 12:24:42,572 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:24:42,572 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:24:42,572 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'ning', 'is', 'seri@@', 'ous', 'seri@@', 'ous', 'issu@@', 'e', 'because', 'it', "doesn't", 'show', 'the', 'size', 'of', 'the', 'black', 'bo@@', 'x@@', '.', '</s>']
2024-05-28 12:24:42,572 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:24:42,575 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:24:42,578 - INFO - joeynmt.training - 	Hypothesis: But this morning is serious serious issue because it doesn't show the size of the black box.
2024-05-28 12:24:42,581 - INFO - joeynmt.training - Example #2
2024-05-28 12:24:42,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:24:42,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:24:42,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'pol@@', 'ar', 'is', 'in', 'a', 'way,', 'the', 'heart', 'of', 'the', 'climate', 'system@@', ',', 'the', 'global', 'system@@', '.', '</s>']
2024-05-28 12:24:42,602 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:24:42,605 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:24:42,607 - INFO - joeynmt.training - 	Hypothesis: The polar polar is in a way, the heart of the climate system, the global system.
2024-05-28 12:24:42,610 - INFO - joeynmt.training - Example #3
2024-05-28 12:24:42,613 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:24:42,613 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:24:42,614 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'is', 'ex@@', 'pan@@', 'ded', 'to', 'the', 'w@@', 'ind', 'and', 'the', 'f@@', 'ear', 'and', 'the', 'f@@', 'ear', 'and', 'the', 'f@@', 'ear', 'of', 'the', 'w@@', 'inter@@', '.', '</s>']
2024-05-28 12:24:42,614 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:24:42,617 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:24:42,620 - INFO - joeynmt.training - 	Hypothesis: It is expanded to the wind and the fear and the fear and the fear of the winter.
2024-05-28 12:24:42,623 - INFO - joeynmt.training - Example #4
2024-05-28 12:24:42,626 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:24:42,626 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:24:42,626 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'that', 'I', 'will', 'show', 'you', 'will', 'show', 'it', 'a', 'quick@@', 'ly', 'sli@@', 'ght@@', 'ly', 'quick@@', 'ly', 'on', 'what', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:24:42,626 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:24:42,629 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:24:42,632 - INFO - joeynmt.training - 	Hypothesis: The next slide that I will show you will show it a quickly slightly quickly on what happened in the last 25 years.
2024-05-28 12:24:45,403 - INFO - joeynmt.training - Epoch   9, Step:    35100, Batch Loss:     1.936962, Batch Acc: 0.523467, Tokens per Sec:    23412, Lr: 0.000300
2024-05-28 12:24:48,174 - INFO - joeynmt.training - Epoch   9, Step:    35200, Batch Loss:     1.624143, Batch Acc: 0.518849, Tokens per Sec:    25145, Lr: 0.000300
2024-05-28 12:24:48,456 - INFO - joeynmt.training - Epoch   9: total training loss 6802.87
2024-05-28 12:24:48,460 - INFO - joeynmt.training - EPOCH 10
2024-05-28 12:24:50,929 - INFO - joeynmt.training - Epoch  10, Step:    35300, Batch Loss:     1.594816, Batch Acc: 0.543308, Tokens per Sec:    24907, Lr: 0.000300
2024-05-28 12:24:53,718 - INFO - joeynmt.training - Epoch  10, Step:    35400, Batch Loss:     1.418517, Batch Acc: 0.543817, Tokens per Sec:    25213, Lr: 0.000300
2024-05-28 12:24:56,468 - INFO - joeynmt.training - Epoch  10, Step:    35500, Batch Loss:     1.481801, Batch Acc: 0.536532, Tokens per Sec:    24917, Lr: 0.000300
2024-05-28 12:24:56,473 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:24:56,476 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:25:03,450 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.86, ppl:   6.42, acc:   0.50, generation: 6.9547[sec], evaluation: 0.0000[sec]
2024-05-28 12:25:03,454 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:25:03,546 - INFO - joeynmt.helpers - delete models/bpe-vocab/33000.ckpt
2024-05-28 12:25:03,559 - INFO - joeynmt.training - Example #0
2024-05-28 12:25:03,562 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:25:03,563 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:25:03,563 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'showed', 'these', 'two', 'di@@', 'ed', 'pos@@', 'itive', 'de@@', 'ep', 'to', 'demonstr@@', 'ate', 'that', 'pol@@', 'ar', 'pol@@', 'ar', 'that', 'the', 'ma@@', 'in', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'size', 'of', 'the', 'mar@@', 'ine', 'of', 'the', 'mar@@', 'ine', 'of', 'the', 'mar@@', 'ine', 'of', 'the', 'mar@@', 'ine', 'of', 'the', 'mar@@', 'vel@@', 'ous', 'state', 'of', '40', 'percent', '</s>']
2024-05-28 12:25:03,563 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:25:03,566 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:25:03,570 - INFO - joeynmt.training - 	Hypothesis: And the year we showed these two died positive deep to demonstrate that polar polar that the main the last three million years of the last three million years of the size of the marine of the marine of the marine of the marine of the marvelous state of 40 percent
2024-05-28 12:25:03,573 - INFO - joeynmt.training - Example #1
2024-05-28 12:25:03,576 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:25:03,576 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:25:03,576 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'seri@@', 'ous', 'seri@@', 'ous', 'issu@@', 'e', 'because', 'it', "doesn't", 'look', 'at', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'gu@@', 'y.', '</s>']
2024-05-28 12:25:03,576 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:25:03,579 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:25:03,610 - INFO - joeynmt.training - 	Hypothesis: But this is the serious serious issue because it doesn't look at the gross of the guy.
2024-05-28 12:25:03,613 - INFO - joeynmt.training - Example #2
2024-05-28 12:25:03,616 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:25:03,616 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:25:03,616 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'pol@@', 'ar', 'is', 'in', 'a', 'way,', 'the', 'heart', 'of', 'the', 'global', 'system', 'that', 'was', 'the', 'global', 'system', 'that', 'was', 'the', 'global', 'system@@', '.', '</s>']
2024-05-28 12:25:03,616 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:25:03,620 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:25:03,623 - INFO - joeynmt.training - 	Hypothesis: The polar polar is in a way, the heart of the global system that was the global system that was the global system.
2024-05-28 12:25:03,626 - INFO - joeynmt.training - Example #3
2024-05-28 12:25:03,630 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:25:03,630 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:25:03,630 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'exp@@', 'and@@', 'ing', 'the', 'w@@', 'o@@', 'und', 'and', 'contr@@', 'ac@@', 'tion', 'is', 'the', 'w@@', 'ind', 'and', 'the', 'f@@', 'ear', 'of', 'the', 'w@@', 'aste', 'of', 'the', 'w@@', 'oo@@', 'd.', '</s>']
2024-05-28 12:25:03,630 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:25:03,633 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:25:03,638 - INFO - joeynmt.training - 	Hypothesis: She expanding the wound and contraction is the wind and the fear of the waste of the wood.
2024-05-28 12:25:03,641 - INFO - joeynmt.training - Example #4
2024-05-28 12:25:03,644 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:25:03,644 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:25:03,644 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'I', 'will', 'show', 'you', 'a', 'very', 'quick@@', 'ly', 'will', 'show', 'you', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:25:03,644 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:25:03,647 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:25:03,651 - INFO - joeynmt.training - 	Hypothesis: The next slide I will show you a very quickly will show you the last 25 years.
2024-05-28 12:25:06,399 - INFO - joeynmt.training - Epoch  10, Step:    35600, Batch Loss:     1.639426, Batch Acc: 0.535921, Tokens per Sec:    22437, Lr: 0.000300
2024-05-28 12:25:09,152 - INFO - joeynmt.training - Epoch  10, Step:    35700, Batch Loss:     1.627773, Batch Acc: 0.541568, Tokens per Sec:    24715, Lr: 0.000300
2024-05-28 12:25:11,909 - INFO - joeynmt.training - Epoch  10, Step:    35800, Batch Loss:     1.655738, Batch Acc: 0.539800, Tokens per Sec:    24993, Lr: 0.000300
2024-05-28 12:25:14,665 - INFO - joeynmt.training - Epoch  10, Step:    35900, Batch Loss:     1.624114, Batch Acc: 0.542169, Tokens per Sec:    25484, Lr: 0.000300
2024-05-28 12:25:17,436 - INFO - joeynmt.training - Epoch  10, Step:    36000, Batch Loss:     1.565755, Batch Acc: 0.536711, Tokens per Sec:    25411, Lr: 0.000300
2024-05-28 12:25:17,440 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:25:17,443 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:25:24,059 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.87, ppl:   6.46, acc:   0.50, generation: 6.5984[sec], evaluation: 0.0000[sec]
2024-05-28 12:25:24,141 - INFO - joeynmt.helpers - delete models/bpe-vocab/33500.ckpt
2024-05-28 12:25:24,146 - INFO - joeynmt.training - Example #0
2024-05-28 12:25:24,150 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:25:24,150 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:25:24,150 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'last', 'year,', 'we', 'showed', 'these', 'two', 'di@@', 'am@@', 'e@@', 'te@@', 'red', 'to', 'demonstr@@', 'ate', 'that', 'pol@@', 'ar', 'pol@@', 'ar', 'in', 'the', 'pol@@', 'ar', 'pol@@', 'ar', 'that', 'the', 'ma@@', 'in', 'of', 'the', 'last', 'three', 'million', 'years', 'was', 'the', 'size', 'of', 'the', 'big', 'size', 'of', '4@@', '8', 'years', 'ago.', '</s>']
2024-05-28 12:25:24,150 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:25:24,153 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:25:24,156 - INFO - joeynmt.training - 	Hypothesis: The last year, we showed these two diametered to demonstrate that polar polar in the polar polar that the main of the last three million years was the size of the big size of 48 years ago.
2024-05-28 12:25:24,159 - INFO - joeynmt.training - Example #1
2024-05-28 12:25:24,163 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:25:24,163 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:25:24,163 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ity', 'is', 'seri@@', 'ous', 'seri@@', 'ous', 'because', 'it', "doesn't", 'look', 'the', 'size', 'of', 'the', 'sea@@', '.', '</s>']
2024-05-28 12:25:24,163 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:25:24,166 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:25:24,169 - INFO - joeynmt.training - 	Hypothesis: But this mornity is serious serious because it doesn't look the size of the sea.
2024-05-28 12:25:24,172 - INFO - joeynmt.training - Example #2
2024-05-28 12:25:24,175 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:25:24,175 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:25:24,175 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'pol@@', 'ar', 'is', 'in', 'a', 'way,', 'the', 'heart', 'of', 'the', 'global', 'system', 'that', 'is', 'the', 'global', 'climate', 'system@@', '.', '</s>']
2024-05-28 12:25:24,176 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:25:24,205 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:25:24,209 - INFO - joeynmt.training - 	Hypothesis: The polar polar is in a way, the heart of the global system that is the global climate system.
2024-05-28 12:25:24,212 - INFO - joeynmt.training - Example #3
2024-05-28 12:25:24,215 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:25:24,215 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:25:24,215 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'was', 'ex@@', 'ten@@', 'ded', 'to', 'the', 'w@@', 'aste', 'and', 'the', 'f@@', 'ear', 'and', 'the', 'f@@', 'ear', 'and', 'the', 'f@@', 'ear', 'of', 'the', 'w@@', 'aste', 'of', 'the', 'w@@', 'oo@@', 'den', 'is', 'ex@@', 'ten@@', 'ded', 'by', 'the', 'w@@', 'oo@@', 'den', 'of', 'w@@', 'oo@@', 'd.', '</s>']
2024-05-28 12:25:24,216 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:25:24,219 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:25:24,222 - INFO - joeynmt.training - 	Hypothesis: She was extended to the waste and the fear and the fear and the fear of the waste of the wooden is extended by the wooden of wood.
2024-05-28 12:25:24,225 - INFO - joeynmt.training - Example #4
2024-05-28 12:25:24,228 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:25:24,228 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:25:24,228 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'that', "I'm", 'going', 'to', 'show', 'you', 'is', 'going', 'to', 'be', 'a', 'very', 'quick@@', 'ly', 'on', 'what', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:25:24,229 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:25:24,232 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:25:24,235 - INFO - joeynmt.training - 	Hypothesis: The next slide that I'm going to show you is going to be a very quickly on what happened in the last 25 years.
2024-05-28 12:25:26,957 - INFO - joeynmt.training - Epoch  10, Step:    36100, Batch Loss:     1.787586, Batch Acc: 0.535700, Tokens per Sec:    23149, Lr: 0.000300
2024-05-28 12:25:29,701 - INFO - joeynmt.training - Epoch  10, Step:    36200, Batch Loss:     1.639089, Batch Acc: 0.536383, Tokens per Sec:    25387, Lr: 0.000300
2024-05-28 12:25:32,441 - INFO - joeynmt.training - Epoch  10, Step:    36300, Batch Loss:     1.679639, Batch Acc: 0.534954, Tokens per Sec:    25790, Lr: 0.000300
2024-05-28 12:25:35,155 - INFO - joeynmt.training - Epoch  10, Step:    36400, Batch Loss:     1.651771, Batch Acc: 0.537351, Tokens per Sec:    24705, Lr: 0.000300
2024-05-28 12:25:37,898 - INFO - joeynmt.training - Epoch  10, Step:    36500, Batch Loss:     1.785072, Batch Acc: 0.531873, Tokens per Sec:    24735, Lr: 0.000300
2024-05-28 12:25:37,921 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:25:37,926 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:25:44,295 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.86, ppl:   6.43, acc:   0.50, generation: 6.3489[sec], evaluation: 0.0000[sec]
2024-05-28 12:25:44,381 - INFO - joeynmt.helpers - delete models/bpe-vocab/34000.ckpt
2024-05-28 12:25:44,386 - INFO - joeynmt.training - Example #0
2024-05-28 12:25:44,389 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:25:44,389 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:25:44,389 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'at', 'the', 'year', 'I', 'showed', 'these', 'two', 'di@@', 'es@@', ':', 'that', 'was', 'to', 'demonstr@@', 'ate', 'that', 'pol@@', 'ar', 'pol@@', 'ar', 'in', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'mar@@', 'ine', 'stat@@', 'es', 'of', 'the', 'mar@@', 'ine', 'of', 'the', 'mar@@', 'ine', 'of', 'the', 'mar@@', 'ine', 'in', 'the', 'time.', '</s>']
2024-05-28 12:25:44,390 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:25:44,393 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:25:44,396 - INFO - joeynmt.training - 	Hypothesis: And at the year I showed these two dies: that was to demonstrate that polar polar in the last three million years of the last three million years of the last three million years of marine states of the marine of the marine of the marine in the time.
2024-05-28 12:25:44,399 - INFO - joeynmt.training - Example #1
2024-05-28 12:25:44,402 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:25:44,402 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:25:44,402 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ity', 'is', 'seri@@', 'ous', 'seri@@', 'ous', 'issu@@', 'e', 'because', 'it', "doesn't", 'look', 'at', 'the', 'black', 'of', 'the', 'black', 'bo@@', 'x@@', '.', '</s>']
2024-05-28 12:25:44,403 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:25:44,406 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:25:44,409 - INFO - joeynmt.training - 	Hypothesis: But this mornity is serious serious issue because it doesn't look at the black of the black box.
2024-05-28 12:25:44,412 - INFO - joeynmt.training - Example #2
2024-05-28 12:25:44,414 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:25:44,415 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:25:44,415 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'one', 'way,', 'the', 'heart', 'is', 'a', 'way', 'that', 'the', 'climate', 'system', 'of', 'global', 'climate', 'system@@', '.', '</s>']
2024-05-28 12:25:44,415 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:25:44,418 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:25:44,420 - INFO - joeynmt.training - 	Hypothesis: The polar one way, the heart is a way that the climate system of global climate system.
2024-05-28 12:25:44,441 - INFO - joeynmt.training - Example #3
2024-05-28 12:25:44,444 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:25:44,444 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:25:44,444 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'goes', 'to', 'the', 'w@@', 'ind', 'and', 'the', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 12:25:44,445 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:25:44,447 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:25:44,450 - INFO - joeynmt.training - 	Hypothesis: It goes to the wind and the contract.
2024-05-28 12:25:44,454 - INFO - joeynmt.training - Example #4
2024-05-28 12:25:44,457 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:25:44,457 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:25:44,457 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'thing', 'I', 'will', 'show', 'you', 'is', 'going', 'to', 'show', 'you', 'is', 'going', 'to', 'be', 'a', 'very', 'quick@@', 'ly', 'about', '25', 'years.', '</s>']
2024-05-28 12:25:44,457 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:25:44,460 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:25:44,466 - INFO - joeynmt.training - 	Hypothesis: The next thing I will show you is going to show you is going to be a very quickly about 25 years.
2024-05-28 12:25:47,272 - INFO - joeynmt.training - Epoch  10, Step:    36600, Batch Loss:     1.492798, Batch Acc: 0.529580, Tokens per Sec:    23094, Lr: 0.000300
2024-05-28 12:25:50,039 - INFO - joeynmt.training - Epoch  10, Step:    36700, Batch Loss:     1.579194, Batch Acc: 0.536152, Tokens per Sec:    25212, Lr: 0.000300
2024-05-28 12:25:52,801 - INFO - joeynmt.training - Epoch  10, Step:    36800, Batch Loss:     1.693721, Batch Acc: 0.532983, Tokens per Sec:    25077, Lr: 0.000300
2024-05-28 12:25:55,561 - INFO - joeynmt.training - Epoch  10, Step:    36900, Batch Loss:     1.672675, Batch Acc: 0.529907, Tokens per Sec:    24841, Lr: 0.000300
2024-05-28 12:25:58,294 - INFO - joeynmt.training - Epoch  10, Step:    37000, Batch Loss:     1.670713, Batch Acc: 0.532256, Tokens per Sec:    24947, Lr: 0.000300
2024-05-28 12:25:58,312 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:25:58,315 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:26:04,818 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.86, ppl:   6.42, acc:   0.50, generation: 6.4841[sec], evaluation: 0.0000[sec]
2024-05-28 12:26:04,902 - INFO - joeynmt.helpers - delete models/bpe-vocab/34500.ckpt
2024-05-28 12:26:04,914 - INFO - joeynmt.training - Example #0
2024-05-28 12:26:04,918 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:26:04,918 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:26:04,918 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'put', 'these', 'two', 'di@@', 'a@@', 'un@@', 't', 'di@@', 'a@@', "'s", 'entire', 'pol@@', 'ar', 'pol@@', 'ar', 'that', 'was', 'the', 'cr@@', 'os@@', 's', 'that', 'in', 'the', 'last', 'three', 'million', 'years', 'was', 'the', 'size', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'mar@@', 'ri@@', 'age', 'of', 'mar@@', 'ching', 'for', '40', 'percent', 'of', 'the', 'mar@@', 'im@@', 'medi@@', 'ately', '4@@', '0@@', '-@@', 'percent', 'of', 'the', 'mar@@', 'ch@@', 'ance', 'of', 'it.', '</s>']
2024-05-28 12:26:04,918 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:26:04,922 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:26:04,925 - INFO - joeynmt.training - 	Hypothesis: And the year we put these two diaunt dia's entire polar polar that was the cross that in the last three million years was the size of the last three million years of marriage of marching for 40 percent of the marimmediately 40-percent of the marchance of it.
2024-05-28 12:26:04,928 - INFO - joeynmt.training - Example #1
2024-05-28 12:26:04,931 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:26:04,931 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:26:04,931 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'seri@@', 'ous', 'mor@@', 'n@@', 'ity', 'of', 'this', 'speci@@', 'fic', 'issu@@', 'e', 'because', 'it', "doesn't", 'look', 'at', 'the', 'black', 'bo@@', 'x@@', '.', '</s>']
2024-05-28 12:26:04,931 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:26:04,935 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:26:04,938 - INFO - joeynmt.training - 	Hypothesis: But this is serious mornity of this specific issue because it doesn't look at the black box.
2024-05-28 12:26:04,941 - INFO - joeynmt.training - Example #2
2024-05-28 12:26:04,945 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:26:04,945 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:26:04,945 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'pol@@', 'ar', 'is', 'in', 'a', 'way,', 'the', 'heart', 'of', 'global', 'climate', 'system@@', '.', '</s>']
2024-05-28 12:26:04,945 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:26:04,948 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:26:05,001 - INFO - joeynmt.training - 	Hypothesis: The polar polar is in a way, the heart of global climate system.
2024-05-28 12:26:05,006 - INFO - joeynmt.training - Example #3
2024-05-28 12:26:05,010 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:26:05,010 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:26:05,010 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'is', 'ex@@', 'ten@@', 'ded', 'the', 'w@@', 'aste', 'and', 'the', 'f@@', 'ear', 'and', 'the', 'f@@', 'ear', 'of', 'the', 'sum@@', 'mer@@', '.', '</s>']
2024-05-28 12:26:05,010 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:26:05,013 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:26:05,016 - INFO - joeynmt.training - 	Hypothesis: It is extended the waste and the fear and the fear of the summer.
2024-05-28 12:26:05,021 - INFO - joeynmt.training - Example #4
2024-05-28 12:26:05,024 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:26:05,024 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:26:05,024 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'that', "I'm", 'going', 'to', 'show', 'you', 'about', 'what', 'was', 'going', 'to', 'be', 'a', 'very', 'quick@@', 'ly', 'about', '25', 'years.', '</s>']
2024-05-28 12:26:05,025 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:26:05,028 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:26:05,031 - INFO - joeynmt.training - 	Hypothesis: The next slide that I'm going to show you about what was going to be a very quickly about 25 years.
2024-05-28 12:26:07,813 - INFO - joeynmt.training - Epoch  10, Step:    37100, Batch Loss:     1.632935, Batch Acc: 0.528180, Tokens per Sec:    22855, Lr: 0.000300
2024-05-28 12:26:10,547 - INFO - joeynmt.training - Epoch  10, Step:    37200, Batch Loss:     1.737412, Batch Acc: 0.535936, Tokens per Sec:    24589, Lr: 0.000300
2024-05-28 12:26:13,315 - INFO - joeynmt.training - Epoch  10, Step:    37300, Batch Loss:     1.411765, Batch Acc: 0.533537, Tokens per Sec:    25368, Lr: 0.000300
2024-05-28 12:26:16,085 - INFO - joeynmt.training - Epoch  10, Step:    37400, Batch Loss:     1.700334, Batch Acc: 0.530285, Tokens per Sec:    24548, Lr: 0.000300
2024-05-28 12:26:18,839 - INFO - joeynmt.training - Epoch  10, Step:    37500, Batch Loss:     1.841836, Batch Acc: 0.533910, Tokens per Sec:    25233, Lr: 0.000300
2024-05-28 12:26:18,860 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:26:18,863 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:26:25,818 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.36, acc:   0.50, generation: 6.9368[sec], evaluation: 0.0000[sec]
2024-05-28 12:26:25,822 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:26:25,933 - INFO - joeynmt.helpers - delete models/bpe-vocab/36000.ckpt
2024-05-28 12:26:25,946 - INFO - joeynmt.training - Example #0
2024-05-28 12:26:25,949 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:26:25,949 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:26:25,949 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'we', 'showed', 'these', 'two', 'di@@', 'ap@@', 's', 'to', 'demonstr@@', 'ate', 'that', 'pol@@', 'ar', 'to', 'pro@@', 've', 'that', 'pol@@', 'ar', 'the', 'pol@@', 'ar', 'that', 'the', 'ma@@', 'in', 'the', 'last', 'three', 'million', 'years', 'was', 'the', 'size', 'of', '4@@', '8', 'million', 'years', 'ol@@', 'd,', 'it', 'was', 'gre@@', 'w', 'the', 'size', 'of', 'the', 'mar@@', 'ine', 'mar@@', 'ine', 'of', 'the', 'mar@@', 'ine', 'ma@@', 'y@@', 'be,', 'he', 'was', 'gre@@', 'w', 'up', 'with', '40', 'percent', '</s>']
2024-05-28 12:26:25,950 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:26:25,952 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:26:25,955 - INFO - joeynmt.training - 	Hypothesis: And the year we showed these two diaps to demonstrate that polar to prove that polar the polar that the main the last three million years was the size of 48 million years old, it was grew the size of the marine marine of the marine maybe, he was grew up with 40 percent
2024-05-28 12:26:25,958 - INFO - joeynmt.training - Example #1
2024-05-28 12:26:25,961 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:26:25,961 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:26:25,961 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ing,', 'this', 'is', 'seri@@', 'ous', 'issu@@', 'e', 'because', 'it', "doesn't", 'look', 'like', 'the', 'black', 'bo@@', 'x@@', 'es.', '</s>']
2024-05-28 12:26:25,962 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:26:25,964 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:26:26,014 - INFO - joeynmt.training - 	Hypothesis: But this morning, this is serious issue because it doesn't look like the black boxes.
2024-05-28 12:26:26,016 - INFO - joeynmt.training - Example #2
2024-05-28 12:26:26,019 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:26:26,019 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:26:26,019 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'pol@@', 'ar', 'is', 'in', 'a', 'way,', 'the', 'heart', 'of', 'the', 'global', 'climate', 'that', 'is', 'the', 'global', 'climate', 'of', 'the', 'global', 'system@@', '.', '</s>']
2024-05-28 12:26:26,020 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:26:26,023 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:26:26,026 - INFO - joeynmt.training - 	Hypothesis: The polar polar is in a way, the heart of the global climate that is the global climate of the global system.
2024-05-28 12:26:26,029 - INFO - joeynmt.training - Example #3
2024-05-28 12:26:26,032 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:26:26,033 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:26:26,033 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'goes', 'back', 'to', 'the', 'w@@', 'ood', 'and', 'contr@@', 'ac@@', 'ts', 'and', 'they', 'are', 'contr@@', 'ac@@', 'ting', 'to', 'the', 'sum@@', 'm@@', 'er', 'on', 'the', 'sum@@', 'mer@@', '.', '</s>']
2024-05-28 12:26:26,033 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:26:26,036 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:26:26,039 - INFO - joeynmt.training - 	Hypothesis: It goes back to the wood and contracts and they are contracting to the summer on the summer.
2024-05-28 12:26:26,043 - INFO - joeynmt.training - Example #4
2024-05-28 12:26:26,046 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:26:26,046 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:26:26,046 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'that', "I'm", 'going', 'to', 'show', 'you', 'will', 'show', 'you', 'a', 'very', 'quick@@', 'ly', 'on', 'what', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:26:26,046 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:26:26,049 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:26:26,052 - INFO - joeynmt.training - 	Hypothesis: The next slide that I'm going to show you will show you a very quickly on what happened in the last 25 years.
2024-05-28 12:26:28,806 - INFO - joeynmt.training - Epoch  10, Step:    37600, Batch Loss:     1.593248, Batch Acc: 0.533217, Tokens per Sec:    22738, Lr: 0.000300
2024-05-28 12:26:31,549 - INFO - joeynmt.training - Epoch  10, Step:    37700, Batch Loss:     1.644283, Batch Acc: 0.531669, Tokens per Sec:    25269, Lr: 0.000300
2024-05-28 12:26:34,272 - INFO - joeynmt.training - Epoch  10, Step:    37800, Batch Loss:     1.468809, Batch Acc: 0.529740, Tokens per Sec:    24796, Lr: 0.000300
2024-05-28 12:26:37,010 - INFO - joeynmt.training - Epoch  10, Step:    37900, Batch Loss:     1.769433, Batch Acc: 0.529854, Tokens per Sec:    25009, Lr: 0.000300
2024-05-28 12:26:39,739 - INFO - joeynmt.training - Epoch  10, Step:    38000, Batch Loss:     1.856457, Batch Acc: 0.529209, Tokens per Sec:    24718, Lr: 0.000300
2024-05-28 12:26:39,743 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:26:39,747 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:26:46,412 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.34, acc:   0.50, generation: 6.6470[sec], evaluation: 0.0000[sec]
2024-05-28 12:26:46,416 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:26:46,501 - INFO - joeynmt.helpers - delete models/bpe-vocab/35000.ckpt
2024-05-28 12:26:46,513 - INFO - joeynmt.training - Example #0
2024-05-28 12:26:46,517 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:26:46,517 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:26:46,517 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'have', 'thro@@', 'wn', 'these', 'two', 'di@@', 'ap@@', 'h@@', 'es@@', 'i@@', 'de', 'to', 'demonstr@@', 'ate', 'that', 'the', 'political', 'political', 'pol@@', 'ar', 'that', 'the', 'political', 'political', 'political', 'political', 'political', 'that', 'was', 'the', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'was', 'the', 'size', 'of', 'a', 'small', 'state', 'of', '4@@', '8', 'stat@@', 'es', 'of', 'the', 'mar@@', 'ch', 'of', '4@@', '0@@', '-@@', 'percent', 'of', 'the', 'year.', '</s>']
2024-05-28 12:26:46,517 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:26:46,521 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:26:46,524 - INFO - joeynmt.training - 	Hypothesis: I have thrown these two diapheside to demonstrate that the political political polar that the political political political political political that was the most of the last three million years was the size of a small state of 48 states of the march of 40-percent of the year.
2024-05-28 12:26:46,527 - INFO - joeynmt.training - Example #1
2024-05-28 12:26:46,531 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:26:46,531 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:26:46,531 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'ning', 'is', 'seri@@', 'ous', 'seri@@', 'ous', 'about', 'this', 'particular', 'issu@@', 'e', 'because', 'it', "doesn't", 'look', 'at', 'the', 'gr@@', 'os@@', 's', 'of', 'the', 'gu@@', 'y.', '</s>']
2024-05-28 12:26:46,532 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:26:46,535 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:26:46,540 - INFO - joeynmt.training - 	Hypothesis: But this morning is serious serious about this particular issue because it doesn't look at the gross of the guy.
2024-05-28 12:26:46,623 - INFO - joeynmt.training - Example #2
2024-05-28 12:26:46,626 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:26:46,626 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:26:46,626 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'pol@@', 'ar', 'is,', 'in', 'a', 'way,', 'the', 'heart', 'of', 'the', 'climate', 'system', 'that', 'has', 'the', 'global', 'climate', 'system@@', '.', '</s>']
2024-05-28 12:26:46,627 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:26:46,631 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:26:46,634 - INFO - joeynmt.training - 	Hypothesis: The polar polar is, in a way, the heart of the climate system that has the global climate system.
2024-05-28 12:26:46,637 - INFO - joeynmt.training - Example #3
2024-05-28 12:26:46,640 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:26:46,640 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:26:46,640 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['She', 'was', 'ex@@', 'ten@@', 'ded', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 12:26:46,641 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:26:46,644 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:26:46,647 - INFO - joeynmt.training - 	Hypothesis: She was extended and contract.
2024-05-28 12:26:46,650 - INFO - joeynmt.training - Example #4
2024-05-28 12:26:46,653 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:26:46,653 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:26:46,653 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'that', "I'm", 'going', 'to', 'show', 'you', 'a', 'quick@@', 'ly', 'ab@@', 'le@@', 'th@@', 'al', 'is', 'going', 'to', 'be', 'a', 'lot', 'of', 'years.', '</s>']
2024-05-28 12:26:46,654 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:26:46,656 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:26:46,660 - INFO - joeynmt.training - 	Hypothesis: The next slide that I'm going to show you a quickly ablethal is going to be a lot of years.
2024-05-28 12:26:49,377 - INFO - joeynmt.training - Epoch  10, Step:    38100, Batch Loss:     1.671096, Batch Acc: 0.522225, Tokens per Sec:    22286, Lr: 0.000300
2024-05-28 12:26:52,104 - INFO - joeynmt.training - Epoch  10, Step:    38200, Batch Loss:     1.657010, Batch Acc: 0.522532, Tokens per Sec:    25259, Lr: 0.000300
2024-05-28 12:26:54,841 - INFO - joeynmt.training - Epoch  10, Step:    38300, Batch Loss:     1.549786, Batch Acc: 0.524118, Tokens per Sec:    24575, Lr: 0.000300
2024-05-28 12:26:57,608 - INFO - joeynmt.training - Epoch  10, Step:    38400, Batch Loss:     1.727491, Batch Acc: 0.529213, Tokens per Sec:    25414, Lr: 0.000300
2024-05-28 12:27:00,381 - INFO - joeynmt.training - Epoch  10, Step:    38500, Batch Loss:     1.752631, Batch Acc: 0.531225, Tokens per Sec:    25401, Lr: 0.000300
2024-05-28 12:27:00,385 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:27:00,388 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:27:07,196 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.36, acc:   0.50, generation: 6.7898[sec], evaluation: 0.0000[sec]
2024-05-28 12:27:07,280 - INFO - joeynmt.helpers - delete models/bpe-vocab/36500.ckpt
2024-05-28 12:27:07,286 - INFO - joeynmt.training - Example #0
2024-05-28 12:27:07,289 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:27:07,289 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:27:07,289 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'went', 'to', 'the', 'next', 'two', 'sli@@', 'des', 'to', 'demonstr@@', 'ate', 'that', 'the', 'second', 'qu@@', 'o@@', 'te', 'pol@@', 'ar', 'pol@@', 'ar', 'that', 'in', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'was', 'the', 'size', 'of', 'the', 'last', '3@@', '0@@', '-@@', 'year', 'year', 'mar@@', 'ch', 'was', 'sm@@', 'all,', 'a', 'small', 'amount', 'of', 'mar@@', 'ch', 'in', 'the', 'mar@@', 'ch', 'of', '4@@', '0', 'percent', 'of', 'the', 'size', 'of', 'the', 'mar@@', 'ch', 'of', 'the', 'mag@@', 'n@@', 'itu@@', 'de', 'of', 'a', 'number', 'of', 'pos@@', 'itive', 'di@@', 'r@@', 'ty', 'percent', 'of', 'the', 'whole', 'r@@', 'ate', 'of', 'the', 'whole']
2024-05-28 12:27:07,290 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:27:07,293 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:27:07,297 - INFO - joeynmt.training - 	Hypothesis: And I went to the next two slides to demonstrate that the second quote polar polar that in the last three million years of the last three million years was the size of the last 30-year year march was small, a small amount of march in the march of 40 percent of the size of the march of the magnitude of a number of positive dirty percent of the whole rate of the whole
2024-05-28 12:27:07,301 - INFO - joeynmt.training - Example #1
2024-05-28 12:27:07,306 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:27:07,307 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:27:07,307 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'what', 'the', 'seri@@', 'ous', 'issu@@', 'e', 'of', 'this', 'particular', 'particular', 'issu@@', 'e', 'because', 'it', "doesn't", 'look', 'at', 'the', 'gu@@', 'ar@@', 'an@@', 'te@@', 's.', '</s>']
2024-05-28 12:27:07,307 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:27:07,310 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:27:07,313 - INFO - joeynmt.training - 	Hypothesis: But this is what the serious issue of this particular particular issue because it doesn't look at the guarantes.
2024-05-28 12:27:07,358 - INFO - joeynmt.training - Example #2
2024-05-28 12:27:07,361 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:27:07,361 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:27:07,361 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'pol@@', 'ar', 'is,', 'in', 'a', 'way,', 'the', 'heart', 'of', 'the', 'global', 'system', 'that', 'is', 'global', 'climate', 'system@@', '.', '</s>']
2024-05-28 12:27:07,361 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:27:07,365 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:27:07,369 - INFO - joeynmt.training - 	Hypothesis: The polar polar is, in a way, the heart of the global system that is global climate system.
2024-05-28 12:27:07,372 - INFO - joeynmt.training - Example #3
2024-05-28 12:27:07,375 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:27:07,375 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:27:07,375 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'goes', 'back', 'and', 'the', 'w@@', 'ide@@', 'r', 'and', 'contr@@', 'ac@@', 't.', '</s>']
2024-05-28 12:27:07,376 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:27:07,379 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:27:07,383 - INFO - joeynmt.training - 	Hypothesis: It goes back and the wider and contract.
2024-05-28 12:27:07,386 - INFO - joeynmt.training - Example #4
2024-05-28 12:27:07,407 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:27:07,407 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:27:07,407 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'that', "I'm", 'going', 'to', 'show', 'you', 'a', 'very', 'quick@@', 'ly', 'on', 'what', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:27:07,407 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:27:07,411 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:27:07,414 - INFO - joeynmt.training - 	Hypothesis: The next slide that I'm going to show you a very quickly on what happened in the last 25 years.
2024-05-28 12:27:10,169 - INFO - joeynmt.training - Epoch  10, Step:    38600, Batch Loss:     1.880257, Batch Acc: 0.533771, Tokens per Sec:    23472, Lr: 0.000300
2024-05-28 12:27:12,913 - INFO - joeynmt.training - Epoch  10, Step:    38700, Batch Loss:     1.730461, Batch Acc: 0.530633, Tokens per Sec:    25074, Lr: 0.000300
2024-05-28 12:27:15,654 - INFO - joeynmt.training - Epoch  10, Step:    38800, Batch Loss:     1.660129, Batch Acc: 0.531771, Tokens per Sec:    25296, Lr: 0.000300
2024-05-28 12:27:18,413 - INFO - joeynmt.training - Epoch  10, Step:    38900, Batch Loss:     1.884133, Batch Acc: 0.529473, Tokens per Sec:    25515, Lr: 0.000300
2024-05-28 12:27:21,182 - INFO - joeynmt.training - Epoch  10, Step:    39000, Batch Loss:     1.737282, Batch Acc: 0.529414, Tokens per Sec:    25479, Lr: 0.000300
2024-05-28 12:27:21,192 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:27:21,195 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:27:27,280 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.84, ppl:   6.29, acc:   0.50, generation: 6.0681[sec], evaluation: 0.0000[sec]
2024-05-28 12:27:27,285 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-28 12:27:27,375 - INFO - joeynmt.helpers - delete models/bpe-vocab/37000.ckpt
2024-05-28 12:27:27,381 - INFO - joeynmt.training - Example #0
2024-05-28 12:27:27,385 - DEBUG - joeynmt.training - 	Tokenized source:     ['An@@', 'ul', 'trecut', 'am', 'ar@@', 'at@@', 'at', 'aceste', 'doua', 'di@@', 'a@@', 'poz@@', 'itive', 'pentru', 'a', 'demonstr@@', 'a', 'ca', 'in@@', 'tre@@', 'ag@@', 'a', 'cal@@', 'o@@', 'ta', 'pol@@', 'ara', 'care', 'in', 'ma@@', 'rea', 'major@@', 'itate', 'a', 'ultim@@', 'ilor', '3', 'milioane', 'de', 'ani', 'a', 'fost', 'de', 'dimensi@@', 'unea', 'a', '4@@', '8', 'de', 'state', 'de', 'mar@@', 'ime', 'mic@@', 'a,', 's-a', 'mic@@', 'sor@@', 'at', 'cu', '4@@', '0%', '.']
2024-05-28 12:27:27,385 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'demonstr@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'stat@@', 'es,', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'perc@@', 'ent.']
2024-05-28 12:27:27,385 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'year', 'I', 'showed', 'these', 'two', 'di@@', 'sor@@', 'der@@', 's', 'to', 'demonstr@@', 'ate', 'that', 'the', 'pol@@', 'ar', 'pol@@', 'ar', 'that', 'the', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'was', 'the', 'size', 'of', 'the', 'last', 'three', 'million', 'years', 'was', 'a', 'small', 'size', 'of', 'the', 'size', 'of', 'a', 'small', 'small', 'stat@@', 'em@@', 'ent.', '</s>']
2024-05-28 12:27:27,385 - INFO - joeynmt.training - 	Source:     Anul trecut am aratat aceste doua diapozitive pentru a  demonstra ca intreaga calota polara  care in marea majoritate a ultimilor 3 milioane de ani  a fost de dimensiunea a 48 de state de marime mica,  s-a micsorat cu 40% .
2024-05-28 12:27:27,389 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-28 12:27:27,392 - INFO - joeynmt.training - 	Hypothesis: And the year I showed these two disorders to demonstrate that the polar polar that the most of the last three million years was the size of the last three million years was a small size of the size of a small small statement.
2024-05-28 12:27:27,395 - INFO - joeynmt.training - Example #1
2024-05-28 12:27:27,398 - DEBUG - joeynmt.training - 	Tokenized source:     ['Dar', 'aceasta', 'dimin@@', 'u@@', 'eaz@@', 'a', 'ser@@', 'io@@', 'z@@', 'itatea', 'acestei', 'probleme', 'speci@@', 'ale', 'deoarece', 'nu', 'ar@@', 'ata', 'gr@@', 'os@@', 'imea', 'gh@@', 'e@@', 'ti@@', 'i.']
2024-05-28 12:27:27,398 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice.']
2024-05-28 12:27:27,398 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'mor@@', 'n@@', 'ity', 'of', 'this', 'speci@@', 'fic', 'issu@@', 'e', 'because', 'it', "doesn't", 'show', 'the', 'gr@@', 'as@@', 's.', '</s>']
2024-05-28 12:27:27,399 - INFO - joeynmt.training - 	Source:     Dar aceasta diminueaza seriozitatea acestei probleme speciale  deoarece nu arata grosimea ghetii.
2024-05-28 12:27:27,402 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-28 12:27:27,405 - INFO - joeynmt.training - 	Hypothesis: But this mornity of this specific issue because it doesn't show the grass.
2024-05-28 12:27:27,408 - INFO - joeynmt.training - Example #2
2024-05-28 12:27:27,451 - DEBUG - joeynmt.training - 	Tokenized source:     ['C@@', 'al@@', 'o@@', 'ta', 'pol@@', 'ara', 'este,', 'in@@', 'tr-un', 'fel,', 'inim@@', 'a', 'care', 'b@@', 'ate', 'a', 'sistem@@', 'ul@@', 'ul', 'clim@@', 'atic', 'glob@@', 'al.']
2024-05-28 12:27:27,451 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system@@', '.']
2024-05-28 12:27:27,451 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 'pol@@', 'ar', 'is,', 'in', 'a', 'way,', 'the', 'heart', 'of', 'global', 'climate', 'system@@', '.', '</s>']
2024-05-28 12:27:27,452 - INFO - joeynmt.training - 	Source:     Calota polara este, intr-un fel,  inima care bate a sistemulul climatic global.
2024-05-28 12:27:27,455 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-28 12:27:27,459 - INFO - joeynmt.training - 	Hypothesis: The polar polar is, in a way, the heart of global climate system.
2024-05-28 12:27:27,462 - INFO - joeynmt.training - Example #3
2024-05-28 12:27:27,466 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ea', 'se', 'extin@@', 'de', 'iar@@', 'na', 'si', 'se', 'contr@@', 'ac@@', 'ta', 'var@@', 'a.']
2024-05-28 12:27:27,466 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'pan@@', 'ds', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer@@', '.']
2024-05-28 12:27:27,466 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'goes', 'on', 'and', 'the', 'ex@@', 'ten@@', 'ded', 'and', 'the', 'f@@', 'la@@', 'w', 'of', 'the', 'sum@@', 'mer@@', '.', '</s>']
2024-05-28 12:27:27,466 - INFO - joeynmt.training - 	Source:     Ea se extinde iarna si se contracta vara.
2024-05-28 12:27:27,470 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-28 12:27:27,473 - INFO - joeynmt.training - 	Hypothesis: It goes on and the extended and the flaw of the summer.
2024-05-28 12:27:27,477 - INFO - joeynmt.training - Example #4
2024-05-28 12:27:27,480 - DEBUG - joeynmt.training - 	Tokenized source:     ['Ur@@', 'mat@@', 'orul', 'di@@', 'a@@', 'poz@@', 'iti@@', 'v', 'pe', 'care', 'vi@@', '-l', 'voi', 'ar@@', 'ata', 'va', 'fi', 'o', 'vedere', 'rapi@@', 'da', 'asupra', 'la', 'ceea', 'ce', 's-a', 'int@@', 'ampl@@', 'at', 'in', 'ultimii', '25', 'de', 'ani.']
2024-05-28 12:27:27,480 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast@@', '-@@', 'for@@', 'ward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-28 12:27:27,480 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'sli@@', 'de', 'that', 'I', 'will', 'show', 'you', 'a', 'quick@@', 'ly', 'going', 'to', 'be', 'a', 'fast@@', '-@@', 'scale', 'of', 'the', 'last', '25', 'years.', '</s>']
2024-05-28 12:27:27,480 - INFO - joeynmt.training - 	Source:     Urmatorul diapozitiv pe care vi-l voi arata va fi  o vedere rapida asupra la ceea ce s-a intamplat in ultimii 25 de ani.
2024-05-28 12:27:27,483 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-28 12:27:27,486 - INFO - joeynmt.training - 	Hypothesis: The next slide that I will show you a quickly going to be a fast-scale of the last 25 years.
2024-05-28 12:27:30,227 - INFO - joeynmt.training - Epoch  10, Step:    39100, Batch Loss:     1.669207, Batch Acc: 0.529653, Tokens per Sec:    22953, Lr: 0.000300
2024-05-28 12:27:30,917 - INFO - joeynmt.training - Epoch  10: total training loss 6627.02
2024-05-28 12:27:30,922 - INFO - joeynmt.training - Training ended after  10 epochs.
2024-05-28 12:27:30,925 - INFO - joeynmt.training - Best validation result (greedy) at step    39000:   6.29 ppl.
2024-05-28 12:27:30,993 - INFO - joeynmt.model - Building an encoder-decoder model...
2024-05-28 12:27:31,057 - INFO - joeynmt.model - Enc-dec model built.
2024-05-28 12:27:31,126 - INFO - joeynmt.helpers - Load model from /scratch/stariq/ex_05/mt-exercise-5/models/bpe-vocab/39000.ckpt.
2024-05-28 12:27:31,143 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=5000),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=5000),
	loss_function=None)
2024-05-28 12:27:31,147 - INFO - joeynmt.prediction - Decoding on dev set...
2024-05-28 12:27:31,150 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:27:31,154 - INFO - joeynmt.prediction - Predicting 914 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:27:46,151 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 14.9814[sec], evaluation: 0.0000[sec]
2024-05-28 12:27:46,174 - INFO - joeynmt.prediction - Translations saved to: /scratch/stariq/ex_05/mt-exercise-5/models/bpe-vocab/00039000.hyps.dev.
2024-05-28 12:27:46,177 - INFO - joeynmt.prediction - Decoding on test set...
2024-05-28 12:27:46,180 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-28 12:27:46,184 - INFO - joeynmt.prediction - Predicting 1678 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-28 12:28:08,233 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 22.0239[sec], evaluation: 0.0000[sec]
2024-05-28 12:28:08,246 - INFO - joeynmt.prediction - Translations saved to: /scratch/stariq/ex_05/mt-exercise-5/models/bpe-vocab/00039000.hyps.test.
